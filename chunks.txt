--- File: cli/cli.go---

--- Chunk 1---
func Register(name string, f HookFunc) { if Registered == nil { Registered = make(map[string]HookFunc) } Registered[name] = f }
------------------

--- File: cli/config.go---

--- Chunk 1---
func init() { Register("config", Config) }
------------------

--- Chunk 2---
Function Config (start): func Config(ctx context.Context, logger *zap.Logger, cfg *config.Config, servicefactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "config", Short: "manage keploy configuration file", Example: "keploy config --generate --path /path/to/localdir", PreRunE: func(cmd *cobra.Command, _ []string) error { return cmdConfigurator.ValidateFlags(ctx, cmd) }, RunE: func(cmd *cobra.Command, _ []string) error { isGenerate, err := cmd.Flags().GetBool("generate") if err != nil { utils.LogError(logger, err, "failed to get generate flag") return err } if isGenerate { filePath := filepath.Join(cfg.Path, "keploy.yml") if !cfg.InCi && utils.CheckFileExists(filePath) { override, err := utils.AskForConfirmation(ctx, "Config file already exists. Do you want to override it?") if err != nil { utils.LogError(logger, err, "failed to ask for confirmation") return err } if !override {
------------------

--- Chunk 3---
Function Config (end): logger.Info("Skipping config file override") return nil } } svc, err := servicefactory.GetService(ctx, cmd.Name()) if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return err } var tools toolsSvc.Service var ok bool if tools, ok = svc.(toolsSvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy tools service interface") return err } if err := tools.CreateConfig(ctx, filePath, ""); err != nil { utils.LogError(logger, err, "failed to create config") return err } logger.Info("Config file generated successfully") return nil } return errors.New("only generate flag is supported in the config command") }, } if err := cmdConfigurator.AddFlags(cmd); err != nil { utils.LogError(logger, err, "failed to add flags") return nil } return cmd }
------------------

--- File: cli/contract.go---

--- Chunk 1---
func init() { Register("contract", Contract) }
------------------

--- Chunk 2---
func Contract(ctx context.Context, logger *zap.Logger, _ *config.Config, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "contract", Short: "Manage keploy contracts", } cmd.AddCommand(Generate(ctx, logger, serviceFactory, cmdConfigurator)) cmd.AddCommand(Download(ctx, logger, serviceFactory, cmdConfigurator)) cmd.AddCommand(Validate(ctx, logger, serviceFactory, cmdConfigurator)) for _, subCmd := range cmd.Commands() { err := cmdConfigurator.AddFlags(subCmd) if err != nil { utils.LogError(logger, err, "failed to add flags to command", zap.String("command", subCmd.Name())) } } return cmd }
------------------

--- Chunk 3---
Function Generate (start): func Generate(ctx context.Context, logger *zap.Logger, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "generate", Short: "Generate contract for specified services", Example: `keploy contract generate --service="email,notify"`, PreRunE: func(cmd *cobra.Command, _ []string) error { return cmdConfigurator.Validate(ctx, cmd) }, RunE: func(cmd *cobra.Command, _ []string) error { svc, err := serviceFactory.GetService(ctx, "contract") if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return nil } var contract contractSvc.Service var ok bool if contract, ok = svc.(contractSvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy contract service interface") return nil } // Extract services from the flag err = contract.Generate(ctx, true) if err != nil { utils.LogError(logger, err, "failed to generate contract") return nil
------------------

--- Chunk 4---
Function Generate (end): } return nil }, } return cmd }
------------------

--- Chunk 5---
Function Download (start): func Download(ctx context.Context, logger *zap.Logger, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "download", Short: "Download contract for specified services", Example: `keploy contract download --service="email,notify" --path /local/path`, PreRunE: func(cmd *cobra.Command, _ []string) error { return cmdConfigurator.Validate(ctx, cmd) }, RunE: func(cmd *cobra.Command, _ []string) error { svc, err := serviceFactory.GetService(ctx, "contract") if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return nil } var contract contractSvc.Service var ok bool if contract, ok = svc.(contractSvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy contract service interface") return nil } err = contract.Download(ctx, true) if err != nil { utils.LogError(logger, err, "failed to download contract") } return nil
------------------

--- Chunk 6---
Function Download (end): }, } return cmd }
------------------

--- Chunk 7---
Function Validate (start): func Validate(ctx context.Context, logger *zap.Logger, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "test", Short: "Validate contract for specified services", Example: `keploy contract test --service="email,notify" --path /local/path`, PreRunE: func(cmd *cobra.Command, _ []string) error { return cmdConfigurator.Validate(ctx, cmd) }, RunE: func(cmd *cobra.Command, _ []string) error { svc, err := serviceFactory.GetService(ctx, "contract") if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return nil } var contract contractSvc.Service var ok bool if contract, ok = svc.(contractSvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy contract service interface") return nil } err = contract.Validate(ctx) if err != nil { utils.LogError(logger, err, "failed to validate contract") } return nil
------------------

--- Chunk 8---
Function Validate (end): }, } return cmd }
------------------

--- File: cli/converse.go---

--- Chunk 1---
func init() { Register("converse", ConverseCommand) }
------------------

--- Chunk 2---
Function ConverseCommand (start): func ConverseCommand(ctx context.Context, logger *zap.Logger, cfg *config.Config, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "converse [question]", Short: "Talk to your codebase in natural language", Example: `keploy converse "how does the user authentication work?"`, Args: cobra.MinimumNArgs(1), PreRunE: func(cmd *cobra.Command, args []string) error { return cmdConfigurator.Validate(ctx, cmd) }, RunE: func(cmd *cobra.Command, args []string) error { svc, err := serviceFactory.GetService(ctx, "embed") // Converse uses the embed service if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return nil } var embedService embedSvc.Service var ok bool if embedService, ok = svc.(embedSvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy embed service interface") return nil } llmBaseUrl,
------------------

--- Chunk 3---
Function ConverseCommand (end): err := cmd.Flags().GetString("llm-base-url") if err == nil && llmBaseUrl != "" { cfg.Embed.LLMBaseURL = llmBaseUrl } question := strings.Join(args, " ") if strings.TrimSpace(question) == "" { return errors.New("the question cannot be empty") } err = embedService.Converse(ctx, question) if err != nil { utils.LogError(logger, err, "failed during conversation") return nil } return nil }, } err := cmdConfigurator.AddFlags(cmd) if err != nil { utils.LogError(logger, err, "failed to add converse flags") return nil } return cmd }
------------------

--- File: cli/embed.go---

--- Chunk 1---
func init() { Register("embed", EmbedCommand) }
------------------

--- Chunk 2---
Function EmbedCommand (start): func EmbedCommand(ctx context.Context, logger *zap.Logger, _ *config.Config, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "embed", Short: "generate embeddings for source code using AI", Example: `keploy embed --source-path="/project"`, PreRunE: func(cmd *cobra.Command, _ []string) error { return cmdConfigurator.Validate(ctx, cmd) }, RunE: func(cmd *cobra.Command, _ []string) error { svc, err := serviceFactory.GetService(ctx, cmd.Name()) if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return nil } var embedService embedSvc.Service var ok bool if embedService, ok = svc.(embedSvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy embed service interface") return nil } err = embedService.Start(ctx) if err != nil { utils.LogError(logger, err, "failed to generate embeddings") return nil
------------------

--- Chunk 3---
Function EmbedCommand (end): } return nil }, } err := cmdConfigurator.AddFlags(cmd) if err != nil { utils.LogError(logger, err, "failed to add embed flags") return nil } return cmd }
------------------

--- File: cli/examples.go---

--- Chunk 1---
func init() { Register("example", Example) }
------------------

--- Chunk 2---
func Example(_ context.Context, logger *zap.Logger, _ *config.Config, _ ServiceFactory, _ CmdConfigurator) *cobra.Command { var customSetup bool var cmd = &cobra.Command{ Use: "example", Short: "Example to record and test via keploy", RunE: func(cmd *cobra.Command, _ []string) error { disableAnsi, _ := (cmd.Flags().GetBool("disable-ansi")) provider.PrintLogo(os.Stdout, disableAnsi) customSetup, err := cmd.Flags().GetBool("customSetup") if err != nil { utils.LogError(logger, nil, "failed to read the customSetup flag") return err } if customSetup { fmt.Println(provider.Examples) return nil } fmt.Println(provider.ExampleOneClickInstall) fmt.Println(provider.WithoutexampleOneClickInstall) return nil }, } cmd.SetHelpTemplate(provider.CustomHelpTemplate) cmd.Flags().Bool("customSetup", customSetup, "Check if the user is using one click install") return cmd }
------------------

--- File: cli/export.go---

--- Chunk 1---
func init() { Register("export", Export) }
------------------

--- Chunk 2---
Function Export (start): func Export(ctx context.Context, logger *zap.Logger, _ *config.Config, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var exportCmd = &cobra.Command{ Use: "export", Short: "export Keploy tests as postman collection", Example: "keploy export", RunE: func(cmd *cobra.Command, _ []string) error { disableAnsi, _ := (cmd.Flags().GetBool("disable-ansi")) provider.PrintLogo(os.Stdout, disableAnsi) return cmd.Help() }, } var postmanCmd = &cobra.Command{ Use: "postman", Short: "export Keploy tests as Postman collection", Example: "keploy export postman", RunE: func(cmd *cobra.Command, _ []string) error { disableAnsi, _ := (cmd.Flags().GetBool("disable-ansi")) provider.PrintLogo(os.Stdout, disableAnsi) svc, err := serviceFactory.GetService(ctx, "export") if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("
------------------

--- Chunk 3---
Function Export (end): command", cmd.Name())) return nil } var tools toolsSvc.Service var ok bool if tools, ok = svc.(toolsSvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy tools service interface") return nil } err = tools.Export(ctx) // Assuming ExportPostmanCollection is a method in tools service if err != nil { utils.LogError(logger, err, "failed to export Postman collection") } return nil }, } exportCmd.AddCommand(postmanCmd) if err := cmdConfigurator.AddFlags(exportCmd); err != nil { utils.LogError(logger, err, "failed to add export cmd flags") return nil } return exportCmd }
------------------

--- File: cli/import.go---

--- Chunk 1---
func init() { Register("import", Import) }
------------------

--- Chunk 2---
Function Import (start): func Import(ctx context.Context, logger *zap.Logger, _ *config.Config, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var importCmd = &cobra.Command{ Use: "import", Short: "import postman collection to Keploy tests", Example: "keploy import", RunE: func(cmd *cobra.Command, _ []string) error { disableAnsi, _ := (cmd.Flags().GetBool("disable-ansi")) provider.PrintLogo(os.Stdout, disableAnsi) return cmd.Help() }, } var postmanCmd = &cobra.Command{ Use: "postman", Short: "import postman collection to Keploy tests", Example: "keploy import postman", RunE: func(cmd *cobra.Command, _ []string) error { disableAnsi, _ := (cmd.Flags().GetBool("disable-ansi")) provider.PrintLogo(os.Stdout, disableAnsi) path, _ := cmd.Flags().GetString("path") if path == "" { path = "output.json" } basePath, _ := cmd.Flags
------------------

--- Chunk 3---
Function Import (end): ().GetString("base-path") svc, err := serviceFactory.GetService(ctx, "import") if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return nil } var tools toolsSvc.Service var ok bool if tools, ok = svc.(toolsSvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy tools service interface") return nil } err = tools.Import(ctx, path, basePath) if err != nil { utils.LogError(logger, err, "failed to import Postman collection") } return nil }, } importCmd.AddCommand(postmanCmd) for _, subCmd := range importCmd.Commands() { err := cmdConfigurator.AddFlags(subCmd) if err != nil { utils.LogError(logger, err, "failed to add flags to command", zap.String("command", subCmd.Name())) } } return importCmd }
------------------

--- File: cli/login.go---

--- Chunk 1---
func init() { Register("login", Login) }
------------------

--- Chunk 2---
func Login(ctx context.Context, logger *zap.Logger, _ *config.Config, serviceFactory ServiceFactory, _ CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "login", Short: "login to keploy via github", Example: `keploy login`, RunE: func(cmd *cobra.Command, _ []string) error { svc, err := serviceFactory.GetService(ctx, cmd.Name()) if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return nil } var tools toolsSvc.Service var ok bool if tools, ok = svc.(toolsSvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy record service interface") return nil } tools.Login(ctx) return nil }, } return cmd }
------------------

--- File: cli/mock.go---

--- Chunk 1---
func init() { Register("mock", Mock) }
------------------

--- Chunk 2---
func Mock(ctx context.Context, logger *zap.Logger, _ *config.Config, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "mock", Short: "Managing mocks", } cmd.AddCommand(DownloadMocks(ctx, logger, serviceFactory, cmdConfigurator)) cmd.AddCommand(UploadMocks(ctx, logger, serviceFactory, cmdConfigurator)) for _, subCmd := range cmd.Commands() { err := cmdConfigurator.AddFlags(subCmd) if err != nil { utils.LogError(logger, err, "failed to add flags to command", zap.String("command", subCmd.Name())) } } return cmd }
------------------

--- Chunk 3---
Function DownloadMocks (start): func DownloadMocks(ctx context.Context, logger *zap.Logger, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "download", Short: "Download mocks from the keploy registry", Example: `keploy mock download`, PreRunE: func(cmd *cobra.Command, _ []string) error { return cmdConfigurator.Validate(ctx, cmd) }, RunE: func(cmd *cobra.Command, _ []string) error { svc, err := serviceFactory.GetService(ctx, cmd.Parent().Name()) if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Parent().Name())) return nil } var replay replaySvc.Service var ok bool if replay, ok = svc.(replaySvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy replay service interface") return nil } if err := replay.DownloadMocks(ctx); err != nil { utils.LogError(logger, err, "failed to download mocks from keploy registry") return nil } return nil
------------------

--- Chunk 4---
Function DownloadMocks (end): }, } return cmd }
------------------

--- Chunk 5---
Function UploadMocks (start): func UploadMocks(ctx context.Context, logger *zap.Logger, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "upload", Short: "Upload mocks to the keploy registry", Example: `keploy mock upload`, PreRunE: func(cmd *cobra.Command, _ []string) error { return cmdConfigurator.Validate(ctx, cmd) }, RunE: func(cmd *cobra.Command, _ []string) error { svc, err := serviceFactory.GetService(ctx, cmd.Parent().Name()) if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Parent().Name())) return nil } var replay replaySvc.Service var ok bool if replay, ok = svc.(replaySvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy replay service interface") return nil } if err := replay.UploadMocks(ctx); err != nil { utils.LogError(logger, err, "failed to upload mocks to the keploy registry") return nil } return
------------------

--- Chunk 6---
Function UploadMocks (end): nil }, } return cmd }
------------------

--- File: cli/normalise.go---

--- Chunk 1---
func init() { Register("normalize", Normalize) }
------------------

--- Chunk 2---
Function Normalize (start): func Normalize(ctx context.Context, logger *zap.Logger, _ *config.Config, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var normalizeCmd = &cobra.Command{ Use: "normalize", Short: "Normalize Keploy", Example: "keploy normalize --test-run testrun --tests test-set-1:test-case-1 test-case-2,test-set-2:test-case-1 test-case-2 ", PreRunE: func(cmd *cobra.Command, _ []string) error { return cmdConfigurator.ValidateFlags(ctx, cmd) }, RunE: func(cmd *cobra.Command, _ []string) error { svc, err := serviceFactory.GetService(ctx, cmd.Name()) if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return nil } var replay replaySvc.Service var ok bool if replay, ok = svc.(replaySvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy replay service interface") return nil } if err := replay.Normalize(ctx); err !=
------------------

--- Chunk 3---
Function Normalize (end): nil { utils.LogError(logger, err, "failed to normalize test cases") return nil } return nil }, } if err := cmdConfigurator.AddFlags(normalizeCmd); err != nil { utils.LogError(logger, err, "failed to add normalize cmd flags") return nil } return normalizeCmd }
------------------

--- File: cli/provider/cmd.go---

--- Chunk 1---
func LogExample(example string) string { return fmt.Sprintf("Example usage: %s", example) }
------------------

--- Chunk 2---
func NewCmdConfigurator(logger *zap.Logger, config *config.Config) *CmdConfigurator { return &CmdConfigurator{ logger: logger, cfg: config, } }
------------------

--- Chunk 3---
Function AddFlags (start): func (c *CmdConfigurator) AddFlags(cmd *cobra.Command) error { //sets the displayment of flag-related errors cmd.SilenceErrors = true cmd.SetFlagErrorFunc(func(_ *cobra.Command, err error) error { PrintLogo(os.Stdout, true) color.Red(fmt.Sprintf("âŒ error: %v", err)) fmt.Println() return err }) //add flags var err error cmd.Flags().SetNormalizeFunc(aliasNormalizeFunc) cmd.Flags().String("configPath", ".", "Path to the local directory where keploy configuration file is stored") switch cmd.Name() { case "upload": //for uploading mocks cmd.Flags().StringP("path", "p", ".", "Path to local keploy directory where generated mocks are stored") cmd.Flags().StringSliceP("test-sets", "t", utils.Keys(c.cfg.Test.SelectedTests), "Testsets to consider e.g. -t \"test-set-1, test-set-2\"") case "generate", "download": if cmd.Name() == "download" && cmd.Parent() != nil && cmd.Parent().Name() == "mock" { // for downloading mocks cmd.Flags().StringP
------------------

--- Chunk 4---
Function AddFlags (part 2): ("path", "p", ".", "Path to local keploy directory where generated mocks are stored") cmd.Flags().StringSliceP("test-sets", "t", utils.Keys(c.cfg.Test.SelectedTests), "Testsets to consider e.g. -t \"test-set-1, test-set-2\"") return nil } cmd.Flags().StringSliceP("services", "s", c.cfg.Contract.Services, "Specify the services for which to generate/download contracts") cmd.Flags().StringSliceP("tests", "t", c.cfg.Contract.Tests, "Specify the tests for which to generate/download contracts") cmd.Flags().StringP("path", "p", ".", "Specify the path to generate/download contracts") if cmd.Name() == "download" { // for downloading contracts cmd.Flags().String("driven", c.cfg.Contract.Driven, "Specify the path to download contracts") } case "update", "export", "import": return nil case "postman": cmd.Flags().StringP("path", "p", "", "Specify the path to the postman collection") cmd.Flags().String("base-path", c.cfg.Test.BasePath, "basePath to hit the
------------------

--- Chunk 5---
Function AddFlags (part 3): server while importing keploy tests from postman collection with no response in the collection") case "normalize": cmd.Flags().StringP("path", "p", ".", "Path to local directory where generated testcases/mocks/reports are stored") cmd.Flags().String("test-run", "", "Test Run to be normalized") cmd.Flags().String("tests", "", "Test Sets to be normalized") case "config": cmd.Flags().StringP("path", "p", ".", "Path to local directory where generated config is stored") cmd.Flags().Bool("generate", false, "Generate a new keploy configuration file") case "templatize": cmd.Flags().StringP("path", "p", ".", "Path to local directory where generated testcases/mocks are stored") cmd.Flags().StringSliceP("testsets", "t", c.cfg.Templatize.TestSets, "Testsets to run e.g. --testsets \"test-set-1, test-set-2\"") case "gen": cmd.Flags().String("source-file-path", "", "Path to the source file.") cmd.Flags().String("test-file-path", "", "Path to the input test file.") cmd.Flags().String("
------------------

--- Chunk 6---
Function AddFlags (part 4): coverage-report-path", "coverage.xml", "Path to the code coverage report file.") cmd.Flags().String("test-command", "", "The command to run tests and generate coverage report.") cmd.Flags().String("coverage-format", "cobertura", "Type of coverage report.") cmd.Flags().Int("expected-coverage", 80, "The desired coverage percentage.") cmd.Flags().Int("max-iterations", 5, "The maximum number of iterations.") cmd.Flags().String("test-dir", "", "Path to the test directory.") cmd.Flags().String("llm-base-url", "", "Base URL for the AI model.") cmd.Flags().String("model", "gpt-4o", "Model to use for the AI.") cmd.Flags().String("llm-api-version", "", "API version of the llm") cmd.Flags().String("additional-prompt", "", "Additional prompt to be used for the AI model.") cmd.Flags().String("function-under-test", "", "The specific function for which tests will be generated.") cmd.Flags().Bool("flakiness", false, "The flakiness check to run the passed tests for flakiness") err := cmd.MarkFlagRequired("
------------------

--- Chunk 7---
Function AddFlags (part 5): test-command") if err != nil { errMsg := "failed to mark testCommand as required flag" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } case "embed": cmd.Flags().String("source-path", "", "Path to the source file for embedding generation.") cmd.Flags().String("model", "text-embedding-ada-002", "Model to use for embedding generation.") cmd.Flags().String("llm-base-url", "", "Base URL for the AI model.") cmd.Flags().String("llm-api-version", "", "API version of the llm") err := cmd.MarkFlagRequired("source-path") if err != nil { errMsg := "failed to mark source-path as required flag" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } case "converse": cmd.Flags().String("llm-base-url", "", "Base URL for the AI model.") return nil case "record", "test", "rerecord": if cmd.Parent() != nil && cmd.Parent().Name() == "contract" { cmd.Flags().StringSliceP("services", "s", c
------------------

--- Chunk 8---
Function AddFlags (part 6): .cfg.Contract.Services, "Specify the services for which to generate contracts") cmd.Flags().StringP("path", "p", ".", "Specify the path to generate contracts") cmd.Flags().Bool("download", true, "Specify whether to download contracts or not") cmd.Flags().Bool("generate", true, "Specify whether to generate schemas for the current service or not") cmd.Flags().String("driven", c.cfg.Contract.Driven, "Specify the driven flag to validate contracts") return nil } cmd.Flags().StringP("path", "p", ".", "Path to local directory where generated testcases/mocks are stored") cmd.Flags().Uint32("proxy-port", c.cfg.ProxyPort, "Port used by the Keploy proxy server to intercept the outgoing dependency calls") cmd.Flags().Uint32("dns-port", c.cfg.DNSPort, "Port used by the Keploy DNS server to intercept the DNS queries") cmd.Flags().StringP("command", "c", c.cfg.Command, "Command to start the user application") cmd.Flags().String("cmd-type", c.cfg.CommandType, "Type of command to start the user application (native/docker/docker-compose)") cmd.Flags().
------------------

--- Chunk 9---
Function AddFlags (part 7): Uint64P("build-delay", "b", c.cfg.BuildDelay, "User provided time to wait docker container build") cmd.Flags().String("container-name", c.cfg.ContainerName, "Name of the application's docker container") cmd.Flags().StringP("network-name", "n", c.cfg.NetworkName, "Name of the application's docker network") cmd.Flags().UintSlice("pass-through-ports", config.GetByPassPorts(c.cfg), "Ports to bypass the proxy server and ignore the traffic") cmd.Flags().Uint64P("app-id", "a", c.cfg.AppID, "A unique name for the user's application") cmd.Flags().String("app-name", c.cfg.AppName, "Name of the user's application") cmd.Flags().Bool("generate-github-actions", c.cfg.GenerateGithubActions, "Generate Github Actions workflow file") cmd.Flags().Bool("in-ci", c.cfg.InCi, "is CI Running or not") //add rest of the uncommon flags for record, test, rerecord commands c.AddUncommonFlags(cmd) case "keploy": cmd.PersistentFlags().Bool("debug", c.cfg.Debug, "Run in debug mode") cmd
------------------

--- Chunk 10---
Function AddFlags (end): .PersistentFlags().Bool("disable-tele", c.cfg.DisableTele, "Run in telemetry mode") cmd.PersistentFlags().Bool("disable-ansi", c.cfg.DisableANSI, "Disable ANSI color in logs") err = cmd.PersistentFlags().MarkHidden("disable-tele") if err != nil { errMsg := "failed to mark telemetry as hidden flag" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } cmd.PersistentFlags().Bool("enable-testing", c.cfg.EnableTesting, "Enable testing keploy with keploy") err = cmd.PersistentFlags().MarkHidden("enable-testing") if err != nil { errMsg := "failed to mark enableTesting as hidden flag" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } default: return errors.New("unknown command name") } return nil }
------------------

--- Chunk 11---
Function AddUncommonFlags (start): func (c *CmdConfigurator) AddUncommonFlags(cmd *cobra.Command) { switch cmd.Name() { case "record": cmd.Flags().Duration("record-timer", 0, "User provided time to record its application (e.g., \"5s\" for 5 seconds, \"1m\" for 1 minute)") cmd.Flags().String("base-path", c.cfg.Record.BasePath, "Base URL to hit the server while recording the testcases") cmd.Flags().String("metadata", c.cfg.Record.Metadata, "Metadata to be stored in config.yaml as key-value pairs (e.g., \"key1=value1,key2=value2\")") case "test", "rerecord": cmd.Flags().StringSliceP("test-sets", "t", utils.Keys(c.cfg.Test.SelectedTests), "Testsets to run e.g. --testsets \"test-set-1, test-set-2\"") cmd.Flags().String("host", c.cfg.Test.Host, "Custom host to replace the actual host in the testcases") cmd.Flags().Uint32("port", c.cfg.Test.Port, "Custom port to replace the actual port in the testcases") if cmd.Name() == "test" {
------------------

--- Chunk 12---
Function AddUncommonFlags (part 2): cmd.Flags().Uint64P("delay", "d", 5, "User provided time to run its application") cmd.Flags().Uint64("api-timeout", c.cfg.Test.APITimeout, "User provided timeout for calling its application") cmd.Flags().String("mongo-password", c.cfg.Test.MongoPassword, "Authentication password for mocking MongoDB conn") cmd.Flags().String("coverage-report-path", c.cfg.Test.CoverageReportPath, "Write a go coverage profile to the file in the given directory.") cmd.Flags().VarP(&c.cfg.Test.Language, "language", "l", "Application programming language") cmd.Flags().Bool("ignore-ordering", c.cfg.Test.IgnoreOrdering, "Ignore ordering of array in response") cmd.Flags().Bool("skip-coverage", c.cfg.Test.SkipCoverage, "skip code coverage computation while running the test cases") cmd.Flags().Bool("remove-unused-mocks", c.cfg.Test.RemoveUnusedMocks, "Clear the unused mocks for the passed test-sets") cmd.Flags().Bool("fallBack-on-miss", c.cfg.Test.FallBackOnMiss, "Enable connecting to actual service if mock not found during test mode") cmd.Flags().String("jac
------------------

--- Chunk 13---
Function AddUncommonFlags (part 3): oco-agent-path", c.cfg.Test.JacocoAgentPath, "Only applicable for test coverage for Java projects. You can override the jacoco agent jar by proving its path") cmd.Flags().String("base-path", c.cfg.Test.BasePath, "Custom api basePath/origin to replace the actual basePath/origin in the testcases; App flag is ignored and app will not be started & instrumented when this is set since the application running on a different machine") cmd.Flags().Bool("update-template", c.cfg.Test.UpdateTemplate, "Update the template with the result of the testcases.") cmd.Flags().Bool("mocking", true, "enable/disable mocking for the testcases") cmd.Flags().Bool("disableMockUpload", c.cfg.Test.DisableMockUpload, "Store/Fetch mocks locally") cmd.Flags().Bool("useLocalMock", false, "Use local mocks instead of fetching from the cloud") cmd.Flags().Bool("disable-line-coverage", c.cfg.Test.DisableLineCoverage, "Disable line coverage generation.") cmd.Flags().Bool("must-pass", c.cfg.Test.MustPass, "enforces that the tests must pass, if it doesn't, remove failing testcases") cmd.Flags().Uint32Var
------------------

--- Chunk 14---
Function AddUncommonFlags (end): (&c.cfg.Test.MaxFailAttempts, "max-fail-attempts", 5, "maximum number of testset failure that can be allowed during must-pass mode") cmd.Flags().Uint32Var(&c.cfg.Test.MaxFlakyChecks, "flaky-check-retry", 1, "maximum number of retries to check for flakiness") } } }
------------------

--- Chunk 15---
Function aliasNormalizeFunc (start): func aliasNormalizeFunc(_ *pflag.FlagSet, name string) pflag.NormalizedName { var flagNameMapping = map[string]string{ "testsets": "test-sets", "delay": "delay", "apiTimeout": "api-timeout", "mongoPassword": "mongo-password", "coverageReportPath": "coverage-report-path", "language": "language", "ignoreOrdering": "ignore-ordering", "coverage": "coverage", "removeUnusedMocks": "remove-unused-mocks", "goCoverage": "go-coverage", "fallBackOnMiss": "fallBack-on-miss", "basePath": "base-path", "updateTemplate": "update-template", "mocking": "mocking", "sourceFilePath": "source-file-path", "testFilePath": "test-file-path", "testCommand": "test-command", "coverageFormat": "coverage-format", "expectedCoverage": "expected-coverage", "maxIterations": "max
------------------

--- Chunk 16---
Function aliasNormalizeFunc (part 2): -iterations", "testDir": "test-dir", "llmBaseUrl": "llm-base-url", "model": "model", "llmApiVersion": "llm-api-version", "configPath": "config-path", "path": "path", "port": "port", "proxyPort": "proxy-port", "dnsPort": "dns-port", "command": "command", "cmdType": "cmd-type", "buildDelay": "build-delay", "containerName": "container-name", "networkName": "network-name", "passThroughPorts": "pass-through-ports", "appId": "app-id", "appName": "app-name", "generateGithubActions": "generate-github-actions", "disableTele": "disable-tele", "disableANSI": "disable-ansi", "selectedTests": "selected-tests", "testReport": "test-report", "enableTesting":
------------------

--- Chunk 17---
Function aliasNormalizeFunc (end): "enable-testing", "inDocker": "in-docker", "keployContainer": "keploy-container", "keployNetwork": "keploy-network", "recordTimer": "record-timer", "urlMethods": "url-methods", "inCi": "in-ci", "sourcePath": "source-path", } if newName, ok := flagNameMapping[name]; ok { name = newName } return pflag.NormalizedName(name) }
------------------

--- Chunk 18---
Function Validate (start): func (c *CmdConfigurator) Validate(ctx context.Context, cmd *cobra.Command) error { err := isCompatible(c.logger) if err != nil { return err } defaultCfg := *c.cfg err = c.PreProcessFlags(cmd) if err != nil { c.logger.Error("failed to preprocess flags", zap.Error(err)) return err } err = c.ValidateFlags(ctx, cmd) if err != nil { if err == c.noCommandError() { utils.LogError(c.logger, nil, "missing required -c flag or appCmd in config file") if c.cfg.InDocker { c.logger.Info(`Example usage: keploy test -c "docker run -p 8080:8080 --network myNetworkName myApplicationImageName" --delay 6`) } else { c.logger.Info(LogExample(RootExamples)) } } c.logger.Error("failed to validate flags", zap.Error(err)) return err } appName, err := utils.GetLastDirectory() if err != nil { return fmt.Errorf("failed to get the last directory for appName: %v", err) } if c.cfg.AppName == "" {
------------------

--- Chunk 19---
Function Validate (end): c.logger.Info("Using the last directory name as appName : " + appName) c.cfg.AppName = appName } else if c.cfg.AppName != appName { c.logger.Warn("AppName in config (" + c.cfg.AppName + ") does not match current directory name (" + appName + "). using current directory name as appName") c.cfg.AppName = appName } if !IsConfigFileFound { err := c.CreateConfigFile(ctx, defaultCfg) if err != nil { c.logger.Error("failed to create config file", zap.Error(err)) return err } } return nil }
------------------

--- Chunk 20---
Function PreProcessFlags (start): func (c *CmdConfigurator) PreProcessFlags(cmd *cobra.Command) error { // used to bind common flags for commands like record, test. For eg: PATH, PORT, COMMAND etc. err := viper.BindPFlags(cmd.Flags()) if err != nil { errMsg := "failed to bind flags to config" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } // used to bind flags with environment variables viper.AutomaticEnv() viper.SetEnvPrefix("KEPLOY") //used to bind flags specific to the command for eg: testsets, delay, recordTimer etc. (nested flags) err = utils.BindFlagsToViper(c.logger, cmd, "") if err != nil { errMsg := "failed to bind cmd specific flags to viper" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } configPath, err := cmd.Flags().GetString("configPath") if err != nil { utils.LogError(c.logger, nil, "failed to read the config path") return err } viper.SetConfigName("keploy") viper.SetConfigType("yml") viper.AddConfigPath(configPath
------------------

--- Chunk 21---
Function PreProcessFlags (end): ) if err := viper.ReadInConfig(); err != nil { var configFileNotFoundError viper.ConfigFileNotFoundError if !errors.As(err, &configFileNotFoundError) { errMsg := "failed to read config file" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } IsConfigFileFound = false c.logger.Info("config file not found; proceeding with flags only") } if err := viper.Unmarshal(c.cfg); err != nil { errMsg := "failed to unmarshal the config" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } c.cfg.ConfigPath = configPath return nil }
------------------

--- Chunk 22---
Function ValidateFlags (start): func (c *CmdConfigurator) ValidateFlags(ctx context.Context, cmd *cobra.Command) error { disableAnsi, _ := (cmd.Flags().GetBool("disable-ansi")) PrintLogo(os.Stdout, disableAnsi) if c.cfg.Debug { logger, err := log.ChangeLogLevel(zap.DebugLevel) *c.logger = *logger if err != nil { errMsg := "failed to change log level" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } } if c.cfg.Record.BasePath != "" { port, err := pkg.ExtractPort(c.cfg.Record.BasePath) if err != nil { errMsg := "failed to extract port from base URL" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } c.cfg.Port = port c.cfg.E2E = true } if c.cfg.EnableTesting { // Add mode to logger to debug the keploy during testing logger, err := log.AddMode(cmd.Name()) *c.logger = *logger if err != nil { errMsg := "failed to add mode to logger" utils.LogError(c
------------------

--- Chunk 23---
Function ValidateFlags (part 2): .logger, err, errMsg) return errors.New(errMsg) } c.cfg.DisableTele = true } if c.cfg.DisableANSI { logger, err := log.ChangeColorEncoding() models.IsAnsiDisabled = true *c.logger = *logger if err != nil { errMsg := "failed to change color encoding" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } c.logger.Info("Color encoding is disabled") } c.logger.Debug("config has been initialised", zap.Any("for cmd", cmd.Name()), zap.Any("config", c.cfg)) switch cmd.Name() { case "upload": //for uploading mocks path, err := cmd.Flags().GetString("path") if err != nil { errMsg := "failed to get the path" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } c.cfg.Path = utils.ToAbsPath(c.logger, path) testSets, err := cmd.Flags().GetStringSlice("test-sets") if err != nil { errMsg := "failed to get the test-sets" utils.LogError(c.logger,
------------------

--- Chunk 24---
Function ValidateFlags (part 3): err, errMsg) return errors.New(errMsg) } config.SetSelectedTests(c.cfg, testSets) case "generate", "download": if cmd.Name() == "download" && cmd.Parent() != nil && cmd.Parent().Name() == "mock" { path, err := cmd.Flags().GetString("path") if err != nil { errMsg := "failed to get the path" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } c.cfg.Path = utils.ToAbsPath(c.logger, path) testSets, err := cmd.Flags().GetStringSlice("testsets") if err != nil { errMsg := "failed to get the testsets" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } config.SetSelectedTests(c.cfg, testSets) return nil } path, err := cmd.Flags().GetString("path") if err != nil { errMsg := "failed to get the path" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } c.cfg.Contract.Path = utils.ToAbsPath(c.logger, path)
------------------

--- Chunk 25---
Function ValidateFlags (part 4): services, err := cmd.Flags().GetStringSlice("services") if err != nil { errMsg := "failed to get the services" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } config.SetSelectedServices(c.cfg, services) selectedTests, err := cmd.Flags().GetStringSlice("tests") if err != nil { errMsg := "failed to get the tests" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } config.SetSelectedContractTests(c.cfg, selectedTests) if cmd.Name() == "download" { c.cfg.Contract.Driven, err = cmd.Flags().GetString("driven") if err != nil { errMsg := "failed to get the driven flag" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } } c.cfg.Path = utils.ToAbsPath(c.logger, path) case "config": path, err := cmd.Flags().GetString("path") if err != nil { errMsg := "failed to get the path" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg
------------------

--- Chunk 26---
Function ValidateFlags (part 5): ) } c.cfg.Path, err = utils.GetAbsPath(path) if err != nil { errMsg := "failed to get the absolute path" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } case "record", "test", "rerecord": if cmd.Parent() != nil && cmd.Parent().Name() == "contract" { path, err := cmd.Flags().GetString("path") if err != nil { errMsg := "failed to get the path" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } c.cfg.Contract.Path = utils.ToAbsPath(c.logger, path) services, err := cmd.Flags().GetStringSlice("services") if err != nil { errMsg := "failed to get the services" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } config.SetSelectedServices(c.cfg, services) c.cfg.Contract.Download, err = cmd.Flags().GetBool("download") if err != nil { errMsg := "failed to get the download flag" utils.LogError(c.logger, err, errMsg) return
------------------

--- Chunk 27---
Function ValidateFlags (part 6): errors.New(errMsg) } c.cfg.Contract.Generate, err = cmd.Flags().GetBool("generate") if err != nil { errMsg := "failed to get the generate flag" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } c.cfg.Contract.Driven, err = cmd.Flags().GetString("driven") if err != nil { errMsg := "failed to get the driven flag" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } c.cfg.Path = utils.ToAbsPath(c.logger, path) return nil } // set the command type c.cfg.CommandType = string(utils.FindDockerCmd(c.cfg.Command)) // empty the command if base path is provided, because no need of command even if provided if c.cfg.Test.BasePath != "" { c.cfg.CommandType = string(utils.Empty) c.cfg.Command = "" } if c.cfg.GenerateGithubActions && utils.CmdType(c.cfg.CommandType) != utils.Empty { defer utils.GenerateGithubActions(c.logger, c.cfg.Command) } if c.cfg.InDocker { c
------------------

--- Chunk 28---
Function ValidateFlags (part 7): .logger.Info("detected that Keploy is running in a docker container") if len(c.cfg.Path) > 0 { curDir, err := os.Getwd() if err != nil { errMsg := "failed to get current working directory" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } if strings.Contains(c.cfg.Path, "..") { c.cfg.Path, err = utils.GetAbsPath(filepath.Clean(c.cfg.Path)) if err != nil { return fmt.Errorf("failed to get the absolute path from relative path: %w", err) } relativePath, err := filepath.Rel(curDir, c.cfg.Path) if err != nil { errMsg := "failed to get the relative path from absolute path" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } if relativePath == ".." || strings.HasPrefix(relativePath, "../") { errMsg := "path provided is not a subdirectory of current directory. Keploy only supports recording testcases in the current directory or its subdirectories" utils.LogError(c.logger, err, errMsg, zap.String("path:", c.cfg
------------------

--- Chunk 29---
Function ValidateFlags (part 8): .Path)) return errors.New(errMsg) } } } // check if the buildDelay is less than 30 seconds if time.Duration(c.cfg.BuildDelay)*time.Second <= 30*time.Second { c.logger.Warn(fmt.Sprintf("buildDelay is set to %v, incase your docker container takes more time to build use --buildDelay to set custom delay", c.cfg.BuildDelay)) c.logger.Info(`Example usage: keploy record -c "docker-compose up --build" --buildDelay 35`) } if utils.CmdType(c.cfg.Command) == utils.DockerCompose { if c.cfg.ContainerName == "" { utils.LogError(c.logger, nil, "Couldn't find containerName") c.logger.Info(`Example usage: keploy record -c "docker run -p 8080:8080 --network myNetworkName myApplicationImageName" --delay 6`) return errors.New("missing required --container-name flag or containerName in config file") } } } err := StartInDocker(ctx, c.logger, c.cfg) if err != nil { return err } absPath,
------------------

--- Chunk 30---
Function ValidateFlags (part 9): err := utils.GetAbsPath(c.cfg.Path) if err != nil { utils.LogError(c.logger, err, "error while getting absolute path") return errors.New("failed to get the absolute path") } c.cfg.Path = absPath + "/keploy" // handle the app command if c.cfg.Command == "" { if !alreadyRunning(cmd.Name(), c.cfg.Test.BasePath) { return c.noCommandError() } } bypassPorts, err := cmd.Flags().GetUintSlice("passThroughPorts") if err != nil { errMsg := "failed to read the ports of outgoing calls to be ignored" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } config.SetByPassPorts(c.cfg, bypassPorts) if cmd.Name() == "record" { metadata, err := cmd.Flags().GetString("metadata") if err != nil { errMsg := "failed to get the metadata flag" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } c.cfg.Record.Metadata = metadata } if cmd.Name() == "test"
------------------

--- Chunk 31---
Function ValidateFlags (part 10): || cmd.Name() == "rerecord" { //check if the keploy folder exists if _, err := os.Stat(c.cfg.Path); os.IsNotExist(err) { recordCmd := models.HighlightGrayString("keploy record") errMsg := fmt.Sprintf("No test-sets found. Please record testcases using %s command", recordCmd) utils.LogError(c.logger, nil, errMsg) return errors.New(errMsg) } testSets, err := cmd.Flags().GetStringSlice("testsets") if err != nil { errMsg := "failed to get the testsets" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } config.SetSelectedTests(c.cfg, testSets) if cmd.Name() == "rerecord" { c.cfg.Test.SkipCoverage = true host, err := cmd.Flags().GetString("host") if err != nil { errMsg := "failed to get the provided host" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } c.cfg.ReRecord.Host = host port, err := cmd.Flags().GetUint32("port")
------------------

--- Chunk 32---
Function ValidateFlags (part 11): if err != nil { errMsg := "failed to get the provided port" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } c.cfg.ReRecord.Port = port return nil } // enforce that the test-sets are provided when --must-pass is set to true // to prevent accidental deletion of failed testcases in testsets which was due to application changes // and not due to flakiness or our internal issue. mustPass, err := cmd.Flags().GetBool("must-pass") if err != nil { errMsg := "failed to get the must-pass flag" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } if mustPass { c.cfg.Test.SkipCoverage = true c.cfg.Test.DisableMockUpload = true } // in mustpass mode, set the maxFlakyChecks count to 3 explicitly, // if it is not set through cmd flag. if mustPass && !cmd.Flags().Changed("flaky-check-retry") { c.cfg.Test.MaxFlakyChecks = 3
------------------

--- Chunk 33---
Function ValidateFlags (part 12): } // if the user passes a value for this field, store it if cmd.Flags().Changed("flaky-check-retry") { c.cfg.Test.MaxFlakyChecks, err = cmd.Flags().GetUint32("flaky-check-retry") if err != nil { errMsg := "failed to get the provided flaky-check-retry count" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } } // if the user passes a value for this field, store it if cmd.Flags().Changed("max-fail-attempts") { c.cfg.Test.MaxFailAttempts, err = cmd.Flags().GetUint32("max-fail-attempts") if err != nil { errMsg := "failed to get the provided max-fail-attempts count" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } } // don't allow zero maxFlakyChecks and if must pass mode is enabled, then maxFailAttempts can't be zero. if c.cfg.Test.MaxFlakyChecks == 0 { return fmt.Errorf("value for maxFlakyChecks cannot be zero")
------------------

--- Chunk 34---
Function ValidateFlags (part 13): } if mustPass && c.cfg.Test.MaxFailAttempts == 0 { return fmt.Errorf("in must pass mode, value for maxFailAttempts cannot be zero") } if mustPass && !cmd.Flags().Changed("test-sets") { return fmt.Errorf("--test-sets flag must be set to use --must-pass=true") } // skip coverage by default if command is of type docker if utils.CmdType(c.cfg.CommandType) != "native" && !cmd.Flags().Changed("skip-coverage") { c.cfg.Test.SkipCoverage = true } if c.cfg.Test.Delay <= 5 { c.logger.Warn(fmt.Sprintf("Delay is set to %d seconds, incase your app takes more time to start use --delay to set custom delay", c.cfg.Test.Delay)) if c.cfg.InDocker { c.logger.Info(`Example usage: keploy test -c "docker run -p 8080:8080 --network myNetworkName myApplicationImageName" --delay 6`) } else { c.logger.Info("Example usage: " + cmd.Example) } } } case "normalize":
------------------

--- Chunk 35---
Function ValidateFlags (part 14): c.cfg.Path = utils.ToAbsPath(c.logger, c.cfg.Path) tests, err := cmd.Flags().GetString("tests") if err != nil { errMsg := "failed to read tests to be normalized" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } err = config.SetSelectedTestsNormalize(c.cfg, tests) if err != nil { errMsg := "failed to normalize the selected tests" utils.LogError(c.logger, err, errMsg) return errors.New(errMsg) } case "templatize": c.cfg.Path = utils.ToAbsPath(c.logger, c.cfg.Path) case "gen": if os.Getenv("API_KEY") == "" { utils.LogError(c.logger, nil, "API_KEY is not set") return errors.New("API_KEY is not set") } if c.cfg.Gen.SourceFilePath == "" { //SourceFilePath is not provided, so TestDir is mandatory for batch processing if c.cfg.Gen.TestFilePath != "" { utils.LogError(c.logger, nil, "TestFilePath should not be provided when SourceFilePath is empty. Use TestDir for batch mode.") return errors.New("testFilePath
------------------

--- Chunk 36---
Function ValidateFlags (part 15): provided without sourceFilePath") } if c.cfg.Gen.TestDir == "" { utils.LogError(c.logger, nil, "SourceFilePath is not provided. TestDir is required for processing multiple files.") return errors.New("TestDir is not set") } } if c.cfg.Gen.TestCommand == "" { utils.LogError(c.logger, nil, "TestCommand is not set. Please specify the command to run tests.") return errors.New("TestCommand is not set") } case "embed": if os.Getenv("API_KEY") == "" { utils.LogError(c.logger, nil, "API_KEY is not set") return errors.New("API_KEY is not set") } if c.cfg.Embed.SourcePath == "" { cwd, err := os.Getwd() if err != nil { utils.LogError(c.logger, err, "Failed to get current working directory") return errors.New("failed to get current working directory") } c.cfg.Embed.SourcePath = cwd c.logger.Info("No source path provided, using current directory", zap.String("path", cwd)) } if _, err := os.Stat(c.cfg.Embed.SourcePath); os.IsNotExist
------------------

--- Chunk 37---
Function ValidateFlags (end): (err) { utils.LogError(c.logger, err, "Source path does not exist", zap.String("path", c.cfg.Embed.SourcePath)) return errors.New("source path does not exist") } } return nil }
------------------

--- Chunk 38---
func (c *CmdConfigurator) CreateConfigFile(ctx context.Context, defaultCfg config.Config) error { defaultCfg = c.UpdateConfigData(defaultCfg) toolSvc := tools.NewTools(c.logger, nil, nil, nil, nil, nil) configData := defaultCfg configDataBytes, err := yaml.Marshal(configData) if err != nil { utils.LogError(c.logger, err, "failed to marshal config data") return errors.New("failed to marshal config data") } err = toolSvc.CreateConfig(ctx, c.cfg.ConfigPath+"/keploy.yml", string(configDataBytes)) if err != nil { utils.LogError(c.logger, err, "failed to create config file") return errors.New("failed to create config file") } c.logger.Info("Generated config file based on the flags that are used") return nil }
------------------

--- Chunk 39---
func (c *CmdConfigurator) UpdateConfigData(defaultCfg config.Config) config.Config { defaultCfg.Command = c.cfg.Command defaultCfg.Test.Delay = c.cfg.Test.Delay defaultCfg.AppName = c.cfg.AppName defaultCfg.Test.APITimeout = c.cfg.Test.APITimeout defaultCfg.ContainerName = c.cfg.ContainerName defaultCfg.Test.IgnoreOrdering = c.cfg.Test.IgnoreOrdering defaultCfg.Test.Language = c.cfg.Test.Language defaultCfg.DisableANSI = c.cfg.DisableANSI defaultCfg.Test.SkipCoverage = c.cfg.Test.SkipCoverage defaultCfg.Test.Mocking = c.cfg.Test.Mocking defaultCfg.Test.DisableLineCoverage = c.cfg.Test.DisableLineCoverage return defaultCfg }
------------------

--- File: cli/provider/compat_linux.go---

--- Chunk 1---
func isCompatible(logger *zap.Logger) error { //check if the version of the kernel is above 5.10 for eBPF support isValid := kernel.CheckKernelVersion(5, 10, 0) if !isValid { c, err := kernel.GetKernelVersion() if err != nil { logger.Error("Error getting kernel version", zap.Error(err)) return err } errMsg := "detected linux kernel version" + c.String() + ". Keploy requires linux kernel version 5.10 or above. Please upgrade your kernel or docker version.\n" logger.Error(errMsg) return errors.New(errMsg) } // TODO check for cgroup v2 support return nil }
------------------

--- File: cli/provider/compat_others.go---

--- Chunk 1---
func isCompatible(logger *zap.Logger) error { return nil }
------------------

--- File: cli/provider/core_service_linux.go---

--- Chunk 1---
Function Get (start): func Get(ctx context.Context, cmd string, cfg *config.Config, logger *zap.Logger, tel *telemetry.Telemetry, auth service.Auth) (interface{}, error) { commonServices, err := GetCommonServices(ctx, cfg, logger) if err != nil { return nil, err } contractSvc := contract.New(logger, commonServices.YamlTestDB, commonServices.YamlMockDb, commonServices.YamlOpenAPIDb, cfg) recordSvc := record.New(logger, commonServices.YamlTestDB, commonServices.YamlMockDb, tel, commonServices.Instrumentation, commonServices.YamlTestSetDB, cfg) replaySvc := replay.NewReplayer(logger, commonServices.YamlTestDB, commonServices.YamlMockDb, commonServices.YamlReportDb, commonServices.YamlTestSetDB, tel, commonServices.Instrumentation, auth, commonServices.Storage, cfg) toolsSvc := tools.NewTools(logger, commonServices.YamlTestSetDB, commonServices.YamlTestDB, tel, auth, cfg) switch cmd { case "rerecord": return orchestrator.New(logger, recordSvc, toolsSvc, replaySvc, cfg), nil case "record": return
------------------

--- Chunk 2---
Function Get (end): recordSvc, nil case "test", "normalize", "mock": return replaySvc, nil case "templatize", "config", "update", "login", "export", "import": return toolsSvc, nil case "contract": return contractSvc, nil default: return nil, errors.New("invalid command") } }
------------------

--- Chunk 3---
Function GetCommonServices (start): func GetCommonServices(_ context.Context, c *config.Config, logger *zap.Logger) (*CommonInternalService, error) { h := hooks.NewHooks(logger, c) p := proxy.New(logger, h, c) //for keploy test bench t := tester.New(logger, h) var client docker.Client var err error if utils.IsDockerCmd(utils.CmdType(c.CommandType)) { client, err = docker.New(logger) if err != nil { utils.LogError(logger, err, "failed to create docker client") } //parse docker command only in case of docker start or docker run commands if utils.CmdType(c.CommandType) != utils.DockerCompose { cont, net, err := docker.ParseDockerCmd(c.Command, utils.CmdType(c.CommandType), client) logger.Debug("container and network parsed from command", zap.String("container", cont), zap.String("network", net), zap.String("command", c.Command)) if err != nil { utils.LogError(logger, err, "failed to parse container name from given docker command", zap.String("cmd", c.Command)) } if c.ContainerName != "" && c.ContainerName != cont { logger.Warn(fmt.Sprintf
------------------

--- Chunk 4---
Function GetCommonServices (part 2): ("given app container:(%v) is different from parsed app container:(%v), taking parsed value", c.ContainerName, cont)) } c.ContainerName = cont if c.NetworkName != "" && c.NetworkName != net { logger.Warn(fmt.Sprintf("given docker network:(%v) is different from parsed docker network:(%v), taking parsed value", c.NetworkName, net)) } c.NetworkName = net logger.Debug("Using container and network", zap.String("container", c.ContainerName), zap.String("network", c.NetworkName)) } } instrumentation := core.New(logger, h, p, t, client) testDB := testdb.New(logger, c.Path) mockDB := mockdb.New(logger, c.Path, "") openAPIdb := openapidb.New(logger, filepath.Join(c.Path, "schema")) reportDB := reportdb.New(logger, c.Path+"/reports") testSetDb := testset.New[*models.TestSet](logger, c.Path) storage := storage.New(c.APIServerURL, logger) return &CommonInternalService{ commonPlatformServices{ YamlTestDB: testDB, YamlMockDb:
------------------

--- Chunk 5---
Function GetCommonServices (end): mockDB, YamlOpenAPIDb: openAPIdb, YamlReportDb: reportDB, YamlTestSetDB: testSetDb, Storage: storage, }, instrumentation, }, nil }
------------------

--- File: cli/provider/core_service_others.go---

--- Chunk 1---
Function Get (start): func Get(ctx context.Context, cmd string, c *config.Config, logger *zap.Logger, tel *telemetry.Telemetry, auth service.Auth) (interface{}, error) { commonServices, err := GetCommonServices(ctx, c, logger) if err != nil { return nil, err } contractSvc := contract.New(logger, commonServices.YamlTestDB, commonServices.YamlMockDb, commonServices.YamlOpenAPIDb, c) replaySvc := replay.NewReplayer(logger, commonServices.YamlTestDB, commonServices.YamlMockDb, commonServices.YamlReportDb, commonServices.YamlTestSetDB, tel, commonServices.Instrumentation, auth, commonServices.Storage, c) toolsSvc := tools.NewTools(logger, commonServices.YamlTestSetDB, commonServices.YamlTestDB, tel, auth, c) if (cmd == "test" && c.Test.BasePath != "") || cmd == "normalize" || cmd == "mock" { return replaySvc, nil } if cmd == "templatize" || cmd == "config" || cmd == "update" || cmd == "login" || cmd == "export" || cmd == "import"
------------------

--- Chunk 2---
Function Get (end): { return toolsSvc, nil } if cmd == "contract" { return contractSvc, nil } return nil, errors.New("command not supported in non linux os. if you are on windows or mac, please use the dockerized version of your application") }
------------------

--- Chunk 3---
func GetCommonServices(_ context.Context, c *config.Config, logger *zap.Logger) (*CommonInternalService, error) { instrumentation := core.New(logger) testDB := testdb.New(logger, c.Path) mockDB := mockdb.New(logger, c.Path, "") openAPIdb := openapidb.New(logger, c.Path) reportDB := reportdb.New(logger, c.Path+"/reports") testSetDb := testset.New[*models.TestSet](logger, c.Path) return &CommonInternalService{ commonPlatformServices{ YamlTestDB: testDB, YamlMockDb: mockDB, YamlOpenAPIDb: openAPIdb, YamlReportDb: reportDB, YamlTestSetDB: testSetDb, }, instrumentation, }, nil }
------------------

--- File: cli/provider/docker.go---

--- Chunk 1---
func GenerateDockerEnvs(config DockerConfigStruct) string { var envs []string for key, value := range config.Envs { envs = append(envs, fmt.Sprintf("-e %s='%s'", key, value)) } return strings.Join(envs, " ") }
------------------

--- Chunk 2---
func StartInDocker(ctx context.Context, logger *zap.Logger, conf *config.Config) error { if DockerConfig.Envs == nil { DockerConfig.Envs = map[string]string{ "INSTALLATION_ID": conf.InstallationID, } } else { DockerConfig.Envs["INSTALLATION_ID"] = conf.InstallationID } //Check if app command starts with docker or docker-compose. // If it does, then we would run the docker version of keploy and // pass the command and control to it. cmdType := utils.FindDockerCmd(conf.Command) if conf.InDocker || !(utils.IsDockerCmd(cmdType)) { return nil } // pass the all the commands and args to the docker version of Keploy err := RunInDocker(ctx, logger) if err != nil { utils.LogError(logger, err, "failed to run the command in docker") return err } // gracefully exit the current process logger.Info("exiting the current process as the command is moved to docker") os.Exit(0) return nil }
------------------

--- Chunk 3---
Function RunInDocker (start): func RunInDocker(ctx context.Context, logger *zap.Logger) error { //Get the correct keploy alias. keployAlias, err := getAlias(ctx, logger) if err != nil { return err } var quotedArgs []string for _, arg := range os.Args[1:] { quotedArgs = append(quotedArgs, strconv.Quote(arg)) } client, err := docker.New(logger) if err != nil { utils.LogError(logger, err, "failed to initalise docker") return err } addKeployNetwork(ctx, logger, client) err = client.CreateVolume(ctx, "debugfs", true) if err != nil { utils.LogError(logger, err, "failed to debugfs volume") return err } var cmd *exec.Cmd // Detect the operating system if runtime.GOOS == "windows" { var args []string args = append(args, "/C") args = append(args, strings.Split(keployAlias, " ")...) args = append(args, os.Args[1:]...) // Use cmd.exe /C for Windows cmd = exec.CommandContext( ctx, "cmd
------------------

--- Chunk 4---
Function RunInDocker (end): .exe", args..., ) } else { // Use sh -c for Unix-like systems cmd = exec.CommandContext( ctx, "sh", "-c", keployAlias+" "+strings.Join(quotedArgs, " "), ) } cmd.Cancel = func() error { err := utils.SendSignal(logger, -cmd.Process.Pid, syscall.SIGINT) if err != nil { utils.LogError(logger, err, "failed to start stop docker") return err } return nil } cmd.Stdout = os.Stdout cmd.Stdin = os.Stdin cmd.Stderr = os.Stderr logger.Debug("running the following command in docker", zap.String("command", cmd.String())) err = cmd.Run() if err != nil { if ctx.Err() == context.Canceled { return ctx.Err() } utils.LogError(logger, err, "failed to start keploy in docker") return err } return nil }
------------------

--- Chunk 5---
Function getAlias (start): func getAlias(ctx context.Context, logger *zap.Logger) (string, error) { // Get the name of the operating system. osName := runtime.GOOS //TODO: configure the hardcoded port mapping img := DockerConfig.DockerImage + ":v" + utils.Version logger.Info("Starting keploy in docker with image", zap.String("image:", img)) envs := GenerateDockerEnvs(DockerConfig) if envs != "" { envs = envs + " " } var ttyFlag string if term.IsTerminal(int(os.Stdin.Fd())) { ttyFlag = " -it " } else { ttyFlag = " " } switch osName { case "linux": alias := "sudo docker container run --name keploy-v2 " + envs + "-e BINARY_TO_DOCKER=true -p 16789:16789 --privileged --pid=host" + ttyFlag + " -v " + os.Getenv("PWD") + ":" + os.Getenv("PWD") + " -w " + os.Getenv("PWD") + " -v /sys/fs/cgroup:/sys/fs/cgroup -v /sys/kernel/debug:/sys/kernel/debug -
------------------

--- Chunk 6---
Function getAlias (part 2): v /sys/fs/bpf:/sys/fs/bpf -v /var/run/docker.sock:/var/run/docker.sock -v " + os.Getenv("HOME") + "/.keploy-config:/root/.keploy-config -v " + os.Getenv("HOME") + "/.keploy:/root/.keploy --rm " + img return alias, nil case "windows": // Get the current working directory pwd, err := os.Getwd() if err != nil { utils.LogError(logger, err, "failed to get the current working directory") } dpwd := convertPathToUnixStyle(pwd) cmd := exec.CommandContext(ctx, "docker", "context", "ls", "--format", "{{.Name}}\t{{.Current}}") out, err := cmd.Output() if err != nil { utils.LogError(logger, err, "failed to get the current docker context") return "", errors.New("failed to get alias") } dockerContext := strings.Split(strings.TrimSpace(string(out)), "\n")[0] if len(dockerContext) == 0 { utils.LogError(logger, nil, "failed to get the current docker context") return "",
------------------

--- Chunk 7---
Function getAlias (part 3): errors.New("failed to get alias") } dockerContext = strings.Split(dockerContext, "\n")[0] if dockerContext == "colima" { logger.Info("Starting keploy in docker with colima context, as that is the current context.") alias := "docker container run --name keploy-v2 " + envs + "-e BINARY_TO_DOCKER=true -p 16789:16789 --privileged --pid=host" + ttyFlag + "-v " + pwd + ":" + dpwd + " -w " + dpwd + " -v /sys/fs/cgroup:/sys/fs/cgroup -v /sys/kernel/debug:/sys/kernel/debug -v /sys/fs/bpf:/sys/fs/bpf -v /var/run/docker.sock:/var/run/docker.sock -v " + os.Getenv("USERPROFILE") + "\\.keploy-config:/root/.keploy-config -v " + os.Getenv("USERPROFILE") + "\\.keploy:/root/.keploy --rm " + img return alias, nil } // if default docker context is used logger.Info("Starting keploy in docker with default context, as that is the current
------------------

--- Chunk 8---
Function getAlias (part 4): context.") alias := "docker container run --name keploy-v2 " + envs + "-e BINARY_TO_DOCKER=true -p 16789:16789 --privileged --pid=host" + ttyFlag + "-v " + pwd + ":" + dpwd + " -w " + dpwd + " -v /sys/fs/cgroup:/sys/fs/cgroup -v debugfs:/sys/kernel/debug:rw -v /sys/fs/bpf:/sys/fs/bpf -v /var/run/docker.sock:/var/run/docker.sock -v " + os.Getenv("USERPROFILE") + "\\.keploy-config:/root/.keploy-config -v " + os.Getenv("USERPROFILE") + "\\.keploy:/root/.keploy --rm " + img return alias, nil case "darwin": // Get the context and docker daemon endpoint. cmd := exec.CommandContext(ctx, "docker", "context", "inspect", "--format", "{{if .Metadata}}Name={{.Name}} {{end}}{{if .Endpoints.docker}}Endpoint={{.Endpoints.docker.Host}}{{end}}") out, err := cmd.Output() if err != nil { utils.LogError(logger, err, "failed to
------------------

--- Chunk 9---
Function getAlias (part 5): inspect the docker context") return "", errors.New("failed to get alias") } output := strings.TrimSpace(string(out)) var currentContext, dockerEndpoint string // Parse the output for current context and endpoint for _, part := range strings.Fields(output) { if strings.HasPrefix(part, "Name=") { currentContext = strings.TrimPrefix(part, "Name=") } else if strings.HasPrefix(part, "Endpoint=") { dockerEndpoint = strings.TrimPrefix(part, "Endpoint=") } } // Check if we found a current context if currentContext == "" { utils.LogError(logger, nil, "failed to find the current docker context") return "", errors.New("failed to get alias") } // Construct the alias command based on context-specific `debugfs` mount var alias string if currentContext == "colima" { // To allow docker client to connect to the colima daemon because by default it uses the default docker daemon err := os.Setenv("DOCKER_HOST", dockerEndpoint) if err != nil { utils.LogError(logger, err, "failed to set DOCKER_HOST environment variable
------------------

--- Chunk 10---
Function getAlias (part 6): for colima context") return "", errors.New("failed to get alias") } logger.Info("Starting keploy in docker with colima context, as that is the current context.") alias := "docker container run --name keploy-v2 " + envs + "-e BINARY_TO_DOCKER=true -p 16789:16789 --privileged --pid=host" + ttyFlag + "-v " + os.Getenv("PWD") + ":" + os.Getenv("PWD") + " -w " + os.Getenv("PWD") + " -v /sys/fs/cgroup:/sys/fs/cgroup -v /sys/kernel/debug:/sys/kernel/debug -v /sys/fs/bpf:/sys/fs/bpf -v /var/run/docker.sock:/var/run/docker.sock -v " + os.Getenv("HOME") + "/.keploy-config:/root/.keploy-config -v " + os.Getenv("HOME") + "/.keploy:/root/.keploy --rm " + img return alias, nil } // if default docker context is used logger.Info("Starting keploy in docker with default context, as that is the current context.") alias = "docker container run
------------------

--- Chunk 11---
Function getAlias (end): --name keploy-v2 " + envs + "-e BINARY_TO_DOCKER=true -p 16789:16789 --privileged --pid=host" + ttyFlag + "-v " + os.Getenv("PWD") + ":" + os.Getenv("PWD") + " -w " + os.Getenv("PWD") + " -v /sys/fs/cgroup:/sys/fs/cgroup -v debugfs:/sys/kernel/debug:rw -v /sys/fs/bpf:/sys/fs/bpf -v /var/run/docker.sock:/var/run/docker.sock -v " + os.Getenv("HOME") + "/.keploy-config:/root/.keploy-config -v " + os.Getenv("HOME") + "/.keploy:/root/.keploy --rm " + img return alias, nil } return "", errors.New("failed to get alias") }
------------------

--- Chunk 12---
func addKeployNetwork(ctx context.Context, logger *zap.Logger, client docker.Client) { // Check if the 'keploy-network' network exists networks, err := client.NetworkList(ctx, types.NetworkListOptions{}) if err != nil { logger.Debug("failed to list docker networks") return } for _, network := range networks { if network.Name == "keploy-network" { logger.Debug("keploy network already exists") return } } // Create the 'keploy' network if it doesn't exist _, err = client.NetworkCreate(ctx, "keploy-network", types.NetworkCreate{ CheckDuplicate: true, }) if err != nil { logger.Debug("failed to create keploy network") return } logger.Debug("keploy network created") }
------------------

--- Chunk 13---
func convertPathToUnixStyle(path string) string { // Replace backslashes with forward slashes unixPath := strings.ReplaceAll(path, "\\", "/") // Remove 'C:' if len(unixPath) > 1 && unixPath[1] == ':' { unixPath = unixPath[2:] } return unixPath }
------------------

--- File: cli/provider/service.go---

--- Chunk 1---
func NewServiceProvider(logger *zap.Logger, cfg *config.Config, auth service.Auth) *ServiceProvider { return &ServiceProvider{ logger: logger, cfg: cfg, auth: auth, } }
------------------

--- Chunk 2---
Function GetService (start): func (n *ServiceProvider) GetService(ctx context.Context, cmd string) (interface{}, error) { tel := telemetry.NewTelemetry(n.logger, telemetry.Options{ Enabled: !n.cfg.DisableTele, Version: utils.Version, GlobalMap: TeleGlobalMap, InstallationID: n.cfg.InstallationID, }) tel.Ping() switch cmd { case "embed": return embed.NewEmbedService(n.cfg, tel, n.auth, n.logger) case "gen": if n.cfg.Gen.SourceFilePath != "" { n.cfg.Embed.SourcePath = n.cfg.Gen.SourceFilePath } else if n.cfg.Gen.TestDir != "" { n.cfg.Embed.SourcePath = n.cfg.Gen.TestDir } embedService, err := embed.NewEmbedService(n.cfg, tel, n.auth, n.logger) if err != nil { n.logger.Warn("failed to create embed service, proceeding without it", zap.Error(err)) } return utgen.NewUnitTestGenerator(n.cfg, tel, n.auth, n.logger, embedService) case "record", "test", "mock", "normalize", "rerecord", "contract", "config",
------------------

--- Chunk 3---
Function GetService (end): "update", "login", "export", "import", "templatize": return Get(ctx, cmd, n.cfg, n.logger, tel, n.auth) default: return nil, errors.New("invalid command") } }
------------------

--- File: cli/provider/util.go---

--- Chunk 1---
func (c *CmdConfigurator) noCommandError() error { return errors.New("missing required -c flag or appCmd in config file") }
------------------

--- Chunk 2---
func alreadyRunning(cmd, basePath string) bool { return (cmd == "test" && basePath != "") }
------------------

--- Chunk 3---
func PrintLogo(wr io.Writer, disableANSI bool) { if os.Getenv("BINARY_TO_DOCKER") != "true" { printKeployLogo(wr, disableANSI, Logo) // print version to the same writer _, err := fmt.Fprintf(wr, "%s: %v\n\n", utils.VersionIdenitfier, utils.Version) if err != nil { log.Fatalf("Error printing version: %v", err) } } }
------------------

--- Chunk 4---
func printKeployLogo(wr io.Writer, disableANSI bool, logo string) { const reset = "\033[0m" lines := strings.Split(logo, "\n") if !disableANSI { for i, line := range lines { for j, ch := range line { color := getLogoColor(i, j) // wrapper now uses fmt.Fprint, so this will correctly print color + char + reset FprintWrapper(false, wr, color, string(ch), reset) } FprintWrapper(true, wr) // newline after each line } } else { // plain logo (no per-char coloring) FprintWrapper(false, wr, logo) FprintWrapper(true, wr) } }
------------------

--- Chunk 5---
func FprintWrapper(newLine bool, wr io.Writer, a ...interface{}) { if newLine { if _, err := fmt.Fprintln(wr); err != nil { log.Fatalf("Error printing newline: %v", err) } } if len(a) > 0 { if _, err := fmt.Fprint(wr, a...); err != nil { log.Fatalf("Error printing output: %v", err) } } }
------------------

--- Chunk 6---
func getLogoColor(i, j int) string { gradientColors := []string{ "\033[38;5;202m", // Dark Orange "\033[38;5;208m", "\033[38;5;214m", // Light Orange "\033[38;5;226m", // Light Yellow } switch { case i <= 5: return gradientColors[0] case i == 6 && j <= 42: return gradientColors[1] case i == 7 && j <= 49: return gradientColors[2] case j <= 38: return gradientColors[3] default: return gradientColors[0] } }
------------------

--- File: cli/record.go---

--- Chunk 1---
func init() { Register("record", Record) }
------------------

--- Chunk 2---
Function Record (start): func Record(ctx context.Context, logger *zap.Logger, _ *config.Config, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "record", Short: "record the keploy testcases from the API calls", Example: `keploy record -c "/path/to/user/app"`, PreRunE: func(cmd *cobra.Command, _ []string) error { return cmdConfigurator.Validate(ctx, cmd) }, RunE: func(cmd *cobra.Command, _ []string) error { svc, err := serviceFactory.GetService(ctx, cmd.Name()) if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return nil } var record recordSvc.Service var ok bool if record, ok = svc.(recordSvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy record service interface") return nil } err = record.Start(ctx, false) if err != nil { utils.LogError(logger, err, "failed to record") return nil
------------------

--- Chunk 3---
Function Record (end): } return nil }, } err := cmdConfigurator.AddFlags(cmd) if err != nil { utils.LogError(logger, err, "failed to add record flags") return nil } return cmd }
------------------

--- File: cli/rerecord.go---

--- Chunk 1---
func init() { Register("rerecord", ReRecord) }
------------------

--- Chunk 2---
Function ReRecord (start): func ReRecord(ctx context.Context, logger *zap.Logger, _ *config.Config, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "rerecord", Short: "ReRecord new keploy testcases/mocks from the existing test cases for the given testset(s)", Example: `keploy rerecord -c "user app cmd" -t "test-set-1,teset-set-3"`, PreRunE: func(cmd *cobra.Command, _ []string) error { return cmdConfigurator.Validate(ctx, cmd) }, RunE: func(cmd *cobra.Command, _ []string) error { svc, err := serviceFactory.GetService(ctx, cmd.Name()) if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return nil } var orch orchestrator.Service var ok bool if orch, ok = svc.(orchestrator.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy orchestrator service interface") return nil }
------------------

--- Chunk 3---
Function ReRecord (end): err = orch.ReRecord(ctx) if err != nil { utils.LogError(logger, err, "failed to re-record") return nil } return nil }, } err := cmdConfigurator.AddFlags(cmd) if err != nil { utils.LogError(logger, err, "failed to add rerecord flags") return nil } return cmd }
------------------

--- File: cli/root.go---

--- Chunk 1---
Function Root (start): func Root(ctx context.Context, logger *zap.Logger, svcFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { conf := config.New() var rootCmd = &cobra.Command{ Use: "keploy", Short: "Keploy CLI", Example: provider.RootExamples, Version: utils.Version, PreRun: func(cmd *cobra.Command, _ []string) { disableAnsi, _ := cmd.Flags().GetBool("disable-ansi") provider.PrintLogo(os.Stdout, disableAnsi) }, } defaultHelpFunc := rootCmd.HelpFunc() rootCmd.SetHelpFunc(func(cmd *cobra.Command, args []string) { disableAnsi, _ := cmd.Flags().GetBool("disable-ansi") provider.PrintLogo(os.Stdout, disableAnsi) // Use the default help function instead of calling the parent's HelpFunc defaultHelpFunc(cmd, args) }) rootCmd.CompletionOptions.DisableDefaultCmd = true rootCmd.SetHelpTemplate(provider.RootCustomHelpTemplate) rootCmd.SetVersionTemplate(provider.VersionTemplate) err := cmdConfigurator.AddFlags(rootCmd) if err != nil { utils.LogError
------------------

--- Chunk 2---
Function Root (end): (logger, err, "failed to set flags") return nil } for _, cmd := range Registered { c := cmd(ctx, logger, conf, svcFactory, cmdConfigurator) rootCmd.AddCommand(c) } return rootCmd }
------------------

--- File: cli/templatize.go---

--- Chunk 1---
func init() { Register("Templatize", Templatize) }
------------------

--- Chunk 2---
Function Templatize (start): func Templatize(ctx context.Context, logger *zap.Logger, _ *config.Config, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "templatize", Short: "templatize the keploy testcases for re-record", Example: `keploy templatize -t "test-set-1,teset-set-3" for particular testsets and keploy templatize for all testsets`, PreRunE: func(cmd *cobra.Command, _ []string) error { return cmdConfigurator.Validate(ctx, cmd) }, RunE: func(cmd *cobra.Command, _ []string) error { // Get the replay service. svc, err := serviceFactory.GetService(ctx, cmd.Name()) if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return nil } var tools toolsSvc.Service var ok bool if tools, ok = svc.(toolsSvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy tools service interface") return nil
------------------

--- Chunk 3---
Function Templatize (end): } if err := tools.Templatize(ctx); err != nil { utils.LogError(logger, err, "failed to templatize test cases") return nil } return nil }, } err := cmdConfigurator.AddFlags(cmd) if err != nil { utils.LogError(logger, err, "failed to add templatize flags") return nil } return cmd }
------------------

--- File: cli/test.go---

--- Chunk 1---
func init() { Register("test", Test) }
------------------

--- Chunk 2---
Function Test (start): func Test(ctx context.Context, logger *zap.Logger, _ *config.Config, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var testCmd = &cobra.Command{ Use: "test", Short: "run the recorded testcases and execute assertions", Example: `keploy test -c "/path/to/user/app" --delay 6`, PreRunE: func(cmd *cobra.Command, _ []string) error { return cmdConfigurator.Validate(ctx, cmd) }, RunE: func(cmd *cobra.Command, _ []string) error { svc, err := serviceFactory.GetService(ctx, cmd.Name()) if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return nil } var replay replaySvc.Service var ok bool if replay, ok = svc.(replaySvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy replay service interface") return nil } // defering the stop function to stop keploy in case of any error in test or in case of context cancellation
------------------

--- Chunk 3---
Function Test (end): defer func() { select { case <-ctx.Done(): break default: utils.ExecCancel() } }() err = replay.Start(ctx) if err != nil { utils.LogError(logger, err, "failed to replay") } return nil }, } err := cmdConfigurator.AddFlags(testCmd) if err != nil { utils.LogError(logger, err, "failed to add test flags") return nil } return testCmd }
------------------

--- File: cli/update.go---

--- Chunk 1---
func init() { Register("update", Update) }
------------------

--- Chunk 2---
Function Update (start): func Update(ctx context.Context, logger *zap.Logger, _ *config.Config, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var updateCmd = &cobra.Command{ Use: "update", Short: "Update Keploy ", Example: "keploy update", RunE: func(cmd *cobra.Command, _ []string) error { disableAnsi, _ := (cmd.Flags().GetBool("disable-ansi")) provider.PrintLogo(os.Stdout, disableAnsi) svc, err := serviceFactory.GetService(ctx, "update") if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return nil } var tools toolsSvc.Service var ok bool if tools, ok = svc.(toolsSvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy tools service interface") return nil } err = tools.Update(ctx) if err != nil { utils.LogError(logger, err, "failed to update") } return nil }, } if err := cmdConfigurator.Add
------------------

--- Chunk 3---
Function Update (end): Flags(updateCmd); err != nil { utils.LogError(logger, err, "failed to add update cmd flags") return nil } return updateCmd }
------------------

--- File: cli/utgen.go---

--- Chunk 1---
func init() { Register("gen", GenerateUT) }
------------------

--- Chunk 2---
Function GenerateUT (start): func GenerateUT(ctx context.Context, logger *zap.Logger, _ *config.Config, serviceFactory ServiceFactory, cmdConfigurator CmdConfigurator) *cobra.Command { var cmd = &cobra.Command{ Use: "gen", Short: "generate unit tests using AI", Example: `keploy gen"`, PreRunE: func(cmd *cobra.Command, _ []string) error { return cmdConfigurator.Validate(ctx, cmd) }, RunE: func(cmd *cobra.Command, _ []string) error { svc, err := serviceFactory.GetService(ctx, cmd.Name()) if err != nil { utils.LogError(logger, err, "failed to get service", zap.String("command", cmd.Name())) return nil } var utg utgenSvc.Service var ok bool if utg, ok = svc.(utgenSvc.Service); !ok { utils.LogError(logger, nil, "service doesn't satisfy unit test generation service interface") return nil } err = utg.Start(ctx) if err != nil { utils.LogError(logger, err, "failed to generate unit tests") return nil }
------------------

--- Chunk 3---
Function GenerateUT (end): return nil }, } err := cmdConfigurator.AddFlags(cmd) if err != nil { utils.LogError(logger, err, "failed to add unit test generation flags") return nil } return cmd }
------------------

--- File: config/config.go---

--- Chunk 1---
func (e *Language) String() string { return string(*e) }
------------------

--- Chunk 2---
func (e *Language) Set(v string) error { switch v { case "go", "java", "python", "javascript": *e = Language(v) return nil default: return errors.New(`must be one of "go", "java", "python" or "javascript"`) } }
------------------

--- Chunk 3---
func (e *Language) Type() string { return "myEnum" }
------------------

--- Chunk 4---
func SetByPassPorts(conf *Config, ports []uint) { for _, port := range ports { conf.BypassRules = append(conf.BypassRules, BypassRule{ Path: "", Host: "", Port: port, }) } }
------------------

--- Chunk 5---
func GetByPassPorts(conf *Config) []uint { var ports []uint for _, rule := range conf.BypassRules { ports = append(ports, rule.Port) } return ports }
------------------

--- Chunk 6---
func SetSelectedTests(conf *Config, testSets []string) { conf.Test.SelectedTests = make(map[string][]string) for _, testSet := range testSets { conf.Test.SelectedTests[testSet] = []string{} } }
------------------

--- Chunk 7---
func SetSelectedServices(conf *Config, services []string) { // string is "s1,s2" so i want to get s1,s2 conf.Contract.Services = services }
------------------

--- Chunk 8---
func SetSelectedContractTests(conf *Config, tests []string) { conf.Contract.Tests = tests }
------------------

--- Chunk 9---
func SetSelectedTestsNormalize(conf *Config, value string) error { testSets := strings.FieldsFunc(value, func(r rune) bool { return r == ',' || r == ' ' }) var tests []SelectedTests if len(testSets) == 0 { conf.Normalize.SelectedTests = tests return nil } for _, ts := range testSets { parts := strings.Split(ts, ":") if len(parts) != 2 { return fmt.Errorf("invalid format: %s", ts) } testCases := strings.Split(parts[1], " ") tests = append(tests, SelectedTests{ TestSet: parts[0], Tests: testCases, }) } conf.Normalize.SelectedTests = tests return nil }
------------------

--- File: config/default.go---

--- Chunk 1---
func GetDefaultConfig() string { return defaultConfig }
------------------

--- Chunk 2---
func SetDefaultConfig(cfgStr string) { defaultConfig = cfgStr }
------------------

--- Chunk 3---
func New() *Config { // merge default config with internal config mergedConfig, err := Merge(defaultConfig, InternalConfig) if err != nil { panic(err) } err = yaml3.Unmarshal([]byte(mergedConfig), config) if err != nil { panic(err) } return config }
------------------

--- Chunk 4---
func Merge(srcStr, destStr string) (string, error) { return mergeStrings(srcStr, destStr, false, yaml.MergeOptions{}) }
------------------

--- Chunk 5---
func mergeStrings(srcStr, destStr string, infer bool, mergeOptions yaml.MergeOptions) (string, error) { src, err := yaml.Parse(srcStr) if err != nil { return "", err } dest, err := yaml.Parse(destStr) if err != nil { return "", err } result, err := walk.Walker{ Sources: []*yaml.RNode{dest, src}, Visitor: merge2.Merger{}, InferAssociativeLists: infer, VisitKeysAsScalars: true, MergeOptions: mergeOptions, }.Walk() if err != nil { return "", err } return result.String() }
------------------

--- File: main.go---

--- Chunk 1---
func main() { // Uncomment the following code to enable pprof for debugging // go func() { // fmt.Println("Starting pprof server for debugging...") // err := http.ListenAndServe("localhost:6060", nil) // if err != nil { // fmt.Println("Failed to start the pprof server for debugging", err) // return // } // }() setVersion() ctx := utils.NewCtx() start(ctx) os.Exit(utils.ErrCode) }
------------------

--- Chunk 2---
func setVersion() { if version == "" { version = "2-dev" } utils.Version = version utils.VersionIdenitfier = "version" }
------------------

--- Chunk 3---
Function start (start): func start(ctx context.Context) { logger, err := log.New() if err != nil { fmt.Println("Failed to start the logger for the CLI", err) return } defer func() { if err := utils.DeleteFileIfNotExists(logger, "keploy-logs.txt"); err != nil { utils.LogError(logger, err, "Failed to delete Keploy Logs") return } if err := utils.DeleteFileIfNotExists(logger, "docker-compose-tmp.yaml"); err != nil { utils.LogError(logger, err, "Failed to delete Temporary Docker Compose") return } }() defer utils.Recover(logger) // The 'umask' command is commonly used in various operating systems to regulate the permissions of newly created files. // These 'umask' values subtract from the permissions assigned by the process, effectively lowering the permissions. // For example, if a file is created with permissions '777' and the 'umask' is '022', the resulting permissions will be '755', // reducing certain permissions for security purposes. // Setting 'umask' to '0' ensures that 'keploy' can precisely control the permissions of the files it creates
------------------

--- Chunk 4---
Function start (part 2): . // However, it's important to note that this approach may not work in scenarios involving mounted volumes, // as the 'umask' is set by the host system, and cannot be overridden by 'keploy' or individual processes. oldMask := utils.SetUmask() defer utils.RestoreUmask(oldMask) if dsn != "" { utils.SentryInit(logger, dsn) //logger = utils.ModifyToSentryLogger(ctx, logger, sentry.CurrentHub().Client(), configDb) } conf := config.New() conf.APIServerURL = apiServerURI conf.GitHubClientID = gitHubClientID userDb := userDb.New(logger, conf) conf.InstallationID, err = userDb.GetInstallationID(ctx) if err != nil { errMsg := "failed to get installation id" utils.LogError(logger, err, errMsg) os.Exit(1) } auth := auth.New(conf.APIServerURL, conf.InstallationID, logger, conf.GitHubClientID) svcProvider := provider.NewServiceProvider(logger, conf, auth) cmdConfigurator := provider.NewCmdConfigurator(logger, conf) rootCmd := cli.Root(ctx, logger,
------------------

--- Chunk 5---
Function start (end): svcProvider, cmdConfigurator) if err := rootCmd.Execute(); err != nil { if strings.HasPrefix(err.Error(), "unknown command") || strings.HasPrefix(err.Error(), "unknown shorthand") { fmt.Println("Error: ", err.Error()) fmt.Println("Run 'keploy --help' for usage.") os.Exit(1) } } }
------------------

--- File: pkg/core/app/app.go---

--- Chunk 1---
func NewApp(logger *zap.Logger, id uint64, cmd string, client docker.Client, opts Options) *App { app := &App{ logger: logger, id: id, cmd: cmd, docker: client, kind: utils.FindDockerCmd(cmd), keployContainer: "keploy-v2", container: opts.Container, containerDelay: opts.DockerDelay, containerNetwork: opts.DockerNetwork, } return app }
------------------

--- Chunk 2---
func (a *App) Setup(_ context.Context) error { if utils.IsDockerCmd(a.kind) && isDetachMode(a.logger, a.cmd, a.kind) { return fmt.Errorf("application could not be started in detached mode") } switch a.kind { case utils.DockerRun, utils.DockerStart: err := a.SetupDocker() if err != nil { return err } case utils.DockerCompose: err := a.SetupCompose() if err != nil { return err } default: // setup native binary } return nil }
------------------

--- Chunk 3---
func (a *App) KeployIPv4Addr() string { return a.keployIPv4 }
------------------

--- Chunk 4---
func (a *App) ContainerIPv4Addr() string { return <-a.containerIPv4 }
------------------

--- Chunk 5---
func (a *App) SetContainerIPv4Addr(ipAddr string) { a.containerIPv4 <- ipAddr }
------------------

--- Chunk 6---
func (a *App) SetupDocker() error { if a.kind == utils.DockerStart { running, err := a.docker.IsContainerRunning(a.container) if err != nil { return err } if running { return fmt.Errorf("docker container is already in running state") } } //injecting appNetwork to keploy. err := a.injectNetwork(a.containerNetwork) if err != nil { utils.LogError(a.logger, err, fmt.Sprintf("failed to inject network:%v to the keploy container", a.containerNetwork)) return err } return nil }
------------------

--- Chunk 7---
Function SetupCompose (start): func (a *App) SetupCompose() error { if a.container == "" { utils.LogError(a.logger, nil, "container name not found", zap.String("AppCmd", a.cmd)) return errors.New("container name not found") } a.logger.Info("keploy requires docker compose containers to be run with external network") //finding the user docker-compose file in the current directory. // TODO currently we just return the first default docker-compose file found in the current directory // we should add support for multiple docker-compose files by either parsing cmd for path // or by asking the user to provide the path // kdocker-compose.yaml file will be run instead of the user docker-compose.yaml file acc to below cases path := findComposeFile(a.cmd) if path == "" { return errors.New("can't find the docker compose file of user. Are you in the right directory? ") } a.logger.Info(fmt.Sprintf("Found docker compose file path: %s", path)) newPath := "docker-compose-tmp.yaml" compose, err := a.docker.ReadComposeFile(path) if err != nil { utils.LogError(a.logger, err, "failed to read the compose file") return err
------------------

--- Chunk 8---
Function SetupCompose (part 2): } composeChanged := false // Check if docker compose file uses relative file names for bind mounts ok := a.docker.HasRelativePath(compose) if ok { err = a.docker.ForceAbsolutePath(compose, path) if err != nil { utils.LogError(a.logger, nil, "failed to convert relative paths to absolute paths in volume mounts in docker compose file") return err } composeChanged = true } // Checking info about the network and whether its external:true info := a.docker.GetNetworkInfo(compose) if info == nil { info, err = a.docker.SetKeployNetwork(compose) if err != nil { utils.LogError(a.logger, nil, "failed to set default network in the compose file", zap.String("network", a.keployNetwork)) return err } composeChanged = true } if !info.External { err = a.docker.MakeNetworkExternal(compose) if err != nil { utils.LogError(a.logger, nil, "failed to make the network external in the compose file", zap.String("network", info.Name)) return fmt.Errorf("error while updating network to external: %v",
------------------

--- Chunk 9---
Function SetupCompose (part 3): err) } composeChanged = true } a.keployNetwork = info.Name ok, err = a.docker.NetworkExists(a.keployNetwork) if err != nil { utils.LogError(a.logger, nil, "failed to find default network", zap.String("network", a.keployNetwork)) return err } //if keploy-network doesn't exist locally then create it if !ok { err = a.docker.CreateNetwork(a.keployNetwork) if err != nil { utils.LogError(a.logger, nil, "failed to create default network", zap.String("network", a.keployNetwork)) return err } } if composeChanged { err = a.docker.WriteComposeFile(compose, newPath) if err != nil { utils.LogError(a.logger, nil, "failed to write the compose file", zap.String("path", newPath)) } a.logger.Info("Created new docker-compose for keploy internal use", zap.String("path", newPath)) //Now replace the running command to run the kdocker-compose.yaml file instead of user docker compose file. a.cmd = modifyDockerComposeCommand(a.cmd, newPath) } if a.containerNetwork ==
------------------

--- Chunk 10---
Function SetupCompose (end): "" { a.containerNetwork = a.keployNetwork } err = a.injectNetwork(a.containerNetwork) if err != nil { utils.LogError(a.logger, err, fmt.Sprintf("failed to inject network:%v to the keploy container", a.containerNetwork)) return err } return nil }
------------------

--- Chunk 11---
func (a *App) Kind(_ context.Context) utils.CmdType { return a.kind }
------------------

--- Chunk 12---
Function injectNetwork (start): func (a *App) injectNetwork(network string) error { // inject the network to the keploy container a.logger.Info(fmt.Sprintf("trying to inject network:%v to the keploy container", network)) err := a.docker.AttachNetwork(a.keployContainer, []string{network}) if err != nil { utils.LogError(a.logger, nil, "failed to inject network to the keploy container") return err } a.keployNetwork = network //sending new proxy ip to kernel, since dynamically injected new network has different ip for keploy. inspect, err := a.docker.ContainerInspect(context.Background(), a.keployContainer) if err != nil { utils.LogError(a.logger, nil, fmt.Sprintf("failed to get inspect keploy container:%v", inspect)) return err } keployNetworks := inspect.NetworkSettings.Networks //Here we considering that the application would use only one custom network. //TODO: handle for application having multiple custom networks //TODO: check the logic for correctness for n, settings := range keployNetworks { if n == network { a.keployIPv4 = settings.IPAddress a.logger.Info("Successfully injected network to the
------------------

--- Chunk 13---
Function injectNetwork (end): keploy container", zap.Any("Keploy container", a.keployContainer), zap.Any("appNetwork", network), zap.String("keploy container ip", a.keployIPv4)) return nil } //if networkName != "bridge" { // network = networkName // newProxyIpString = networkSettings.IPAddress // a.logger.Debug(fmt.Sprintf("Network Name: %s, New Proxy IP: %s\n", networkName, networkSettings.IPAddress)) //} } return fmt.Errorf("failed to find the network:%v in the keploy container", network) }
------------------

--- Chunk 14---
Function extractMeta (start): func (a *App) extractMeta(ctx context.Context, e events.Message) (bool, error) { if e.Action != "start" { return false, nil } // Fetch container details by inspecting using container ID to check if container is created info, err := a.docker.ContainerInspect(ctx, e.ID) if err != nil { a.logger.Debug("failed to inspect container by container Id", zap.Error(err)) return false, err } // Check if the container's name matches the desired name if info.Name != "/"+a.container { a.logger.Debug("ignoring container creation for unrelated container", zap.String("containerName", info.Name)) return false, nil } // Set Docker Container ID a.docker.SetContainerID(e.ID) a.logger.Debug("checking for container pid", zap.Any("containerDetails.State.Pid", info.State.Pid)) if info.State.Pid == 0 { return false, errors.New("failed to get the pid of the container") } a.logger.Debug("", zap.Any("containerDetails.State.Pid", info.State.Pid), zap.String("containerName", a.container)) inode, err := getInode(info.State.Pid)
------------------

--- Chunk 15---
Function extractMeta (end): if err != nil { return false, err } a.inodeChan <- inode a.logger.Debug("container started and successfully extracted inode", zap.Any("inode", inode)) if info.NetworkSettings == nil || info.NetworkSettings.Networks == nil { a.logger.Debug("container network settings not available", zap.Any("containerDetails.NetworkSettings", info.NetworkSettings)) return false, nil } n, ok := info.NetworkSettings.Networks[a.containerNetwork] if !ok || n == nil { a.logger.Debug("container network not found", zap.Any("containerDetails.NetworkSettings.Networks", info.NetworkSettings.Networks)) return false, fmt.Errorf("container network not found: %s", fmt.Sprintf("%+v", info.NetworkSettings.Networks)) } a.SetContainerIPv4Addr(n.IPAddress) return inode != 0 && n.IPAddress != "", nil }
------------------

--- Chunk 16---
Function getDockerMeta (start): func (a *App) getDockerMeta(ctx context.Context) <-chan error { // listen for the docker daemon events defer a.logger.Debug("exiting from goroutine of docker daemon event listener") errCh := make(chan error, 1) timer := time.NewTimer(time.Duration(a.containerDelay) * time.Second) logTicker := time.NewTicker(1 * time.Second) defer logTicker.Stop() eventFilter := filters.NewArgs( filters.KeyValuePair{Key: "type", Value: "container"}, filters.KeyValuePair{Key: "type", Value: "network"}, filters.KeyValuePair{Key: "action", Value: "create"}, filters.KeyValuePair{Key: "action", Value: "connect"}, filters.KeyValuePair{Key: "action", Value: "start"}, ) messages, errCh2 := a.docker.Events(ctx, types.EventsOptions{ Filters: eventFilter, }) g, ok := ctx.Value(models.ErrGroupKey).(*errgroup.Group) if !ok { errCh <- errors.New("failed to get the error group from the context") return errCh } g.Go(func() error { defer utils.Recover(a.logger
------------------

--- Chunk 17---
Function getDockerMeta (end): ) // closing the channels in any case when returning. defer func() { a.logger.Debug("closing err, containerIPv4 and inode channels ") close(errCh) close(a.containerIPv4) close(a.inodeChan) }() for { select { case <-timer.C: errCh <- errors.New("timeout waiting for the container to start") return nil case <-ctx.Done(): a.logger.Debug("context cancelled, stopping the listener for container creation event.") errCh <- ctx.Err() return nil case e := <-messages: done, err := a.extractMeta(ctx, e) if err != nil { errCh <- err return nil } if done { return nil } // for debugging purposes case <-logTicker.C: a.logger.Debug("still waiting for the container to start.", zap.String("containerName", a.container)) return nil case err := <-errCh2: errCh <- err return nil } } }) return errCh }
------------------

--- Chunk 18---
Function runDocker (start): func (a *App) runDocker(ctx context.Context) models.AppError { // if a.cmd is empty, it means the user wants to run the application manually, // so we don't need to run the application in a goroutine if a.cmd == "" { return models.AppError{} } g, ctx := errgroup.WithContext(ctx) ctx = context.WithValue(ctx, models.ErrGroupKey, g) dockerMetaCtx, cancel := context.WithCancel(ctx) defer func() { cancel() err := g.Wait() if err != nil { utils.LogError(a.logger, err, "failed to run dockerized app") } }() errCh := make(chan error, 1) // listen for the "create container" event in order to send the inode of the container to the kernel errCh2 := a.getDockerMeta(dockerMetaCtx) g.Go(func() error { defer utils.Recover(a.logger) defer close(errCh) err := a.run(ctx) if err.Err != nil { utils.LogError(a.logger, err.Err, "Application stopped with the error") errCh <- err.Err } return nil }) select {
------------------

--- Chunk 19---
Function runDocker (end): case err := <-errCh: if err != nil && errors.Is(err, context.Canceled) { return models.AppError{AppErrorType: models.ErrCtxCanceled, Err: ctx.Err()} } return models.AppError{AppErrorType: models.ErrInternal, Err: err} case err := <-errCh2: if err != nil && errors.Is(err, context.Canceled) { return models.AppError{AppErrorType: models.ErrCtxCanceled, Err: ctx.Err()} } return models.AppError{AppErrorType: models.ErrInternal, Err: err} case <-ctx.Done(): return models.AppError{AppErrorType: models.ErrCtxCanceled, Err: ctx.Err()} } }
------------------

--- Chunk 20---
func (a *App) Run(ctx context.Context, inodeChan chan uint64) models.AppError { a.inodeChan = inodeChan a.containerIPv4 = make(chan string, 1) if utils.IsDockerCmd(a.kind) { return a.runDocker(ctx) } return a.run(ctx) }
------------------

--- Chunk 21---
func (a *App) waitTillExit() { timeout := time.NewTimer(30 * time.Second) logTicker := time.NewTicker(1 * time.Second) defer logTicker.Stop() defer timeout.Stop() containerID := a.container for { select { case <-logTicker.C: // Inspect the container status containerJSON, err := a.docker.ContainerInspect(context.Background(), containerID) if err != nil { a.logger.Debug("failed to inspect container", zap.String("containerID", containerID), zap.Error(err)) return } a.logger.Debug("container status", zap.String("status", containerJSON.State.Status), zap.String("containerName", a.container)) // Check if container is stopped or dead if containerJSON.State.Status == "exited" || containerJSON.State.Status == "dead" { return } case <-timeout.C: a.logger.Warn("timeout waiting for the container to stop", zap.String("containerID", containerID)) return } } }
------------------

--- Chunk 22---
Function run (start): func (a *App) run(ctx context.Context) models.AppError { userCmd := a.cmd if utils.FindDockerCmd(a.cmd) == utils.DockerRun { userCmd = utils.EnsureRmBeforeName(userCmd) } // Define the function to cancel the command cmdCancel := func(cmd *exec.Cmd) func() error { return func() error { if utils.IsDockerCmd(a.kind) { a.logger.Debug("sending SIGINT to the container", zap.Any("cmd.Process.Pid", cmd.Process.Pid)) err := utils.SendSignal(a.logger, -cmd.Process.Pid, syscall.SIGINT) return err } return utils.InterruptProcessTree(a.logger, cmd.Process.Pid, syscall.SIGINT) } } var err error cmdErr := utils.ExecuteCommand(ctx, a.logger, userCmd, cmdCancel, 25*time.Second) if cmdErr.Err != nil { switch cmdErr.Type { case utils.Init: return models.AppError{AppErrorType: models.ErrCommandError, Err: cmdErr.Err} case utils.Runtime: err = cmdErr.Err } } if utils.IsDockerCmd(a
------------------

--- Chunk 23---
Function run (end): .kind) { a.waitTillExit() } select { case <-ctx.Done(): a.logger.Debug("context cancelled, error while waiting for the app to exit", zap.Error(ctx.Err())) return models.AppError{AppErrorType: models.ErrCtxCanceled, Err: ctx.Err()} default: if a.Mode == models.MODE_RECORD && a.EnableTesting { a.logger.Info("waiting for some time before returning the error to allow recording of test cases when testing keploy with itself") time.Sleep(3 * time.Second) a.logger.Debug("test binary stopped", zap.Error(err)) return models.AppError{AppErrorType: models.ErrTestBinStopped, Err: context.Canceled} } if err != nil { return models.AppError{AppErrorType: models.ErrUnExpected, Err: err} } return models.AppError{AppErrorType: models.ErrAppStopped, Err: nil} } }
------------------

--- File: pkg/core/app/util.go---

--- Chunk 1---
func findComposeFile(cmd string) string { cmdArgs := strings.Fields(cmd) for i := 0; i < len(cmdArgs); i++ { if cmdArgs[i] == "-f" && i+1 < len(cmdArgs) { return cmdArgs[i+1] } } filenames := []string{"docker-compose.yml", "docker-compose.yaml", "compose.yml", "compose.yaml"} for _, filename := range filenames { if _, err := os.Stat(filename); !os.IsNotExist(err) { return filename } } return "" }
------------------

--- Chunk 2---
func modifyDockerComposeCommand(appCmd, newComposeFile string) string { // Ensure newComposeFile starts with ./ if !strings.HasPrefix(newComposeFile, "./") { newComposeFile = "./" + newComposeFile } // Define a regular expression pattern to match "-f <file>" pattern := `(-f\s+("[^"]+"|'[^']+'|\S+))` re := regexp.MustCompile(pattern) // Check if the "-f <file>" pattern exists in the appCmd if re.MatchString(appCmd) { // Replace it with the new Compose file return re.ReplaceAllString(appCmd, fmt.Sprintf("-f %s", newComposeFile)) } // If the pattern doesn't exist, inject the new Compose file right after "docker-compose" or "docker compose" upIdx := strings.Index(appCmd, " up") if upIdx != -1 { return fmt.Sprintf("%s -f %s%s", appCmd[:upIdx], newComposeFile, appCmd[upIdx:]) } return fmt.Sprintf("%s -f %s", appCmd, newComposeFile) }
------------------

--- Chunk 3---
func getInode(pid int) (uint64, error) { path := filepath.Join("/proc", strconv.Itoa(pid), "ns", "pid") f, err := os.Stat(path) if err != nil { return 0, err } // Dev := (f.Sys().(*syscall.Stat_t)).Dev i := (f.Sys().(*syscall.Stat_t)).Ino if i == 0 { return 0, fmt.Errorf("failed to get the inode of the process") } return i, nil }
------------------

--- Chunk 4---
func isDetachMode(logger *zap.Logger, command string, kind utils.CmdType) bool { args := strings.Fields(command) if kind == utils.DockerStart { flags := []string{"-a", "--attach", "-i", "--interactive"} for _, arg := range args { if slices.Contains(flags, arg) { return false } } utils.LogError(logger, fmt.Errorf("docker start require --attach/-a or --interactive/-i flag"), "failed to start command") return true } for _, arg := range args { if arg == "-d" || arg == "--detach" { utils.LogError(logger, fmt.Errorf("detach mode is not allowed in Keploy command"), "failed to start command") return true } } return false }
------------------

--- File: pkg/core/core_linux.go---

--- Chunk 1---
func New(logger *zap.Logger, hook Hooks, proxy Proxy, tester Tester, client docker.Client) *Core { return &Core{ logger: logger, Hooks: hook, Proxy: proxy, Tester: tester, dockerClient: client, } }
------------------

--- Chunk 2---
func (c *Core) Setup(ctx context.Context, cmd string, opts models.SetupOptions) (uint64, error) { // create a new app and store it in the map id := uint64(c.id.Next()) a := app.NewApp(c.logger, id, cmd, c.dockerClient, app.Options{ DockerNetwork: opts.DockerNetwork, Container: opts.Container, DockerDelay: opts.DockerDelay, }) c.apps.Store(id, a) err := a.Setup(ctx) if err != nil { utils.LogError(c.logger, err, "failed to setup app") return 0, err } return id, nil }
------------------

--- Chunk 3---
func (c *Core) getApp(id uint64) (*app.App, error) { a, ok := c.apps.Load(id) if !ok { return nil, fmt.Errorf("app with id:%v not found", id) } // type assertion on the app h, ok := a.(*app.App) if !ok { return nil, fmt.Errorf("failed to type assert app with id:%v", id) } return h, nil }
------------------

--- Chunk 4---
Function Hook (start): func (c *Core) Hook(ctx context.Context, id uint64, opts models.HookOptions) error { hookErr := errors.New("failed to hook into the app") a, err := c.getApp(id) if err != nil { utils.LogError(c.logger, err, "failed to get app") return hookErr } isDocker := utils.IsDockerCmd(a.Kind(ctx)) select { case <-ctx.Done(): return ctx.Err() default: } g, ok := ctx.Value(models.ErrGroupKey).(*errgroup.Group) if !ok { return errors.New("failed to get the error group from the context") } // Create a new error group for the hooks (Always required) hookErrGrp, _ := errgroup.WithContext(ctx) hookCtx := context.WithoutCancel(ctx) //so that main context doesn't cancel the hookCtx to control the lifecycle of the hooks hookCtx, hookCtxCancel := context.WithCancel(hookCtx) hookCtx = context.WithValue(hookCtx, models.ErrGroupKey, hookErrGrp) // create a new error group for the proxy proxyErrGrp, _ := errgroup.WithContext(ctx)
------------------

--- Chunk 5---
Function Hook (part 2): proxyCtx := context.WithoutCancel(ctx) //so that main context doesn't cancel the proxyCtx to control the lifecycle of the proxy proxyCtx, proxyCtxCancel := context.WithCancel(proxyCtx) proxyCtx = context.WithValue(proxyCtx, models.ErrGroupKey, proxyErrGrp) g.Go(func() error { <-ctx.Done() proxyCtxCancel() err = proxyErrGrp.Wait() if err != nil { utils.LogError(c.logger, err, "failed to stop the proxy") } hookCtxCancel() err := hookErrGrp.Wait() if err != nil { utils.LogError(c.logger, err, "failed to unload the hooks") } //deleting in order to free the memory in case of rerecord. otherwise different app id will be created for the same app. c.apps.Delete(id) c.id = utils.AutoInc{} return nil }) // Load hooks err = c.Load(hookCtx, id, HookCfg{ AppID: id, Pid: 0, IsDocker: isDocker, KeployIPV4: a.K
------------------

--- Chunk 6---
Function Hook (part 3): eployIPv4Addr(), Mode: opts.Mode, Rules: opts.Rules, E2E: opts.E2E, Port: opts.Port, }) if err != nil { utils.LogError(c.logger, err, "failed to load hooks") return hookErr } if c.proxyStarted { c.logger.Debug("Proxy already started") // return nil } select { case <-ctx.Done(): return ctx.Err() default: } // TODO: Hooks can be loaded multiple times but proxy should be started only once // if there is another containerized app, then we need to pass new (ip:port) of proxy to the eBPF // as the network namespace is different for each container and so is the keploy/proxy IP to communicate with the app. // start proxy err = c.StartProxy(proxyCtx, ProxyOptions{ DNSIPv4Addr: a.KeployIPv4Addr(), //DnsIPv6Addr: "" }) if err != nil { utils.LogError(c.logger, err, "failed to start proxy") return hookErr } c.proxyStarted = true
------------------

--- Chunk 7---
Function Hook (end): // For keploy test bench if opts.EnableTesting { // enable testing in the app a.EnableTesting = true a.Mode = opts.Mode // Setting up the test bench err := c.Tester.Setup(ctx, models.TestingOptions{Mode: opts.Mode}) if err != nil { utils.LogError(c.logger, err, "error while setting up the test bench environment") return errors.New("failed to setup the test bench") } } return nil }
------------------

--- Chunk 8---
Function Run (start): func (c *Core) Run(ctx context.Context, id uint64, _ models.RunOptions) models.AppError { a, err := c.getApp(id) if err != nil { utils.LogError(c.logger, err, "failed to get app") return models.AppError{AppErrorType: models.ErrInternal, Err: err} } runAppErrGrp, runAppCtx := errgroup.WithContext(ctx) inodeErrCh := make(chan error, 1) appErrCh := make(chan models.AppError, 1) inodeChan := make(chan uint64, 1) //send inode to the hook defer func() { err := runAppErrGrp.Wait() defer close(inodeErrCh) if err != nil { utils.LogError(c.logger, err, "failed to stop the app") } }() runAppErrGrp.Go(func() error { defer utils.Recover(c.logger) if a.Kind(ctx) == utils.Native { close(inodeChan) // since we are not using inode in native mode return nil } select { case inode := <-inodeChan: err := c.SendDockerAppInfo(id, structs.DockerAppInfo{App
------------------

--- Chunk 9---
Function Run (end): Inode: inode, ClientID: id}) if err != nil { utils.LogError(c.logger, err, "") inodeErrCh <- errors.New("failed to send inode to the kernel") } case <-ctx.Done(): return nil } return nil }) runAppErrGrp.Go(func() error { defer utils.Recover(c.logger) defer close(appErrCh) appErr := a.Run(runAppCtx, inodeChan) if appErr.Err != nil { utils.LogError(c.logger, appErr.Err, "error while running the app") appErrCh <- appErr } return nil }) select { case <-runAppCtx.Done(): return models.AppError{AppErrorType: models.ErrCtxCanceled, Err: nil} case appErr := <-appErrCh: return appErr case inodeErr := <-inodeErrCh: return models.AppError{AppErrorType: models.ErrInternal, Err: inodeErr} } }
------------------

--- Chunk 10---
func (c *Core) GetContainerIP(_ context.Context, id uint64) (string, error) { a, err := c.getApp(id) if err != nil { utils.LogError(c.logger, err, "failed to get app") return "", err } ip := a.ContainerIPv4Addr() c.logger.Debug("ip address of the target app container", zap.Any("ip", ip)) if ip == "" { return "", fmt.Errorf("failed to get the IP address of the app container. Try increasing --delay (in seconds)") } return ip, nil }
------------------

--- File: pkg/core/core_others.go---

--- Chunk 1---
func New(logger *zap.Logger) *Core { return &Core{ logger: logger, } }
------------------

--- Chunk 2---
func (c *Core) Setup(ctx context.Context, cmd string, opts models.SetupOptions) (uint64, error) { return 0, errUnsupported }
------------------

--- Chunk 3---
func (c *Core) Hook(ctx context.Context, id uint64, opts models.HookOptions) error { return errUnsupported }
------------------

--- Chunk 4---
func (c *Core) MockOutgoing(ctx context.Context, id uint64, opts models.OutgoingOptions) error { return errUnsupported }
------------------

--- Chunk 5---
func (c *Core) SetMocks(ctx context.Context, id uint64, filtered []*models.Mock, unFiltered []*models.Mock) error { return errUnsupported }
------------------

--- Chunk 6---
func (c *Core) GetConsumedMocks(ctx context.Context, id uint64) ([]models.MockState, error) { return nil, errUnsupported }
------------------

--- Chunk 7---
func (c *Core) Run(ctx context.Context, id uint64, _ models.RunOptions) models.AppError { return models.AppError{ Err: errUnsupported, } }
------------------

--- Chunk 8---
func (c *Core) GetContainerIP(_ context.Context, id uint64) (string, error) { return "", errUnsupported }
------------------

--- File: pkg/core/hooks/bpf_arm64_bpfel.go---

--- Chunk 1---
func loadBpf() (*ebpf.CollectionSpec, error) { reader := bytes.NewReader(_BpfBytes) spec, err := ebpf.LoadCollectionSpecFromReader(reader) if err != nil { return nil, fmt.Errorf("can't load bpf: %w", err) } return spec, err }
------------------

--- Chunk 2---
func loadBpfObjects(obj interface{}, opts *ebpf.CollectionOptions) error { spec, err := loadBpf() if err != nil { return err } return spec.LoadAndAssign(obj, opts) }
------------------

--- Chunk 3---
func (o *bpfObjects) Close() error { return _BpfClose( &o.bpfPrograms, &o.bpfMaps, ) }
------------------

--- Chunk 4---
func (m *bpfMaps) Close() error { return _BpfClose( m.ActiveAcceptArgsMap, m.ActiveCloseArgsMap, m.ActiveReadArgsMap, m.ActiveWriteArgsMap, m.AppChildKernelPidMap, m.ConnInfoMap, m.CurrentSockMap, m.DestInfoMap, m.DockerAppRegistrationMap, m.E2eInfoMap, m.KeployAgentKernelPidMap, m.KeployAgentRegistrationMap, m.KeployClientKernelPidMap, m.KeployClientRegistrationMap, m.OutgoingConnCheckMap, m.OutgoingConnectArgsMap, m.RedirectProxyMap, m.SocketCloseEvents, m.SocketDataEventBufferHeap, m.SocketDataEvents, m.SocketOpenEvents, m.TaskStructMap, ) }
------------------

--- Chunk 5---
Function Close (start): func (p *bpfPrograms) Close() error { return _BpfClose( p.K_connect4, p.K_connect6, p.K_getpeername4, p.K_getpeername6, p.SyscallProbeEntryAccept, p.SyscallProbeEntryAccept4, p.SyscallProbeEntryClose, p.SyscallProbeEntryRead, p.SyscallProbeEntryReadv, p.SyscallProbeEntryRecvfrom, p.SyscallProbeEntrySendto, p.SyscallProbeEntryTcpV4Connect, p.SyscallProbeEntryTcpV4PreConnect, p.SyscallProbeEntryTcpV6Connect, p.SyscallProbeEntryTcpV6PreConnect, p.SyscallProbeEntryUdpPreConnect, p.SyscallProbeEntryWrite, p.SyscallProbeEntryWritev, p.SyscallProbeRetAccept, p.SyscallProbeRetAccept4, p.SyscallProbeRetClose, p.SyscallProbeRetConnect, p.SyscallProbeRetRead, p.SyscallProbeRetReadv, p.SyscallProbeRetRecvfrom, p.SyscallProbeRetSendto, p.SyscallProbeRetTcp
------------------

--- Chunk 6---
Function Close (end): V4Connect, p.SyscallProbeRetTcpV6Connect, p.SyscallProbeRetWrite, p.SyscallProbeRetWritev, p.SyscallProbeEntryConnect, p.SyscallProbeEntrySocket, ) }
------------------

--- Chunk 7---
func _BpfClose(closers ...io.Closer) error { for _, closer := range closers { if err := closer.Close(); err != nil { return err } } return nil }
------------------

--- File: pkg/core/hooks/bpf_x86_bpfel.go---

--- Chunk 1---
func loadBpf() (*ebpf.CollectionSpec, error) { reader := bytes.NewReader(_BpfBytes) spec, err := ebpf.LoadCollectionSpecFromReader(reader) if err != nil { return nil, fmt.Errorf("can't load bpf: %w", err) } return spec, err }
------------------

--- Chunk 2---
func loadBpfObjects(obj interface{}, opts *ebpf.CollectionOptions) error { spec, err := loadBpf() if err != nil { return err } return spec.LoadAndAssign(obj, opts) }
------------------

--- Chunk 3---
func (o *bpfObjects) Close() error { return _BpfClose( &o.bpfPrograms, &o.bpfMaps, ) }
------------------

--- Chunk 4---
func (m *bpfMaps) Close() error { return _BpfClose( m.ActiveAcceptArgsMap, m.ActiveCloseArgsMap, m.ActiveReadArgsMap, m.ActiveWriteArgsMap, m.AppChildKernelPidMap, m.ConnInfoMap, m.CurrentSockMap, m.DestInfoMap, m.DockerAppRegistrationMap, m.E2eInfoMap, m.KeployAgentKernelPidMap, m.KeployAgentRegistrationMap, m.KeployClientKernelPidMap, m.KeployClientRegistrationMap, m.OutgoingConnCheckMap, m.OutgoingConnectArgsMap, m.RedirectProxyMap, m.SocketCloseEvents, m.SocketDataEventBufferHeap, m.SocketDataEvents, m.SocketOpenEvents, m.TaskStructMap, ) }
------------------

--- Chunk 5---
Function Close (start): func (p *bpfPrograms) Close() error { return _BpfClose( p.K_connect4, p.K_connect6, p.K_getpeername4, p.K_getpeername6, p.SyscallProbeEntryAccept, p.SyscallProbeEntryAccept4, p.SyscallProbeEntryClose, p.SyscallProbeEntryRead, p.SyscallProbeEntryReadv, p.SyscallProbeEntryRecvfrom, p.SyscallProbeEntrySendto, p.SyscallProbeEntryTcpV4Connect, p.SyscallProbeEntryTcpV4PreConnect, p.SyscallProbeEntryTcpV6Connect, p.SyscallProbeEntryTcpV6PreConnect, p.SyscallProbeEntryUdpPreConnect, p.SyscallProbeEntryWrite, p.SyscallProbeEntryWritev, p.SyscallProbeRetAccept, p.SyscallProbeRetAccept4, p.SyscallProbeRetClose, p.SyscallProbeRetConnect, p.SyscallProbeRetRead, p.SyscallProbeRetReadv, p.SyscallProbeRetRecvfrom, p.SyscallProbeRetSendto, p.SyscallProbeRetTcp
------------------

--- Chunk 6---
Function Close (end): V4Connect, p.SyscallProbeRetTcpV6Connect, p.SyscallProbeRetWrite, p.SyscallProbeRetWritev, p.SyscallProbeEntryConnect, p.SyscallProbeEntrySocket, ) }
------------------

--- Chunk 7---
func _BpfClose(closers ...io.Closer) error { for _, closer := range closers { if err := closer.Close(); err != nil { return err } } return nil }
------------------

--- File: pkg/core/hooks/conn/conn.go---

--- Chunk 1---
func (t TrafficDirectionEnum) String() string { names := [...]string{ "EgressTraffic", "IngressTraffic", } switch t { case EgressTraffic: return names[0] case IngressTraffic: return names[1] default: return "Invalid TrafficDirectionEnum value" } }
------------------

--- File: pkg/core/hooks/conn/factory.go---

--- Chunk 1---
func NewFactory(inactivityThreshold time.Duration, logger *zap.Logger, opts models.IncomingOptions) *Factory { return &Factory{ connections: make(map[ID]*Tracker), mutex: &sync.RWMutex{}, inactivityThreshold: inactivityThreshold, logger: logger, incomingOpts: opts, } }
------------------

--- Chunk 2---
Function ProcessActiveTrackers (start): func (factory *Factory) ProcessActiveTrackers(ctx context.Context, t chan *models.TestCase, opts models.IncomingOptions) { factory.mutex.Lock() defer factory.mutex.Unlock() var trackersToDelete []ID for connID, tracker := range factory.connections { select { case <-ctx.Done(): return default: // For gRPC (HTTP2) requests, handle them natively if tracker.protocol == HTTP2 { // Get the completed stream stream := tracker.getHTTP2CompletedStream() if stream != nil { // Skip HTTP gateway requests if pkg.IsGRPCGatewayRequest(stream) { factory.logger.Debug("Skipping internal gRPC request proxied by gRPC-gateway", zap.Any("stream", stream)) continue } factory.logger.Debug("Processing HTTP2/gRPC request", zap.Any("connection_id", connID)) // Get timestamps from the stream CaptureGRPC(ctx, factory.logger, t, stream) } } else { // Handle HTTP1 requests ok, requestBuf, responseBuf, reqTimestampTest, resTimestampTest := tracker.isHTTP1Complete() if
------------------

--- Chunk 3---
Function ProcessActiveTrackers (part 2): ok { if len(requestBuf) == 0 || len(responseBuf) == 0 { factory.logger.Warn("failed processing a request due to invalid request or response", zap.Any("Request Size", len(requestBuf)), zap.Any("Response Size", len(responseBuf))) continue } parsedHTTPReq, err := pkg.ParseHTTPRequest(requestBuf) if err != nil { utils.LogError(factory.logger, err, "failed to parse the http request from byte array", zap.Any("requestBuf", requestBuf)) continue } parsedHTTPRes, err := pkg.ParseHTTPResponse(responseBuf, parsedHTTPReq) if err != nil { utils.LogError(factory.logger, err, "failed to parse the http response from byte array", zap.Any("responseBuf", responseBuf)) continue } basePath := factory.incomingOpts.BasePath parsedBaseURL, err := url.Parse(basePath) if err != nil { factory.logger.Error("Error parsing base path: %s\n", zap.Error(err)) } baseHost := parsedBaseURL.Host if len(strings.TrimSpace(basePath)) == 0 { factory.logger.Debug("Base
------------------

--- Chunk 4---
Function ProcessActiveTrackers (part 3): path is not set, proceeding with request capture", zap.String("basePath", basePath), ) Capture(ctx, factory.logger, t, parsedHTTPReq, parsedHTTPRes, reqTimestampTest, resTimestampTest, opts) continue } if parsedHTTPReq.Host != baseHost { factory.logger.Info("Skipping capture due to host mismatch", zap.String("expectedHost", baseHost), zap.String("actualHost", parsedHTTPReq.Host), ) continue } if !strings.HasPrefix(parsedHTTPReq.URL.Path, parsedBaseURL.Path) { factory.logger.Info("Skipping capture due to base path mismatch", zap.String("expectedBasePath", parsedBaseURL.Path), zap.String("actualPath", parsedHTTPReq.URL.Path), ) continue } factory.logger.Info("Capturing test case for request matching base path", zap.String("host", parsedHTTPReq.Host), zap.String("path", parsedHTTPReq.URL.Path), ) Capture(ctx, factory.logger, t, parsedHTTPReq, parsedHTTPRes, reqTimestampTest, resTimestampTest, opts) } else
------------------

--- Chunk 5---
Function ProcessActiveTrackers (end): if tracker.IsInactive(factory.inactivityThreshold) { trackersToDelete = append(trackersToDelete, connID) } } } } // Delete all the processed trackers. if len(trackersToDelete) > 0 { factory.logger.Debug("Deleting inactive trackers", zap.Int("count", len(trackersToDelete))) } for _, key := range trackersToDelete { delete(factory.connections, key) } }
------------------

--- Chunk 6---
func (factory *Factory) GetOrCreate(connectionID ID) *Tracker { factory.mutex.Lock() defer factory.mutex.Unlock() tracker, ok := factory.connections[connectionID] if !ok { tracker = NewTracker(connectionID, factory.logger) factory.connections[connectionID] = tracker } return tracker }
------------------

--- File: pkg/core/hooks/conn/socket.go---

--- Chunk 1---
Function ListenSocket (start): func ListenSocket(ctx context.Context, l *zap.Logger, openMap, dataMap, closeMap *ebpf.Map, opts models.IncomingOptions) (<-chan *models.TestCase, error) { t := make(chan *models.TestCase, 500) err := initRealTimeOffset() if err != nil { utils.LogError(l, err, "failed to initialize real time offset") return nil, errors.New("failed to start socket listeners") } c := NewFactory(time.Minute, l, opts) g, ok := ctx.Value(models.ErrGroupKey).(*errgroup.Group) if !ok { return nil, errors.New("failed to get the error group from the context") } g.Go(func() error { defer utils.Recover(l) go func() { defer utils.Recover(l) for { select { case <-ctx.Done(): return default: // TODO refactor this to directly consume the events from the maps c.ProcessActiveTrackers(ctx, t, opts) time.Sleep(100 * time.Millisecond) } } }() <-ctx.Done() close(t) return nil }) err = open(ctx, c, l
------------------

--- Chunk 2---
Function ListenSocket (end): , openMap) if err != nil { utils.LogError(l, err, "failed to start open socket listener") return nil, errors.New("failed to start socket listeners") } err = data(ctx, c, l, dataMap) if err != nil { utils.LogError(l, err, "failed to start data socket listener") return nil, errors.New("failed to start socket listeners") } err = exit(ctx, c, l, closeMap) if err != nil { utils.LogError(l, err, "failed to start close socket listener") return nil, errors.New("failed to start socket listeners") } return t, err }
------------------

--- Chunk 3---
Function open (start): func open(ctx context.Context, c *Factory, l *zap.Logger, m *ebpf.Map) error { r, err := perf.NewReader(m, os.Getpagesize()) if err != nil { utils.LogError(l, nil, "failed to create perf event reader of socketOpenEvent") return err } g, ok := ctx.Value(models.ErrGroupKey).(*errgroup.Group) if !ok { return errors.New("failed to get the error group from the context") } g.Go(func() error { defer utils.Recover(l) go func() { defer utils.Recover(l) for { rec, err := r.Read() if err != nil { if errors.Is(err, perf.ErrClosed) { return } utils.LogError(l, err, "failed to read from perf socketOpenEvent reader") continue } if rec.LostSamples != 0 { l.Debug("Unable to add samples to the socketOpenEvent array due to its full capacity", zap.Any("samples", rec.LostSamples)) continue } data := rec.RawSample var event SocketOpenEvent if err := binary.Read(bytes.NewReader(data), binary
------------------

--- Chunk 4---
Function open (end): .LittleEndian, &event); err != nil { utils.LogError(l, err, "failed to decode the received data from perf socketOpenEvent reader") continue } event.TimestampNano += getRealTimeOffset() c.GetOrCreate(event.ConnID).AddOpenEvent(event) } }() <-ctx.Done() // Check for context cancellation err := r.Close() if err != nil { utils.LogError(l, err, "failed to close perf socketOpenEvent reader") } return nil }) return nil }
------------------

--- Chunk 5---
Function data (start): func data(ctx context.Context, c *Factory, l *zap.Logger, m *ebpf.Map) error { r, err := ringbuf.NewReader(m) if err != nil { utils.LogError(l, nil, "failed to create ring buffer of socketDataEvent") return err } g, ok := ctx.Value(models.ErrGroupKey).(*errgroup.Group) if !ok { return errors.New("failed to get the error group from the context") } g.Go(func() error { defer utils.Recover(l) go func() { defer utils.Recover(l) for { record, err := r.Read() if err != nil { if !errors.Is(err, ringbuf.ErrClosed) { utils.LogError(l, err, "failed to receive signal from ringbuf socketDataEvent reader") return } continue } bin := record.RawSample if len(bin) < eventAttributesSize { l.Debug(fmt.Sprintf("Buffer's for SocketDataEvent is smaller (%d) than the minimum required (%d)", len(bin), eventAttributesSize)) continue } else if len(bin) > EventBodyMaxSize+eventAttributesSize {
------------------

--- Chunk 6---
Function data (end): l.Debug(fmt.Sprintf("Buffer's for SocketDataEvent is bigger (%d) than the maximum for the struct (%d)", len(bin), EventBodyMaxSize+eventAttributesSize)) continue } var event SocketDataEvent if err := binary.Read(bytes.NewReader(bin), binary.LittleEndian, &event); err != nil { utils.LogError(l, err, "failed to decode the received data from ringbuf socketDataEvent reader") continue } event.TimestampNano += getRealTimeOffset() if event.Direction == IngressTraffic { event.EntryTimestampNano += getRealTimeOffset() l.Debug(fmt.Sprintf("Request EntryTimestamp :%v\n", convertUnixNanoToTime(event.EntryTimestampNano))) } c.GetOrCreate(event.ConnID).AddDataEvent(event) } }() <-ctx.Done() // Check for context cancellation err := r.Close() if err != nil { utils.LogError(l, err, "failed to close ringbuf socketDataEvent reader") } return nil }) return nil }
------------------

--- Chunk 7---
Function exit (start): func exit(ctx context.Context, c *Factory, l *zap.Logger, m *ebpf.Map) error { r, err := perf.NewReader(m, os.Getpagesize()) if err != nil { utils.LogError(l, nil, "failed to create perf event reader of socketCloseEvent") return err } g, ok := ctx.Value(models.ErrGroupKey).(*errgroup.Group) if !ok { return errors.New("failed to get the error group from the context") } g.Go(func() error { defer utils.Recover(l) go func() { defer utils.Recover(l) for { rec, err := r.Read() if err != nil { if errors.Is(err, perf.ErrClosed) { return } utils.LogError(l, err, "failed to read from perf socketCloseEvent reader") continue } if rec.LostSamples != 0 { l.Debug(fmt.Sprintf("perf socketCloseEvent array full, dropped %d samples", rec.LostSamples)) continue } data := rec.RawSample var event SocketCloseEvent if err := binary.Read(bytes.NewReader(data), binary.LittleEndian, &event);
------------------

--- Chunk 8---
Function exit (end): err != nil { l.Debug(fmt.Sprintf("Failed to decode received data: %+v", err)) continue } event.TimestampNano += getRealTimeOffset() c.GetOrCreate(event.ConnID).AddCloseEvent(event) } }() <-ctx.Done() // Check for context cancellation err := r.Close() if err != nil { utils.LogError(l, err, "failed to close perf socketCloseEvent reader") return err } return nil }) return nil }
------------------

--- Chunk 9---
func initRealTimeOffset() error { var monotonicTime, realTime unix.Timespec if err := unix.ClockGettime(unix.CLOCK_MONOTONIC, &monotonicTime); err != nil { return fmt.Errorf("failed getting monotonic clock due to: %v", err) } if err := unix.ClockGettime(unix.CLOCK_REALTIME, &realTime); err != nil { return fmt.Errorf("failed getting real clock time due to: %v", err) } realTimeOffset = uint64(time.Second)*(uint64(realTime.Sec)-uint64(monotonicTime.Sec)) + uint64(realTime.Nsec) - uint64(monotonicTime.Nsec) // realTimeCopy := time.Unix(int64(realTimeOffset/1e9), int64(realTimeOffset%1e9)) // log.Debug(fmt.Sprintf("%s real time offset is: %v", Emoji, realTimeCopy)) return nil }
------------------

--- Chunk 10---
func getRealTimeOffset() uint64 { return realTimeOffset }
------------------

--- File: pkg/core/hooks/conn/tracker.go---

--- Chunk 1---
func NewTracker(connID ID, logger *zap.Logger) *Tracker { t := &Tracker{ connID: connID, logger: logger, mutex: sync.RWMutex{}, // Initialize HTTP/1 fields req: []byte{}, resp: []byte{}, kernelRespSizes: []uint64{}, kernelReqSizes: []uint64{}, userRespSizes: []uint64{}, userReqSizes: []uint64{}, userResps: [][]byte{}, userReqs: [][]byte{}, firstRequest: true, isNewRequest: true, buffer: make([]byte, 0, pkg.DefaultMaxFrameSize), } // Always start with HTTP/1 t.protocol = HTTP1 t.protocolDetected = false // Allow protocol detection return t }
------------------

--- Chunk 2---
func (conn *Tracker) ToBytes() ([]byte, []byte) { conn.mutex.RLock() defer conn.mutex.RUnlock() return conn.req, conn.resp }
------------------

--- Chunk 3---
func (conn *Tracker) IsInactive(duration time.Duration) bool { conn.mutex.RLock() defer conn.mutex.RUnlock() return uint64(time.Now().UnixNano())-conn.lastActivityTimestamp > uint64(duration.Nanoseconds()) }
------------------

--- Chunk 4---
func (conn *Tracker) incRecordTestCount() { atomic.AddInt32(&conn.recTestCounter, 1) }
------------------

--- Chunk 5---
func (conn *Tracker) decRecordTestCount() { atomic.AddInt32(&conn.recTestCounter, -1) }
------------------

--- Chunk 6---
func (conn *Tracker) reset() { conn.firstRequest = true conn.lastChunkWasResp = false conn.lastChunkWasReq = false conn.reqSize = 0 conn.respSize = 0 conn.resp = []byte{} conn.req = []byte{} }
------------------

--- Chunk 7---
func (conn *Tracker) verifyRequestData(expectedRecvBytes, actualRecvBytes uint64) bool { return expectedRecvBytes == actualRecvBytes }
------------------

--- Chunk 8---
func (conn *Tracker) verifyResponseData(expectedSentBytes, actualSentBytes uint64) bool { return expectedSentBytes == actualSentBytes }
------------------

--- Chunk 9---
func (conn *Tracker) AddOpenEvent(event SocketOpenEvent) { conn.mutex.Lock() defer conn.mutex.Unlock() conn.UpdateTimestamps() conn.addr = event.Addr if conn.openTimestamp != 0 && conn.openTimestamp != event.TimestampNano { conn.logger.Debug("Changed open info timestamp due to new request", zap.Any("from", conn.openTimestamp), zap.Any("to", event.TimestampNano)) } conn.openTimestamp = event.TimestampNano }
------------------

--- Chunk 10---
Function AddDataEvent (start): func (conn *Tracker) AddDataEvent(event SocketDataEvent) { conn.mutex.Lock() defer conn.mutex.Unlock() conn.UpdateTimestamps() data := event.Msg[:event.MsgSize] // Check for HTTP/2 preface if we haven't detected protocol yet if !conn.protocolDetected { conn.logger.Debug("Connection check") if isHTTP2Request(data) { // Create HTTP/2 parser and stream manager conn.protocol = HTTP2 conn.streamMgr = pkg.NewStreamManager(conn.logger) conn.protocolDetected = true conn.logger.Debug("Detected HTTP/2 protocol (preface received)") // If there's more data after preface, process it as HTTP/2 if len(data) > 24 { // Create new event with remaining data newEvent := event copy(newEvent.Msg[:], data[24:]) newEvent.MsgSize = uint32(len(data) - 24) conn.handleHTTP2Data(newEvent) } return } // If we see a valid HTTP/1 request line, mark as HTTP/1 if isHTTP1Request(data) { conn.protocolDetected
------------------

--- Chunk 11---
Function AddDataEvent (end): = true conn.logger.Debug("Detected HTTP/1.x protocol") } } // Process based on current protocol switch conn.protocol { case HTTP2: conn.handleHTTP2Data(event) default: conn.handleHTTP1Data(event) } }
------------------

--- Chunk 12---
func isHTTP1Request(data []byte) bool { // Convert to string for easier checking s := string(data) // Check for common HTTP methods return strings.HasPrefix(s, "GET ") || strings.HasPrefix(s, "POST ") || strings.HasPrefix(s, "PUT ") || strings.HasPrefix(s, "DELETE ") || strings.HasPrefix(s, "HEAD ") || strings.HasPrefix(s, "OPTIONS ") || strings.HasPrefix(s, "PATCH ") }
------------------

--- Chunk 13---
func isHTTP2Request(data []byte) bool { return len(data) >= 24 && bytes.Equal(data[:24], []byte(pkg.HTTP2Preface)) }
------------------

--- Chunk 14---
func (conn *Tracker) AddCloseEvent(event SocketCloseEvent) { conn.mutex.Lock() defer conn.mutex.Unlock() conn.UpdateTimestamps() if conn.closeTimestamp != 0 && conn.closeTimestamp != event.TimestampNano { conn.logger.Debug("Changed close info timestamp due to new request", zap.Any("from", conn.closeTimestamp), zap.Any("to", event.TimestampNano)) } conn.closeTimestamp = event.TimestampNano conn.logger.Debug(fmt.Sprintf("Got a close event from eBPF on connectionId:%v\n", event.ConnID)) }
------------------

--- Chunk 15---
func (conn *Tracker) UpdateTimestamps() { conn.lastActivityTimestamp = uint64(time.Now().UnixNano()) }
------------------

--- Chunk 16---
func ConvertUnixNanoToTime(unixNano uint64) time.Time { // Unix time is the number of seconds since January 1, 1970 UTC, // so convert nanoseconds to seconds for time.Unix function seconds := int64(unixNano / uint64(time.Second)) nanoRemainder := int64(unixNano % uint64(time.Second)) return time.Unix(seconds, nanoRemainder) }
------------------

--- Chunk 17---
func (conn *Tracker) getHTTP2CompletedStream() *pkg.HTTP2Stream { conn.mutex.RLock() defer conn.mutex.RUnlock() if conn.streamMgr == nil { return nil } streams := conn.streamMgr.GetCompleteStreams() if len(streams) == 0 { return nil } // Return the first completed stream stream := streams[0] // Cleanup the processed stream conn.streamMgr.CleanupStream(stream.ID) return stream }
------------------

--- Chunk 18---
Function isHTTP1Complete (start): func (conn *Tracker) isHTTP1Complete() (bool, []byte, []byte, time.Time, time.Time) { conn.mutex.RLock() defer conn.mutex.RUnlock() // Get the current timestamp in nanoseconds. currentTimestamp := uint64(time.Now().UnixNano()) // Calculate the time elapsed since the last activity in nanoseconds. elapsedTime := currentTimestamp - conn.lastActivityTimestamp //Caveat: Added a timeout of 4 seconds, after this duration we assume that the last response data event would have come. // This will ensure that we capture the requests responses where Connection:keep-alive is enabled. recordTraffic := false requestBuf, responseBuf := []byte{}, []byte{} var reqTimestamps, respTimestamp time.Time //if recTestCounter > 0, it means that we have num(recTestCounter) of request and response present in the queues to record. if conn.recTestCounter > 0 { if (len(conn.userReqSizes) > 0 && len(conn.kernelReqSizes) > 0) && (len(conn.userRespSizes) > 0 && len(conn.kernelRespSizes) > 0) { validReq, validRes := false
------------------

--- Chunk 19---
Function isHTTP1Complete (part 2): , false expectedRecvBytes := conn.userReqSizes[0] actualRecvBytes := conn.kernelReqSizes[0] if expectedRecvBytes == 0 || actualRecvBytes == 0 { conn.logger.Warn("Malformed request", zap.Any("ExpectedRecvBytes", expectedRecvBytes), zap.Any("ActualRecvBytes", actualRecvBytes)) } //popping out the current request info conn.userReqSizes = conn.userReqSizes[1:] conn.kernelReqSizes = conn.kernelReqSizes[1:] if conn.verifyRequestData(expectedRecvBytes, actualRecvBytes) { validReq = true } else { conn.logger.Debug("Malformed request", zap.Any("ExpectedRecvBytes", expectedRecvBytes), zap.Any("ActualRecvBytes", actualRecvBytes)) } expectedSentBytes := conn.userRespSizes[0] actualSentBytes := conn.kernelRespSizes[0] //popping out the current response info conn.userRespSizes = conn.userRespSizes[1:] conn.kernelRespSizes = conn.kernelRespSizes[1:] if conn.verifyResponseData(expectedSentBytes, actualSentBytes) { validRes = true
------------------

--- Chunk 20---
Function isHTTP1Complete (part 3): respTimestamp = time.Now() } else { conn.logger.Debug("Malformed response", zap.Any("ExpectedSentBytes", expectedSentBytes), zap.Any("ActualSentBytes", actualSentBytes)) } if len(conn.userReqs) > 0 && len(conn.userResps) > 0 { //validated request, response requestBuf = conn.userReqs[0] responseBuf = conn.userResps[0] //popping out the current request & response data conn.userReqs = conn.userReqs[1:] conn.userResps = conn.userResps[1:] } else { conn.logger.Debug("no data buffer for request or response", zap.Any("Length of RecvBufQueue", len(conn.userReqs)), zap.Any("Length of SentBufQueue", len(conn.userResps))) } recordTraffic = validReq && validRes } else { utils.LogError(conn.logger, nil, "malformed request or response") recordTraffic = false } conn.logger.Debug(fmt.Sprintf("recording traffic after verifying the request and reponse data:%v", recordTraffic)) // // decrease the
------------------

--- Chunk 21---
Function isHTTP1Complete (part 4): recTestCounter conn.decRecordTestCount() conn.logger.Debug("verified recording", zap.Any("recordTraffic", recordTraffic)) } else if conn.lastChunkWasResp && elapsedTime >= uint64(time.Second*2) { // Check if 2 seconds has passed since the last activity. conn.logger.Debug("might be last request on the conn") if len(conn.userReqSizes) > 0 && len(conn.kernelReqSizes) > 0 { expectedRecvBytes := conn.userReqSizes[0] actualRecvBytes := conn.kernelReqSizes[0] //popping out the current request info conn.userReqSizes = conn.userReqSizes[1:] conn.kernelReqSizes = conn.kernelReqSizes[1:] if expectedRecvBytes == 0 || actualRecvBytes == 0 { conn.logger.Warn("Malformed request", zap.Any("ExpectedRecvBytes", expectedRecvBytes), zap.Any("ActualRecvBytes", actualRecvBytes)) } if conn.verifyRequestData(expectedRecvBytes, actualRecvBytes) { recordTraffic = true } else { conn.logger.Debug("Malformed request", zap.Any("ExpectedRecvBytes", expectedRecvBytes), zap.Any("
------------------

--- Chunk 22---
Function isHTTP1Complete (part 5): ActualRecvBytes", actualRecvBytes)) recordTraffic = false } if len(conn.userReqs) > 0 { //validated request, invalided response requestBuf = conn.userReqs[0] //popping out the current request data conn.userReqs = conn.userReqs[1:] responseBuf = conn.resp respTimestamp = time.Now() } else { conn.logger.Debug("no data buffer for request", zap.Any("Length of RecvBufQueue", len(conn.userReqs))) recordTraffic = false } } else { utils.LogError(conn.logger, nil, "malformed request") recordTraffic = false } conn.logger.Debug(fmt.Sprintf("recording traffic after verifying the request data (but not response data):%v", recordTraffic)) //treat immediate next request as first request (2 seconds after last activity) // this can be to avoid potential corruption in the conn conn.reset() conn.logger.Debug("unverified recording", zap.Any("recordTraffic", recordTraffic)) } // Checking if record traffic is recorded and request & response timestamp is captured or not. if
------------------

--- Chunk 23---
Function isHTTP1Complete (end): recordTraffic { if len(conn.reqTimestamps) > 0 { // Get the timestamp of current request reqTimestamps = conn.reqTimestamps[0] // Pop the timestamp of current request conn.reqTimestamps = conn.reqTimestamps[1:] } else { conn.logger.Debug("no request timestamp found") if len(requestBuf) > 0 { reqLine := strings.Split(string(requestBuf), "\n") if models.GetMode() == models.MODE_RECORD && len(reqLine) > 0 && reqLine[0] != "" { conn.logger.Warn(fmt.Sprintf("failed to capture request timestamp for a request. Please record it again if important:%v", reqLine[0])) } } recordTraffic = false } conn.logger.Debug(fmt.Sprintf("TestRequestTimestamp:%v || TestResponseTimestamp:%v", reqTimestamps, respTimestamp)) } return recordTraffic, requestBuf, responseBuf, reqTimestamps, respTimestamp }
------------------

--- Chunk 24---
Function handleHTTP2Data (start): func (conn *Tracker) handleHTTP2Data(event SocketDataEvent) { // Convert fixed-size array to slice data := event.Msg[:event.MsgSize] // Append new data to the buffer conn.buffer = append(conn.buffer, data...) // Process as many complete frames as possible for len(conn.buffer) >= 9 { // Minimum frame size frame, consumed, err := pkg.ExtractHTTP2Frame(conn.buffer) if err != nil { if strings.Contains(err.Error(), "incomplete frame") { conn.logger.Debug("Incomplete frame", zap.Any("error", err)) // Not enough data yet, wait for more break } // Real error, log and remove the problematic data conn.logger.Error("Failed to extract HTTP/2 frame", zap.Error(err)) if len(conn.buffer) > 9 { // Try to recover by removing the first byte and trying again next time conn.buffer = conn.buffer[1:] } else { conn.buffer = nil } break } // Handle the frame if err := conn.streamMgr.HandleFrame(frame, event.Direction == EgressTraffic, Convert
------------------

--- Chunk 25---
Function handleHTTP2Data (end): UnixNanoToTime(event.TimestampNano)); err != nil { conn.logger.Error("Failed to handle HTTP/2 frame", zap.Error(err)) } // Remove processed data from buffer conn.buffer = conn.buffer[consumed:] } // Store timestamps for requests if event.Direction == IngressTraffic { conn.reqTimestamps = append(conn.reqTimestamps, ConvertUnixNanoToTime(event.EntryTimestampNano)) } }
------------------

--- Chunk 26---
Function handleHTTP1Data (start): func (conn *Tracker) handleHTTP1Data(event SocketDataEvent) { conn.logger.Debug(fmt.Sprintf("Got a data event from eBPF, Direction:%v || current Event Size:%v || ConnectionID:%v\n", event.Direction, event.MsgSize, event.ConnID)) switch event.Direction { case EgressTraffic: // Capturing the timestamp of response as the response just started to come. // This is to ensure that we capture the response timestamp for the first chunk of the response. if !conn.isNewRequest { conn.isNewRequest = true } // Assign the size of the message to the variable msgLength msgLength := event.MsgSize // If the size of the message exceeds the maximum allowed size, // set msgLength to the maximum allowed size instead if event.MsgSize > EventBodyMaxSize { msgLength = EventBodyMaxSize } // Append the message (up to msgLength) to the conn's sent buffer conn.resp = append(conn.resp, event.Msg[:msgLength]...) conn.respSize += uint64(event.MsgSize) //Handling multiple request on same conn to support conn:
------------------

--- Chunk 27---
Function handleHTTP1Data (part 2): keep-alive if conn.firstRequest || conn.lastChunkWasReq { conn.userReqSizes = append(conn.userReqSizes, conn.reqSize) conn.reqSize = 0 conn.userReqs = append(conn.userReqs, conn.req) conn.req = []byte{} conn.lastChunkWasReq = false conn.lastChunkWasResp = true conn.kernelReqSizes = append(conn.kernelReqSizes, uint64(event.ValidateReadBytes)) conn.firstRequest = false } case IngressTraffic: conn.logger.Debug("isNewRequest", zap.Any("isNewRequest", conn.isNewRequest), zap.Any("connID", conn.connID)) // Capturing the timestamp of request as the request just started to come. if conn.isNewRequest { conn.reqTimestamps = append(conn.reqTimestamps, ConvertUnixNanoToTime(event.EntryTimestampNano)) conn.isNewRequest = false } // Assign the size of the message to the variable msgLength msgLength := event.MsgSize // If the size of the message exceeds the maximum allowed size, // set msgLength to the maximum allowed size instead if event.MsgSize
------------------

--- Chunk 28---
Function handleHTTP1Data (end): > EventBodyMaxSize { msgLength = EventBodyMaxSize } // Append the message (up to msgLength) to the conn's receive buffer conn.req = append(conn.req, event.Msg[:msgLength]...) conn.reqSize += uint64(event.MsgSize) //Handling multiple request on same conn to support conn:keep-alive if conn.lastChunkWasResp { // conn.userRespSizes is the total numner of bytes received in the user side // consumer for the last response. conn.userRespSizes = append(conn.userRespSizes, conn.respSize) conn.respSize = 0 conn.userResps = append(conn.userResps, conn.resp) conn.resp = []byte{} conn.lastChunkWasReq = true conn.lastChunkWasResp = false conn.kernelRespSizes = append(conn.kernelRespSizes, uint64(event.ValidateWrittenBytes)) //Record a test case for the current request/ conn.incRecordTestCount() } default: } }
------------------

--- File: pkg/core/hooks/conn/util.go---

--- Chunk 1---
func convertUnixNanoToTime(unixNano uint64) time.Time { // Unix time is the number of seconds since January 1, 1970 UTC, // so convert nanoseconds to seconds for time.Unix function seconds := int64(unixNano / uint64(time.Second)) nanoRemainder := int64(unixNano % uint64(time.Second)) return time.Unix(seconds, nanoRemainder) }
------------------

--- Chunk 2---
Function isFiltered (start): func isFiltered(logger *zap.Logger, req *http.Request, opts models.IncomingOptions) bool { dstPort := 0 var err error if p := req.URL.Port(); p != "" { dstPort, err = strconv.Atoi(p) if err != nil { utils.LogError(logger, err, "failed to obtain destination port from request") return false } } var passThrough bool type cond struct { eligible bool match bool } for _, filter := range opts.Filters { // 1. bypass rule bypassEligible := !(filter.BypassRule.Host == "" && filter.BypassRule.Path == "" && filter.BypassRule.Port == 0) opts := models.OutgoingOptions{Rules: []config.BypassRule{filter.BypassRule}} byPassMatch := utils.IsPassThrough(logger, req, uint(dstPort), opts) // 2. URL-method rule urlMethodEligible := len(filter.URLMethods) > 0 urlMethodMatch := false if urlMethodEligible { for _, m := range filter.URLMethods { if m == req.Method
------------------

--- Chunk 3---
Function isFiltered (part 2): { urlMethodMatch = true break } } } // 3. header rule headerEligible := len(filter.Headers) > 0 headerMatch := false if headerEligible { for key, vals := range filter.Headers { rx, err := regexp.Compile(vals) if err != nil { utils.LogError(logger, err, "bad header regex") continue } for _, v := range req.Header.Values(key) { if rx.MatchString(v) { headerMatch = true break } } if headerMatch { break } } } conds := []cond{ {bypassEligible, byPassMatch}, {urlMethodEligible, urlMethodMatch}, {headerEligible, headerMatch}, } switch filter.MatchType { case config.AND: pass := true seen := false for _, c := range conds { if !c.eligible { continue } // ignore ineligible ones seen = true
------------------

--- Chunk 4---
Function isFiltered (end): if !c.match { pass = false break } } if seen && pass { passThrough = true return passThrough } case config.OR: fallthrough default: for _, c := range conds { if c.eligible && c.match { passThrough = true return passThrough } } } } return passThrough }
------------------

--- Chunk 5---
Function Capture (start): func Capture(_ context.Context, logger *zap.Logger, t chan *models.TestCase, req *http.Request, resp *http.Response, reqTimeTest time.Time, resTimeTest time.Time, opts models.IncomingOptions) { reqBody, err := io.ReadAll(req.Body) if err != nil { utils.LogError(logger, err, "failed to read the http request body") return } defer func() { err := resp.Body.Close() if err != nil { utils.LogError(logger, err, "failed to close the http response body") } }() respBody, err := io.ReadAll(resp.Body) if err != nil { utils.LogError(logger, err, "failed to read the http response body") return } if isFiltered(logger, req, opts) { logger.Debug("The request is a filtered request") return } var formData []models.FormData if contentType := req.Header.Get("Content-Type"); strings.HasPrefix(contentType, "multipart/form-data") { parts := strings.Split(contentType, ";") if len(parts) > 1 { req.Header.Set("Content-Type", strings.TrimSpace(parts[0])) } formData = extractFormData(logger, req
------------------

--- Chunk 6---
Function Capture (part 2): Body, contentType) reqBody = []byte{} } else if contentType := req.Header.Get("Content-Type"); contentType == "application/x-www-form-urlencoded" { decodedBody, err := url.QueryUnescape(string(reqBody)) if err != nil { utils.LogError(logger, err, "failed to decode the url-encoded request body") return } reqBody = []byte(decodedBody) } t <- &models.TestCase{ Version: models.GetVersion(), Name: pkg.ToYamlHTTPHeader(req.Header)["Keploy-Test-Name"], Kind: models.HTTP, Created: time.Now().Unix(), HTTPReq: models.HTTPReq{ Method: models.Method(req.Method), ProtoMajor: req.ProtoMajor, ProtoMinor: req.ProtoMinor, // URL: req.URL.String(), // URL: fmt.Sprintf("%s://%s%s?%s", req.URL.Scheme, req.Host, req.URL.Path, req.URL.RawQuery), URL: fmt.Sprintf("http://%s%s", req.Host, req.URL.RequestURI()), // URL: string(b), Form: formData, Header
------------------

--- Chunk 7---
Function Capture (end): : pkg.ToYamlHTTPHeader(req.Header), Body: string(reqBody), URLParams: pkg.URLParams(req), Timestamp: reqTimeTest, }, HTTPResp: models.HTTPResp{ StatusCode: resp.StatusCode, Header: pkg.ToYamlHTTPHeader(resp.Header), Body: string(respBody), Timestamp: resTimeTest, StatusMessage: http.StatusText(resp.StatusCode), }, Noise: map[string][]string{}, // Mocks: mocks, } }
------------------

--- Chunk 8---
func extractFormData(logger *zap.Logger, body []byte, contentType string) []models.FormData { boundary := "" if strings.HasPrefix(contentType, "multipart/form-data") { parts := strings.Split(contentType, "boundary=") if len(parts) > 1 { boundary = strings.TrimSpace(parts[1]) } else { utils.LogError(logger, nil, "Invalid multipart/form-data content type") return nil } } reader := multipart.NewReader(bytes.NewReader(body), boundary) var formData []models.FormData for { part, err := reader.NextPart() if err == io.EOF { break } if err != nil { utils.LogError(logger, err, "Error reading part") continue } key := part.FormName() if key == "" { continue } value, err := io.ReadAll(part) if err != nil { utils.LogError(logger, err, "Error reading part value") continue } formData = append(formData, models.FormData{ Key: key, Values: []string{string(value)}, }) } return formData }
------------------

--- Chunk 9---
func CaptureGRPC(ctx context.Context, logger *zap.Logger, t chan *models.TestCase, http2Stream *pkg.HTTP2Stream) { if http2Stream == nil { logger.Error("Stream is nil") return } if http2Stream.GRPCReq == nil || http2Stream.GRPCResp == nil { logger.Error("gRPC request or response is nil") return } // Create test case from stream data testCase := &models.TestCase{ Version: models.GetVersion(), Name: http2Stream.GRPCReq.Headers.OrdinaryHeaders["Keploy-Test-Name"], Kind: models.GRPC_EXPORT, Created: time.Now().Unix(), GrpcReq: *http2Stream.GRPCReq, GrpcResp: *http2Stream.GRPCResp, Noise: map[string][]string{}, } select { case <-ctx.Done(): return case t <- testCase: logger.Debug("Captured gRPC test case", zap.String("path", http2Stream.GRPCReq.Headers.PseudoHeaders[":path"])) } }
------------------

--- File: pkg/core/hooks/hooks.go---

--- Chunk 1---
func NewHooks(logger *zap.Logger, cfg *config.Config) *Hooks { return &Hooks{ logger: logger, sess: core.NewSessions(), m: sync.Mutex{}, proxyIP4: "127.0.0.1", proxyIP6: [4]uint32{0000, 0000, 0000, 0001}, proxyPort: cfg.ProxyPort, dnsPort: cfg.DNSPort, conf: cfg, } }
------------------

--- Chunk 2---
func (h *Hooks) Load(ctx context.Context, id uint64, opts core.HookCfg) error { h.sess.Set(id, &core.Session{ ID: id, }) err := h.load(ctx, opts) if err != nil { return err } g, ok := ctx.Value(models.ErrGroupKey).(*errgroup.Group) if !ok { return errors.New("failed to get the error group from the context") } g.Go(func() error { defer utils.Recover(h.logger) <-ctx.Done() h.unLoad(ctx, opts) //deleting in order to free the memory in case of rerecord. h.sess.Delete(id) return nil }) return nil }
------------------

--- Chunk 3---
Function load (start): func (h *Hooks) load(ctx context.Context, opts core.HookCfg) error { // Allow the current process to lock memory for eBPF resources. if err := rlimit.RemoveMemlock(); err != nil { utils.LogError(h.logger, err, "failed to lock memory for eBPF resources") return err } // Load pre-compiled programs and maps into the kernel. objs := bpfObjects{} if err := loadBpfObjects(&objs, nil); err != nil { var ve *ebpf.VerifierError if errors.As(err, &ve) { errString := strings.Join(ve.Log, "\n") h.logger.Debug("verifier log: ", zap.String("err", errString)) } utils.LogError(h.logger, err, "failed to load eBPF objects") return err } //getting all the ebpf maps h.clientRegistrationMap = objs.KeployClientRegistrationMap h.agentRegistartionMap = objs.KeployAgentRegistrationMap h.e2eAppRegistrationMap = objs.E2eInfoMap h.dockerAppRegistrationMap = objs.DockerAppRegistrationMap h.objects = objs
------------------

--- Chunk 4---
Function load (part 2): // --------------- // ----- used in case of wsl ----- socket, err := link.Kprobe("sys_socket", objs.SyscallProbeEntrySocket, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on sys_socket") return err } h.socket = socket if !opts.E2E { h.redirectProxyMap = objs.RedirectProxyMap h.objects = objs // ------------ For Egress ------------- udppC4, err := link.Kprobe("udp_pre_connect", objs.SyscallProbeEntryUdpPreConnect, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on udp_pre_connect") return err } h.udpp4 = udppC4 // FOR IPV4 tcppC4, err := link.Kprobe("tcp_v4_pre_connect", objs.SyscallProbeEntryTcpV4PreConnect, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on tcp_v4_pre_connect") return err } h.tcppv
------------------

--- Chunk 5---
Function load (part 3): 4 = tcppC4 tcpC4, err := link.Kprobe("tcp_v4_connect", objs.SyscallProbeEntryTcpV4Connect, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on tcp_v4_connect") return err } h.tcpv4 = tcpC4 tcpRC4, err := link.Kretprobe("tcp_v4_connect", objs.SyscallProbeRetTcpV4Connect, &link.KprobeOptions{RetprobeMaxActive: 1024}) if err != nil { utils.LogError(h.logger, err, "failed to attach the kretprobe hook on tcp_v4_connect") return err } h.tcpv4Ret = tcpRC4 // Get the first-mounted cgroupv2 path. cGroupPath, err := detectCgroupPath(h.logger) if err != nil { utils.LogError(h.logger, err, "failed to detect the cgroup path") return err } c4, err := link.AttachCgroup(link.CgroupOptions{ Path: cGroupPath, Attach:
------------------

--- Chunk 6---
Function load (part 4): ebpf.AttachCGroupInet4Connect, Program: objs.K_connect4, }) if err != nil { utils.LogError(h.logger, err, "failed to attach the connect4 cgroup hook") return err } h.connect4 = c4 gp4, err := link.AttachCgroup(link.CgroupOptions{ Path: cGroupPath, Attach: ebpf.AttachCgroupInet4GetPeername, Program: objs.K_getpeername4, }) if err != nil { utils.LogError(h.logger, err, "failed to attach the GetPeername4 cgroup hook") return err } h.gp4 = gp4 // FOR IPV6 tcpPreC6, err := link.Kprobe("tcp_v6_pre_connect", objs.SyscallProbeEntryTcpV6PreConnect, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on tcp_v6_pre_connect") return err } h.tcppv6 = tcpPreC6 tcpC6, err := link
------------------

--- Chunk 7---
Function load (part 5): .Kprobe("tcp_v6_connect", objs.SyscallProbeEntryTcpV6Connect, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on tcp_v6_connect") return err } h.tcpv6 = tcpC6 tcpRC6, err := link.Kretprobe("tcp_v6_connect", objs.SyscallProbeRetTcpV6Connect, &link.KprobeOptions{RetprobeMaxActive: 1024}) if err != nil { utils.LogError(h.logger, err, "failed to attach the kretprobe hook on tcp_v6_connect") return err } h.tcpv6Ret = tcpRC6 c6, err := link.AttachCgroup(link.CgroupOptions{ Path: cGroupPath, Attach: ebpf.AttachCGroupInet6Connect, Program: objs.K_connect6, }) if err != nil { utils.LogError(h.logger, err, "failed to attach the connect6 cgroup hook") return err } h.connect6 = c6 gp6, err := link.AttachCgroup
------------------

--- Chunk 8---
Function load (part 6): (link.CgroupOptions{ Path: cGroupPath, Attach: ebpf.AttachCgroupInet6GetPeername, Program: objs.K_getpeername6, }) if err != nil { utils.LogError(h.logger, err, "failed to attach the GetPeername6 cgroup hook") return err } h.gp6 = gp6 } // The hook sys_connect is used to identify outgoing connections to avoid misclassifying reused FDs // as incoming, especially when analyzing `write` syscalls. //Open a kprobe at the entry of connect syscall cnt, err := link.Kprobe("sys_connect", objs.SyscallProbeEntryConnect, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on sys_connect") return err } h.connect = cnt //Opening a kretprobe at the exit of connect syscall cntr, err := link.Kretprobe("sys_connect", objs.SyscallProbeRetConnect, &link.KprobeOptions{RetprobeMaxActive: 1024}) if err != nil { utils.LogError(h.logger, err
------------------

--- Chunk 9---
Function load (part 7): , "failed to attach the kretprobe hook on sys_connect") return err } h.connectRet = cntr // ------------ For Ingress using Kprobes -------------- //Open a kprobe at the entry of sendto syscall snd, err := link.Kprobe("sys_sendto", objs.SyscallProbeEntrySendto, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on sys_sendto") return err } h.sendto = snd //Opening a kretprobe at the exit of sendto syscall sndr, err := link.Kretprobe("sys_sendto", objs.SyscallProbeRetSendto, &link.KprobeOptions{RetprobeMaxActive: 1024}) if err != nil { utils.LogError(h.logger, err, "failed to attach the kretprobe hook on sys_sendto") return err } h.sendtoRet = sndr // Open a Kprobe at the entry point of the kernel function and attach the // pre-compiled program. ac, err := link.Kprobe("sys_accept", objs.SyscallProbeEntryAccept, nil) if err !=
------------------

--- Chunk 10---
Function load (part 8): nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on sys_accept") return err } h.accept = ac // Open a Kprobe at the exit point of the kernel function and attach the // pre-compiled program. acRet, err := link.Kretprobe("sys_accept", objs.SyscallProbeRetAccept, &link.KprobeOptions{RetprobeMaxActive: 1024}) if err != nil { utils.LogError(h.logger, err, "failed to attach the kretprobe hook on sys_accept") return err } h.acceptRet = acRet // Open a Kprobe at the entry point of the kernel function and attach the // pre-compiled program. ac4, err := link.Kprobe("sys_accept4", objs.SyscallProbeEntryAccept4, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on sys_accept4") return err } h.accept4 = ac4 // Open a Kprobe at the exit point of the kernel function and attach the // pre-compiled program. ac4Ret, err := link.Kretprobe("sys
------------------

--- Chunk 11---
Function load (part 9): _accept4", objs.SyscallProbeRetAccept4, &link.KprobeOptions{RetprobeMaxActive: 1024}) if err != nil { utils.LogError(h.logger, err, "failed to attach the kretprobe hook on sys_accept4") return err } h.accept4Ret = ac4Ret // Open a Kprobe at the entry point of the kernel function and attach the // pre-compiled program. rd, err := link.Kprobe("sys_read", objs.SyscallProbeEntryRead, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on sys_read") return err } h.read = rd // Open a Kprobe at the exit point of the kernel function and attach the // pre-compiled program. rdRet, err := link.Kretprobe("sys_read", objs.SyscallProbeRetRead, &link.KprobeOptions{RetprobeMaxActive: 1024}) if err != nil { utils.LogError(h.logger, err, "failed to attach the kretprobe hook on sys_read") return err } h.readRet = rdRet // Open a Kprobe at the
------------------

--- Chunk 12---
Function load (part 10): entry point of the kernel function and attach the // pre-compiled program. wt, err := link.Kprobe("sys_write", objs.SyscallProbeEntryWrite, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on sys_write") return err } h.write = wt // Open a Kprobe at the exit point of the kernel function and attach the // pre-compiled program. wtRet, err := link.Kretprobe("sys_write", objs.SyscallProbeRetWrite, &link.KprobeOptions{RetprobeMaxActive: 1024}) if err != nil { utils.LogError(h.logger, err, "failed to attach the kretprobe hook on sys_write") return err } h.writeRet = wtRet // Open a Kprobe at the entry point of the kernel function and attach the // pre-compiled program for readv. readv, err := link.Kprobe("sys_readv", objs.SyscallProbeEntryReadv, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on sys_readv") return err
------------------

--- Chunk 13---
Function load (part 11): } h.readv = readv // Open a Kprobe at the exit point of the kernel function and attach the // pre-compiled program for readv. readvRet, err := link.Kretprobe("sys_readv", objs.SyscallProbeRetReadv, &link.KprobeOptions{RetprobeMaxActive: 1024}) if err != nil { utils.LogError(h.logger, err, "failed to attach the kretprobe hook on sys_readv") return err } h.readvRet = readvRet // Open a Kprobe at the entry point of the kernel function and attach the // pre-compiled program for writev. wtv, err := link.Kprobe("sys_writev", objs.SyscallProbeEntryWritev, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on sys_writev") return err } h.writev = wtv // Open a Kprobe at the exit point of the kernel function and attach the // pre-compiled program for writev. wtvRet, err := link.Kretprobe("sys_writev", objs.SyscallProbeRetWritev
------------------

--- Chunk 14---
Function load (part 12): , &link.KprobeOptions{RetprobeMaxActive: 1024}) if err != nil { utils.LogError(h.logger, err, "failed to attach the kretprobe hook on sys_writev") return err } h.writevRet = wtvRet // Open a Kprobe at the entry point of the kernel function and attach the // pre-compiled program. cl, err := link.Kprobe("sys_close", objs.SyscallProbeEntryClose, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on sys_close") return err } h.close = cl //Attaching a kprobe at the entry of recvfrom syscall rcv, err := link.Kprobe("sys_recvfrom", objs.SyscallProbeEntryRecvfrom, nil) if err != nil { utils.LogError(h.logger, err, "failed to attach the kprobe hook on sys_recvfrom") return err } h.recvfrom = rcv //Attaching a kretprobe at the exit of recvfrom syscall rcvr, err := link.Kretprobe("sys_recvfrom", objs.SyscallProbeRetRecvfrom, &link
------------------

--- Chunk 15---
Function load (part 13): .KprobeOptions{RetprobeMaxActive: 1024}) if err != nil { utils.LogError(h.logger, err, "failed to attach the kretprobe hook on sys_recvfrom") return err } h.recvfromRet = rcvr // Open a Kprobe at the exit point of the kernel function and attach the // pre-compiled program. clRet, err := link.Kretprobe("sys_close", objs.SyscallProbeRetClose, &link.KprobeOptions{RetprobeMaxActive: 1024}) if err != nil { utils.LogError(h.logger, err, "failed to attach the kretprobe hook on sys_close") return err } h.closeRet = clRet h.logger.Info("keploy initialized and probes added to the kernel.") var clientInfo = structs.ClientInfo{} switch opts.Mode { case models.MODE_RECORD: clientInfo.Mode = uint32(1) case models.MODE_TEST: clientInfo.Mode = uint32(2) default: clientInfo.Mode = uint32(0) } //sending keploy pid to kernel to get filtered inode, err := getSelfInodeNumber() if err != nil { utils.LogError(h.logger
------------------

--- Chunk 16---
Function load (part 14): , err, "failed to get inode of the keploy process") return err } clientInfo.KeployClientInode = inode clientInfo.KeployClientNsPid = uint32(os.Getpid()) if opts.E2E { pid, err := utils.GetPIDFromPort(ctx, h.logger, int(opts.Port)) if err != nil { utils.LogError(h.logger, err, "failed to get the keploy pid from the port in case of e2e") return err } err = h.SendE2EInfo(pid) if err != nil { h.logger.Error("failed to send e2e info to the ebpf program", zap.Error(err)) } } clientInfo.IsKeployClientRegistered = uint32(0) if opts.IsDocker { h.proxyIP4 = opts.KeployIPV4 ipv6, err := ToIPv4MappedIPv6(opts.KeployIPV4) if err != nil { return fmt.Errorf("failed to convert ipv4:%v to ipv4 mapped ipv6 in docker env:%v", opts.KeployIPV4, err) } h.logger.Debug
------------------

--- Chunk 17---
Function load (part 15): (fmt.Sprintf("IPv4-mapped IPv6 for %s is: %08x:%08x:%08x:%08x\n", h.proxyIP4, ipv6[0], ipv6[1], ipv6[2], ipv6[3])) h.proxyIP6 = ipv6 } h.logger.Debug("proxy ips", zap.String("ipv4", h.proxyIP4), zap.Any("ipv6", h.proxyIP6)) proxyIP, err := IPv4ToUint32(h.proxyIP4) if err != nil { return fmt.Errorf("failed to convert ip string:[%v] to 32-bit integer", opts.KeployIPV4) } var agentInfo = structs.AgentInfo{} agentInfo.ProxyInfo = structs.ProxyInfo{ IP4: proxyIP, IP6: h.proxyIP6, Port: h.proxyPort, } agentInfo.DNSPort = int32(h.dnsPort) if opts.IsDocker { clientInfo.IsDockerApp = uint32(1) } else { clientInfo.IsDockerApp = uint32(0) } ports := GetPortToSendToKernel(ctx, opts.Rules
------------------

--- Chunk 18---
Function load (end): ) for i := 0; i < 10; i++ { if len(ports) <= i { clientInfo.PassThroughPorts[i] = -1 continue } clientInfo.PassThroughPorts[i] = int32(ports[i]) } err = h.SendClientInfo(opts.AppID, clientInfo) if err != nil { h.logger.Error("failed to send app info to the ebpf program", zap.Error(err)) return err } err = h.SendAgentInfo(agentInfo) if err != nil { h.logger.Error("failed to send agent info to the ebpf program", zap.Error(err)) return err } return nil }
------------------

--- Chunk 19---
func (h *Hooks) Record(ctx context.Context, _ uint64, opts models.IncomingOptions) (<-chan *models.TestCase, error) { // TODO use the session to get the app id // and then use the app id to get the test cases chan // and pass that to eBPF consumers/listeners return conn.ListenSocket(ctx, h.logger, h.objects.SocketOpenEvents, h.objects.SocketDataEvents, h.objects.SocketCloseEvents, opts) }
------------------

--- Chunk 20---
Function unLoad (start): func (h *Hooks) unLoad(_ context.Context, opts core.HookCfg) { // closing all events //other if err := h.socket.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the socket") } if !opts.E2E { if err := h.udpp4.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the udpp4") } if err := h.connect4.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the connect4") } if err := h.gp4.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the gp4") } if err := h.tcppv4.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the tcppv4") } if err := h.tcpv4.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the tcpv4") } if err := h.tcpv4Ret.Close(); err != nil { utils.LogError(h.logger, err,
------------------

--- Chunk 21---
Function unLoad (part 2): "failed to close the tcpv4Ret") } if err := h.connect6.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the connect6") } if err := h.gp6.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the gp6") } if err := h.tcppv6.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the tcppv6") } if err := h.tcpv6.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the tcpv6") } if err := h.tcpv6Ret.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the tcpv6Ret") } } if err := h.accept.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the accept") } if err := h.acceptRet.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the acceptRet") } if err := h.accept4.Close(); err != nil {
------------------

--- Chunk 22---
Function unLoad (part 3): utils.LogError(h.logger, err, "failed to close the accept4") } if err := h.accept4Ret.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the accept4Ret") } if err := h.read.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the read") } if err := h.readRet.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the readRet") } if err := h.write.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the write") } if err := h.writeRet.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the writeRet") } if err := h.writev.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the writev") } if err := h.writevRet.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the writevRet") } if err := h.readv.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the readv")
------------------

--- Chunk 23---
Function unLoad (part 4): } if err := h.readvRet.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the readvRet") } if err := h.close.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the close") } if err := h.closeRet.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the closeRet") } if err := h.sendto.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the sendto") } if err := h.sendtoRet.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the sendtoRet") } if err := h.recvfrom.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the recvfrom") } if err := h.recvfromRet.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the recvfromRet") } if err := h.objects.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the objects") } if err := h.connect.Close(); err != nil {
------------------

--- Chunk 24---
Function unLoad (end): utils.LogError(h.logger, err, "failed to close the connect") } if err := h.connectRet.Close(); err != nil { utils.LogError(h.logger, err, "failed to close the connectRet") } h.logger.Info("eBPF resources released successfully...") }
------------------

--- File: pkg/core/hooks/kernelComm.go---

--- Chunk 1---
func (h *Hooks) Get(_ context.Context, srcPort uint16) (*core.NetworkAddress, error) { d, err := h.GetDestinationInfo(srcPort) if err != nil { return nil, err } // TODO : need to implement eBPF code to differentiate between different apps s, ok := h.sess.Get(0) if !ok { return nil, fmt.Errorf("session not found") } return &core.NetworkAddress{ AppID: s.ID, Version: d.IPVersion, IPv4Addr: d.DestIP4, IPv6Addr: d.DestIP6, Port: d.DestPort, }, nil }
------------------

--- Chunk 2---
func (h *Hooks) GetDestinationInfo(srcPort uint16) (*structs.DestInfo, error) { h.m.Lock() defer h.m.Unlock() destInfo := structs.DestInfo{} if err := h.redirectProxyMap.Lookup(srcPort, &destInfo); err != nil { return nil, err } return &destInfo, nil }
------------------

--- Chunk 3---
func (h *Hooks) Delete(_ context.Context, srcPort uint16) error { return h.CleanProxyEntry(srcPort) }
------------------

--- Chunk 4---
func (h *Hooks) CleanProxyEntry(srcPort uint16) error { h.m.Lock() defer h.m.Unlock() err := h.redirectProxyMap.Delete(srcPort) if err != nil { utils.LogError(h.logger, err, "failed to remove entry from redirect proxy map") return err } h.logger.Debug("successfully removed entry from redirect proxy map", zap.Any("(Key)/SourcePort", srcPort)) return nil }
------------------

--- Chunk 5---
func (h *Hooks) SendClientInfo(id uint64, appInfo structs.ClientInfo) error { err := h.clientRegistrationMap.Update(id, appInfo, ebpf.UpdateAny) if err != nil { utils.LogError(h.logger, err, "failed to send the app info to the ebpf program") return err } return nil }
------------------

--- Chunk 6---
func (h *Hooks) SendAgentInfo(agentInfo structs.AgentInfo) error { key := 0 err := h.agentRegistartionMap.Update(uint32(key), agentInfo, ebpf.UpdateAny) if err != nil { utils.LogError(h.logger, err, "failed to send the agent info to the ebpf program") return err } return nil }
------------------

--- Chunk 7---
func (h *Hooks) SendE2EInfo(pid uint32) error { key := 0 err := h.e2eAppRegistrationMap.Update(uint64(key), pid, ebpf.UpdateAny) if err != nil { utils.LogError(h.logger, err, "failed to send the E2E info to the ebpf program") return err } return nil }
------------------

--- Chunk 8---
func (h *Hooks) SendDockerAppInfo(_ uint64, dockerAppInfo structs.DockerAppInfo) error { if h.appID != 0 { err := h.dockerAppRegistrationMap.Delete(h.appID) if err != nil { utils.LogError(h.logger, err, "failed to remove entry from dockerAppRegistrationMap") return err } } r := rand.New(rand.NewSource(time.Now().UnixNano())) randomNum := r.Uint64() % 10 h.appID = randomNum err := h.dockerAppRegistrationMap.Update(h.appID, dockerAppInfo, ebpf.UpdateAny) if err != nil { utils.LogError(h.logger, err, "failed to send the dockerAppInfo info to the ebpf program") return err } return nil }
------------------

--- File: pkg/core/hooks/util.go---

--- Chunk 1---
func IPv4ToUint32(ipStr string) (uint32, error) { ipAddr := net.ParseIP(ipStr) if ipAddr != nil { ipAddr = ipAddr.To4() if ipAddr != nil { return binary.BigEndian.Uint32(ipAddr), nil } return 0, errors.New("not a valid IPv4 address") } return 0, errors.New("failed to parse IP address") }
------------------

--- Chunk 2---
Function ToIPv4MappedIPv6 (start): func ToIPv4MappedIPv6(ipv4 string) ([4]uint32, error) { var result [4]uint32 // Parse the input IPv4 address ip := net.ParseIP(ipv4) if ip == nil { return result, errors.New("invalid IPv4 address") } // Check if the input is an IPv4 address ip = ip.To4() if ip == nil { return result, errors.New("not a valid IPv4 address") } // Convert IPv4 address to IPv4-mapped IPv6 address // IPv4-mapped IPv6 address is ::ffff:a.b.c.d ipv6 := "::ffff:" + ipv4 // Parse the resulting IPv6 address ip6 := net.ParseIP(ipv6) if ip6 == nil { return result, errors.New("failed to parse IPv4-mapped IPv6 address") } // Convert the IPv6 address to a 16-byte representation ip6Bytes := ip6.To16() if ip6Bytes == nil { return result, errors.New("failed to convert IPv6 address to bytes") } // Populate the result array for i := 0; i <
------------------

--- Chunk 3---
Function ToIPv4MappedIPv6 (end): 4; i++ { result[i] = uint32(ip6Bytes[i*4])<<24 | uint32(ip6Bytes[i*4+1])<<16 | uint32(ip6Bytes[i*4+2])<<8 | uint32(ip6Bytes[i*4+3]) } return result, nil }
------------------

--- Chunk 4---
func detectCgroupPath(logger *zap.Logger) (string, error) { f, err := os.Open("/proc/mounts") if err != nil { return "", err } defer func() { err := f.Close() if err != nil { utils.LogError(logger, err, "failed to close /proc/mounts file") } }() scanner := bufio.NewScanner(f) for scanner.Scan() { // example fields: cgroup2 /sys/fs/cgroup/unified cgroup2 rw,nosuid,nodev,noexec,relatime 0 0 fields := strings.Split(scanner.Text(), " ") if len(fields) >= 3 && fields[2] == "cgroup2" { return fields[1], nil } } return "", errors.New("cgroup2 not mounted") }
------------------

--- Chunk 5---
func getSelfInodeNumber() (uint64, error) { p := filepath.Join("/proc", "self", "ns", "pid") f, err := os.Stat(p) if err != nil { return 0, errors.New("failed to get inode of the keploy process") } // Dev := (f.Sys().(*syscall.Stat_t)).Dev Ino := (f.Sys().(*syscall.Stat_t)).Ino if Ino != 0 { return Ino, nil } return 0, nil }
------------------

--- Chunk 6---
func GetPortToSendToKernel(_ context.Context, rules []config.BypassRule) []uint { // if the rule only contains port, then it should be sent to kernel ports := []uint{} for _, rule := range rules { if rule.Host == "" && rule.Path == "" { if rule.Port != 0 { ports = append(ports, rule.Port) } } } return ports }
------------------

--- File: pkg/core/proxy/dns.go---

--- Chunk 1---
func (p *Proxy) startTCPDNSServer(_ context.Context) error { addr := fmt.Sprintf(":%v", p.DNSPort) handler := p server := &dns.Server{ Addr: addr, Net: "tcp", Handler: handler, ReusePort: true, } p.TCPDNSServer = server p.logger.Info(fmt.Sprintf("starting TCP DNS server at addr %v", server.Addr)) err := server.ListenAndServe() if err != nil { utils.LogError(p.logger, err, "failed to start tcp dns server", zap.Any("addr", server.Addr)) } return nil }
------------------

--- Chunk 2---
func (p *Proxy) startUDPDNSServer(_ context.Context) error { addr := fmt.Sprintf(":%v", p.DNSPort) handler := p server := &dns.Server{ Addr: addr, Net: "udp", Handler: handler, ReusePort: true, // DisableBackground: true, } p.UDPDNSServer = server p.logger.Info(fmt.Sprintf("starting UDP DNS server at addr %v", server.Addr)) err := server.ListenAndServe() if err != nil { utils.LogError(p.logger, err, "failed to start udp dns server", zap.Any("addr", server.Addr)) return err } return nil }
------------------

--- Chunk 3---
func generateCacheKey(name string, qtype uint16) string { return fmt.Sprintf("%s-%s", name, dns.TypeToString[qtype]) }
------------------

--- Chunk 4---
Function ServeDNS (start): func (p *Proxy) ServeDNS(w dns.ResponseWriter, r *dns.Msg) { p.logger.Debug("", zap.Any("Source socket info", w.RemoteAddr().String())) msg := new(dns.Msg) msg.SetReply(r) msg.Authoritative = true p.logger.Debug("Got some Dns queries") for _, question := range r.Question { p.logger.Debug("", zap.Any("Record Type", question.Qtype), zap.Any("Received Query", question.Name)) key := generateCacheKey(question.Name, question.Qtype) // Check if the answer is cached cache.RLock() answers, found := cache.m[key] cache.RUnlock() if !found { // If not found in cache, resolve the DNS query only in case of record mode //TODO: Add support for passThrough here using the src<->dst mapping if models.GetMode() == models.MODE_RECORD { answers = resolveDNSQuery(p.logger, question.Name) } if len(answers) == 0 { switch question.Qtype { // If the resolution failed, return a default A record with Proxy IP // or AAAA record with Proxy IP6 case
------------------

--- Chunk 5---
Function ServeDNS (part 2): dns.TypeA: answers = []dns.RR{&dns.A{ Hdr: dns.RR_Header{Name: question.Name, Rrtype: dns.TypeA, Class: dns.ClassINET, Ttl: 3600}, A: net.ParseIP(p.IP4), }} p.logger.Debug("failed to resolve dns query hence sending proxy ip4", zap.Any("proxy Ip", p.IP4)) case dns.TypeAAAA: answers = []dns.RR{&dns.AAAA{ Hdr: dns.RR_Header{Name: question.Name, Rrtype: dns.TypeAAAA, Class: dns.ClassINET, Ttl: 3600}, AAAA: net.ParseIP(p.IP6), }} p.logger.Debug("failed to resolve dns query hence sending proxy ip6", zap.Any("proxy Ip", p.IP6)) default: p.logger.Error("Unsupported DNS query type", zap.Any("query type", question.Qtype)) } } p.logger.Debug(fmt.Sprintf("Answers[when resolution failed for query:%v]:\n%v\n", question.Qtype, answers)) // Cache the answer cache.Lock() cache.m
------------------

--- Chunk 6---
Function ServeDNS (end): [key] = answers cache.Unlock() p.logger.Debug(fmt.Sprintf("Answers[after caching it]:\n%v\n", answers)) } p.logger.Debug(fmt.Sprintf("Answers[before appending to msg]:\n%v\n", answers)) msg.Answer = append(msg.Answer, answers...) p.logger.Debug(fmt.Sprintf("Answers[After appending to msg]:\n%v\n", msg.Answer)) } p.logger.Debug(fmt.Sprintf("dns msg sending back:\n%v\n", msg)) p.logger.Debug(fmt.Sprintf("dns msg RCODE sending back:\n%v\n", msg.Rcode)) p.logger.Debug("Writing dns info back to the client...") err := w.WriteMsg(msg) if err != nil { utils.LogError(p.logger, err, "failed to write dns info back to the client") } }
------------------

--- Chunk 7---
Function resolveDNSQuery (start): func resolveDNSQuery(logger *zap.Logger, domain string) []dns.RR { // Remove the last dot from the domain name if it exists domain = strings.TrimSuffix(domain, ".") // Use the default system resolver resolver := net.DefaultResolver // Perform the lookup with the context ips, err := resolver.LookupIPAddr(context.Background(), domain) if err != nil { logger.Debug(fmt.Sprintf("failed to resolve the dns query for:%v", domain), zap.Error(err)) return nil } // Convert the resolved IPs to dns.RR var answers []dns.RR for _, ip := range ips { if ipv4 := ip.IP.To4(); ipv4 != nil { answers = append(answers, &dns.A{ Hdr: dns.RR_Header{Name: dns.Fqdn(domain), Rrtype: dns.TypeA, Class: dns.ClassINET, Ttl: 3600}, A: ipv4, }) } else { answers = append(answers, &dns.AAAA{ Hdr: dns.RR_Header{Name: dns.Fqdn(domain), Rrtype: dns.TypeAAAA, Class: dns.Class
------------------

--- Chunk 8---
Function resolveDNSQuery (end): INET, Ttl: 3600}, AAAA: ip.IP, }) } } if len(answers) > 0 { logger.Debug("net.LookupIP resolved the ip address...") } return answers }
------------------

--- Chunk 9---
func (p *Proxy) stopDNSServers(_ context.Context) error { // stop tcp dns server if err := p.stopTCPDNSServer(); err != nil { return err } // stop udp dns server err := p.stopUDPDNSServer() return err }
------------------

--- Chunk 10---
func (p *Proxy) stopTCPDNSServer() error { if p.TCPDNSServer != nil { err := p.TCPDNSServer.Shutdown() if err != nil { utils.LogError(p.logger, err, "failed to stop tcp dns server") return err } p.logger.Info("Tcp Dns server stopped successfully") } return nil }
------------------

--- Chunk 11---
func (p *Proxy) stopUDPDNSServer() error { if p.UDPDNSServer != nil { err := p.UDPDNSServer.Shutdown() if err != nil { utils.LogError(p.logger, err, "failed to stop udp dns server") return err } p.logger.Info("Udp Dns server stopped successfully") } return nil }
------------------

--- Chunk 12---
Function setupNsswitchConfig (start): func (p *Proxy) setupNsswitchConfig() error { // Check if the nsswitch.conf present for the system if _, err := os.Stat(nsSwitchConfig); err == nil { // Read the current nsswitch.conf data, err := os.ReadFile(nsSwitchConfig) if err != nil { utils.LogError(p.logger, err, "failed to read the nsswitch.conf file from system") return errors.New("failed to setup the nsswitch.conf file to redirect the DNS queries to proxy") } // copy the data of the nsswitch.conf file in order to reset it back to the original state in the end p.nsswitchData = data // Replace the hosts field value if it exists lines := strings.Split(string(data), "\n") for i, line := range lines { if strings.HasPrefix(line, "hosts:") { lines[i] = "hosts: files dns" } } data = []byte(strings.Join(lines, "\n")) // Write the modified nsswitch.conf back to the file err = writeNsswitchConfig(p.logger, nsSwitchConfig, data, ns
------------------

--- Chunk 13---
Function setupNsswitchConfig (end): SwitchPerm) if err != nil { return errors.New("failed to setup the nsswitch.conf file to redirect the DNS queries to proxy") } p.logger.Debug("Successfully written to nsswitch config of linux") } return nil }
------------------

--- Chunk 14---
func (p *Proxy) resetNsSwitchConfig() error { data := p.nsswitchData // Write the original data back to the nsswitch.conf file err := writeNsswitchConfig(p.logger, nsSwitchConfig, data, nsSwitchPerm) if err != nil { return errors.New("failed to reset the nsswitch.conf back to the original state") } p.logger.Debug("Successfully reset the nsswitch config of linux") return nil }
------------------

--- File: pkg/core/proxy/integrations/generic/decode.go---

--- Chunk 1---
Function decodeGeneric (start): func decodeGeneric(ctx context.Context, logger *zap.Logger, reqBuf []byte, clientConn net.Conn, dstCfg *models.ConditionalDstCfg, mockDb integrations.MockMemDb, _ models.OutgoingOptions) error { genericRequests := [][]byte{reqBuf} logger.Debug("Into the generic parser in test mode") errCh := make(chan error, 1) go func(errCh chan error, genericRequests [][]byte) { defer pUtil.Recover(logger, clientConn, nil) defer close(errCh) for { // Since protocol packets have to be parsed for checking stream end, // clientConnection have deadline for read to determine the end of stream. err := clientConn.SetReadDeadline(time.Now().Add(10 * time.Millisecond)) if err != nil { utils.LogError(logger, err, "failed to set the read deadline for the client conn") return } // To read the stream of request packets from the client for { buffer, err := pUtil.ReadBytes(ctx, logger, clientConn) // Applied this nolint to ignore the staticcheck error here because of readability // nolint:staticcheck
------------------

--- Chunk 2---
Function decodeGeneric (part 2): if netErr, ok := err.(net.Error); !(ok && netErr.Timeout()) && err != nil && err.Error() != "EOF" { utils.LogError(logger, err, "failed to read the request message in proxy for generic dependency") return } if netErr, ok := err.(net.Error); (ok && netErr.Timeout()) || (err != nil && err.Error() == "EOF") { logger.Debug("the timeout for the client read in generic or EOF") break } genericRequests = append(genericRequests, buffer) } if len(genericRequests) == 0 { logger.Debug("the generic request buffer is empty") continue } // bestMatchedIndx := 0 // fuzzy match gives the index for the best matched generic mock matched, genericResponses, err := fuzzyMatch(ctx, logger, genericRequests, mockDb) if err != nil { utils.LogError(logger, err, "error while matching generic mocks") } if !matched { err := clientConn.SetReadDeadline(time.Time{}) if err != nil { utils.LogError(logger, err, "failed
------------------

--- Chunk 3---
Function decodeGeneric (part 3): to set the read deadline for the client conn") return } logger.Debug("the genericRequests before pass through are", zap.Any("length", len(genericRequests))) for _, genReq := range genericRequests { logger.Debug("the genericRequests are:", zap.Any("h", string(genReq))) } reqBuffer, err := pUtil.PassThrough(ctx, logger, clientConn, dstCfg, genericRequests) if err != nil { utils.LogError(logger, err, "failed to passthrough the generic request") return } genericRequests = [][]byte{} logger.Debug("the request buffer after pass through in generic", zap.Any("buffer", string(reqBuffer))) if len(reqBuffer) > 0 { genericRequests = [][]byte{reqBuffer} } logger.Debug("the length of genericRequests after passThrough ", zap.Any("length", len(genericRequests))) continue } for _, genericResponse := range genericResponses { encoded := []byte(genericResponse.Message[0].Data) if genericResponse.Message[0].Type != models.String { encoded, err = util.DecodeBase64(genericResponse.Message[
------------------

--- Chunk 4---
Function decodeGeneric (end): 0].Data) if err != nil { utils.LogError(logger, err, "failed to decode the base64 response") return } } _, err := clientConn.Write(encoded) if err != nil { if ctx.Err() != nil { return } utils.LogError(logger, err, "failed to write the response message to the client application") return } } // Clear the genericRequests buffer for the next dependency call genericRequests = [][]byte{} logger.Debug("the genericRequests after the iteration", zap.Any("length", len(genericRequests))) } }(errCh, genericRequests) select { case <-ctx.Done(): return ctx.Err() case err := <-errCh: if err == io.EOF { return nil } return err } }
------------------

--- File: pkg/core/proxy/integrations/generic/encode.go---

--- Chunk 1---
Function encodeGeneric (start): func encodeGeneric(ctx context.Context, logger *zap.Logger, reqBuf []byte, clientConn, destConn net.Conn, mocks chan<- *models.Mock, _ models.OutgoingOptions) error { var genericRequests []models.Payload bufStr := string(reqBuf) dataType := models.String if !util.IsASCII(string(reqBuf)) { bufStr = util.EncodeBase64(reqBuf) dataType = "binary" } if bufStr != "" { genericRequests = append(genericRequests, models.Payload{ Origin: models.FromClient, Message: []models.OutputBinary{ { Type: dataType, Data: bufStr, }, }, }) } _, err := destConn.Write(reqBuf) if err != nil { utils.LogError(logger, err, "failed to write request message to the destination server") return err } var genericResponses []models.Payload clientBuffChan := make(chan []byte) destBuffChan := make(chan []byte) errChan := make(chan error) //TODO: where to close the error channel since it is used in both the go routines //close(errChan) // read requests from client err = pUtil
------------------

--- Chunk 2---
Function encodeGeneric (part 2): .ReadFromPeer(ctx, logger, clientConn, clientBuffChan, errChan, pUtil.Client) if err != nil { return fmt.Errorf("error reading from client:%v", err) } // read responses from destination err = pUtil.ReadFromPeer(ctx, logger, destConn, destBuffChan, errChan, pUtil.Destination) if err != nil { return fmt.Errorf("error reading from destination:%v", err) } prevChunkWasReq := false var reqTimestampMock = time.Now() var resTimestampMock time.Time // ticker := time.NewTicker(1 * time.Second) logger.Debug("the iteration for the generic request starts", zap.Any("genericReqs", len(genericRequests)), zap.Any("genericResps", len(genericResponses))) for { select { case <-ctx.Done(): if !prevChunkWasReq && len(genericRequests) > 0 && len(genericResponses) > 0 { genericRequestsCopy := make([]models.Payload, len(genericRequests)) genericResponsesCopy := make([]models.Payload, len(genericResponses)) copy(genericResponsesCopy, genericResponses) copy(genericRequestsCopy, genericRequests)
------------------

--- Chunk 3---
Function encodeGeneric (part 3): metadata := make(map[string]string) metadata["type"] = "config" metadata["connID"] = ctx.Value(models.ClientConnectionIDKey).(string) // Save the mock mocks <- &models.Mock{ Version: models.GetVersion(), Name: "mocks", Kind: models.GENERIC, Spec: models.MockSpec{ GenericRequests: genericRequestsCopy, GenericResponses: genericResponsesCopy, ReqTimestampMock: reqTimestampMock, ResTimestampMock: resTimestampMock, Metadata: metadata, }, } return ctx.Err() } case buffer := <-clientBuffChan: // Write the request message to the destination _, err := destConn.Write(buffer) if err != nil { utils.LogError(logger, err, "failed to write request message to the destination server") return err } logger.Debug("the iteration for the generic request ends with no of genericReqs:" + strconv.Itoa(len(genericRequests)) + " and genericResps: " + strconv.Itoa(len(genericResponses))) if !prevChunkWasReq && len
------------------

--- Chunk 4---
Function encodeGeneric (part 4): (genericRequests) > 0 && len(genericResponses) > 0 { genericRequestsCopy := make([]models.Payload, len(genericRequests)) genericResponseCopy := make([]models.Payload, len(genericResponses)) copy(genericResponseCopy, genericResponses) copy(genericRequestsCopy, genericRequests) go func(reqs []models.Payload, resps []models.Payload) { metadata := make(map[string]string) metadata["type"] = "config" metadata["connID"] = ctx.Value(models.ClientConnectionIDKey).(string) // Save the mock mocks <- &models.Mock{ Version: models.GetVersion(), Name: "mocks", Kind: models.GENERIC, Spec: models.MockSpec{ GenericRequests: reqs, GenericResponses: resps, ReqTimestampMock: reqTimestampMock, ResTimestampMock: resTimestampMock, Metadata: metadata, }, } }(genericRequestsCopy, genericResponseCopy) genericRequests = []models.Payload{} genericResponses = []models.Payload{} } bufStr :=
------------------

--- Chunk 5---
Function encodeGeneric (part 5): string(buffer) buffDataType := models.String if !util.IsASCII(string(buffer)) { bufStr = util.EncodeBase64(buffer) buffDataType = "binary" } if bufStr != "" { genericRequests = append(genericRequests, models.Payload{ Origin: models.FromClient, Message: []models.OutputBinary{ { Type: buffDataType, Data: bufStr, }, }, }) } prevChunkWasReq = true case buffer := <-destBuffChan: if prevChunkWasReq { // store the request timestamp reqTimestampMock = time.Now() } // Write the response message to the client _, err := clientConn.Write(buffer) if err != nil { utils.LogError(logger, err, "failed to write response message to the client") return err } bufStr := string(buffer) buffDataType := models.String if !util.IsASCII(string(buffer)) { bufStr = base64.StdEncoding.EncodeToString(buffer) buffDataType = "binary" } if bufStr != "" { genericResponses = append
------------------

--- Chunk 6---
Function encodeGeneric (end): (genericResponses, models.Payload{ Origin: models.FromServer, Message: []models.OutputBinary{ { Type: buffDataType, Data: bufStr, }, }, }) } resTimestampMock = time.Now() logger.Debug("the iteration for the generic response ends with no of genericReqs:" + strconv.Itoa(len(genericRequests)) + " and genericResps: " + strconv.Itoa(len(genericResponses))) prevChunkWasReq = false case err := <-errChan: if err == io.EOF { return nil } return err } } }
------------------

--- File: pkg/core/proxy/integrations/generic/generic.go---

--- Chunk 1---
func init() { integrations.Register(integrations.GENERIC, &integrations.Parsers{ Initializer: New, Priority: 100, }) }
------------------

--- Chunk 2---
func New(logger *zap.Logger) integrations.Integrations { return &Generic{ logger: logger, } }
------------------

--- Chunk 3---
func (g *Generic) MatchType(_ context.Context, _ []byte) bool { // generic is checked explicitly in the proxy return false }
------------------

--- Chunk 4---
func (g *Generic) RecordOutgoing(ctx context.Context, src net.Conn, dst net.Conn, mocks chan<- *models.Mock, opts models.OutgoingOptions) error { logger := g.logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", src.RemoteAddr().String())) reqBuf, err := util.ReadInitialBuf(ctx, logger, src) if err != nil { utils.LogError(logger, err, "failed to read the initial generic message") return err } err = encodeGeneric(ctx, logger, reqBuf, src, dst, mocks, opts) if err != nil { utils.LogError(logger, err, "failed to encode the generic message into the yaml") return err } return nil }
------------------

--- Chunk 5---
func (g *Generic) MockOutgoing(ctx context.Context, src net.Conn, dstCfg *models.ConditionalDstCfg, mockDb integrations.MockMemDb, opts models.OutgoingOptions) error { logger := g.logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", src.RemoteAddr().String())) reqBuf, err := util.ReadInitialBuf(ctx, logger, src) if err != nil { utils.LogError(logger, err, "failed to read the initial generic message") return err } err = decodeGeneric(ctx, logger, reqBuf, src, dstCfg, mockDb, opts) if err != nil { utils.LogError(logger, err, "failed to decode the generic message") return err } return nil }
------------------

--- File: pkg/core/proxy/integrations/generic/match.go---

--- Chunk 1---
Function fuzzyMatch (start): func fuzzyMatch(ctx context.Context, logger *zap.Logger, reqBuff [][]byte, mockDb integrations.MockMemDb) (bool, []models.Payload, error) { for { select { case <-ctx.Done(): return false, nil, ctx.Err() default: mocks, err := mockDb.GetUnFilteredMocks() if err != nil { return false, nil, fmt.Errorf("error while getting unfiltered mocks %v", err) } var filteredMocks []*models.Mock var unfilteredMocks []*models.Mock for _, mock := range mocks { if mock.Kind != "Generic" { continue } if mock.TestModeInfo.IsFiltered { filteredMocks = append(filteredMocks, mock) } else { unfilteredMocks = append(unfilteredMocks, mock) } } logger.Debug("List of mocks in the database", zap.Any("Filtered Mocks", len(filteredMocks)), zap.Any("Unfiltered Mocks", len(unfilteredMocks))) for i, mock := range filteredMocks { logger.Debug("Filtered Mocks", zap.Any(fmt.Sprintf("Mock[%d]", i), mock.Name), zap.Any("sortOrder",
------------------

--- Chunk 2---
Function fuzzyMatch (part 2): mock.TestModeInfo.SortOrder)) } for i, mock := range unfilteredMocks { logger.Debug("Unfiltered Mocks", zap.Any(fmt.Sprintf("Mock[%d]", i), mock.Name), zap.Any("sortOrder", mock.TestModeInfo.SortOrder)) } index := findExactMatch(filteredMocks, reqBuff) if index == -1 { index = findBinaryMatch(filteredMocks, reqBuff, 0.9) } if index != -1 { responseMock := make([]models.Payload, len(filteredMocks[index].Spec.GenericResponses)) copy(responseMock, filteredMocks[index].Spec.GenericResponses) originalFilteredMock := *filteredMocks[index] filteredMocks[index].TestModeInfo.IsFiltered = false filteredMocks[index].TestModeInfo.SortOrder = pkg.GetNextSortNum() isUpdated := mockDb.UpdateUnFilteredMock(&originalFilteredMock, filteredMocks[index]) if !isUpdated { continue } logger.Debug("Filtered mock found for generic request", zap.Any("Mock", filteredMocks[index].Name), zap.Any("sortOrder", filteredMocks[index].TestModeInfo.SortOrder)) return true, responseMock,
------------------

--- Chunk 3---
Function fuzzyMatch (end): nil } index = findExactMatch(unfilteredMocks, reqBuff) if index == -1 { index = findBinaryMatch(unfilteredMocks, reqBuff, 0.4) } if index != -1 { responseMock := make([]models.Payload, len(unfilteredMocks[index].Spec.GenericResponses)) copy(responseMock, unfilteredMocks[index].Spec.GenericResponses) originalFilteredMock := *unfilteredMocks[index] unfilteredMocks[index].TestModeInfo.IsFiltered = false unfilteredMocks[index].TestModeInfo.SortOrder = pkg.GetNextSortNum() isUpdated := mockDb.UpdateUnFilteredMock(&originalFilteredMock, unfilteredMocks[index]) if !isUpdated { continue } logger.Debug("Unfiltered mock found for generic request", zap.Any("Mock", unfilteredMocks[index].Name), zap.Any("sortOrder", unfilteredMocks[index].TestModeInfo.SortOrder)) return true, responseMock, nil } return false, nil, nil } } }
------------------

--- Chunk 4---
func findBinaryMatch(tcsMocks []*models.Mock, reqBuffs [][]byte, mxSim float64) int { // TODO: need find a proper similarity index to set a benchmark for matching or need to find another way to do approximate matching mxIdx := -1 for idx, mock := range tcsMocks { if len(mock.Spec.GenericRequests) == len(reqBuffs) { for requestIndex, reqBuff := range reqBuffs { _ = base64.StdEncoding.EncodeToString(reqBuff) encoded, _ := util.DecodeBase64(mock.Spec.GenericRequests[requestIndex].Message[0].Data) similarity := fuzzyCheck(encoded, reqBuff) if mxSim < similarity { mxSim = similarity mxIdx = idx } } } } return mxIdx }
------------------

--- Chunk 5---
func fuzzyCheck(encoded, reqBuf []byte) float64 { k := util.AdaptiveK(len(reqBuf), 3, 8, 5) shingles1 := util.CreateShingles(encoded, k) shingles2 := util.CreateShingles(reqBuf, k) similarity := util.JaccardSimilarity(shingles1, shingles2) return similarity }
------------------

--- Chunk 6---
func findExactMatch(tcsMocks []*models.Mock, reqBuffs [][]byte) int { for idx, mock := range tcsMocks { if len(mock.Spec.GenericRequests) == len(reqBuffs) { matched := true // Flag to track if all requests match for requestIndex, reqBuff := range reqBuffs { bufStr := string(reqBuff) if !util.IsASCII(string(reqBuff)) { bufStr = util.EncodeBase64(reqBuff) } // Compare the encoded data if mock.Spec.GenericRequests[requestIndex].Message[0].Data != bufStr { matched = false break // Exit the loop if any request doesn't match } } if matched { return idx } } } return -1 }
------------------

--- File: pkg/core/proxy/integrations/grpc/decode.go---

--- Chunk 1---
func decodeGrpc(ctx context.Context, logger *zap.Logger, _ []byte, clientConn net.Conn, _ *models.ConditionalDstCfg, mockDb integrations.MockMemDb, _ models.OutgoingOptions) error { framer := http2.NewFramer(clientConn, clientConn) srv := NewTranscoder(logger, framer, mockDb) // fake server in the test mode err := srv.ListenAndServe(ctx) if err != nil { if err == io.EOF { // EOF is expected when the server closes the connection. logger.Debug("EOF while serving grpc request") return nil } utils.LogError(logger, nil, "could not serve grpc request") return err } return nil }
------------------

--- File: pkg/core/proxy/integrations/grpc/encode.go---

--- Chunk 1---
Function encodeGrpc (start): func encodeGrpc(ctx context.Context, logger *zap.Logger, reqBuf []byte, clientConn, destConn net.Conn, mocks chan<- *models.Mock, _ models.OutgoingOptions) error { // Send the client preface to the server. This should be the first thing sent from the client. _, err := destConn.Write(reqBuf) if err != nil { utils.LogError(logger, err, "Could not write preface onto the destination server") return err } if ctx.Err() != nil { return ctx.Err() } streamInfoCollection := NewStreamInfoCollection() reqFromClient := true serverSideDecoder := NewDecoder() // get the error group from the context g := ctx.Value(models.ErrGroupKey).(*errgroup.Group) errCh := make(chan error, 2) defer close(errCh) // Route requests from the client to the server. g.Go(func() error { defer pUtil.Recover(logger, clientConn, destConn) err := transferFrame(ctx, logger, destConn, clientConn, streamInfoCollection, reqFromClient, serverSideDecoder, mocks) if err != nil { // check for EOF error if err == io
------------------

--- Chunk 2---
Function encodeGrpc (part 2): .EOF { logger.Debug("EOF error received from client. Closing conn") return nil } utils.LogError(logger, err, "failed to transfer frame from client to server") if ctx.Err() != nil { //to avoid sending error to the closed channel if the context is cancelled return ctx.Err() } errCh <- err } return nil }) // Route response from the server to the client. clientSideDecoder := NewDecoder() g.Go(func() error { defer pUtil.Recover(logger, clientConn, destConn) err := transferFrame(ctx, logger, clientConn, destConn, streamInfoCollection, !reqFromClient, clientSideDecoder, mocks) if err != nil { utils.LogError(logger, err, "failed to transfer frame from server to client") if ctx.Err() != nil { //to avoid sending error to the closed channel if the context is cancelled return ctx.Err() } errCh <- err } return nil }) select { case <-ctx.Done(): return ctx.Err() case err := <-errCh: if err == io.EOF { return nil }
------------------

--- Chunk 3---
Function encodeGrpc (end): return err } // This would practically be an infinite loop, unless the client closes the grpc conn // during the runtime of the application. // A grpc server/client terminating after some time maybe intentional. }
------------------

--- File: pkg/core/proxy/integrations/grpc/frame.go---

--- Chunk 1---
Function transferFrame (start): func transferFrame(ctx context.Context, _ *zap.Logger, lhs net.Conn, rhs net.Conn, sic *StreamInfoCollection, reqFromClient bool, decoder *hpack.Decoder, mocks chan<- *models.Mock) error { respFromServer := !reqFromClient framer := http2.NewFramer(lhs, rhs) for { select { case <-ctx.Done(): return ctx.Err() default: frame, err := framer.ReadFrame() if err != nil { if err == io.EOF { return err } return fmt.Errorf("error reading frame %v", err) } switch frame := frame.(type) { case *http2.SettingsFrame: settingsFrame := frame if settingsFrame.IsAck() { // Transfer Ack. if err := framer.WriteSettingsAck(); err != nil { return fmt.Errorf("could not write ack for settings frame: %v", err) } } else { var settingsCollection []http2.Setting err = settingsFrame.ForeachSetting(func(setting http2.Setting) error { settingsCollection = append(settingsCollection, setting) return nil }) if
------------------

--- Chunk 2---
Function transferFrame (part 2): err != nil { return fmt.Errorf("could not read settings from settings frame: %v", err) } if err := framer.WriteSettings(settingsCollection...); err != nil { return fmt.Errorf("could not write settings fraame: %v", err) } } case *http2.HeadersFrame: headersFrame := frame streamID := headersFrame.StreamID err := framer.WriteHeaders(http2.HeadersFrameParam{ StreamID: streamID, BlockFragment: headersFrame.HeaderBlockFragment(), EndStream: headersFrame.StreamEnded(), EndHeaders: headersFrame.HeadersEnded(), PadLength: 0, Priority: headersFrame.Priority, }) if err != nil { return fmt.Errorf("could not write headers frame: %v", err) } pseudoHeaders, ordinaryHeaders, err := extractHeaders(headersFrame, decoder) if err != nil { return fmt.Errorf("could not extract headers from frame: %v", err) } if reqFromClient { sic.AddHeadersForRequest(streamID, pseudoHeaders, true) sic.AddHeadersForRequest
------------------

--- Chunk 3---
Function transferFrame (part 3): (streamID, ordinaryHeaders, false) } else if respFromServer { if headersFrame.StreamEnded() { // Trailers â€” filter grpc-* as trailer, rest as normal headers pseudoNormal, pseudoTrailer := splitGrpcTrailerHeaders(pseudoHeaders) ordinaryNormal, ordinaryTrailer := splitGrpcTrailerHeaders(ordinaryHeaders) // Add "normal" parts as headers (still appears in trailers, but your system might need this distinction) sic.AddHeadersForResponse(streamID, pseudoNormal, true, false) sic.AddHeadersForResponse(streamID, ordinaryNormal, false, false) // Add "grpc-" keys as actual trailers sic.AddHeadersForResponse(streamID, pseudoTrailer, true, true) sic.AddHeadersForResponse(streamID, ordinaryTrailer, false, true) } else { // Just regular headers sic.AddHeadersForResponse(streamID, pseudoHeaders, true, false) sic.AddHeadersForResponse(streamID, ordinaryHeaders, false, false) } } // The trailers frame has been received. The stream has been closed by the server
------------------

--- Chunk 4---
Function transferFrame (part 4): . // Capture the mock and clear the map, as the stream ID can be reused by client. if respFromServer && headersFrame.StreamEnded() { sic.PersistMockForStream(ctx, streamID, mocks) sic.ResetStream(streamID) } case *http2.DataFrame: dataFrame := frame err := framer.WriteData(dataFrame.StreamID, dataFrame.StreamEnded(), dataFrame.Data()) if err != nil { return fmt.Errorf("could not write data frame: %v", err) } if reqFromClient { // Capturing the request timestamp sic.ReqTimestampMock = time.Now() sic.AddPayloadForRequest(dataFrame.StreamID, dataFrame.Data()) } else if respFromServer { // Capturing the response timestamp sic.ResTimestampMock = time.Now() sic.AddPayloadForResponse(dataFrame.StreamID, dataFrame.Data()) } case *http2.PingFrame: pingFrame := frame err := framer.WritePing(pingFrame.IsAck(), pingFrame.Data) if err != nil { return fmt.Errorf("could not write ACK
------------------

--- Chunk 5---
Function transferFrame (part 5): for ping: %v", err) } case *http2.WindowUpdateFrame: windowUpdateFrame := frame err := framer.WriteWindowUpdate(windowUpdateFrame.StreamID, windowUpdateFrame.Increment) if err != nil { return fmt.Errorf("could not write window tools frame: %v", err) } case *http2.ContinuationFrame: continuationFrame := frame err := framer.WriteContinuation(continuationFrame.StreamID, continuationFrame.HeadersEnded(), continuationFrame.HeaderBlockFragment()) if err != nil { return fmt.Errorf("could not write continuation frame: %v", err) } case *http2.PriorityFrame: priorityFrame := frame err := framer.WritePriority(priorityFrame.StreamID, priorityFrame.PriorityParam) if err != nil { return fmt.Errorf("could not write priority frame: %v", err) } case *http2.RSTStreamFrame: rstStreamFrame := frame err := framer.WriteRSTStream(rstStreamFrame.StreamID, rstStreamFrame.ErrCode) if err != nil { return fmt.Errorf("could not write
------------------

--- Chunk 6---
Function transferFrame (end): reset stream frame: %v", err) } case *http2.GoAwayFrame: goAwayFrame := frame err := framer.WriteGoAway(goAwayFrame.StreamID, goAwayFrame.ErrCode, goAwayFrame.DebugData()) if err != nil { return fmt.Errorf("could not write GoAway frame: %v", err) } case *http2.PushPromiseFrame: pushPromiseFrame := frame err := framer.WritePushPromise(http2.PushPromiseParam{ StreamID: pushPromiseFrame.StreamID, PromiseID: pushPromiseFrame.PromiseID, BlockFragment: pushPromiseFrame.HeaderBlockFragment(), EndHeaders: pushPromiseFrame.HeadersEnded(), PadLength: 0, }) if err != nil { return fmt.Errorf("could not write PushPromise frame: %v", err) } } } } }
------------------

--- Chunk 7---
func splitGrpcTrailerHeaders(headers map[string]string) (normal map[string]string, trailer map[string]string) { normal = make(map[string]string) trailer = make(map[string]string) for k, v := range headers { if strings.HasPrefix(k, "grpc-") { trailer[k] = v } else { normal[k] = v } } return }
------------------

--- Chunk 8---
func extractHeaders(frame *http2.HeadersFrame, decoder *hpack.Decoder) (pseudoHeaders, ordinaryHeaders map[string]string, err error) { hf, err := decoder.DecodeFull(frame.HeaderBlockFragment()) if err != nil { return nil, nil, fmt.Errorf("could not decode headers: %v", err) } pseudoHeaders = make(map[string]string) ordinaryHeaders = make(map[string]string) for _, header := range hf { if header.IsPseudo() { pseudoHeaders[header.Name] = header.Value } else { ordinaryHeaders[header.Name] = header.Value } } return pseudoHeaders, ordinaryHeaders, nil }
------------------

--- File: pkg/core/proxy/integrations/grpc/grpc.go---

--- Chunk 1---
func init() { integrations.Register(integrations.GRPC, &integrations.Parsers{ Initializer: New, Priority: 100, }) }
------------------

--- Chunk 2---
func New(logger *zap.Logger) integrations.Integrations { return &Grpc{ logger: logger, } }
------------------

--- Chunk 3---
func (g *Grpc) MatchType(_ context.Context, reqBuf []byte) bool { return bytes.HasPrefix(reqBuf[:], []byte("PRI * HTTP/2")) }
------------------

--- Chunk 4---
func (g *Grpc) RecordOutgoing(ctx context.Context, src net.Conn, dst net.Conn, mocks chan<- *models.Mock, opts models.OutgoingOptions) error { logger := g.logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", src.RemoteAddr().String())) reqBuf, err := util.ReadInitialBuf(ctx, logger, src) if err != nil { utils.LogError(logger, err, "failed to read the initial grpc message") return err } err = encodeGrpc(ctx, logger, reqBuf, src, dst, mocks, opts) if err != nil { utils.LogError(logger, err, "failed to encode the grpc message into the yaml") return err } return nil }
------------------

--- Chunk 5---
func (g *Grpc) MockOutgoing(ctx context.Context, src net.Conn, dstCfg *models.ConditionalDstCfg, mockDb integrations.MockMemDb, opts models.OutgoingOptions) error { logger := g.logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", src.RemoteAddr().String())) reqBuf, err := util.ReadInitialBuf(ctx, logger, src) if err != nil { utils.LogError(logger, err, "failed to read the initial grpc message") return err } err = decodeGrpc(ctx, logger, reqBuf, src, dstCfg, mockDb, opts) if err != nil { utils.LogError(logger, err, "failed to decode the grpc message from the yaml") return err } return nil }
------------------

--- File: pkg/core/proxy/integrations/grpc/match.go---

--- Chunk 1---
func FilterMocksRelatedToGrpc(mocks []*models.Mock) []*models.Mock { var res []*models.Mock for _, mock := range mocks { if mock != nil && mock.Kind == models.GRPC_EXPORT && mock.Spec.GRPCReq != nil && mock.Spec.GRPCResp != nil { res = append(res, mock) } } return res }
------------------

--- Chunk 2---
Function FilterMocksBasedOnGrpcRequest (start): func FilterMocksBasedOnGrpcRequest(ctx context.Context, logger *zap.Logger, grpcReq models.GrpcReq, mockDb integrations.MockMemDb) (*models.Mock, error) { for { select { case <-ctx.Done(): return nil, ctx.Err() default: mocks, err := mockDb.GetFilteredMocks() if err != nil { return nil, fmt.Errorf("error while getting tsc mocks %v", err) } var matchedMock *models.Mock var isMatched bool grpcMocks := FilterMocksRelatedToGrpc(mocks) if len(grpcMocks) == 0 { logger.Debug("No grpc mocks found in the db") return nil, nil } logger.Debug("Here are the grpc mocks in the db", zap.Int("len", len(grpcMocks)), zap.Any("grpcMocks", grpcMocks)) schemaMatched, err := schemaMatch(ctx, grpcReq, grpcMocks) if err != nil { return nil, err } if len(schemaMatched) == 0 { logger.Debug("No mock found with schema match") return nil, nil }
------------------

--- Chunk 3---
Function FilterMocksBasedOnGrpcRequest (end): logger.Debug("Here are the grpc mocks with schema match", zap.Int("len", len(schemaMatched)), zap.Any("schemaMatched", schemaMatched)) // Exact body Match ok, matchedMock := exactBodyMatch(grpcReq.Body, schemaMatched) if ok { logger.Debug("Exact body match found", zap.Any("matchedMock", matchedMock)) if !mockDb.DeleteFilteredMock(*matchedMock) { continue } return matchedMock, nil } // apply fuzzy match for body with schemaMatched mocks logger.Debug("Performing fuzzy match for decoded data in body") // Perform fuzzy match on the request isMatched, bestMatch := fuzzyMatch(schemaMatched, grpcReq.Body.DecodedData) if isMatched { if !mockDb.DeleteFilteredMock(*bestMatch) { continue } return bestMatch, nil } return nil, nil } } }
------------------

--- Chunk 4---
func schemaMatch(ctx context.Context, req models.GrpcReq, mocks []*models.Mock) ([]*models.Mock, error) { var schemaMatched []*models.Mock for _, mock := range mocks { if ctx.Err() != nil { return nil, ctx.Err() } mockReq := mock.Spec.GRPCReq // the pseudo headers should defintely match. if !compareMap(mockReq.Headers.PseudoHeaders, req.Headers.PseudoHeaders) { continue } // the ordinary headers keys should match. if !compareMapKeys(mockReq.Headers.OrdinaryHeaders, req.Headers.OrdinaryHeaders) { continue } // the content type should match. if mockReq.Headers.OrdinaryHeaders["content-type"] != req.Headers.OrdinaryHeaders["content-type"] { continue } // additionally check for the compression flag here only if mockReq.Body.CompressionFlag != req.Body.CompressionFlag { continue } schemaMatched = append(schemaMatched, mock) } return schemaMatched, nil }
------------------

--- Chunk 5---
func compareMapKeys(m1, m2 map[string]string) bool { if len(m1) > len(m2) { for k := range m2 { if _, ok := m1[k]; !ok { return false } } } else { for k := range m1 { if _, ok := m2[k]; !ok { return false } } } return true }
------------------

--- Chunk 6---
func compareMap(m1, m2 map[string]string) bool { if len(m1) != len(m2) { return false } for k, v := range m1 { if v2, ok := m2[k]; !ok || v != v2 { return false } } return true }
------------------

--- Chunk 7---
func exactBodyMatch(body models.GrpcLengthPrefixedMessage, schemaMatched []*models.Mock) (bool, *models.Mock) { for _, mock := range schemaMatched { if mock.Spec.GRPCReq.Body.MessageLength == body.MessageLength && mock.Spec.GRPCReq.Body.DecodedData == body.DecodedData { return true, mock } } return false, nil }
------------------

--- Chunk 8---
func findStringMatch(req string, mockStrings []string) int { minDist := int(^uint(0) >> 1) bestMatch := -1 for idx, mock := range mockStrings { if !util.IsASCII(mock) { continue } dist := levenshtein.ComputeDistance(req, mock) if dist == 0 { return 0 } if dist < minDist { minDist = dist bestMatch = idx } } return bestMatch }
------------------

--- Chunk 9---
func findBinaryMatch(mocks []*models.Mock, reqBuff []byte) int { mxSim := -1.0 mxIdx := -1 // find the fuzzy hash of the mocks for idx, mock := range mocks { encoded := []byte(mock.Spec.GRPCReq.Body.DecodedData) k := util.AdaptiveK(len(reqBuff), 3, 8, 5) shingles1 := util.CreateShingles(encoded, k) shingles2 := util.CreateShingles(reqBuff, k) similarity := util.JaccardSimilarity(shingles1, shingles2) // log.Debugf("Jaccard Similarity:%f\n", similarity) if mxSim < similarity { mxSim = similarity mxIdx = idx } } return mxIdx }
------------------

--- Chunk 10---
func fuzzyMatch(tcsMocks []*models.Mock, reqBuff string) (bool, *models.Mock) { // String-based fuzzy matching mockStrings := make([]string, len(tcsMocks)) for i := range tcsMocks { mockStrings[i] = tcsMocks[i].Spec.GRPCReq.Body.DecodedData } if util.IsASCII(reqBuff) { idx := findStringMatch(string(reqBuff), mockStrings) if idx != -1 { return true, tcsMocks[idx] } } idx := findBinaryMatch(tcsMocks, []byte(reqBuff)) if idx != -1 { return true, tcsMocks[idx] } return false, nil }
------------------

--- File: pkg/core/proxy/integrations/grpc/stream.go---

--- Chunk 1---
func NewStreamInfoCollection() *StreamInfoCollection { return &StreamInfoCollection{ StreamInfo: make(map[uint32]models.GrpcStream), } }
------------------

--- Chunk 2---
func (sic *StreamInfoCollection) InitialiseStream(streamID uint32) { sic.mutex.Lock() defer sic.mutex.Unlock() _, ok := sic.StreamInfo[streamID] if !ok { sic.StreamInfo[streamID] = models.NewGrpcStream(streamID) } }
------------------

--- Chunk 3---
func (sic *StreamInfoCollection) AddHeadersForRequest(streamID uint32, headers map[string]string, isPseudo bool) { // Initialise the stream before acquiring the lock for yourself. sic.InitialiseStream(streamID) sic.mutex.Lock() defer sic.mutex.Unlock() for key, value := range headers { if isPseudo { sic.StreamInfo[streamID].GrpcReq.Headers.PseudoHeaders[key] = value } else { sic.StreamInfo[streamID].GrpcReq.Headers.OrdinaryHeaders[key] = value } } }
------------------

--- Chunk 4---
func (sic *StreamInfoCollection) AddHeadersForResponse(streamID uint32, headers map[string]string, isPseudo, isTrailer bool) { // Initialise the stream before acquiring the lock for yourself. sic.InitialiseStream(streamID) sic.mutex.Lock() defer sic.mutex.Unlock() for key, value := range headers { if isTrailer { if isPseudo { sic.StreamInfo[streamID].GrpcResp.Trailers.PseudoHeaders[key] = value } else { sic.StreamInfo[streamID].GrpcResp.Trailers.OrdinaryHeaders[key] = value } } else { if isPseudo { sic.StreamInfo[streamID].GrpcResp.Headers.PseudoHeaders[key] = value } else { sic.StreamInfo[streamID].GrpcResp.Headers.OrdinaryHeaders[key] = value } } } }
------------------

--- Chunk 5---
func (sic *StreamInfoCollection) AddPayloadForRequest(streamID uint32, payload []byte) { sic.mutex.Lock() defer sic.mutex.Unlock() info := sic.StreamInfo[streamID] info.ReqRawData = append(info.ReqRawData, payload...) if !info.ReqPrefixParsed && len(info.ReqRawData) >= 5 { info.ReqExpectedLength = binary.BigEndian.Uint32(info.ReqRawData[1:5]) info.ReqPrefixParsed = true } totalLen := 5 + int(info.ReqExpectedLength) if info.ReqPrefixParsed && len(info.ReqRawData) >= totalLen { info.GrpcReq.Body = pkg.CreateLengthPrefixedMessageFromPayload(info.ReqRawData[:totalLen]) } sic.StreamInfo[streamID] = info }
------------------

--- Chunk 6---
func (sic *StreamInfoCollection) AddPayloadForResponse(streamID uint32, payload []byte) { sic.mutex.Lock() defer sic.mutex.Unlock() info := sic.StreamInfo[streamID] info.RespRawData = append(info.RespRawData, payload...) if !info.RespPrefixParsed && len(info.RespRawData) >= 5 { info.RespExpectedLength = binary.BigEndian.Uint32(info.RespRawData[1:5]) info.RespPrefixParsed = true } totalLen := 5 + int(info.RespExpectedLength) if info.RespPrefixParsed && len(info.RespRawData) >= totalLen { info.GrpcResp.Body = pkg.CreateLengthPrefixedMessageFromPayload(info.RespRawData[:totalLen]) } sic.StreamInfo[streamID] = info }
------------------

--- Chunk 7---
func (sic *StreamInfoCollection) PersistMockForStream(ctx context.Context, streamID uint32, mocks chan<- *models.Mock) { sic.mutex.Lock() defer sic.mutex.Unlock() grpcReq := sic.StreamInfo[streamID].GrpcReq grpcResp := sic.StreamInfo[streamID].GrpcResp metadata := make(map[string]string) metadata["connID"] = ctx.Value(models.ClientConnectionIDKey).(string) // save the mock mocks <- &models.Mock{ Version: models.GetVersion(), Name: "mocks", Kind: models.GRPC_EXPORT, Spec: models.MockSpec{ Metadata: metadata, GRPCReq: &grpcReq, GRPCResp: &grpcResp, ReqTimestampMock: sic.ReqTimestampMock, ResTimestampMock: sic.ResTimestampMock, }, } }
------------------

--- Chunk 8---
func (sic *StreamInfoCollection) FetchRequestForStream(streamID uint32) models.GrpcReq { sic.mutex.Lock() defer sic.mutex.Unlock() return sic.StreamInfo[streamID].GrpcReq }
------------------

--- Chunk 9---
func (sic *StreamInfoCollection) ResetStream(streamID uint32) { sic.mutex.Lock() defer sic.mutex.Unlock() delete(sic.StreamInfo, streamID) }
------------------

--- File: pkg/core/proxy/integrations/grpc/transcoder.go---

--- Chunk 1---
func NewTranscoder(logger *zap.Logger, framer *http2.Framer, mockDb integrations.MockMemDb) *Transcoder { return &Transcoder{ logger: logger, framer: framer, mockDb: mockDb, sic: NewStreamInfoCollection(), decoder: NewDecoder(), } }
------------------

--- Chunk 2---
func (srv *Transcoder) WriteInitialSettingsFrame() error { var settings []http2.Setting // TODO : Get Settings from config file. settings = append(settings, http2.Setting{ ID: http2.SettingMaxFrameSize, Val: MAX_FRAME_SIZE, }) return srv.framer.WriteSettings(settings...) }
------------------

--- Chunk 3---
func (srv *Transcoder) ProcessPingFrame(pingFrame *http2.PingFrame) error { if pingFrame.IsAck() { // An endpoint MUST NOT respond to PING frames containing this flag. return nil } if pingFrame.StreamID != 0 { // "PING frames are not associated with any individual // stream. If a PING frame is received with a stream // identifier field value other than 0x0, the recipient MUST // respond with a conn error (Section 5.4.1) of type // PROTOCOL_ERROR." utils.LogError(srv.logger, nil, "As per HTTP/2 spec, stream ID for PING frame should be zero.", zap.Any("stream_id", pingFrame.StreamID)) return http2.ConnectionError(http2.ErrCodeProtocol) } // Write the ACK for the PING request. return srv.framer.WritePing(true, pingFrame.Data) }
------------------

--- Chunk 4---
Function ProcessDataFrame (start): func (srv *Transcoder) ProcessDataFrame(ctx context.Context, dataFrame *http2.DataFrame) error { id := dataFrame.Header().StreamID // DATA frame must be associated with a stream if id == 0 { utils.LogError(srv.logger, nil, "As per HTTP/2 spec, DATA frame must be associated with a stream.", zap.Any("stream_id", id)) return http2.ConnectionError(http2.ErrCodeProtocol) } srv.sic.AddPayloadForRequest(id, dataFrame.Data()) if dataFrame.StreamEnded() { defer srv.sic.ResetStream(dataFrame.StreamID) } grpcReq := srv.sic.FetchRequestForStream(id) srv.logger.Debug("Getting mock for request from the mock database", zap.Any("request", grpcReq)) // Fetch all the mocks. We can't assume that the grpc calls are made in a certain order. mock, err := FilterMocksBasedOnGrpcRequest(ctx, srv.logger, grpcReq, srv.mockDb) if err != nil { return fmt.Errorf("failed match mocks: %v", err) } if mock == nil { return fmt.Errorf("failed to mock the output for unrecorded outgoing grpc call")
------------------

--- Chunk 5---
Function ProcessDataFrame (part 2): } srv.logger.Debug("Found a mock for the request", zap.Any("mock", mock)) grpcMockResp := mock.Spec.GRPCResp // First, send the headers frame. buf := new(bytes.Buffer) encoder := hpack.NewEncoder(buf) // The pseudo headers should be written before ordinary ones. for key, value := range grpcMockResp.Headers.PseudoHeaders { err := encoder.WriteField(hpack.HeaderField{ Name: key, Value: value, }) if err != nil { utils.LogError(srv.logger, err, "could not encode pseudo header", zap.Any("key", key), zap.Any("value", value)) return err } } for key, value := range grpcMockResp.Headers.OrdinaryHeaders { err := encoder.WriteField(hpack.HeaderField{ Name: key, Value: value, }) if err != nil { utils.LogError(srv.logger, err, "could not encode ordinary header", zap.Any("key", key), zap.Any("value", value)) return err } } // The headers are prepared. Write the frame. srv.logger.Debug("Writing the first set
------------------

--- Chunk 6---
Function ProcessDataFrame (part 3): of headers in a new HEADER frame.") err = srv.framer.WriteHeaders(http2.HeadersFrameParam{ StreamID: id, BlockFragment: buf.Bytes(), EndStream: false, EndHeaders: true, }) if err != nil { utils.LogError(srv.logger, err, "could not write the first set of headers onto client") return err } payload, err := pkg.CreatePayloadFromLengthPrefixedMessage(grpcMockResp.Body) if err != nil { utils.LogError(srv.logger, err, "could not create grpc payload from mocks") return err } srv.logger.Debug("Writing the payload in a DATA frame", zap.Int("payload length", len(payload))) // Write the DATA frame with the payload. err = srv.WriteData(ctx, id, payload) if err != nil { utils.LogError(srv.logger, err, "could not write the data frame onto the client") return err } // Reset the buffer and start with a new encoding. buf = new(bytes.Buffer) encoder = hpack.NewEncoder(buf) srv.logger.Debug("preparing the trailers in a different HEADER frame") //Prepare the trailers. //The
------------------

--- Chunk 7---
Function ProcessDataFrame (part 4): pseudo headers should be written before ordinary ones. for key, value := range grpcMockResp.Trailers.PseudoHeaders { err := encoder.WriteField(hpack.HeaderField{ Name: key, Value: value, }) if err != nil { utils.LogError(srv.logger, err, "could not encode pseudo header", zap.Any("key", key), zap.Any("value", value)) return err } } for key, value := range grpcMockResp.Trailers.OrdinaryHeaders { err := encoder.WriteField(hpack.HeaderField{ Name: key, Value: value, }) if err != nil { utils.LogError(srv.logger, err, "could not encode ordinary header", zap.Any("key", key), zap.Any("value", value)) return err } } // The trailer is prepared. Write the frame. srv.logger.Debug("Writing the trailers in a different HEADER frame") err = srv.framer.WriteHeaders(http2.HeadersFrameParam{ StreamID: id, BlockFragment: buf.Bytes(), EndStream: true, EndHeaders: true, }) if err != nil {
------------------

--- Chunk 8---
Function ProcessDataFrame (end): utils.LogError(srv.logger, err, "could not write the trailers onto client") return err } return nil }
------------------

--- Chunk 9---
Function WriteData (start): func (srv *Transcoder) WriteData(ctx context.Context, streamID uint32, payload []byte) error { totalLen := len(payload) // Fast path: if payload fits in one frame if totalLen <= MAX_FRAME_SIZE { select { case <-ctx.Done(): srv.logger.Warn("context cancelled before writing single frame") return ctx.Err() default: err := srv.framer.WriteData(streamID, false, payload) if err != nil { utils.LogError(srv.logger, err, "could not write data frame") return err } return nil } } // Chunked path offset := 0 for offset < totalLen { // Check for context cancellation before each write select { case <-ctx.Done(): srv.logger.Warn("context cancelled during chunked frame write") return ctx.Err() default: } remaining := totalLen - offset chunkSize := min(remaining, MAX_FRAME_SIZE) end := offset + chunkSize data := payload[offset:end] srv.logger.Debug("Writing chunked data frame", zap.Int("chunk size", chunkSize), zap.Int("
------------------

--- Chunk 10---
Function WriteData (end): offset", offset), zap.Int("end", end)) err := srv.framer.WriteData(streamID, false, data) if err != nil { utils.LogError(srv.logger, err, "could not write chunked data frame") return err } offset = end if offset == totalLen { srv.logger.Debug("the offset is equal to the total length of the payload", zap.Int("offset", offset)) } } return nil }
------------------

--- Chunk 11---
func (srv *Transcoder) ProcessWindowUpdateFrame(_ *http2.WindowUpdateFrame) error { // Silently ignore Window tools frames, as we already know the mock payloads that we would send. srv.logger.Debug("Received Window Update Frame. Skipping it...") return nil }
------------------

--- Chunk 12---
func (srv *Transcoder) ProcessResetStreamFrame(resetStreamFrame *http2.RSTStreamFrame) error { srv.sic.ResetStream(resetStreamFrame.StreamID) return nil }
------------------

--- Chunk 13---
func (srv *Transcoder) ProcessSettingsFrame(settingsFrame *http2.SettingsFrame) error { // ACK the settings and silently skip the processing. // There is no actual server to tune the settings on. We already know the default settings from record mode. // TODO : Add support for dynamically updating the settings. if !settingsFrame.IsAck() { return srv.framer.WriteSettingsAck() } return nil }
------------------

--- Chunk 14---
func (srv *Transcoder) ProcessGoAwayFrame(_ *http2.GoAwayFrame) error { // We do not support a client that requests a server to shut down during test mode. Warn the user. // TODO : Add support for dynamically shutting down mock server using a channel to send close request. srv.logger.Warn("Received GoAway Frame. Ideally, clients should not close server during test mode.") return nil }
------------------

--- Chunk 15---
func (srv *Transcoder) ProcessPriorityFrame(_ *http2.PriorityFrame) error { // We do not support reordering of frames based on priority, because we flush after each response. // Silently skip it. srv.logger.Debug("Received PRIORITY frame, Skipping it...") return nil }
------------------

--- Chunk 16---
func (srv *Transcoder) ProcessHeadersFrame(headersFrame *http2.HeadersFrame) error { id := headersFrame.StreamID // Streams initiated by a client MUST use odd-numbered stream identifiers if id%2 != 1 { utils.LogError(srv.logger, nil, "As per HTTP/2 spec, stream_id must be odd for a client if conn init by client.", zap.Any("stream_id", id)) return http2.ConnectionError(http2.ErrCodeProtocol) } pseudoHeaders, ordinaryHeaders, err := extractHeaders(headersFrame, srv.decoder) if err != nil { utils.LogError(srv.logger, err, "could not extract headers from frame") } srv.sic.AddHeadersForRequest(id, pseudoHeaders, true) srv.sic.AddHeadersForRequest(id, ordinaryHeaders, false) return nil }
------------------

--- Chunk 17---
func (srv *Transcoder) ProcessPushPromise(_ *http2.PushPromiseFrame) error { // A client cannot push. Thus, servers MUST treat the receipt of a PUSH_PROMISE // frame as a conn error (Section 5.4.1) of type PROTOCOL_ERROR. utils.LogError(srv.logger, nil, "As per HTTP/2 spec, client cannot send PUSH_PROMISE.") return http2.ConnectionError(http2.ErrCodeProtocol) }
------------------

--- Chunk 18---
func (srv *Transcoder) ProcessContinuationFrame(_ *http2.ContinuationFrame) error { // Continuation frame support is overkill currently because the headers won't exceed the frame size // used by our mock server. // However, if we really need this feature, we can implement it later. utils.LogError(srv.logger, nil, "Continuation Frame received. This is unsupported currently") return fmt.Errorf("continuation frame is unsupported in the current implementation") }
------------------

--- Chunk 19---
func (srv *Transcoder) ProcessGenericFrame(ctx context.Context, frame http2.Frame) error { var err error switch frame := frame.(type) { case *http2.PingFrame: err = srv.ProcessPingFrame(frame) case *http2.DataFrame: err = srv.ProcessDataFrame(ctx, frame) case *http2.WindowUpdateFrame: err = srv.ProcessWindowUpdateFrame(frame) case *http2.RSTStreamFrame: err = srv.ProcessResetStreamFrame(frame) case *http2.SettingsFrame: err = srv.ProcessSettingsFrame(frame) case *http2.GoAwayFrame: err = srv.ProcessGoAwayFrame(frame) case *http2.PriorityFrame: err = srv.ProcessPriorityFrame(frame) case *http2.HeadersFrame: err = srv.ProcessHeadersFrame(frame) case *http2.PushPromiseFrame: err = srv.ProcessPushPromise(frame) case *http2.ContinuationFrame: err = srv.ProcessContinuationFrame(frame) default: err = fmt.Errorf("unknown frame received from the client") } return err }
------------------

--- Chunk 20---
func (srv *Transcoder) ListenAndServe(ctx context.Context) error { err := srv.WriteInitialSettingsFrame() if err != nil { utils.LogError(srv.logger, err, "could not write initial settings frame") return err } for { select { case <-ctx.Done(): return ctx.Err() default: frame, err := srv.framer.ReadFrame() if err != nil { if err == io.EOF { srv.logger.Debug("EOF reached. Closing the connection.") return io.EOF } utils.LogError(srv.logger, err, "Failed to read frame") return err } if ctx.Err() != nil { return ctx.Err() } err = srv.ProcessGenericFrame(ctx, frame) if err != nil { return err } } } }
------------------

--- File: pkg/core/proxy/integrations/grpc/util.go---

--- Chunk 1---
func NewDecoder() *hpack.Decoder { return hpack.NewDecoder(KmaxDynamicTableSize, nil) }
------------------

--- File: pkg/core/proxy/integrations/http/chunk.go---

--- Chunk 1---
Function HandleChunkedRequests (start): func (h *HTTP) HandleChunkedRequests(ctx context.Context, finalReq *[]byte, clientConn, destConn net.Conn) error { if hasCompleteHeaders(*finalReq) { h.Logger.Debug("this request has complete headers in the first chunk itself.") } for !hasCompleteHeaders(*finalReq) { h.Logger.Debug("couldn't get complete headers in first chunk so reading more chunks") reqHeader, err := pUtil.ReadBytes(ctx, h.Logger, clientConn) if err != nil { utils.LogError(h.Logger, nil, "failed to read the request message from the client") return err } // destConn is nil in case of test mode if destConn != nil { _, err = destConn.Write(reqHeader) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(h.Logger, nil, "failed to write request message to the destination server") return err } } *finalReq = append(*finalReq, reqHeader...) } lines := strings.Split(string(*finalReq), "\n") var contentLengthHeader string var transferEncodingHeader string
------------------

--- Chunk 2---
Function HandleChunkedRequests (part 2): for _, line := range lines { if strings.HasPrefix(line, "Content-Length:") { contentLengthHeader = strings.TrimSpace(strings.TrimPrefix(line, "Content-Length:")) break } else if strings.HasPrefix(line, "Transfer-Encoding:") { transferEncodingHeader = strings.TrimSpace(strings.TrimPrefix(line, "Transfer-Encoding:")) break } } //Handle chunked requests if contentLengthHeader != "" { contentLength, err := strconv.Atoi(contentLengthHeader) if err != nil { utils.LogError(h.Logger, err, "failed to get the content-length header") return fmt.Errorf("failed to handle chunked request") } //Get the length of the body in the request. bodyLength := len(*finalReq) - strings.Index(string(*finalReq), "\r\n\r\n") - 4 contentLength -= bodyLength if contentLength > 0 { err := h.contentLengthRequest(ctx, finalReq, clientConn, destConn, contentLength) if err != nil { return err } } } else if transferEncodingHeader != "" { // check if the initial request is the complete
------------------

--- Chunk 3---
Function HandleChunkedRequests (end): request. if strings.HasSuffix(string(*finalReq), "0\r\n\r\n") { return nil } if transferEncodingHeader == "chunked" { err := h.chunkedRequest(ctx, finalReq, clientConn, destConn, transferEncodingHeader) if err != nil { return err } } } return nil }
------------------

--- Chunk 4---
Function contentLengthRequest (start): func (h *HTTP) contentLengthRequest(ctx context.Context, finalReq *[]byte, clientConn, destConn net.Conn, contentLength int) error { for contentLength > 0 { err := clientConn.SetReadDeadline(time.Now().Add(5 * time.Second)) if err != nil { utils.LogError(h.Logger, err, "failed to set the read deadline for the client conn") return err } requestChunked, err := pUtil.ReadBytes(ctx, h.Logger, clientConn) if err != nil { if err == io.EOF { utils.LogError(h.Logger, nil, "conn closed by the user client") return err } else if netErr, ok := err.(net.Error); ok && netErr.Timeout() { h.Logger.Info("Stopped getting data from the conn", zap.Error(err)) break } utils.LogError(h.Logger, nil, "failed to read the response message from the destination server") return err } h.Logger.Debug("This is a chunk of request[content-length]: " + string(requestChunked)) *finalReq = append(*finalReq, requestChunked...) contentLength -= len
------------------

--- Chunk 5---
Function contentLengthRequest (end): (requestChunked) // destConn is nil in case of test mode. if destConn != nil { _, err = destConn.Write(requestChunked) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(h.Logger, nil, "failed to write request message to the destination server") return err } } } return nil }
------------------

--- Chunk 6---
Function chunkedRequest (start): func (h *HTTP) chunkedRequest(ctx context.Context, finalReq *[]byte, clientConn, destConn net.Conn, _ string) error { for { select { case <-ctx.Done(): return ctx.Err() default: //TODO: we have to implement a way to read the buffer chunk wise according to the chunk size (chunk size comes in hexadecimal) // because it can happen that some chunks come after 5 seconds. err := clientConn.SetReadDeadline(time.Now().Add(5 * time.Second)) if err != nil { utils.LogError(h.Logger, err, "failed to set the read deadline for the client conn") return err } requestChunked, err := pUtil.ReadBytes(ctx, h.Logger, clientConn) if err != nil { if netErr, ok := err.(net.Error); ok && netErr.Timeout() { break } utils.LogError(h.Logger, nil, "failed to read the response message from the destination server") return err } *finalReq = append(*finalReq, requestChunked...) // destConn is nil in case of test mode. if destConn
------------------

--- Chunk 7---
Function chunkedRequest (end): != nil { _, err = destConn.Write(requestChunked) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(h.Logger, nil, "failed to write request message to the destination server") return err } } //check if the initial request is completed if strings.HasSuffix(string(requestChunked), "0\r\n\r\n") { return nil } } } }
------------------

--- Chunk 8---
Function handleChunkedResponses (start): func (h *HTTP) handleChunkedResponses(ctx context.Context, finalResp *[]byte, clientConn, destConn net.Conn, resp []byte) error { if hasCompleteHeaders(*finalResp) { h.Logger.Debug("this response has complete headers in the first chunk itself.") } for !hasCompleteHeaders(resp) { h.Logger.Debug("couldn't get complete headers in first chunk so reading more chunks") respHeader, err := pUtil.ReadBytes(ctx, h.Logger, destConn) if err != nil { if err == io.EOF { h.Logger.Debug("received EOF from the server") // if there is any buffer left before EOF, we must send it to the client and save this as mock if len(respHeader) != 0 { // write the response message to the user client _, err = clientConn.Write(resp) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(h.Logger, nil, "failed to write response message to the user client") return err } *finalResp = append(*finalResp, respHeader...) } return err
------------------

--- Chunk 9---
Function handleChunkedResponses (part 2): } utils.LogError(h.Logger, nil, "failed to read the response message from the destination server") return err } // write the response message to the user client _, err = clientConn.Write(respHeader) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(h.Logger, nil, "failed to write response message to the user client") return err } *finalResp = append(*finalResp, respHeader...) resp = append(resp, respHeader...) } //Getting the content-length or the transfer-encoding header var contentLengthHeader, transferEncodingHeader string lines := strings.Split(string(resp), "\n") for _, line := range lines { if strings.HasPrefix(line, "Content-Length:") { contentLengthHeader = strings.TrimSpace(strings.TrimPrefix(line, "Content-Length:")) break } else if strings.HasPrefix(line, "Transfer-Encoding:") { transferEncodingHeader = strings.TrimSpace(strings.TrimPrefix(line, "Transfer-Encoding:")) break } } //Handle chunked responses if contentLengthHeader != "" { contentLength, err :=
------------------

--- Chunk 10---
Function handleChunkedResponses (end): strconv.Atoi(contentLengthHeader) if err != nil { utils.LogError(h.Logger, err, "failed to get the content-length header") return fmt.Errorf("failed to handle chunked response") } bodyLength := len(resp) - strings.Index(string(resp), "\r\n\r\n") - 4 contentLength -= bodyLength if contentLength > 0 { err := h.contentLengthResponse(ctx, finalResp, clientConn, destConn, contentLength) if err != nil { return err } } } else if transferEncodingHeader != "" { //check if the initial response is the complete response. if strings.HasSuffix(string(*finalResp), "0\r\n\r\n") { return nil } if transferEncodingHeader == "chunked" { err := h.chunkedResponse(ctx, finalResp, clientConn, destConn) if err != nil { return err } } } return nil }
------------------

--- Chunk 11---
Function chunkedResponse (start): func (h *HTTP) chunkedResponse(ctx context.Context, finalResp *[]byte, clientConn, destConn net.Conn) error { isEOF := false for { select { case <-ctx.Done(): return ctx.Err() default: resp, err := pUtil.ReadBytes(ctx, h.Logger, destConn) if err != nil { if err != io.EOF { utils.LogError(h.Logger, err, "failed to read the response message from the destination server") return err } isEOF = true h.Logger.Debug("received EOF", zap.Error(err)) if len(resp) == 0 { h.Logger.Debug("exiting loop as response is complete") break } } *finalResp = append(*finalResp, resp...) // write the response message to the user client _, err = clientConn.Write(resp) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(h.Logger, nil, "failed to write response message to the user client") return err } //In some cases need to write the response to the client
------------------

--- Chunk 12---
Function chunkedResponse (end): // where there is some response before getting the true EOF if isEOF { break } if string(resp) == "0\r\n\r\n" { return nil } } } }
------------------

--- Chunk 13---
Function contentLengthResponse (start): func (h *HTTP) contentLengthResponse(ctx context.Context, finalResp *[]byte, clientConn, destConn net.Conn, contentLength int) error { isEOF := false for contentLength > 0 { resp, err := pUtil.ReadBytes(ctx, h.Logger, destConn) if err != nil { if err == io.EOF { isEOF = true h.Logger.Debug("received EOF, conn closed by the destination server") if len(resp) == 0 { break } } else if netErr, ok := err.(net.Error); ok && netErr.Timeout() { h.Logger.Info("Stopped getting data from the conn", zap.Error(err)) break } else { utils.LogError(h.Logger, nil, "failed to read the response message from the destination server") return err } } h.Logger.Debug("This is a chunk of response[content-length]: " + string(resp)) *finalResp = append(*finalResp, resp...) contentLength -= len(resp) // write the response message to the user client _, err = clientConn.Write(resp) if err != nil {
------------------

--- Chunk 14---
Function contentLengthResponse (end): if ctx.Err() != nil { return ctx.Err() } utils.LogError(h.Logger, nil, "failed to write response message to the user client") return err } if isEOF { break } } return nil }
------------------

--- File: pkg/core/proxy/integrations/http/decode.go---

--- Chunk 1---
Function decodeHTTP (start): func (h *HTTP) decodeHTTP(ctx context.Context, reqBuf []byte, clientConn net.Conn, dstCfg *models.ConditionalDstCfg, mockDb integrations.MockMemDb, opts models.OutgoingOptions) error { errCh := make(chan error, 1) go func(errCh chan error, reqBuf []byte, opts models.OutgoingOptions) { defer pUtil.Recover(h.Logger, clientConn, nil) defer close(errCh) for { //Check if the expected header is present if bytes.Contains(reqBuf, []byte("Expect: 100-continue")) { h.Logger.Debug("The expect header is present in the request buffer and writing the 100 continue response to the client") //Send the 100 continue response _, err := clientConn.Write([]byte("HTTP/1.1 100 Continue\r\n\r\n")) if err != nil { if ctx.Err() != nil { return } utils.LogError(h.Logger, err, "failed to write the 100 continue response to the user application") errCh <- err return } h.Logger.Debug("The 100 continue response has been sent to the
------------------

--- Chunk 2---
Function decodeHTTP (part 2): user application") //Read the request buffer again newRequest, err := pUtil.ReadBytes(ctx, h.Logger, clientConn) if err != nil { utils.LogError(h.Logger, err, "failed to read the request buffer from the user application") errCh <- err return } //Append the new request buffer to the old request buffer reqBuf = append(reqBuf, newRequest...) } h.Logger.Debug("handling the chunked requests to read the complete request") err := h.HandleChunkedRequests(ctx, &reqBuf, clientConn, nil) if err != nil { utils.LogError(h.Logger, err, "failed to handle chunked requests") errCh <- err return } h.Logger.Debug(fmt.Sprintf("This is the complete request:\n%v", string(reqBuf))) //Parse the request buffer request, err := http.ReadRequest(bufio.NewReader(bytes.NewReader(reqBuf))) if err != nil { utils.LogError(h.Logger, err, "failed to parse the http request message") errCh <- err return } // Set the host header explicitely because the
------------------

--- Chunk 3---
Function decodeHTTP (part 3): `http.ReadRequest`` trim the host header // func ReadRequest(b *bufio.Reader) (*Request, error) { // req, err := readRequest(b) // if err != nil { // return nil, err // } // delete(req.Header, "Host") // return req, err // } request.Header.Set("Host", request.Host) reqBody, err := io.ReadAll(request.Body) if err != nil { utils.LogError(h.Logger, err, "failed to read from request body", zap.Any("metadata", utils.GetReqMeta(request))) errCh <- err return } input := &req{ method: request.Method, url: request.URL, header: request.Header, body: reqBody, raw: reqBuf, } ok, stub, err := h.match(ctx, input, mockDb) // calling match function to match mocks if err != nil { utils.LogError(h.Logger, err, "error while matching http mocks", zap.Any("metadata", utils.GetReqMeta(request))) errCh <- err
------------------

--- Chunk 4---
Function decodeHTTP (part 4): return } h.Logger.Debug("after matching the http request", zap.Any("isMatched", ok), zap.Any("stub", stub), zap.Error(err)) if !ok { if !utils.IsPassThrough(h.Logger, request, dstCfg.Port, opts) { utils.LogError(h.Logger, nil, "Didn't match any preExisting http mock", zap.Any("metadata", utils.GetReqMeta(request))) } if opts.FallBackOnMiss { _, err = pUtil.PassThrough(ctx, h.Logger, clientConn, dstCfg, [][]byte{reqBuf}) if err != nil { utils.LogError(h.Logger, err, "failed to passThrough http request", zap.Any("metadata", utils.GetReqMeta(request))) errCh <- err return } } errCh <- nil return } if stub == nil { utils.LogError(h.Logger, nil, "matched mock is nil", zap.Any("metadata", utils.GetReqMeta(request))) errCh <- errors.New("matched mock is nil") return } statusLine := fmt.Sprintf("HTTP/%d.%d %d %s\r\n
------------------

--- Chunk 5---
Function decodeHTTP (part 5): ", stub.Spec.HTTPReq.ProtoMajor, stub.Spec.HTTPReq.ProtoMinor, stub.Spec.HTTPResp.StatusCode, http.StatusText(stub.Spec.HTTPResp.StatusCode)) body := stub.Spec.HTTPResp.Body var respBody string var responseString string // Fetching the response headers header := pkg.ToHTTPHeader(stub.Spec.HTTPResp.Header) //Check if the gzip encoding is present in the header if header["Content-Encoding"] != nil && header["Content-Encoding"][0] == "gzip" { var compressedBuffer bytes.Buffer gw := gzip.NewWriter(&compressedBuffer) _, err := gw.Write([]byte(body)) if err != nil { utils.LogError(h.Logger, err, "failed to compress the response body", zap.Any("metadata", utils.GetReqMeta(request))) errCh <- err return } err = gw.Close() if err != nil { utils.LogError(h.Logger, err, "failed to close the gzip writer", zap.Any("metadata", utils.GetReqMeta(request))) errCh <- err return } h.Logger.Debug("the length of the response body: " + strconv.Itoa(len(compressed
------------------

--- Chunk 6---
Function decodeHTTP (part 6): Buffer.String()))) respBody = compressedBuffer.String() // responseString = statusLine + headers + "\r\n" + compressedBuffer.String() } else { respBody = body // responseString = statusLine + headers + "\r\n" + body } var headers string for key, values := range header { if key == "Content-Length" { values = []string{strconv.Itoa(len(respBody))} } for _, value := range values { headerLine := fmt.Sprintf("%s: %s\r\n", key, value) headers += headerLine } } responseString = statusLine + headers + "\r\n" + "" + respBody h.Logger.Debug(fmt.Sprintf("Mock Response sending back to client:\n%v", responseString)) _, err = clientConn.Write([]byte(responseString)) if err != nil { if ctx.Err() != nil { return } utils.LogError(h.Logger, err, "failed to write the mock output to the user application", zap.Any("metadata", utils.GetReqMeta(request))) errCh <- err return }
------------------

--- Chunk 7---
Function decodeHTTP (end): reqBuf, err = pUtil.ReadBytes(ctx, h.Logger, clientConn) if err != nil { h.Logger.Debug("failed to read the request buffer from the client", zap.Error(err)) h.Logger.Debug("This was the last response from the server:\n" + string(responseString)) errCh <- nil return } } }(errCh, reqBuf, opts) select { case <-ctx.Done(): return ctx.Err() case err := <-errCh: if err == io.EOF { return nil } return err } }
------------------

--- File: pkg/core/proxy/integrations/http/encode.go---

--- Chunk 1---
Function encodeHTTP (start): func (h *HTTP) encodeHTTP(ctx context.Context, reqBuf []byte, clientConn, destConn net.Conn, mocks chan<- *models.Mock, opts models.OutgoingOptions) error { remoteAddr := destConn.RemoteAddr().(*net.TCPAddr) destPort := uint(remoteAddr.Port) //Writing the request to the server. _, err := destConn.Write(reqBuf) if err != nil { h.Logger.Error("failed to write request message to the destination server", zap.Error(err)) return err } if ctx.Err() != nil { return ctx.Err() } h.Logger.Debug("This is the initial request: " + string(reqBuf)) var finalReq []byte errCh := make(chan error, 1) finalReq = append(finalReq, reqBuf...) //get the error group from the context g, ok := ctx.Value(models.ErrGroupKey).(*errgroup.Group) if !ok { return errors.New("failed to get the error group from the context") } //for keeping conn alive g.Go(func() error { defer pUtil.Recover(h.Logger, clientConn, destConn) defer close(errCh) for { //check
------------------

--- Chunk 2---
Function encodeHTTP (part 2): if expect : 100-continue header is present lines := strings.Split(string(finalReq), "\n") var expectHeader string for _, line := range lines { if strings.HasPrefix(line, "Expect:") { expectHeader = strings.TrimSpace(strings.TrimPrefix(line, "Expect:")) break } } if expectHeader == "100-continue" { //Read if the response from the server is 100-continue resp, err := pUtil.ReadBytes(ctx, h.Logger, destConn) if err != nil { utils.LogError(h.Logger, err, "failed to read the response message from the server after 100-continue request") errCh <- err return nil } // write the response message to the client _, err = clientConn.Write(resp) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(h.Logger, err, "failed to write response message to the user client") errCh <- err return nil } h.Logger.Debug("This is the response from the server after the expect header" + string(resp))
------------------

--- Chunk 3---
Function encodeHTTP (part 3): if string(resp) != "HTTP/1.1 100 Continue\r\n\r\n" { utils.LogError(h.Logger, nil, "failed to get the 100 continue response from the user client") errCh <- err return nil } //Reading the request buffer again reqBuf, err = pUtil.ReadBytes(ctx, h.Logger, clientConn) if err != nil { utils.LogError(h.Logger, err, "failed to read the request buffer from the user client") errCh <- err return nil } // write the request message to the actual destination server _, err = destConn.Write(reqBuf) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(h.Logger, err, "failed to write request message to the destination server") errCh <- err return nil } finalReq = append(finalReq, reqBuf...) } // Capture the request timestamp reqTimestampMock := time.Now() err := h.HandleChunkedRequests(ctx, &finalReq, clientConn, destConn) if err != nil {
------------------

--- Chunk 4---
Function encodeHTTP (part 4): utils.LogError(h.Logger, err, "failed to handle chunked requests") errCh <- err return nil } h.Logger.Debug(fmt.Sprintf("This is the complete request:\n%v", string(finalReq))) // read the response from the actual server resp, err := pUtil.ReadBytes(ctx, h.Logger, destConn) if err != nil { if err == io.EOF { h.Logger.Debug("Response complete, exiting the loop.") // if there is any buffer left before EOF, we must send it to the client and save this as mock if len(resp) != 0 { // Capturing the response timestamp resTimestampMock := time.Now() // write the response message to the user client _, err = clientConn.Write(resp) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(h.Logger, err, "failed to write response message to the user client") errCh <- err return nil } // saving last request/response on this conn. m := &FinalHTTP{ Req: finalReq,
------------------

--- Chunk 5---
Function encodeHTTP (part 5): Resp: resp, ReqTimestampMock: reqTimestampMock, ResTimestampMock: resTimestampMock, } err := h.parseFinalHTTP(ctx, m, destPort, mocks, opts) if err != nil { utils.LogError(h.Logger, err, "failed to parse the final http request and response") errCh <- err return nil } } break } utils.LogError(h.Logger, err, "failed to read the response message from the destination server") errCh <- err return nil } // Capturing the response timestamp resTimestampMock := time.Now() // write the response message to the user client _, err = clientConn.Write(resp) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(h.Logger, err, "failed to write response message to the user client") errCh <- err return nil } var finalResp []byte finalResp = append(finalResp, resp...) h.Logger.Debug("This is the initial response: " + string(resp)) err =
------------------

--- Chunk 6---
Function encodeHTTP (part 6): h.handleChunkedResponses(ctx, &finalResp, clientConn, destConn, resp) if err != nil { if err == io.EOF { h.Logger.Debug("conn closed by the server", zap.Error(err)) //check if before EOF complete response came, and try to parse it. m := &FinalHTTP{ Req: finalReq, Resp: finalResp, ReqTimestampMock: reqTimestampMock, ResTimestampMock: resTimestampMock, } parseErr := h.parseFinalHTTP(ctx, m, destPort, mocks, opts) if parseErr != nil { utils.LogError(h.Logger, parseErr, "failed to parse the final http request and response") errCh <- parseErr } errCh <- nil return nil } utils.LogError(h.Logger, err, "failed to handle chunk response") errCh <- err return nil } h.Logger.Debug("This is the final response: " + string(finalResp)) m := &FinalHTTP{ Req: finalReq, Resp: finalResp, ReqTimestampMock: reqTimestampMock
------------------

--- Chunk 7---
Function encodeHTTP (part 7): , ResTimestampMock: resTimestampMock, } err = h.parseFinalHTTP(ctx, m, destPort, mocks, opts) if err != nil { utils.LogError(h.Logger, err, "failed to parse the final http request and response") errCh <- err return nil } //resetting for the new request and response. finalReq = []byte("") finalResp = []byte("") // read the request from the same connection h.Logger.Debug("Reading the request from the user client again from the same connection") finalReq, err = pUtil.ReadBytes(ctx, h.Logger, clientConn) if err != nil { if err != io.EOF { h.Logger.Debug("failed to read the request message from the user client", zap.Error(err)) h.Logger.Debug("This was the last response from the server: " + string(resp)) errCh <- nil return nil } errCh <- err return nil } // write the request message to the actual destination server _, err = destConn.Write(finalReq) if err != nil { if ctx.Err
------------------

--- Chunk 8---
Function encodeHTTP (end): () != nil { return ctx.Err() } utils.LogError(h.Logger, err, "failed to write request message to the destination server") errCh <- err return nil } } return nil }) select { case <-ctx.Done(): return ctx.Err() case err := <-errCh: if err == io.EOF { return nil } return err } }
------------------

--- File: pkg/core/proxy/integrations/http/http.go---

--- Chunk 1---
func init() { integrations.Register(integrations.HTTP, &integrations.Parsers{ Initializer: New, Priority: 100, }) }
------------------

--- Chunk 2---
func New(logger *zap.Logger) integrations.Integrations { return &HTTP{ Logger: logger, } }
------------------

--- Chunk 3---
func (h *HTTP) MatchType(_ context.Context, buf []byte) bool { isHTTP := bytes.HasPrefix(buf[:], []byte("HTTP/")) || bytes.HasPrefix(buf[:], []byte("GET ")) || bytes.HasPrefix(buf[:], []byte("POST ")) || bytes.HasPrefix(buf[:], []byte("PUT ")) || bytes.HasPrefix(buf[:], []byte("PATCH ")) || bytes.HasPrefix(buf[:], []byte("DELETE ")) || bytes.HasPrefix(buf[:], []byte("OPTIONS ")) || bytes.HasPrefix(buf[:], []byte("HEAD ")) h.Logger.Debug(fmt.Sprintf("is Http Protocol?: %v ", isHTTP)) return isHTTP }
------------------

--- Chunk 4---
func (h *HTTP) RecordOutgoing(ctx context.Context, src net.Conn, dst net.Conn, mocks chan<- *models.Mock, opts models.OutgoingOptions) error { logger := h.Logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", src.RemoteAddr().String())) h.Logger.Debug("Recording the outgoing http call in record mode") reqBuf, err := util.ReadInitialBuf(ctx, logger, src) if err != nil { utils.LogError(logger, err, "failed to read the initial http message") return err } err = h.encodeHTTP(ctx, reqBuf, src, dst, mocks, opts) if err != nil { utils.LogError(logger, err, "failed to encode the http message into the yaml") return err } return nil }
------------------

--- Chunk 5---
func (h *HTTP) MockOutgoing(ctx context.Context, src net.Conn, dstCfg *models.ConditionalDstCfg, mockDb integrations.MockMemDb, opts models.OutgoingOptions) error { h.Logger = h.Logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", src.RemoteAddr().String())) h.Logger.Debug("Mocking the outgoing http call in test mode") reqBuf, err := util.ReadInitialBuf(ctx, h.Logger, src) if err != nil { utils.LogError(h.Logger, err, "failed to read the initial http message") return err } err = h.decodeHTTP(ctx, reqBuf, src, dstCfg, mockDb, opts) if err != nil { utils.LogError(h.Logger, err, "failed to decode the http message from the yaml") return err } return nil }
------------------

--- Chunk 6---
Function parseFinalHTTP (start): func (h *HTTP) parseFinalHTTP(ctx context.Context, mock *FinalHTTP, destPort uint, mocks chan<- *models.Mock, opts models.OutgoingOptions) error { var req *http.Request // converts the request message buffer to http request req, err := http.ReadRequest(bufio.NewReader(bytes.NewReader(mock.Req))) if err != nil { utils.LogError(h.Logger, err, "failed to parse the http request message") return err } // Set the host header explicitely because the `http.ReadRequest`` trim the host header // func ReadRequest(b *bufio.Reader) (*Request, error) { // req, err := readRequest(b) // if err != nil { // return nil, err // } // delete(req.Header, "Host") // return req, err // } req.Header.Set("Host", req.Host) var reqBody []byte if req.Body != nil { // Read var err error reqBody, err = io.ReadAll(req.Body) if err != nil { // TODO right way to log errors utils.LogError(h.Logger, err, "failed to read the
------------------

--- Chunk 7---
Function parseFinalHTTP (part 2): http request body", zap.Any("metadata", utils.GetReqMeta(req))) return err } } // converts the response message buffer to http response respParsed, err := http.ReadResponse(bufio.NewReader(bytes.NewReader(mock.Resp)), req) if err != nil { utils.LogError(h.Logger, err, "failed to parse the http response message", zap.Any("metadata", utils.GetReqMeta(req))) return err } //Add the content length to the headers. var respBody []byte //Checking if the body of the response is empty or does not exist. if respParsed.Body != nil { // Read if respParsed.Header.Get("Content-Encoding") == "gzip" { check := respParsed.Body ok, reader := isGZipped(check, h.Logger) h.Logger.Debug("The body is gzip? " + strconv.FormatBool(ok)) h.Logger.Debug("", zap.Any("isGzipped", ok)) if ok { gzipReader, err := gzip.NewReader(reader) if err != nil { utils.LogError(h.Logger, err, "failed to create a gzip reader", zap.Any("metadata", utils.GetReqMeta(req))) return err
------------------

--- Chunk 8---
Function parseFinalHTTP (part 3): } respParsed.Body = gzipReader } } respBody, err = io.ReadAll(respParsed.Body) if err != nil { utils.LogError(h.Logger, err, "failed to read the the http response body", zap.Any("metadata", utils.GetReqMeta(req))) return err } h.Logger.Debug("This is the response body: " + string(respBody)) //Set the content length to the headers. respParsed.Header.Set("Content-Length", strconv.Itoa(len(respBody))) } // store the request and responses as mocks meta := map[string]string{ "name": "Http", "type": models.HTTPClient, "operation": req.Method, "connID": ctx.Value(models.ClientConnectionIDKey).(string), } // Check if the request is a passThrough request if utils.IsPassThrough(h.Logger, req, destPort, opts) { h.Logger.Debug("The request is a passThrough request", zap.Any("metadata", utils.GetReqMeta(req))) return nil } mocks <- &models.Mock{ Version: models.GetVersion(), Name: "mocks",
------------------

--- Chunk 9---
Function parseFinalHTTP (end): Kind: models.HTTP, Spec: models.MockSpec{ Metadata: meta, HTTPReq: &models.HTTPReq{ Method: models.Method(req.Method), ProtoMajor: req.ProtoMajor, ProtoMinor: req.ProtoMinor, URL: req.URL.String(), Header: pkg.ToYamlHTTPHeader(req.Header), Body: string(reqBody), URLParams: pkg.URLParams(req), }, HTTPResp: &models.HTTPResp{ StatusCode: respParsed.StatusCode, Header: pkg.ToYamlHTTPHeader(respParsed.Header), Body: string(respBody), }, Created: time.Now().Unix(), ReqTimestampMock: mock.ReqTimestampMock, ResTimestampMock: mock.ResTimestampMock, }, } return nil }
------------------

--- File: pkg/core/proxy/integrations/http/match.go---

--- Chunk 1---
Function match (start): func (h *HTTP) match(ctx context.Context, input *req, mockDb integrations.MockMemDb) (bool, *models.Mock, error) { for { if ctx.Err() != nil { return false, nil, ctx.Err() } // Fetch and filter HTTP mocks mocks, err := mockDb.GetUnFilteredMocks() if err != nil { utils.LogError(h.Logger, err, "failed to get unfilteredMocks mocks") return false, nil, errors.New("error while matching the request with the mocks") } unfilteredMocks := FilterHTTPMocks(mocks) h.Logger.Debug(fmt.Sprintf("Length of unfilteredMocks:%v", len(unfilteredMocks))) // Matching process schemaMatched, err := h.SchemaMatch(ctx, input, unfilteredMocks) if err != nil { return false, nil, err } if len(schemaMatched) == 0 { return false, nil, nil } // Exact body match ok, bestMatch := h.ExactBodyMatch(input.body, schemaMatched) if ok { if !h.updateMock(ctx, bestMatch,
------------------

--- Chunk 2---
Function match (part 2): mockDb) { continue } return true, bestMatch, nil } shortListed := schemaMatched // Schema match for JSON bodies if pkg.IsJSON(input.body) { bodyMatched, err := h.PerformBodyMatch(ctx, schemaMatched, input.body) if err != nil { return false, nil, err } if len(bodyMatched) == 0 { h.Logger.Debug("No mock found with body schema match") return false, nil, nil } if len(bodyMatched) == 1 { if !h.updateMock(ctx, bodyMatched[0], mockDb) { continue } return true, bodyMatched[0], nil } // More than one match, perform fuzzy match shortListed = bodyMatched } h.Logger.Debug("Performing fuzzy match for req buffer") // Perform fuzzy match on the request isMatched, bestMatch := h.PerformFuzzyMatch(shortListed, input.raw) if isMatched { if !h.updateMock(ctx, bestMatch, mock
------------------

--- Chunk 3---
Function match (end): Db) { continue } return true, bestMatch, nil } return false, nil, nil } }
------------------

--- Chunk 4---
func FilterHTTPMocks(mocks []*models.Mock) []*models.Mock { var httpMocks []*models.Mock for _, mock := range mocks { if mock.Kind != models.Kind(models.HTTP) { continue } httpMocks = append(httpMocks, mock) } return httpMocks }
------------------

--- Chunk 5---
func (h *HTTP) MatchBodyType(mockBody string, reqBody []byte) bool { if mockBody == "" && string(reqBody) == "" { return true } mockBodyType := pkg.GuessContentType([]byte(mockBody)) reqBodyType := pkg.GuessContentType(reqBody) return mockBodyType == reqBodyType }
------------------

--- Chunk 6---
func (h *HTTP) MatchURLPath(mockURL, reqPath string) bool { parsedURL, err := url.Parse(mockURL) if err != nil { return false } return parsedURL.Path == reqPath }
------------------

--- Chunk 7---
func (h *HTTP) MapsHaveSameKeys(map1 map[string]string, map2 map[string][]string) bool { if len(map1) != len(map2) { return false } for key := range map1 { lkey := strings.ToLower(key) if lkey == "keploy-test-id" || lkey == "keploy-test-set-id" { continue } if _, exists := map2[key]; !exists { return false } } for key := range map2 { lkey := strings.ToLower(key) if lkey == "keploy-test-id" || lkey == "keploy-test-set-id" { continue } if _, exists := map1[key]; !exists { return false } } return true }
------------------

--- Chunk 8---
Function SchemaMatch (start): func (h *HTTP) SchemaMatch(ctx context.Context, input *req, unfilteredMocks []*models.Mock) ([]*models.Mock, error) { var schemaMatched []*models.Mock for _, mock := range unfilteredMocks { if ctx.Err() != nil { return nil, ctx.Err() } // Content type check if input.header.Get("Content-Type") != "" { if input.header.Get("Content-Type") != mock.Spec.HTTPReq.Header["Content-Type"] { h.Logger.Debug("The content type of mock and request aren't the same") continue } } // Body type check if !h.MatchBodyType(mock.Spec.HTTPReq.Body, input.body) { h.Logger.Debug("The body of mock and request aren't of same type") continue } // URL path match if !h.MatchURLPath(mock.Spec.HTTPReq.URL, input.url.Path) { h.Logger.Debug("The url path of mock and request aren't the same") continue } // HTTP method match if mock.Spec.HTTPReq.Method != models.Method(input.method) { h.Logger.Debug("The method of mock
------------------

--- Chunk 9---
Function SchemaMatch (end): and request aren't the same") continue } // Header key match if !h.MapsHaveSameKeys(mock.Spec.HTTPReq.Header, input.header) { h.Logger.Debug("The header keys of mock and request aren't the same") continue } // Query parameter match if !h.MapsHaveSameKeys(mock.Spec.HTTPReq.URLParams, input.url.Query()) { h.Logger.Debug("The query params of mock and request aren't the same") continue } schemaMatched = append(schemaMatched, mock) } return schemaMatched, nil }
------------------

--- Chunk 10---
func (h *HTTP) ExactBodyMatch(body []byte, schemaMatched []*models.Mock) (bool, *models.Mock) { for _, mock := range schemaMatched { if mock.Spec.HTTPReq.Body == string(body) { return true, mock } } return false, nil }
------------------

--- Chunk 11---
func (h *HTTP) bodyMatch(mockBody, reqBody []byte) (bool, error) { var mockData map[string]any var reqData map[string]any err := json.Unmarshal(mockBody, &mockData) if err != nil { utils.LogError(h.Logger, err, "failed to unmarshal the mock request body", zap.String("Req", string(mockBody))) return false, err } err = json.Unmarshal(reqBody, &reqData) if err != nil { utils.LogError(h.Logger, err, "failed to unmarshal the request body", zap.String("Req", string(reqBody))) return false, err } for key := range mockData { _, exists := reqData[key] if !exists { return false, nil } } return true, nil }
------------------

--- Chunk 12---
func (h *HTTP) PerformBodyMatch(ctx context.Context, schemaMatched []*models.Mock, reqBody []byte) ([]*models.Mock, error) { h.Logger.Debug("Performing schema match for body") var bodyMatched []*models.Mock for _, mock := range schemaMatched { if ctx.Err() != nil { return nil, ctx.Err() } ok, err := h.bodyMatch([]byte(mock.Spec.HTTPReq.Body), reqBody) if err != nil { h.Logger.Error("failed to do schema matching on request body", zap.Error(err)) break } if ok { bodyMatched = append(bodyMatched, mock) h.Logger.Debug("found a mock with body schema match") } } return bodyMatched, nil }
------------------

--- Chunk 13---
func (h *HTTP) findStringMatch(req string, mockStrings []string) int { minDist := int(^uint(0) >> 1) bestMatch := -1 for idx, mock := range mockStrings { if !util.IsASCII(mock) { continue } dist := levenshtein.ComputeDistance(req, mock) if dist == 0 { return 0 } if dist < minDist { minDist = dist bestMatch = idx } } return bestMatch }
------------------

--- Chunk 14---
func (h *HTTP) findBinaryMatch(mocks []*models.Mock, reqBuff []byte) int { mxSim := -1.0 mxIdx := -1 // find the fuzzy hash of the mocks for idx, mock := range mocks { encoded, _ := decode(mock.Spec.HTTPReq.Body) k := util.AdaptiveK(len(reqBuff), 3, 8, 5) shingles1 := util.CreateShingles(encoded, k) shingles2 := util.CreateShingles(reqBuff, k) similarity := util.JaccardSimilarity(shingles1, shingles2) // log.Debugf("Jaccard Similarity:%f\n", similarity) if mxSim < similarity { mxSim = similarity mxIdx = idx } } return mxIdx }
------------------

--- Chunk 15---
func (h *HTTP) PerformFuzzyMatch(tcsMocks []*models.Mock, reqBuff []byte) (bool, *models.Mock) { encodedReq := encode(reqBuff) for _, mock := range tcsMocks { encodedMock, _ := decode(mock.Spec.HTTPReq.Body) if string(encodedMock) == string(reqBuff) || mock.Spec.HTTPReq.Body == encodedReq { return true, mock } } // String-based fuzzy matching mockStrings := make([]string, len(tcsMocks)) for i := range tcsMocks { mockStrings[i] = tcsMocks[i].Spec.HTTPReq.Body } if util.IsASCII(string(reqBuff)) { idx := h.findStringMatch(string(reqBuff), mockStrings) if idx != -1 { return true, tcsMocks[idx] } } idx := h.findBinaryMatch(tcsMocks, reqBuff) if idx != -1 { return true, tcsMocks[idx] } return false, nil }
------------------

--- Chunk 16---
func (h *HTTP) updateMock(_ context.Context, matchedMock *models.Mock, mockDb integrations.MockMemDb) bool { originalMatchedMock := *matchedMock matchedMock.TestModeInfo.IsFiltered = false matchedMock.TestModeInfo.SortOrder = pkg.GetNextSortNum() updated := mockDb.UpdateUnFilteredMock(&originalMatchedMock, matchedMock) return updated }
------------------

--- File: pkg/core/proxy/integrations/http/util.go---

--- Chunk 1---
func isGZipped(check io.ReadCloser, l *zap.Logger) (bool, *bufio.Reader) { bufReader := bufio.NewReader(check) peekedBytes, err := bufReader.Peek(2) if err != nil && err != io.EOF { l.Debug("failed to peek the response", zap.Error(err)) return false, nil } if len(peekedBytes) < 2 { return false, nil } if peekedBytes[0] == 0x1f && peekedBytes[1] == 0x8b { return true, bufReader } return false, nil }
------------------

--- Chunk 2---
func hasCompleteHeaders(httpChunk []byte) bool { // Define the sequence for header end: "\r\n\r\n" headerEndSequence := []byte{'\r', '\n', '\r', '\n'} // Check if the byte slice contains the header end sequence return bytes.Contains(httpChunk, headerEndSequence) }
------------------

--- Chunk 3---
func encode(buffer []byte) string { //Encode the buffer to string encoded := string(buffer) return encoded }
------------------

--- Chunk 4---
func decode(encoded string) ([]byte, error) { // decode the string to a buffer. data := []byte(encoded) return data, nil }
------------------

--- File: pkg/core/proxy/integrations/integrations.go---

--- Chunk 1---
func Register(name IntegrationType, p *Parsers) { Registered[name] = p }
------------------

--- File: pkg/core/proxy/integrations/mongo/command.go---

--- Chunk 1---
func IsWrite(command Command) bool { switch command { case CommitTransaction, CreateIndexes, Delete, Drop, DropIndexes, DropDatabase, FindAndModify, Insert, Update: return true } return false }
------------------

--- Chunk 2---
func CommandAndCollection(msg bsoncore.Document) (Command, string) { for _, s := range collectionCommands { if coll, ok := msg.Lookup(string(s)).StringValueOK(); ok { return s, coll } } for _, s := range int32Commands { value := msg.Lookup(string(s)) if value.Data != nil { return s, "" } } for _, s := range int64Commands { value := msg.Lookup(string(s)) if value.Data != nil { if coll, ok := msg.Lookup("collection").StringValueOK(); ok { return s, coll } return s, "" } } for _, s := range arrayCommands { value := msg.Lookup(string(s)) if value.Data != nil { return s, "" } } return Unknown, "" }
------------------

--- Chunk 3---
func IsIsMasterDoc(doc bsoncore.Document) bool { isMaster := doc.Lookup(string(IsMaster)) ismaster := doc.Lookup(string(Ismaster)) return IsIsMasterValueTruthy(isMaster) || IsIsMasterValueTruthy(ismaster) }
------------------

--- Chunk 4---
func IsIsMasterValueTruthy(val bsoncore.Value) bool { if intValue, isInt := val.Int32OK(); intValue > 0 { return true } else if !isInt { boolValue, isBool := val.BooleanOK() return boolValue && isBool } return false }
------------------

--- File: pkg/core/proxy/integrations/mongo/decode.go---

--- Chunk 1---
Function decodeMongo (start): func decodeMongo(ctx context.Context, logger *zap.Logger, reqBuf []byte, clientConn net.Conn, dstCfg *models.ConditionalDstCfg, mockDb integrations.MockMemDb, opts models.OutgoingOptions) error { startedDecoding := time.Now() requestBuffers := [][]byte{reqBuf} errCh := make(chan error, 1) go func(errCh chan error, reqBuf []byte, startedDecoding time.Time, requestBuffers [][]byte) { defer util.Recover(logger, clientConn, nil) defer close(errCh) var readRequestDelay time.Duration var err error for { var ( mongoRequests []models.MongoRequest // stores the request packet ) // check to read the request buffer from the client connection after the initial packet if string(reqBuf) == "read form client conn" { started := time.Now() // reads the first chunk of the mongo request reqBuf, err = util.ReadBytes(ctx, logger, clientConn) if err != nil { if err == io.EOF { logger.Debug("received request buffer is empty in test mode for mongo calls") errCh <- err return
------------------

--- Chunk 2---
Function decodeMongo (part 2): } utils.LogError(logger, err, "failed to read request from the mongo client") errCh <- err return } requestBuffers = append(requestBuffers, reqBuf) logger.Debug("the request from the mongo client", zap.Any("buffer", reqBuf)) readRequestDelay = time.Since(started) } if len(reqBuf) == 0 { errCh <- errors.New("the request buffer is empty") return } logger.Debug(fmt.Sprintf("the loop starts with the time delay: %v", time.Since(startedDecoding))) // convert the request buffer to the mongo wire message in the go struct opReq, requestHeader, mongoRequest, err := Decode(reqBuf, logger) if err != nil { utils.LogError(logger, err, "failed to decode the mongo wire message from the client") errCh <- err return } mongoRequests = append(mongoRequests, models.MongoRequest{ Header: &requestHeader, Message: mongoRequest, ReadDelay: int64(readRequestDelay), }) // check for the more_to_come flag bit
------------------

--- Chunk 3---
Function decodeMongo (part 3): in the mongo request // header to read the next chunks of the request if val, ok := mongoRequest.(*models.MongoOpMessage); ok && hasSecondSetBit(val.FlagBits) { for { started := time.Now() logger.Debug("into the for loop for request stream") // reads the next chunk of the mongo request requestBuffer1, err := util.ReadBytes(ctx, logger, clientConn) if err != nil { if err == io.EOF { logger.Debug("received request buffer is empty for streaming mongo request call") errCh <- err return } utils.LogError(logger, err, "failed to read request from the mongo client", zap.String("mongo server address", dstCfg.Addr)) errCh <- err return } requestBuffers = append(requestBuffers, reqBuf) readRequestDelay = time.Since(started) if len(requestBuffer1) == 0 { logger.Debug("the response from the server is complete") break } // convert the request buffer to the mongo response wire message in the go struct _, reqHeader, mongoReq, err := Decode(requestBuffer
------------------

--- Chunk 4---
Function decodeMongo (part 4): 1, logger) if err != nil { utils.LogError(logger, err, "failed to decode the mongo wire message from the mongo client") errCh <- err return } if mongoReqVal, ok := mongoReq.(models.MongoOpMessage); ok && !hasSecondSetBit(mongoReqVal.FlagBits) { logger.Debug("the request from the client is complete since the more_to_come flagbit is 0") break } mongoRequests = append(mongoRequests, models.MongoRequest{ Header: &reqHeader, Message: mongoReq, ReadDelay: int64(readRequestDelay), }) } } // check for the heartbeat request from client and use the config mocks to respond if isHeartBeat(logger, opReq, *mongoRequests[0].Header, mongoRequests[0].Message) { // isScramAuth(logger, opReq) { var bestMatchIndex = -1 var maxMatchScore = 0.0 var configMocks []*models.Mock for { configMocks, err = mockDb.GetUnFilteredMocks() if err !=
------------------

--- Chunk 5---
Function decodeMongo (part 5): nil { utils.LogError(logger, err, "error while getting config mock") } logger.Debug(fmt.Sprintf("the config mocks are: %v", configMocks)) maxMatchScore = 0.0 bestMatchIndex = -1 // loop over the recorded config mocks to match with the incoming request for configIndex, configMock := range configMocks { logger.Debug("the config mock is: ", zap.Any("config mock", configMock), zap.Any("actual request", mongoRequests)) // checking the number of chunks for recorded config mocks and the incoming request if len(configMock.Spec.MongoRequests) != len(mongoRequests) { continue } for i, req := range configMock.Spec.MongoRequests { // check the opcode of the incoming request and the recorded config mocks if len(configMock.Spec.MongoRequests) != len(mongoRequests) || req.Header.Opcode != mongoRequests[i].Header.Opcode { continue } switch req.Header.Opcode { case wiremessage.OpQuery: // check the query fields of the incoming request and the recorded config mocks expectedQuery := req.Message.(*models.MongoOpQuery)
------------------

--- Chunk 6---
Function decodeMongo (part 6): actualQuery := mongoRequests[i].Message.(*models.MongoOpQuery) if actualQuery.FullCollectionName != expectedQuery.FullCollectionName || actualQuery.ReturnFieldsSelector != expectedQuery.ReturnFieldsSelector || actualQuery.Flags != expectedQuery.Flags || actualQuery.NumberToReturn != expectedQuery.NumberToReturn || actualQuery.NumberToSkip != expectedQuery.NumberToSkip { continue } // calculate the matching score for query bson dcouments of the incoming request and the recorded config mocks expected := map[string]interface{}{} actual := map[string]interface{}{} err = bson.UnmarshalExtJSON([]byte(expectedQuery.Query), true, &expected) if err != nil { utils.LogError(logger, err, "failed to unmarshal the section of recorded request to bson document") continue } err = bson.UnmarshalExtJSON([]byte(actualQuery.Query), true, &actual) if err != nil { utils.LogError(logger, err, "failed to unmarshal the section of incoming request to bson document") continue } score := calculateMatchingScore(expected, actual) logger.Debug("the expected and actual msg in the heartbeat OpQuery query.", zap.Any("expected", expected
------------------

--- Chunk 7---
Function decodeMongo (part 7): ), zap.Any("actual", actual), zap.Any("score", score)) if score > maxMatchScore { maxMatchScore = score bestMatchIndex = configIndex } case wiremessage.OpMsg: // check the OpMsg sections of the incoming request and the recorded config mocks if req.Message.(*models.MongoOpMessage).FlagBits != mongoRequests[i].Message.(*models.MongoOpMessage).FlagBits { continue } scoreSum := 0.0 if len(req.Message.(*models.MongoOpMessage).Sections) != len(mongoRequests[i].Message.(*models.MongoOpMessage).Sections) { continue } // calculate the matching score for each section of the incoming request and the recorded config mocks for sectionIndx, section := range req.Message.(*models.MongoOpMessage).Sections { if len(req.Message.(*models.MongoOpMessage).Sections) == len(mongoRequests[i].Message.(*models.MongoOpMessage).Sections) { score := compareOpMsgSection(logger, section, mongoRequests[i].Message.(*models.MongoOpMessage).Sections[sectionIndx]) scoreSum += score } } currentScore :=
------------------

--- Chunk 8---
Function decodeMongo (part 8): scoreSum / float64(len(mongoRequests)) logger.Debug("the expected and actual msg in the heartbeat OpMsg single section.", zap.Any("expected", req.Message.(*models.MongoOpMessage).Sections), zap.Any("actual", mongoRequests[i].Message.(*models.MongoOpMessage).Sections), zap.Any("score", currentScore)) if currentScore > maxMatchScore { maxMatchScore = currentScore bestMatchIndex = configIndex } default: utils.LogError(logger, err, "the OpCode of the mongo wiremessage is invalid.", zap.Any("opcode", req.Header.Opcode)) } } } if bestMatchIndex != -1 && maxMatchScore != 0.0 { matchedMock := *configMocks[bestMatchIndex] matchedMock.TestModeInfo.SortOrder = pkg.GetNextSortNum() isUpdated := mockDb.UpdateUnFilteredMock(configMocks[bestMatchIndex], &matchedMock) if !isUpdated { continue } } break } responseTo := mongoRequests[0].Header.RequestID if bestMatchIndex == -1 || maxMatchScore == 0.0 {
------------------

--- Chunk 9---
Function decodeMongo (part 9): logger.Debug("the mongo request do not matches with any config mocks", zap.Any("request", mongoRequests)) continue } // write the mongo response to the client connection from the recorded config mocks that most matches the incoming request for _, mongoResponse := range configMocks[bestMatchIndex].Spec.MongoResponses { switch mongoResponse.Header.Opcode { case wiremessage.OpReply: replySpec := mongoResponse.Message.(*models.MongoOpReply) replyMessage, err := encodeOpReply(ctx, mongoRequests[0], configMocks[bestMatchIndex].Spec.MongoRequests[0], replySpec, opts.MongoPassword, logger) if err != nil { utils.LogError(logger, err, "failed to encode the recorded OpReply yaml", zap.Any("for request with id", responseTo)) errCh <- err return } requestID := wiremessage.NextRequestID() heathCheckReplyBuffer := replyMessage.Encode(responseTo, requestID) responseTo = requestID logger.Debug(fmt.Sprintf("the bufffer response is: %v", string(heathCheckReplyBuffer))) // handle scram auth request _, err = clientConn.Write(
------------------

--- Chunk 10---
Function decodeMongo (part 10): heathCheckReplyBuffer) if err != nil { if ctx.Err() != nil { return } utils.LogError(logger, err, "failed to write the health check reply to mongo client") errCh <- err return } case wiremessage.OpMsg: respMessage := mongoResponse.Message.(*models.MongoOpMessage) var expectedRequestSections []string if len(configMocks[bestMatchIndex].Spec.MongoRequests) > 0 { expectedRequestSections = configMocks[bestMatchIndex].Spec.MongoRequests[0].Message.(*models.MongoOpMessage).Sections } message, err := encodeOpMsg(ctx, respMessage, mongoRequest.(*models.MongoOpMessage).Sections, expectedRequestSections, opts.MongoPassword, logger) if err != nil { utils.LogError(logger, err, "failed to encode the recorded OpMsg response", zap.Any("for request with id", responseTo)) errCh <- err return } _, err = clientConn.Write(message.Encode(responseTo, wiremessage.NextRequestID())) if err != nil { if ctx.Err() != nil { return } utils.LogError(logger,
------------------

--- Chunk 11---
Function decodeMongo (part 11): err, "failed to write the health check opmsg to mongo client") errCh <- err return } } } } else { // handle for the non-heartbeat request from the client // match the incoming request with the recorded tcsMocks and return a mocked response which matches most with incoming request matched, matchedMock, err := match(ctx, logger, mongoRequests, mockDb) if err != nil { errCh <- err utils.LogError(logger, err, "error while matching mongo mocks") return } if !matched { logger.Debug("mongo request not matched with any tcsMocks", zap.Any("request", mongoRequests)) reqBuf, err = util.PassThrough(ctx, logger, clientConn, dstCfg, requestBuffers) if err != nil { utils.LogError(logger, err, "failed to passthrough the mongo request to the actual database server") errCh <- err return } continue } responseTo := mongoRequests[0].Header.RequestID logger.Debug("the mock matched with the current request", zap.Any("mock", matchedMock),
------------------

--- Chunk 12---
Function decodeMongo (part 12): zap.Any("responseTo", responseTo)) // write the mongo response to the client connection from the recorded tcsMocks that most matches the incoming request for _, resp := range matchedMock.Spec.MongoResponses { respMessage := resp.Message.(*models.MongoOpMessage) var expectedRequestSections []string if len(matchedMock.Spec.MongoRequests) > 0 { expectedRequestSections = matchedMock.Spec.MongoRequests[0].Message.(*models.MongoOpMessage).Sections } message, err := encodeOpMsg(ctx, respMessage, mongoRequest.(*models.MongoOpMessage).Sections, expectedRequestSections, opts.MongoPassword, logger) if err != nil { utils.LogError(logger, err, "failed to encode the recorded OpMsg response", zap.Any("for request with id", responseTo)) errCh <- err return } requestID := wiremessage.NextRequestID() _, err = clientConn.Write(message.Encode(responseTo, requestID)) if err != nil { if ctx.Err() != nil { return } utils.LogError(logger, err, "failed to write the health check opmsg to mongo client", zap.Any("for request with id
------------------

--- Chunk 13---
Function decodeMongo (end): ", responseTo)) errCh <- err return } responseTo = requestID } } logger.Debug("the length of the requestBuffer after matching: " + strconv.Itoa(len(reqBuf)) + strconv.Itoa(len(requestBuffers[0]))) if len(requestBuffers) > 0 && len(reqBuf) == len(requestBuffers[0]) { reqBuf = []byte("read form client conn") } // Clear the buffer for the next dependency call requestBuffers = [][]byte{} } }(errCh, reqBuf, startedDecoding, requestBuffers) select { case <-ctx.Done(): return ctx.Err() case err := <-errCh: if err == io.EOF { logger.Debug("connection lost from client") return nil } return err } }
------------------

--- File: pkg/core/proxy/integrations/mongo/encode.go---

--- Chunk 1---
Function encodeMongo (start): func (m *Mongo) encodeMongo(ctx context.Context, logger *zap.Logger, reqBuf []byte, clientConn, destConn net.Conn, mocks chan<- *models.Mock, _ models.OutgoingOptions) error { errCh := make(chan error, 1) //get the error group from the context g, ok := ctx.Value(models.ErrGroupKey).(*errgroup.Group) if !ok { return errors.New("failed to get the error group from the context") } g.Go(func() error { defer pUtil.Recover(logger, clientConn, destConn) defer close(errCh) for { var err error var readRequestDelay time.Duration // reads the request packets from the client connection after the first request packet. // Since, that is already read in the RecordOutgoing function. if string(reqBuf) == "read form client conn" { started := time.Now() reqBuf, err = pUtil.ReadBytes(ctx, logger, clientConn) logger.Debug("reading from the mongo conn", zap.Any("", string(reqBuf))) if err != nil { if err == io.EOF { logger.Debug("received request buffer is empty in record
------------------

--- Chunk 2---
Function encodeMongo (part 2): mode for mongo call") errCh <- err return nil } utils.LogError(logger, err, "failed to read request from the mongo client", zap.String("mongo client address", clientConn.RemoteAddr().String())) errCh <- err return nil } readRequestDelay = time.Since(started) // logStr += lstr logger.Debug(fmt.Sprintf("the request in the mongo parser before passing to dest: %v", len(reqBuf))) } var ( mongoRequests []models.MongoRequest // stores the decoded binary packets for a request mongoResponses []models.MongoResponse // stores the decoded binary packets for a response ) // decode the binary packet and store the values in the corresponding struct opReq, requestHeader, mongoRequest, err := Decode(reqBuf, logger) if err != nil { utils.LogError(logger, err, "failed to decode the mongo wire message from the client") errCh <- err return nil } mongoRequests = append(mongoRequests, models.MongoRequest{ Header: &requestHeader, Message: mongoRequest, Read
------------------

--- Chunk 3---
Function encodeMongo (part 3): Delay: int64(readRequestDelay), }) // forwards the request packet to the destination server _, err = destConn.Write(reqBuf) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(logger, err, "failed to write the request buffer to mongo server", zap.String("mongo server address", destConn.RemoteAddr().String())) errCh <- err return nil } logger.Debug(fmt.Sprintf("the request in the mongo parser after passing to dest: %v", len(reqBuf))) // check for the request packet streaming for the mongo wire message if val, ok := mongoRequest.(*models.MongoOpMessage); ok && hasSecondSetBit(val.FlagBits) { for { // read the streaming request packets requestBuffer1, err := pUtil.ReadBytes(ctx, logger, clientConn) if err != nil { if err == io.EOF { logger.Debug("received request buffer is empty in record mode for mongo request") errCh <- err return nil } utils.LogError(logger, err, "failed to read request from the mongo client", zap.String
------------------

--- Chunk 4---
Function encodeMongo (part 4): ("mongo client address", clientConn.RemoteAddr().String())) errCh <- err return nil } // forward the request packet to the destination server _, err = destConn.Write(requestBuffer1) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(logger, err, "failed to write the reply message to mongo client") errCh <- err return nil } if len(requestBuffer1) == 0 { logger.Debug("the response from the server is complete") break } // decode the binary packet and return the values in the corresponding structs // for header and message. _, reqHeader, mongoReq, err := Decode(requestBuffer1, logger) if err != nil { utils.LogError(logger, err, "failed to decode the mongo wire message from the destination server") errCh <- err return nil } if mongoReqVal, ok := mongoReq.(models.MongoOpMessage); ok && !hasSecondSetBit(mongoReqVal.FlagBits) { logger.Debug("the request from the client is complete since the
------------------

--- Chunk 5---
Function encodeMongo (part 5): more_to_come flagbit is 0") break } mongoRequests = append(mongoRequests, models.MongoRequest{ Header: &reqHeader, Message: mongoReq, ReadDelay: int64(readRequestDelay), }) } } reqTimestampMock := time.Now() started := time.Now() // read reply message length from the destination mongo server responsePckLengthBuffer, err := pUtil.ReadRequiredBytes(ctx, logger, destConn, 4) if err != nil { if err == io.EOF { logger.Debug("received response buffer is empty in record mode for mongo call") errCh <- err return nil } utils.LogError(logger, err, "failed to read reply from the mongo server", zap.String("mongo server address", destConn.RemoteAddr().String())) errCh <- err return nil } logger.Debug("received these pck length packets", zap.Any("packets", responsePckLengthBuffer)) // convert packet length to LittleEndian integer. pckLength := getPacketLength(responsePckLengthBuffer) logger.Debug("received
------------------

--- Chunk 6---
Function encodeMongo (part 6): pck length ", zap.Any("packet length", pckLength)) // read the entire response packet responsePckDataBuffer, err := pUtil.ReadRequiredBytes(ctx, logger, destConn, int(pckLength)-4) logger.Debug("received these packets", zap.Any("packets", responsePckDataBuffer)) responseBuffer := append(responsePckLengthBuffer, responsePckDataBuffer...) logger.Debug("reading from the destination mongo server", zap.Any("", string(responseBuffer))) if err != nil { if err == io.EOF { logger.Debug("received response buffer is empty in record mode for mongo call") errCh <- err return nil } utils.LogError(logger, err, "failed to read reply from the mongo server", zap.String("mongo server address", destConn.RemoteAddr().String())) errCh <- err return nil } readResponseDelay := time.Since(started) // write the response packet to mongo client _, err = clientConn.Write(responseBuffer) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(logger, err, "failed to
------------------

--- Chunk 7---
Function encodeMongo (part 7): write the reply message to mongo client") errCh <- err return nil } // decode the binary packet of response and return the values in the corresponding structs _, responseHeader, mongoResponse, err := Decode(responseBuffer, logger) if err != nil { utils.LogError(logger, err, "failed to decode the mongo wire message from the destination server") errCh <- err return nil } mongoResponses = append(mongoResponses, models.MongoResponse{ Header: &responseHeader, Message: mongoResponse, ReadDelay: int64(readResponseDelay), }) // check for the response packet streaming for the mongo wire message if val, ok := mongoResponse.(*models.MongoOpMessage); ok && hasSecondSetBit(val.FlagBits) { for i := 0; ; i++ { // handle the streaming response packets for heartbeat calls if i == 0 && isHeartBeat(logger, opReq, *mongoRequests[0].Header, mongoRequests[0].Message) { m.recordMessage(ctx, logger, mongoRequests, mongoResponses, opReq, reqTimestampMock, mocks)
------------------

--- Chunk 8---
Function encodeMongo (part 8): } started = time.Now() // read the response packets from the destination server responseBuffer, err = pUtil.ReadBytes(ctx, logger, destConn) if err != nil { if err == io.EOF { logger.Debug("received response buffer is empty in record mode for mongo call") errCh <- err return nil } utils.LogError(logger, err, "failed to read reply from the mongo server", zap.String("mongo server address", destConn.RemoteAddr().String())) errCh <- err return nil } logger.Debug(fmt.Sprintf("the response in the mongo parser before passing to client: %v", len(responseBuffer))) readResponseDelay := time.Since(started) // write the reply to mongo client _, err = clientConn.Write(responseBuffer) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(logger, err, "failed to write the reply message to mongo client") errCh <- err return nil } logger.Debug(fmt.Sprintf("the response in the mongo parser after passing to client: %v", len(responseBuffer)))
------------------

--- Chunk 9---
Function encodeMongo (part 9): if len(responseBuffer) == 0 { logger.Debug("the response from the server is complete") break } // decode the binary packet for response and return the values in the corresponding structs _, respHeader, mongoResp, err := Decode(responseBuffer, logger) if err != nil { utils.LogError(logger, err, "failed to decode the mongo wire message from the destination server") errCh <- err return nil } if mongoRespVal, ok := mongoResp.(models.MongoOpMessage); ok && !hasSecondSetBit(mongoRespVal.FlagBits) { logger.Debug("the response from the server is complete since the more_to_come flagbit is 0") break } mongoResponses = append(mongoResponses, models.MongoResponse{ Header: &respHeader, Message: mongoResp, ReadDelay: int64(readResponseDelay), }) } } // write the response packet to the yaml file m.recordMessage(ctx, logger, mongoRequests, mongoResponses, opReq, reqTimestampMock, mocks) // assigns "read form client conn"
------------------

--- Chunk 10---
Function encodeMongo (end): to the reqBuf to read the next request packet from the client connection reqBuf = []byte("read form client conn") } }) select { case <-ctx.Done(): return ctx.Err() case err := <-errCh: if err == io.EOF { return nil } return err } }
------------------

--- Chunk 11---
func getPacketLength(src []byte) (length int32) { length = int32(src[0]) | int32(src[1])<<8 | int32(src[2])<<16 | int32(src[3])<<24 return length }
------------------

--- File: pkg/core/proxy/integrations/mongo/match.go---

--- Chunk 1---
Function match (start): func match(ctx context.Context, logger *zap.Logger, mongoRequests []models.MongoRequest, mockDb integrations.MockMemDb) (bool, *models.Mock, error) { for { select { case <-ctx.Done(): return false, nil, ctx.Err() default: mocks, err := mockDb.GetFilteredMocks() if err != nil { return false, nil, fmt.Errorf("error while getting tcs mock: %v", err) } var tcsMocks []*models.Mock for _, mock := range mocks { if mock.Kind != "Mongo" { continue } tcsMocks = append(tcsMocks, mock) } maxMatchScore := 0.0 bestMatchIndex := -1 // iterate over the tcsMocks and compare the incoming mongo requests with the recorded mongo requests. for tcsIndx, tcsMock := range tcsMocks { if ctx.Err() != nil { return false, nil, ctx.Err() } // check for the number of chunks in the incoming mongo requests and the recorded mongo requests. if len(tcsMock.Spec.MongoRequests) == len(m
------------------

--- Chunk 2---
Function match (part 2): ongoRequests) { for i, req := range tcsMock.Spec.MongoRequests { if ctx.Err() != nil { return false, nil, ctx.Err() } // check for the opcode of the incoming mongo requests and the recorded mongo requests. if len(tcsMock.Spec.MongoRequests) != len(mongoRequests) || req.Header.Opcode != mongoRequests[i].Header.Opcode { logger.Debug("the received request is not of same type with the tcmocks", zap.Any("at index", tcsIndx)) continue } switch req.Header.Opcode { case wiremessage.OpMsg: if req.Message.(*models.MongoOpMessage).FlagBits != mongoRequests[i].Message.(*models.MongoOpMessage).FlagBits { logger.Debug("the received request is not of same flagbit with the tcmocks", zap.Any("at index", tcsIndx)) continue } scoreSum := 0.0 for sectionIndx, section := range req.Message.(*models.MongoOpMessage).Sections { if len(req.Message.(*models.MongoOpMessage).Sections) == len(mongoRequests[i].Message.(*models.MongoOpMessage).Sections) {
------------------

--- Chunk 3---
Function match (end): score := compareOpMsgSection(logger, section, mongoRequests[i].Message.(*models.MongoOpMessage).Sections[sectionIndx]) scoreSum += score } } currentScore := scoreSum / float64(len(mongoRequests)) if currentScore > maxMatchScore { maxMatchScore = currentScore bestMatchIndex = tcsIndx } default: utils.LogError(logger, nil, "the OpCode of the mongo wiremessage is invalid.", zap.Any("OpCode", req.Header.Opcode)) } } } } if bestMatchIndex == -1 { return false, nil, nil } mock := tcsMocks[bestMatchIndex] isDeleted := mockDb.DeleteFilteredMock(*mock) if !isDeleted { continue } return true, mock, nil } } }
------------------

--- Chunk 4---
Function compareOpMsgSection (start): func compareOpMsgSection(logger *zap.Logger, expectedSection, actualSection string) float64 { // check that the sections are of same type. SectionSingle (section[16] is "m") or SectionSequence (section[16] is "i"). if (len(expectedSection) < 16 || len(actualSection) < 16) && expectedSection[16] != actualSection[16] { return 0 } logger.Debug(fmt.Sprintf("the sections are. Expected: %v\n and actual: %v", expectedSection, actualSection)) switch { case strings.HasPrefix(expectedSection, "{ SectionSingle identifier:"): var expectedIdentifier string var expectedMsgsStr string // // Define the regular expression pattern // // Compile the regular expression // // Find submatches using the regular expression expectedIdentifier, expectedMsgsStr, err := decodeOpMsgSectionSequence(expectedSection) if err != nil { logger.Debug(fmt.Sprintf("the section in mongo OpMsg wiremessage: %v", expectedSection)) utils.LogError(logger, err, "failed to fetch the identifier/msgs from the section single of recorded OpMsg", zap.Any("identifier", expectedIdentifier))
------------------

--- Chunk 5---
Function compareOpMsgSection (part 2): return 0 } var actualIdentifier string var actualMsgsStr string // _, err = fmt.Sscanf(actualSection, "{ SectionSingle identifier: %s , msgs: [ %s ] }", &actualIdentifier, &actualMsgsStr) actualIdentifier, actualMsgsStr, err = decodeOpMsgSectionSequence(actualSection) if err != nil { utils.LogError(logger, err, "failed to fetch the identifier/msgs from the section single of incoming OpMsg", zap.Any("identifier", actualIdentifier)) return 0 } // // Compile the regular expression // // Find submatches using the regular expression logger.Debug("the expected section", zap.Any("identifier", expectedIdentifier), zap.Any("docs", expectedMsgsStr)) logger.Debug("the actual section", zap.Any("identifier", actualIdentifier), zap.Any("docs", actualMsgsStr)) expectedMsgs := strings.Split(expectedMsgsStr, ", ") actualMsgs := strings.Split(actualMsgsStr, ", ") if len(expectedMsgs) != len(actualMsgs) || expectedIdentifier != actualIdentifier { return 0 } score :=
------------------

--- Chunk 6---
Function compareOpMsgSection (part 3): 0.0 for i := range expectedMsgs { expected := map[string]interface{}{} actual := map[string]interface{}{} err := bson.UnmarshalExtJSON([]byte(expectedMsgs[i]), true, &expected) if err != nil { utils.LogError(logger, err, "failed to unmarshal the section of recorded request to bson document") return 0 } err = bson.UnmarshalExtJSON([]byte(actualMsgs[i]), true, &actual) if err != nil { utils.LogError(logger, err, "failed to unmarshal the section of incoming request to bson document") return 0 } score += calculateMatchingScore(expected, actual) } logger.Debug("the matching score for sectionSequence", zap.Any("", score)) return score case strings.HasPrefix(expectedSection, "{ SectionSingle msg:"): var expectedMsgsStr string expectedMsgsStr, err := extractSectionSingle(expectedSection) if err != nil { utils.LogError(logger, err, "failed to fetch the msgs from the single section of recorded OpMsg") return 0 } // // Define the regular expression pattern // // Compile
------------------

--- Chunk 7---
Function compareOpMsgSection (part 4): the regular expression // // Find submatches using the regular expression var actualMsgsStr string actualMsgsStr, err = extractSectionSingle(actualSection) if err != nil { utils.LogError(logger, err, "failed to fetch the msgs from the single section of incoming OpMsg") return 0 } // // Compile the regular expression // // Find submatches using the regular expression expected := map[string]interface{}{} actual := map[string]interface{}{} err = bson.UnmarshalExtJSON([]byte(expectedMsgsStr), true, &expected) if err != nil { utils.LogError(logger, err, "failed to unmarshal the section of recorded request to bson document") return 0 } err = bson.UnmarshalExtJSON([]byte(actualMsgsStr), true, &actual) if err != nil { utils.LogError(logger, err, "failed to unmarshal the section of incoming request to bson document") return 0 } logger.Debug("the expected and actual msg in the single section.", zap.Any("expected", expected), zap.Any("actual", actual), zap.Any("score", calculateMatchingScore(expected
------------------

--- Chunk 8---
Function compareOpMsgSection (end): , actual))) return calculateMatchingScore(expected, actual) default: utils.LogError(logger, nil, "failed to detect the OpMsg section into mongo request wiremessage due to invalid format") return 0 } }
------------------

--- Chunk 9---
func calculateMatchingScore(obj1, obj2 map[string]interface{}) float64 { totalFields := len(obj2) if len(obj1) > totalFields { totalFields = len(obj1) } matchingFields := 0.0 for key, value := range obj2 { if obj1Value, ok := obj1[key]; ok { if reflect.DeepEqual(value, obj1Value) { matchingFields++ } else if reflect.TypeOf(value) == reflect.TypeOf(obj1Value) { if isNestedMap(value) { if isNestedMap(obj1Value) { matchingFields += calculateMatchingScore(obj1Value.(map[string]interface{}), value.(map[string]interface{})) } } else if isSlice(value) { if isSlice(obj1Value) { matchingFields += calculateMatchingScoreForSlices(obj1Value.([]interface{}), value.([]interface{})) } } } } } return float64(matchingFields) / float64(totalFields) }
------------------

--- Chunk 10---
func calculateMatchingScoreForSlices(slice1, slice2 []interface{}) float64 { matchingCount := 0 if len(slice1) == len(slice2) { for indx2, item2 := range slice2 { if len(slice1) > indx2 && reflect.DeepEqual(item2, slice1[indx2]) { matchingCount++ } } } return float64(matchingCount) / float64(len(slice2)) }
------------------

--- Chunk 11---
func isNestedMap(value interface{}) bool { _, ok := value.(map[string]interface{}) return ok }
------------------

--- Chunk 12---
func isSlice(value interface{}) bool { _, ok := value.([]interface{}) return ok }
------------------

--- File: pkg/core/proxy/integrations/mongo/mongo.go---

--- Chunk 1---
func init() { integrations.Register(integrations.MONGO, &integrations.Parsers{ Initializer: New, Priority: 100, }) }
------------------

--- Chunk 2---
func New(logger *zap.Logger) integrations.Integrations { return &Mongo{ logger: logger, recordedConfigRequests: sync.Map{}, } }
------------------

--- Chunk 3---
func (m *Mongo) MatchType(_ context.Context, buffer []byte) bool { if len(buffer) < 4 { return false } // identifies by the starting 4 bytes of the message, since that // are the length of the message. messageLength := binary.LittleEndian.Uint32(buffer[0:4]) return int(messageLength) == len(buffer) }
------------------

--- Chunk 4---
func (m *Mongo) RecordOutgoing(ctx context.Context, src net.Conn, dst net.Conn, mocks chan<- *models.Mock, opts models.OutgoingOptions) error { logger := m.logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", src.RemoteAddr().String())) reqBuf, err := util.ReadInitialBuf(ctx, logger, src) if err != nil { utils.LogError(logger, err, "failed to read the initial mongo message") return err } // the mongo messages are converted to the yaml format. // // initially the reqBuf contains the first network packet // from the client connection which is used to determine // the packet type in MatchType. err = m.encodeMongo(ctx, logger, reqBuf, src, dst, mocks, opts) if err != nil { utils.LogError(logger, err, "failed to encode the mongo message into the yaml") return err } return nil }
------------------

--- Chunk 5---
func (m *Mongo) MockOutgoing(ctx context.Context, src net.Conn, dstCfg *models.ConditionalDstCfg, mockDb integrations.MockMemDb, opts models.OutgoingOptions) error { // read the initial buffer from the client connection. Initially the // reqBuf contains the first network packet from the client connection // which is used to determine the packet type in MatchType. logger := m.logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", src.RemoteAddr().String())) reqBuf, err := util.ReadInitialBuf(ctx, logger, src) if err != nil { utils.LogError(logger, err, "failed to read the initial mongo message") return err } // converts the yaml string into the binary packet err = decodeMongo(ctx, logger, reqBuf, src, dstCfg, mockDb, opts) if err != nil { utils.LogError(logger, err, "failed to decode the mongo message") return err } return nil }
------------------

--- Chunk 6---
Function recordMessage (start): func (m *Mongo) recordMessage(ctx context.Context, logger *zap.Logger, mongoRequests []models.MongoRequest, mongoResponses []models.MongoResponse, opReq Operation, reqTimestampMock time.Time, mocks chan<- *models.Mock) { shouldRecordCalls := true // boolean to check for already saved config mocks name := "mocks" meta1 := map[string]string{ "operation": opReq.String(), "connID": ctx.Value(models.ClientConnectionIDKey).(string), } // check that the packet is heartbeat or not. // See: https://github.com/mongodb/mongo-go-driver/blob/8489898c64a2d8c2e2160006eb851a11a9db9e9d/x/mongo/driver/operation/hello.go#L503 if isHeartBeat(logger, opReq, *mongoRequests[0].Header, mongoRequests[0].Message) { meta1["type"] = "config" } // record the mongo messages if shouldRecordCalls { mongoMock := &models.Mock{ Version: models.GetVersion(), Kind: models.Mongo, Name: name, Spec:
------------------

--- Chunk 7---
Function recordMessage (end): models.MockSpec{ Metadata: meta1, MongoRequests: mongoRequests, MongoResponses: mongoResponses, Created: time.Now().Unix(), ReqTimestampMock: reqTimestampMock, ResTimestampMock: time.Now(), }, } // Save the mock mocks <- mongoMock } }
------------------

--- File: pkg/core/proxy/integrations/mongo/operation.go---

--- Chunk 1---
Function Decode (start): func Decode(wm []byte, logger *zap.Logger) (Operation, models.MongoHeader, interface{}, error) { wmLength := len(wm) // the wiremessage is at least 16 bytes long length, reqID, responseTo, opCode, wmBody, ok := wiremessage.ReadHeader(wm) messageHeader := models.MongoHeader{ Length: length, RequestID: reqID, ResponseTo: responseTo, Opcode: wiremessage.OpCode(opCode), } logger.Debug(fmt.Sprintf("the mongo msg header: %v", messageHeader)) if !ok || int(length) > wmLength { return nil, messageHeader, &models.MongoOpMessage{}, errors.New("malformed wire message: insufficient bytes") } var ( op Operation err error mongoMsg interface{} ) switch opCode { case wiremessage.OpQuery: // decodeQuery is a helper function to decode the OpQuery operation op, err = decodeQuery(reqID, wmBody) if err != nil { return nil, messageHeader, mongoMsg, err } // marshal the query document to json json
------------------

--- Chunk 2---
Function Decode (part 2): Bytes, err := bson.MarshalExtJSON(op.(*opQuery).query, true, false) if err != nil { return nil, messageHeader, &models.MongoOpMessage{}, fmt.Errorf("malformed bson document: %v", err.Error()) } jsonString := string(jsonBytes) mongoMsg = &models.MongoOpQuery{ Flags: int32(op.(*opQuery).flags), FullCollectionName: op.(*opQuery).fullCollectionName, NumberToSkip: op.(*opQuery).numberToSkip, NumberToReturn: op.(*opQuery).numberToReturn, Query: jsonString, ReturnFieldsSelector: op.(*opQuery).returnFieldsSelector.String(), } case wiremessage.OpMsg: // decodeMsg is a helper function to decode the OpMsg operation op, err = decodeMsg(reqID, wmBody, logger) if err != nil { return nil, messageHeader, mongoMsg, err } var sections []string for _, section := range op.(*opMsg).sections { sections = append(sections, section.String()) } mongoMsg =
------------------

--- Chunk 3---
Function Decode (part 3): &models.MongoOpMessage{ FlagBits: int(op.(*opMsg).flags), Sections: sections, Checksum: int(op.(*opMsg).checksum), } case wiremessage.OpReply: // decodeReply is a helper function to decode the OpReply operation op, err = decodeReply(reqID, wmBody) if err != nil { return nil, messageHeader, mongoMsg, err } var replyDocs []string for _, v := range op.(*opReply).documents { // marshal the reply document to json jsonBytes, err := bson.MarshalExtJSON(v, true, false) if err != nil { return nil, messageHeader, &models.MongoOpMessage{}, fmt.Errorf("malformed bson document: %v", err.Error()) } jsonString := string(jsonBytes) replyDocs = append(replyDocs, jsonString) } mongoMsg = &models.MongoOpReply{ ResponseFlags: int32(op.(*opReply).flags), CursorID: op.(*opReply).cursorID, StartingFrom: op.(*opReply).startingFrom, NumberReturned
------------------

--- Chunk 4---
Function Decode (end): : op.(*opReply).numReturned, Documents: replyDocs, } default: op = &opUnknown{ opCode: opCode, reqID: reqID, wm: wm, } } if err != nil { return nil, messageHeader, mongoMsg, err } logger.Debug(fmt.Sprintf("the decoded string for the wiremessage: %v", op.String())) return op, messageHeader, mongoMsg, nil }
------------------

--- Chunk 5---
func (o *opUnknown) IsIsAdminDB() bool { return false }
------------------

--- Chunk 6---
func (o *opUnknown) TransactionDetails() *TransactionDetails { return nil }
------------------

--- Chunk 7---
func (o *opUnknown) OpCode() wiremessage.OpCode { return o.opCode }
------------------

--- Chunk 8---
func (o *opUnknown) Encode(_, _ int32) []byte { return o.wm }
------------------

--- Chunk 9---
func (o *opUnknown) IsIsMaster() bool { return false }
------------------

--- Chunk 10---
func (o *opUnknown) CursorID() (cursorID int64, ok bool) { return 0, false }
------------------

--- Chunk 11---
func (o *opUnknown) RequestID() int32 { return o.reqID }
------------------

--- Chunk 12---
func (o *opUnknown) Error() error { return nil }
------------------

--- Chunk 13---
func (o *opUnknown) Unacknowledged() bool { return false }
------------------

--- Chunk 14---
func (o *opUnknown) CommandAndCollection() (Command, string) { return Unknown, "" }
------------------

--- Chunk 15---
func (o *opUnknown) String() string { return fmt.Sprintf("{ OpUnknown opCode: %d, wm: %s }", o.opCode, o.wm) }
------------------

--- Chunk 16---
func (q *opQuery) IsIsAdminDB() bool { return false }
------------------

--- Chunk 17---
func (q *opQuery) TransactionDetails() *TransactionDetails { return nil }
------------------

--- Chunk 18---
Function decodeQuery (start): func decodeQuery(reqID int32, wm []byte) (*opQuery, error) { var ok bool q := opQuery{ reqID: reqID, } q.flags, wm, ok = wiremessage.ReadQueryFlags(wm) if !ok { return nil, errors.New("malformed query message: missing OP_QUERY flags") } q.fullCollectionName, wm, ok = wiremessage.ReadQueryFullCollectionName(wm) if !ok { return nil, errors.New("malformed query message: full collection name") } q.numberToSkip, wm, ok = wiremessage.ReadQueryNumberToSkip(wm) if !ok { return nil, errors.New("malformed query message: number to skip") } q.numberToReturn, wm, ok = wiremessage.ReadQueryNumberToReturn(wm) if !ok { return nil, errors.New("malformed query message: number to return") } q.query, wm, ok = wiremessage.ReadQueryQuery(wm) if !ok { return nil, errors.New("malformed query message: query document") } if len(wm) > 0 { q.returnFieldsSelector, _, ok = wiremessage.ReadQuery
------------------

--- Chunk 19---
Function decodeQuery (end): ReturnFieldsSelector(wm) if !ok { return nil, errors.New("malformed query message: return fields selector") } } return &q, nil }
------------------

--- Chunk 20---
func (q *opQuery) OpCode() wiremessage.OpCode { return wiremessage.OpQuery }
------------------

--- Chunk 21---
func (q *opQuery) Encode(responseTo, _ int32) []byte { var buffer []byte idx, buffer := wiremessage.AppendHeaderStart(buffer, 0, responseTo, wiremessage.OpQuery) buffer = wiremessage.AppendQueryFlags(buffer, q.flags) buffer = wiremessage.AppendQueryFullCollectionName(buffer, q.fullCollectionName) buffer = wiremessage.AppendQueryNumberToSkip(buffer, q.numberToSkip) buffer = wiremessage.AppendQueryNumberToReturn(buffer, q.numberToReturn) buffer = append(buffer, q.query...) if len(q.returnFieldsSelector) != 0 { // returnFieldsSelector is optional buffer = append(buffer, q.returnFieldsSelector...) } buffer = bsoncore.UpdateLength(buffer, idx, int32(len(buffer[idx:]))) return buffer }
------------------

--- Chunk 22---
func (q *opQuery) CursorID() (cursorID int64, ok bool) { return q.query.Lookup("getMore").Int64OK() }
------------------

--- Chunk 23---
func (q *opQuery) RequestID() int32 { return q.reqID }
------------------

--- Chunk 24---
func (q *opQuery) IsIsMaster() bool { if q.fullCollectionName != "admin.$cmd" { return false } return IsIsMasterDoc(q.query) }
------------------

--- Chunk 25---
func (q *opQuery) Error() error { return nil }
------------------

--- Chunk 26---
func (q *opQuery) Unacknowledged() bool { return false }
------------------

--- Chunk 27---
func (q *opQuery) CommandAndCollection() (Command, string) { return Find, q.fullCollectionName }
------------------

--- Chunk 28---
func (q *opQuery) String() string { return fmt.Sprintf("{ OpQuery flags: %s, fullCollectionName: %s, numberToSkip: %d, numberToReturn: %d, query: %s, returnFieldsSelector: %s }", q.flags.String(), q.fullCollectionName, q.numberToSkip, q.numberToReturn, q.query.String(), q.returnFieldsSelector.String()) }
------------------

--- Chunk 29---
func (o *opMsgSectionSingle) cursorID() (cursorID int64, ok bool) { if getMore, ok := o.msg.Lookup("getMore").Int64OK(); ok { return getMore, ok } return o.msg.Lookup("cursor", "id").Int64OK() }
------------------

--- Chunk 30---
func (o *opMsgSectionSingle) isIsMaster() bool { if db, ok := o.msg.Lookup("$db").StringValueOK(); ok && db == "admin" { return IsIsMasterDoc(o.msg) } return false }
------------------

--- Chunk 31---
func (o *opMsgSectionSingle) isDbAdmin() bool { if db, ok := o.msg.Lookup("$db").StringValueOK(); ok && db == "admin" { return true } return false }
------------------

--- Chunk 32---
func (o *opMsgSectionSingle) append(buffer []byte) []byte { buffer = wiremessage.AppendMsgSectionType(buffer, wiremessage.SingleDocument) return append(buffer, o.msg...) }
------------------

--- Chunk 33---
func (o *opMsgSectionSingle) commandAndCollection() (Command, string) { return CommandAndCollection(o.msg) }
------------------

--- Chunk 34---
func (o *opMsgSectionSingle) String() string { jsonBytes, err := bson.MarshalExtJSON(o.msg, true, false) if err != nil { return "" } jsonString := string(jsonBytes) return fmt.Sprintf("{ SectionSingle msg: %s }", jsonString) }
------------------

--- Chunk 35---
func (o *opMsgSectionSequence) cursorID() (cursorID int64, ok bool) { // assume no cursor IDs are returned in OP_MSG document sequences return 0, false }
------------------

--- Chunk 36---
func (o *opMsgSectionSequence) isIsMaster() bool { return false }
------------------

--- Chunk 37---
func (o *opMsgSectionSequence) isDbAdmin() bool { res := true for _, v := range o.msgs { if db, ok := v.Lookup("$db").StringValueOK(); !ok || db != "admin" { res = false break } } return res }
------------------

--- Chunk 38---
func (o *opMsgSectionSequence) append(buffer []byte) []byte { buffer = wiremessage.AppendMsgSectionType(buffer, wiremessage.DocumentSequence) length := int32(len(o.identifier) + 5) for _, msg := range o.msgs { length += int32(len(msg)) } buffer = appendi32(buffer, length) buffer = appendCString(buffer, o.identifier) for _, msg := range o.msgs { buffer = append(buffer, msg...) } return buffer }
------------------

--- Chunk 39---
func (o *opMsgSectionSequence) commandAndCollection() (Command, string) { return Unknown, "" }
------------------

--- Chunk 40---
func (o *opMsgSectionSequence) String() string { var msgs []string for _, msg := range o.msgs { jsonBytes, err := bson.MarshalExtJSON(msg, true, false) if err != nil { return "" } jsonString := string(jsonBytes) msgs = append(msgs, jsonString) } return fmt.Sprintf("{ SectionSingle identifier: %s , msgs: [ %s ] }", o.identifier, strings.Join(msgs, ", ")) }
------------------

--- Chunk 41---
func decodeOpMsgSectionSequence(section string) (string, string, error) { var identifier, message = "", "" // Define the regular expression pattern pattern := `\{ SectionSingle identifier: (.+?) , msgs: \[ (.+?) \] \}` // Compile the regular expression regex := regexp.MustCompile(pattern) // Find submatches using the regular expression submatches := regex.FindStringSubmatch(section) if submatches == nil || len(submatches) != 3 { return identifier, message, errors.New("invalid format of message section sequence") } identifier = submatches[1] message = submatches[2] return identifier, message, nil }
------------------

--- Chunk 42---
func extractSectionSingle(data string) (string, error) { // Look for the prefix before the actual content prefix := "{ SectionSingle msg: " startIndex := strings.Index(data, prefix) if startIndex == -1 { return "", fmt.Errorf("start not found") } // Adjust the start index to skip the prefix startIndex += len(prefix) // We'll assume the content ends with " }" that closes the sectionSingle endIndex := strings.LastIndex(data[startIndex:], " }") if endIndex == -1 { return "", fmt.Errorf("end not found") } // Adjust the end index relative to the entire string endIndex += startIndex // Extract the content between the start and end indexes content := data[startIndex:endIndex] // Clean up the extracted content content = strings.Trim(content, " ") return content, nil }
------------------

--- Chunk 43---
Function processOpReply (start): func processOpReply(ctx context.Context, expectedRequest, actualRequest models.MongoRequest, expectedResponse *models.MongoOpReply, mongoPassword string, logger *zap.Logger) (string, bool) { if len(expectedResponse.Documents) == 0 { return "", false } for _, document := range expectedResponse.Documents { var responseMsg map[string]interface{} err := json.Unmarshal([]byte(document), &responseMsg) if err != nil { logger.Error("Failed to unmarshal JSON document of OpReply", zap.Error(err)) return "", false } // Extract and decode the payload from the actual MongoDB request responseMsgData, ok := responseMsg["speculativeAuthenticate"].(map[string]interface{}) if !ok { _, ok = responseMsg["payload"].(map[string]interface{}) if !ok { logger.Debug("failed to extract payload from response data", zap.Any("responseMsg", responseMsg)) continue } responseMsgData = responseMsg } // Extract and decode the expected MongoDB request payload expectedrequestPayload := expectedRequest.Message.(*models.MongoOpQuery).Query // Assuming the query is the payload var expectedrequestPayloadMap map[string
------------------

--- Chunk 44---
Function processOpReply (part 2): ]interface{} err = json.Unmarshal([]byte(expectedrequestPayload), &expectedrequestPayloadMap) if err != nil { utils.LogError(logger, err, "failed to unmarshal request payload into map") return "", false } expectedRequest, ok := expectedrequestPayloadMap["speculativeAuthenticate"].(map[string]interface{}) if !ok { _, ok = expectedrequestPayloadMap["payload"].(map[string]interface{}) if !ok { logger.Debug("failed to extract payload from response data", zap.Any("responseMsg", responseMsg)) continue } expectedRequest = expectedrequestPayloadMap } actualRequestPayload := actualRequest.Message.(*models.MongoOpQuery).Query // Assuming the query is the payload var actualRequestPayloadMap map[string]interface{} err = json.Unmarshal([]byte(actualRequestPayload), &actualRequestPayloadMap) if err != nil { utils.LogError(logger, err, "failed to unmarshal request payload into map") return "", false } actualRequest, ok := actualRequestPayloadMap["speculativeAuthenticate"].(map[string]interface{}) if !ok { _, ok = actualRequestPayloadMap["payload"].(map[string]interface{})
------------------

--- Chunk 45---
Function processOpReply (part 3): if !ok { logger.Debug("failed to extract payload from response data", zap.Any("responseMsg", responseMsg)) continue } actualRequest = actualRequestPayloadMap } // TODO should move this to scram related file _, ok = actualRequest["saslStart"] if !ok { logger.Debug("failed to extract saslStart from response data", zap.Any("responseMsgData", responseMsgData)) } else { resPayload, err := extractAuthPayload(responseMsgData) if err != nil { logger.Debug("Failed to fetch the payload from the received MongoDB response", zap.Error(err)) continue } logger.Debug(fmt.Sprintf("Payload of the received response: %s", resPayload)) decodedResPayload, err := decodeBase64Str(resPayload) if err != nil { logger.Error("Error decoding the received payload base64 string", zap.Error(err)) return "", false } logger.Debug(fmt.Sprintf("Decoded payload of the actual for the SASLStart: %s", string(decodedResPayload))) expectedPayload, err := extractAuthPayload(expectedRequest) if err != nil { logger
------------------

--- Chunk 46---
Function processOpReply (part 4): .Debug("Failed to fetch the payload from the expected MongoDB request", zap.Error(err)) continue } logger.Debug(fmt.Sprintf("Payload of the expected request: %s", expectedPayload)) decodedExpPayload, err := decodeBase64Str(expectedPayload) if err != nil { logger.Error("Error decoding the expected request payload base64 string", zap.Error(err)) return "", false } logger.Debug(fmt.Sprintf("Decoded payload of the expected for the SASLStart: %s", string(decodedExpPayload))) actualReqPayload, err := extractAuthPayload(actualRequest) if err != nil { logger.Debug("Failed to extract the payload from the actual MongoDB request", zap.Error(err)) continue } // Extract and decode the payload from the actual MongoDB request decodedReqPayload, err := decodeBase64Str(actualReqPayload) if err != nil { logger.Error("Failed to fetch the payload from the actual MongoDB request", zap.Error(err)) return "", false } logger.Debug(fmt.Sprintf("Payload of the actual request: %s", decodedReqPayload)) newFirstAuthResponse, err := scram.GenerateServerFirstMessage(decodedExpPayload
------------------

--- Chunk 47---
Function processOpReply (part 5): , decodedReqPayload, decodedResPayload, logger) if err != nil { return "", false } logger.Debug("After replacing the new client nonce in auth response", zap.String("first response", newFirstAuthResponse)) conversationID, err := extractConversationID(responseMsgData) if err != nil { logger.Error("Failed to fetch the conversationId for the SCRAM auth from the recorded first response", zap.Error(err)) return "", false } // Generate the auth message from the received first request and recorded first response authMessage := scram.GenerateAuthMessage(string(decodedReqPayload), newFirstAuthResponse, logger) if authMessage == "" { err := errors.New("failed to generate auth message") logger.Error("Auth message generation failed", zap.Error(err)) return "", false } authMechanism, ok := actualRequest["mechanism"].(string) if !ok { logger.Debug("failed to auth mechanism from expected request data", zap.Any("expectedRequest", actualRequest)) continue } if authMechanism != util.SCRAM_SHA_1 && authMechanism != util.SCRAM_SHA_256 {
------------------

--- Chunk 48---
Function processOpReply (part 6): logger.Error("Invalid authentication mechanism", zap.String("authMechanism", authMechanism)) return "", false } authMessage = authMessage + ",auth=" + authMechanism logger.Debug("the auth message for the SCRAM saslstart authentication", zap.String("conversation-id", conversationID), zap.String("authMessage", authMessage)) connID := ctx.Value(models.ClientConnectionIDKey).(string) authMessageMap.Store(connID+"+"+conversationID, authMessage) // Marshal the new first response for the SCRAM authentication authResponse := base64.StdEncoding.EncodeToString([]byte(newFirstAuthResponse)) if authResponse != "" { return authResponse, true } } _, ok = actualRequest["saslContinue"] if !ok { logger.Debug("failed to extract saslContinue from response data", zap.Any("responseMsgData", responseMsgData)) } else { responsePayload, err := extractAuthPayload(responseMsgData) if err != nil { utils.LogError(logger, err, "failed to fetch the payload from the recorded mongo response") return "", false } logger.Debug(fmt.Sprint("
------------------

--- Chunk 49---
Function processOpReply (part 7): the payload of the recorded second response of SCRAM: ", responsePayload)) decodedResponsePayload, err := decodeBase64Str(responsePayload) if err != nil { utils.LogError(logger, err, "Error decoding the recorded saslContinue response payload base64 string") return "", false } logger.Debug(fmt.Sprint("the decoded payload of the repsonse for the saslContinue: ", (string)(decodedResponsePayload))) fields := strings.Split(string(decodedResponsePayload), ",") verifier, err := parseFieldBase64(fields[0], "v") if err != nil { logger.Debug("failed to parse the verifier of final response message", zap.Any("parsing error", err.Error())) return "", false } logger.Debug("the recorded verifier of the auth request", zap.Any("verifier/server-signature", string(verifier))) // fetch the conversation id conversationID, err := extractConversationID(actualRequest) if err != nil { utils.LogError(logger, err, "failed to fetch the conversationId for the SCRAM auth from the received final response") return "", false } logger.Debug("fetched conversationId for
------------------

--- Chunk 50---
Function processOpReply (part 8): the SCRAM authentication", zap.String("cid", conversationID)) salt := "" itr := 0 authType := "" // get the authMessage from the saslStart conversation. Since, saslContinue have the same conversationId // authMsg := authMessageMap[conversationID] authMessage, ok := authMessageMap.Load(conversationID) authMessageStr := "" if ok { authMessageStr = authMessage.(string) } // get the salt and iteration from the authMessage to generate salted password fields = strings.Split(authMessageStr, ",") filteredFields := []string{} for _, part := range fields { if strings.HasPrefix(part, "s=") { // Split based on "=" and get the value of "s" saltByt, err := decodeBase64Str(strings.TrimPrefix(part, "s=")) if err != nil { utils.LogError(logger, err, "failed to decode the base64 string of salt") return "", false } salt = string(saltByt) } if strings.HasPrefix(part, "i=") { //
------------------

--- Chunk 51---
Function processOpReply (part 9): Split based on "=" and get the value of "i" itr, err = strconv.Atoi(strings.Split(part, "=")[1]) if err != nil { utils.LogError(logger, err, "failed to convert the string into integer") return "", false } } if strings.HasPrefix(part, "auth=") { // Only add fields that are not prefixed with "auth=" authType = strings.Split(part, "=")[1] if err != nil { utils.LogError(logger, err, "failed to convert the string into integer") return "", false } } else { filteredFields = append(filteredFields, part) } } authMessageStr = strings.Join(filteredFields, ",") // Since, the server proof is the signature generated by the authMessage and salted password. // So, need to return the new server proof according to the new authMessage which is different from the recorded. newVerifier, err := scram.GenerateServerFinalMessage(authMessageStr, authType, mongoPassword, salt, itr, logger) if err != nil { utils.LogError(logger, err, "failed to get the new server proof
------------------

--- Chunk 52---
Function processOpReply (end): ") return "", false } return base64.StdEncoding.EncodeToString([]byte("v=" + newVerifier)), true } } return "", false }
------------------

--- Chunk 53---
Function encodeOpMsg (start): func encodeOpMsg(ctx context.Context, responseOpMsg *models.MongoOpMessage, actualRequestMsgSections []string, expectedRequestMsgSections []string, mongoPassword string, logger *zap.Logger) (*opMsg, error) { message := &opMsg{ flags: wiremessage.MsgFlag(responseOpMsg.FlagBits), checksum: uint32(responseOpMsg.Checksum), sections: []opMsgSection{}, logger: logger, } for messageIndex, messageValue := range responseOpMsg.Sections { switch { case strings.HasPrefix(messageValue, "{ SectionSingle identifier:"): identifier, msgsStr, err := decodeOpMsgSectionSequence(responseOpMsg.Sections[messageIndex]) if err != nil { utils.LogError(logger, err, "failed to extract the msg section from recorded message") return nil, err } msgs := strings.Split(msgsStr, ", ") docs := []bsoncore.Document{} for _, msg := range msgs { var unmarshaledDoc bsoncore.Document err = bson.UnmarshalExtJSON([]byte(msg), true, &unmarshaledDoc) if err != nil { utils.LogError(logger, err, "failed to
------------------

--- Chunk 54---
Function encodeOpMsg (part 2): unmarshal the recorded document string of OpMsg") return nil, err } docs = append(docs, unmarshaledDoc) } message.sections = append(message.sections, &opMsgSectionSequence{ identifier: identifier, msgs: docs, }) case strings.HasPrefix(messageValue, "{ SectionSingle msg:"): sectionStr, err := extractSectionSingle(responseOpMsg.Sections[messageIndex]) if err != nil { utils.LogError(logger, err, "failed to extract the msg section from recorded message single section") return nil, err } resultStr, ok, err := handleScramAuth(ctx, actualRequestMsgSections, expectedRequestMsgSections, sectionStr, mongoPassword, logger) if err != nil { return nil, err } if ok { logger.Debug("new responses have been generated for the scram authentication", zap.Any("response", resultStr)) sectionStr = resultStr } var unmarshaledDoc bsoncore.Document err = bson.UnmarshalExtJSON([]byte(sectionStr), true, &unmarshaledDoc) if err != nil { utils.LogError(logger,
------------------

--- Chunk 55---
Function encodeOpMsg (end): err, "failed to unmarshal the recorded document string of OpMsg") return nil, err } message.sections = append(message.sections, &opMsgSectionSingle{ msg: unmarshaledDoc, }) default: utils.LogError(logger, nil, "failed to encode the OpMsg section into mongo wiremessage because of invalid format", zap.Any("section", messageValue)) } } return message, nil }
------------------

--- Chunk 56---
Function decodeMsg (start): func decodeMsg(reqID int32, wm []byte, logger *zap.Logger) (*opMsg, error) { var ok bool m := opMsg{ reqID: reqID, logger: logger, } m.flags, wm, ok = wiremessage.ReadMsgFlags(wm) if !ok { return nil, errors.New("malformed wire message: missing OP_MSG flags") } checksumPresent := m.flags&wiremessage.ChecksumPresent == wiremessage.ChecksumPresent for len(wm) > 0 { // If the checksumPresent flag is set, the last four bytes of the message contain the checksum. if checksumPresent && len(wm) == 4 { m.checksum, wm, ok = wiremessage.ReadMsgChecksum(wm) if !ok { return nil, errors.New("malformed wire message: insufficient bytes to read checksum") } continue } var stype wiremessage.SectionType stype, wm, ok = wiremessage.ReadMsgSectionType(wm) if !ok { return nil, errors.New("malformed wire message: insufficient bytes to read section type") } switch stype {
------------------

--- Chunk 57---
Function decodeMsg (end): case wiremessage.SingleDocument: s := opMsgSectionSingle{} s.msg, wm, ok = wiremessage.ReadMsgSectionSingleDocument(wm) if !ok { return nil, errors.New("malformed wire message: insufficient bytes to read single document") } m.sections = append(m.sections, &s) case wiremessage.DocumentSequence: s := opMsgSectionSequence{} s.identifier, s.msgs, wm, ok = wiremessage.ReadMsgSectionDocumentSequence(wm) if !ok { return nil, errors.New("malformed wire message: insufficient bytes to read document sequence") } m.sections = append(m.sections, &s) default: return nil, fmt.Errorf("malformed wire message: unknown section type %v", stype) } } return &m, nil }
------------------

--- Chunk 58---
func (m *opMsg) OpCode() wiremessage.OpCode { return wiremessage.OpMsg }
------------------

--- Chunk 59---
func (m *opMsg) Encode(responseTo, requestID int32) []byte { var buffer []byte m.logger.Debug(fmt.Sprintf("the responseTo for the OpMsg: %v, for requestId: %v", responseTo, wiremessage.NextRequestID())) idx, buffer := wiremessage.AppendHeaderStart(buffer, requestID, responseTo, wiremessage.OpMsg) buffer = wiremessage.AppendMsgFlags(buffer, m.flags) for _, section := range m.sections { buffer = section.append(buffer) } if m.flags&wiremessage.ChecksumPresent == wiremessage.ChecksumPresent { // The checksum is a uint32, but we can use appendi32 to encode it. Overflow/underflow when casting to int32 is // not a concern here because the bytes in the number do not change after casting. buffer = appendi32(buffer, int32(m.checksum)) } buffer = bsoncore.UpdateLength(buffer, idx, int32(len(buffer[idx:]))) m.logger.Debug(fmt.Sprintf("opmsg string: %v", m.String())) return buffer }
------------------

--- Chunk 60---
func (m *opMsg) IsIsMaster() bool { for _, section := range m.sections { if section.isIsMaster() { return true } } return false }
------------------

--- Chunk 61---
func (m *opMsg) IsIsAdminDB() bool { for _, section := range m.sections { if section.isDbAdmin() { return true } } return false }
------------------

--- Chunk 62---
func (m *opMsg) CursorID() (cursorID int64, ok bool) { for _, section := range m.sections { if cursorID, ok := section.cursorID(); ok { return cursorID, ok } } return 0, false }
------------------

--- Chunk 63---
func (m *opMsg) RequestID() int32 { return m.reqID }
------------------

--- Chunk 64---
func (m *opMsg) Error() error { if len(m.sections) == 0 { return nil } single, ok := m.sections[0].(*opMsgSectionSingle) if !ok { return nil } return driver.ExtractErrorFromServerResponse(single.msg) }
------------------

--- Chunk 65---
func (m *opMsg) Unacknowledged() bool { return m.flags&wiremessage.MoreToCome == wiremessage.MoreToCome }
------------------

--- Chunk 66---
func (m *opMsg) CommandAndCollection() (Command, string) { for _, section := range m.sections { command, collection := section.commandAndCollection() if command != Unknown { return command, collection } } return Unknown, "" }
------------------

--- Chunk 67---
func (m *opMsg) TransactionDetails() *TransactionDetails { for _, section := range m.sections { if single, ok := section.(*opMsgSectionSingle); ok { _, lsID, ok := single.msg.Lookup("lsid", "id").BinaryOK() if !ok { continue } txnNumber, ok := single.msg.Lookup("txnNumber").Int64OK() if !ok { continue } _, ok = single.msg.Lookup("autocommit").BooleanOK() if !ok { continue } startTransaction, ok := single.msg.Lookup("startTransaction").BooleanOK() return &TransactionDetails{ LsID: lsID, TxnNumber: txnNumber, IsStartTransaction: ok && startTransaction, } } } return nil }
------------------

--- Chunk 68---
func (m *opMsg) GetFlagBits() int32 { return int32(m.flags) }
------------------

--- Chunk 69---
func (m *opMsg) String() string { var sections []string for _, section := range m.sections { sections = append(sections, section.String()) } return fmt.Sprintf("{ OpMsg flags: %d, sections: [%s], checksum: %d }", m.flags, strings.Join(sections, ", "), m.checksum) }
------------------

--- Chunk 70---
func (r *opReply) TransactionDetails() *TransactionDetails { return nil }
------------------

--- Chunk 71---
Function encodeOpReply (start): func encodeOpReply(ctx context.Context, actualRequest models.MongoRequest, expectedRequest models.MongoRequest, expectedResponse *models.MongoOpReply, mongoPassword string, logger *zap.Logger) (*opReply, error) { replyDocs := []bsoncore.Document{} updatedFirstResponse, isResponseUpdated := processOpReply(ctx, expectedRequest, actualRequest, expectedResponse, mongoPassword, logger) for _, v := range expectedResponse.Documents { var unmarshaledDoc bsoncore.Document logger.Debug(fmt.Sprintf("the document string is: %v", string(v))) var result map[string]interface{} err := json.Unmarshal([]byte(v), &result) if err != nil { utils.LogError(logger, err, "failed to unmarshal string document of OpReply") return nil, err } // set the fields for handshake calls at test mode localTime, ok := result["localTime"].(map[string]interface{}) if ok { localTime["$date"].(map[string]interface{})["$numberLong"] = strconv.FormatInt(time.Now().Unix(), 10) logger.Debug(fmt.Sprintf("the updated document string is: %v", result["localTime"].(map[string]interface{})["$date"].(map[string]interface
------------------

--- Chunk 72---
Function encodeOpReply (part 2): {})["$numberLong"])) } if isResponseUpdated { // add checks query, ok := result["speculativeAuthenticate"].(map[string]interface{}) if !ok { logger.Debug("failed to extract payload from response data", zap.Any("responseMsg", result)) payload, ok := result["payload"].(map[string]interface{}) if !ok { logger.Debug("failed to extract payload from response data", zap.Any("responseMsg", result)) continue } payload["$binary"].(map[string]interface{})["base64"] = updatedFirstResponse } else { query["payload"].(map[string]interface{})["$binary"].(map[string]interface{})["base64"] = updatedFirstResponse } } v, err := json.Marshal(result) if err != nil { utils.LogError(logger, err, "failed to marshal the updated string document of OpReply") return nil, err } err = bson.UnmarshalExtJSON([]byte(v), false, &unmarshaledDoc) if err != nil { utils.LogError(logger, err, "failed to unmarshal the updated document string of OpReply") return nil, err }
------------------

--- Chunk 73---
Function encodeOpReply (end): elements, _ := unmarshaledDoc.Elements() logger.Debug(fmt.Sprintf("the elements of the reply docs: %v", elements)) replyDocs = append(replyDocs, unmarshaledDoc) } return &opReply{ flags: wiremessage.ReplyFlag(expectedResponse.ResponseFlags), cursorID: expectedResponse.CursorID, startingFrom: expectedResponse.StartingFrom, numReturned: expectedResponse.NumberReturned, documents: replyDocs, }, nil }
------------------

--- Chunk 74---
func decodeReply(reqID int32, wm []byte) (*opReply, error) { var ok bool r := opReply{ reqID: reqID, } r.flags, wm, ok = wiremessage.ReadReplyFlags(wm) if !ok { return nil, errors.New("malformed reply message: missing OP_REPLY flags") } r.cursorID, wm, ok = wiremessage.ReadReplyCursorID(wm) if !ok { return nil, errors.New("malformed reply message: cursor id") } r.startingFrom, wm, ok = wiremessage.ReadReplyStartingFrom(wm) if !ok { return nil, errors.New("malformed reply message: starting from") } r.numReturned, wm, ok = wiremessage.ReadReplyNumberReturned(wm) if !ok { return nil, errors.New("malformed reply message: number returned") } r.documents, _, ok = wiremessage.ReadReplyDocuments(wm) if !ok { return nil, errors.New("malformed reply message: could not read documents from reply") } return &r, nil }
------------------

--- Chunk 75---
func (r *opReply) OpCode() wiremessage.OpCode { return wiremessage.OpReply }
------------------

--- Chunk 76---
func (r *opReply) Encode(responseTo, requestID int32) []byte { var buffer []byte idx, buffer := wiremessage.AppendHeaderStart(buffer, requestID, responseTo, wiremessage.OpReply) buffer = wiremessage.AppendReplyFlags(buffer, r.flags) buffer = wiremessage.AppendReplyCursorID(buffer, r.cursorID) buffer = wiremessage.AppendReplyStartingFrom(buffer, r.startingFrom) buffer = wiremessage.AppendReplyNumberReturned(buffer, r.numReturned) for _, doc := range r.documents { buffer = append(buffer, doc...) } buffer = bsoncore.UpdateLength(buffer, idx, int32(len(buffer[idx:]))) return buffer }
------------------

--- Chunk 77---
func (r *opReply) IsIsMaster() bool { return false }
------------------

--- Chunk 78---
func (r *opReply) IsIsAdminDB() bool { return false }
------------------

--- Chunk 79---
func (r *opReply) CursorID() (cursorID int64, ok bool) { return r.cursorID, true }
------------------

--- Chunk 80---
func (r *opReply) RequestID() int32 { return r.reqID }
------------------

--- Chunk 81---
func (r *opReply) Error() error { if len(r.documents) == 0 { return nil } return driver.ExtractErrorFromServerResponse(r.documents[0]) }
------------------

--- Chunk 82---
func (r *opReply) Unacknowledged() bool { return false }
------------------

--- Chunk 83---
func (r *opReply) CommandAndCollection() (Command, string) { return Find, "" }
------------------

--- Chunk 84---
func (r *opReply) String() string { var documents []string for _, document := range r.documents { documents = append(documents, document.String()) } return fmt.Sprintf("{ OpReply flags: %d, cursorID: %d, startingFrom: %d, numReturned: %d, documents: [%s] }", r.flags, r.cursorID, r.startingFrom, r.numReturned, strings.Join(documents, ", ")) }
------------------

--- Chunk 85---
func appendi32(dst []byte, i32 int32) []byte { return append(dst, byte(i32), byte(i32>>8), byte(i32>>16), byte(i32>>24)) }
------------------

--- Chunk 86---
func appendCString(b []byte, str string) []byte { b = append(b, str...) return append(b, 0x00) }
------------------

--- File: pkg/core/proxy/integrations/mongo/scramAuth.go---

--- Chunk 1---
Function isScramAuthRequest (start): func isScramAuthRequest(actualRequestSections []string, logger *zap.Logger) bool { // Iterate over each section in the actual request sections for _, v := range actualRequestSections { // Extract the message from the section actualMsg, err := extractMsgFromSection(v) if err != nil { utils.LogError(logger, err, "failed to extract the section of the received mongo request message", zap.Any("the section", v)) return false } conversationID, _ := extractConversationID(actualMsg) // Check if the message is for starting the SASL (authentication) process if _, exists := actualMsg["saslStart"]; exists { logger.Debug("the received request is saslStart", zap.Any("OpMsg", actualMsg), zap.Any("conversationId", conversationID)) return true // Check if the message is for final request of the SASL (authentication) process } else if _, exists := actualMsg["saslContinue"]; exists { logger.Debug("the received request is saslContinue", zap.Any("OpMsg", actualMsg), zap.Any("conversationId", conversationID
------------------

--- Chunk 2---
Function isScramAuthRequest (end): ), ) return true } } return false }
------------------

--- Chunk 3---
Function handleScramAuth (start): func handleScramAuth(ctx context.Context, actualRequestSections, expectedRequestSections []string, responseSection, mongoPassword string, logger *zap.Logger) (string, bool, error) { // Iterate over each section in the actual request sections for i, v := range actualRequestSections { // single document do not uses section sequence for SCRAM auth if !strings.HasPrefix(v, "{ SectionSingle msg:") { continue } // Extract the message from the section actualMsg, err := extractMsgFromSection(v) if err != nil { utils.LogError(logger, err, "failed to extract the section of the received mongo request message") return "", false, err } // Check if the message is for starting the SASL (authentication) process if _, exists := actualMsg["saslStart"]; exists { mechanism, exists := actualMsg["mechanism"] // Check the authentication mechanism used and ensure it contains "SCRAM" if mechanism, ok := mechanism.(string); exists && ok && strings.Contains(mechanism, "SCRAM") { if _, exists := actualMsg["payload"]; exists { return handleS
------------------

--- Chunk 4---
Function handleScramAuth (end): aslStart(ctx, i, actualMsg, expectedRequestSections, responseSection, logger) } } // Check if the message is for final request of the SASL (authentication) process } else if _, exists := actualMsg["saslContinue"]; exists { if _, exists := actualMsg["payload"]; exists { return handleSaslContinue(ctx, actualMsg, responseSection, mongoPassword, logger) } } } return "", false, nil }
------------------

--- Chunk 5---
func extractAuthPayload(data interface{}) (string, error) { // Top-level map topMap, ok := data.(map[string]interface{}) if !ok { return "", errors.New("expected top-level data to be a map") } // Payload map payload, ok := topMap["payload"].(map[string]interface{}) if !ok { return "", errors.New("expected 'payload' to be a map") } // $binary map binaryMap, ok := payload["$binary"].(map[string]interface{}) if !ok { return "", errors.New("expected '$binary' to be a map") } // Base64 string base64Str, ok := binaryMap["base64"].(string) if !ok { return "", errors.New("expected 'base64' to be a string") } return base64Str, nil }
------------------

--- Chunk 6---
func extractConversationID(data interface{}) (string, error) { // Top-level map topMap, ok := data.(map[string]interface{}) if !ok { return "", errors.New("expected top-level data to be a map") } conversationID, exists := topMap["conversationId"] if !exists { return "", errors.New("'conversationId' not found") } // conversationId map conversationIDMap, ok := conversationID.(map[string]interface{}) if !ok { return "", errors.New("expected 'conversationId' to be a map") } // Check presence of "$numberInt" num, exists := conversationIDMap["$numberInt"] if !exists { return "", errors.New("'$numberInt' not found") } numberIntStr, present := num.(string) if !present { return "", errors.New("expected '$numberInt' to be a string") } return numberIntStr, nil }
------------------

--- Chunk 7---
func updateConversationID(actualMsg map[string]interface{}, newConversationID int) (map[string]interface{}, error) { // Check if conversationID exists and is a map conversationID, exists := actualMsg["conversationId"] if !exists { return actualMsg, errors.New("'conversationId' not found") } conversationIDMap, ok := conversationID.(map[string]interface{}) if !ok { return actualMsg, errors.New("expected 'conversationId' to be a map") } // Update the "$numberInt" field with the new value conversationIDMap["$numberInt"] = fmt.Sprintf("%d", newConversationID) actualMsg["conversationId"] = conversationIDMap return actualMsg, nil }
------------------

--- Chunk 8---
func extractMsgFromSection(section string) (map[string]interface{}, error) { var err error var sectionStr string var result map[string]interface{} if strings.HasPrefix(section, "{ SectionSingle msg:") { sectionStr, err = extractSectionSingle(section) if err != nil { return nil, err } err = json.Unmarshal([]byte(sectionStr), &result) if err != nil { return nil, err } } return result, nil }
------------------

--- Chunk 9---
Function handleSaslStart (start): func handleSaslStart(ctx context.Context, i int, actualMsg map[string]interface{}, expectedRequestSections []string, responseSection string, logger *zap.Logger) (string, bool, error) { actualReqPayload, err := extractAuthPayload(actualMsg) if err != nil { utils.LogError(logger, err, "failed to fetch the payload from the received mongo request") return "", false, err } logger.Debug(fmt.Sprint("the payload of the received request: ", actualReqPayload)) // Decode the base64 encoded payload of the received mongo request decodedActualReqPayload, err := decodeBase64Str(actualReqPayload) if err != nil { utils.LogError(logger, err, "Error decoding the received payload base64 string") return "", false, err } logger.Debug(fmt.Sprint("the decoded payload of the actual for the saslstart: ", (string)(decodedActualReqPayload))) // check to ensure that the matched recorded mongo request contains the auth payload for SCRAM if len(expectedRequestSections) < i+1 { err = errors.New("unrecorded message sections for the received auth request") utils.LogError(logger, err, "failed to match the message section payload")
------------------

--- Chunk 10---
Function handleSaslStart (part 2): return "", false, err } expectedMsg, err := extractMsgFromSection(expectedRequestSections[i]) if err != nil { utils.LogError(logger, err, "failed to extract the section of the recorded mongo request message") return "", false, err } expectedReqPayload, err := extractAuthPayload(expectedMsg) if err != nil { utils.LogError(logger, err, "failed to fetch the payload from the recorded mongo request") return "", false, err } logger.Debug(fmt.Sprint("the payload of the recorded request: ", expectedReqPayload)) // Decode the base64 encoded payload of the recorded mongo request decodedExpectedReqPayload, err := decodeBase64Str(expectedReqPayload) if err != nil { utils.LogError(logger, err, "Error decoding the recorded request payload base64 string") return "", false, err } logger.Debug(fmt.Sprint("the decoded payload of the expected for the saslstart: ", (string)(decodedExpectedReqPayload))) // the payload of the recorded first response of SCRAM authentication var responseMsg map[string]interface{} err = json.Unmarshal([]byte(responseSection), &responseMsg) if err != nil { utils.LogError(logger, err, "failed
------------------

--- Chunk 11---
Function handleSaslStart (part 3): to unmarshal string document of OpReply") return "", false, err } responsePayload, err := extractAuthPayload(responseMsg) if err != nil { utils.LogError(logger, err, "failed to fetch the payload from the recorded mongo response") return "", false, err } logger.Debug(fmt.Sprint("the payload of the recorded response: ", responsePayload)) // Decode the base64 encoded payload of the recorded mongo response decodedResponsePayload, err := decodeBase64Str(responsePayload) if err != nil { utils.LogError(logger, err, "Error decoding the recorded response payload base64 string") return "", false, err } logger.Debug(fmt.Sprint("the decoded payload of the repsonse for the saslstart: ", (string)(decodedResponsePayload))) // Generate the first response for the saslStart request by // replacing the old client nonce with new client nonce newFirstAuthResponse, err := scram.GenerateServerFirstMessage(decodedExpectedReqPayload, decodedActualReqPayload, decodedResponsePayload, logger) if err != nil { utils.LogError(logger, err, "failed to generate the new first response for the SCRAM authentication") return "", false, err }
------------------

--- Chunk 12---
Function handleSaslStart (part 4): logger.Debug("after replacing the new client nonce in auth response", zap.String("first response", newFirstAuthResponse)) // replace the payload with new first response auth responseMsg["payload"].(map[string]interface{})["$binary"].(map[string]interface{})["base64"] = base64.StdEncoding.EncodeToString([]byte(newFirstAuthResponse)) responseMsg, err = updateConversationID(responseMsg, int(util.GetNextID())) if err != nil { utils.LogError(logger, err, "failed to update the conversationId in the sasl start auth message") return "", false, err } // fetch the conversation id conversationID, err := extractConversationID(responseMsg) if err != nil { utils.LogError(logger, err, "failed to fetch the conversationId for the SCRAM auth from the recorded first response") return "", false, err } logger.Debug("fetch the conversationId for the SCRAM authentication", zap.String("cid", conversationID)) // generate the auth message from the received first request and recorded first response authMessage := scram.GenerateAuthMessage(string(decodedActualReqPayload), newFirstAuthResponse, logger) authMechanism, ok := actualMsg["mechanism"].(string) if !ok {
------------------

--- Chunk 13---
Function handleSaslStart (end): logger.Debug("failed to auth mechanism from expected request data", zap.Any("expectedRequest", actualMsg)) } else { if authMechanism != scramUtil.SCRAM_SHA_1 && authMechanism != scramUtil.SCRAM_SHA_256 { logger.Error("Invalid authentication mechanism", zap.String("authMechanism", authMechanism)) return "", false, errors.New("invalid authentication mechanism") } authMessage = authMessage + ",auth=" + authMechanism // store the auth message in the global map for the conversationId } connID := ctx.Value(models.ClientConnectionIDKey).(string) authMessageMap.Store(connID+"+"+conversationID, authMessage) logger.Debug("generate the new auth message for the received auth request", zap.String("msg", authMessage)) // marshal the new first response for the SCRAM authentication newAuthResponse, err := json.Marshal(responseMsg) if err != nil { utils.LogError(logger, err, "failed to marshal the first auth response for SCRAM") return "", false, err } return string(newAuthResponse), true, nil }
------------------

--- Chunk 14---
Function handleSaslContinue (start): func handleSaslContinue(ctx context.Context, actualMsg map[string]interface{}, responseSection, mongoPassword string, logger *zap.Logger) (string, bool, error) { var responseMsg map[string]interface{} err := json.Unmarshal([]byte(responseSection), &responseMsg) if err != nil { utils.LogError(logger, err, "failed to unmarshal string document of OpReply") return "", false, err } logger.Debug(fmt.Sprintf("the recorded OpMsg section: %v", responseMsg)) responsePayload, err := extractAuthPayload(responseMsg) if err != nil { utils.LogError(logger, err, "failed to fetch the payload from the recorded mongo response") return "", false, err } logger.Debug(fmt.Sprint("the payload of the recorded second response of SCRAM: ", responsePayload)) decodedResponsePayload, err := decodeBase64Str(responsePayload) if err != nil { utils.LogError(logger, err, "Error decoding the recorded saslContinue response payload base64 string") return "", false, err } logger.Debug(fmt.Sprint("the decoded payload of the repsonse for the saslContinue: ", (string)(decodedResponsePayload))) fields := strings.Split(string(decodedResponsePayload), ",
------------------

--- Chunk 15---
Function handleSaslContinue (part 2): ") verifier, err := parseFieldBase64(fields[0], "v") if err != nil { logger.Debug("failed to parse the verifier of final response message", zap.Any("parsing error", err.Error())) return "", false, nil } logger.Debug("the recorded verifier of the auth request", zap.Any("verifier/server-signature", string(verifier))) // fetch the conversation id conversationID, err := extractConversationID(actualMsg) if err != nil { utils.LogError(logger, err, "failed to fetch the conversationId for the SCRAM auth from the received final response") return "", false, err } logger.Debug("fetched conversationId for the SCRAM authentication", zap.String("cid", conversationID), zap.String("verifier", string(verifier))) salt := "" itr := 0 authType := "" // get the authMessage from the saslStart conversation. Since, saslContinue have the same conversationId // authMsg := authMessageMap[conversationID] connID := ctx.Value(models.ClientConnectionIDKey).(string) authMessage, ok := authMessageMap.Load(connID + "+" + conversationID) authMessageStr := "" if ok
------------------

--- Chunk 16---
Function handleSaslContinue (part 3): { authMessageStr = authMessage.(string) } logger.Debug("fetch the auth message for the SCRAM authentication", zap.String("cid", conversationID), zap.String("authMessage", authMessageStr)) // get the salt and iteration from the authMessage to generate salted password fields = strings.Split(authMessageStr, ",") filteredFields := []string{} for _, part := range fields { if strings.HasPrefix(part, "s=") { // Split based on "=" and get the value of "s" saltByt, err := decodeBase64Str(strings.TrimPrefix(part, "s=")) if err != nil { utils.LogError(logger, err, "failed to decode the base64 string of salt") return "", false, err } salt = string(saltByt) } if strings.HasPrefix(part, "i=") { // Split based on "=" and get the value of "i" itr, err = strconv.Atoi(strings.Split(part, "=")[1]) if err != nil { utils.LogError(logger, err, "failed to convert the string into integer") return "", false, err } }
------------------

--- Chunk 17---
Function handleSaslContinue (part 4): if strings.HasPrefix(part, "auth=") { // Only add fields that are not prefixed with "auth=" authType = strings.Split(part, "=")[1] if err != nil { utils.LogError(logger, err, "failed to convert the string into integer") return "", false, err } } else { filteredFields = append(filteredFields, part) } } authMessageStr = strings.Join(filteredFields, ",") // Since, the server proof is the signature generated by the authMessage and salted password. // So, need to return the new server proof according to the new authMessage which is different from the recorded. newVerifier, err := scram.GenerateServerFinalMessage(authMessageStr, authType, mongoPassword, salt, itr, logger) if err != nil { utils.LogError(logger, err, "failed to get the new server proof") return "", false, err } // tools the payload of the mongo response for the authentication responseMsg["payload"].(map[string]interface{})["$binary"].(map[string]interface{})["base64"] = base64.StdEncoding.EncodeToString([]byte("v=" + newVerifier)) byt, err :=
------------------

--- Chunk 18---
Function handleSaslContinue (end): json.Marshal(responseMsg) if err != nil { utils.LogError(logger, err, "failed to marshal the updated string document of OpReply") return "", false, err } responseSection = string(byt) return responseSection, true, nil }
------------------

--- Chunk 19---
func parseField(s, k string) (string, error) { t := strings.TrimPrefix(s, k+"=") if t == s { return "", fmt.Errorf("error parsing '%s' for field '%s'", s, k) } return t, nil }
------------------

--- Chunk 20---
func parseFieldBase64(s, k string) ([]byte, error) { if !strings.Contains(s, k+"=") { return nil, fmt.Errorf("verifier doesn't exist in string '%s'", s) } raw, err := parseField(s, k) if err != nil { return nil, err } dec, err := decodeBase64Str(raw) if err != nil { return nil, err } return dec, nil }
------------------

--- File: pkg/core/proxy/integrations/mongo/util.go---

--- Chunk 1---
func hasSecondSetBit(num int) bool { // Shift the number right by 1 bit and check if the least significant bit is set return (num>>1)&1 == 1 }
------------------

--- Chunk 2---
func isHeartBeat(logger *zap.Logger, opReq Operation, requestHeader models.MongoHeader, mongoRequest interface{}) bool { switch requestHeader.Opcode { case wiremessage.OpQuery: return true case wiremessage.OpMsg: _, ok := mongoRequest.(*models.MongoOpMessage) if ok { return (opReq.IsIsAdminDB() && strings.Contains(opReq.String(), "hello")) || opReq.IsIsMaster() || isScramAuthRequest(mongoRequest.(*models.MongoOpMessage).Sections, logger) } default: return false } return false }
------------------

--- File: pkg/core/proxy/integrations/mysql/mysql.go---

--- Chunk 1---
func init() { integrations.Register(integrations.MYSQL, &integrations.Parsers{ Initializer: New, Priority: 100, }) }
------------------

--- Chunk 2---
func New(logger *zap.Logger) integrations.Integrations { return &MySQL{ logger: logger, } }
------------------

--- Chunk 3---
func (m *MySQL) MatchType(_ context.Context, _ []byte) bool { //Returning false here because sql parser is using the ports to check if the packet is mysql or not. return false }
------------------

--- Chunk 4---
func (m *MySQL) RecordOutgoing(ctx context.Context, src net.Conn, dst net.Conn, mocks chan<- *models.Mock, opts models.OutgoingOptions) error { logger := m.logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", src.RemoteAddr().String())) err := recorder.Record(ctx, logger, src, dst, mocks, opts) if err != nil { utils.LogError(logger, err, "failed to encode the mysql message into the yaml") return err } return nil }
------------------

--- Chunk 5---
func (m *MySQL) MockOutgoing(ctx context.Context, src net.Conn, dstCfg *models.ConditionalDstCfg, mockDb integrations.MockMemDb, opts models.OutgoingOptions) error { logger := m.logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", src.RemoteAddr().String())) err := replayer.Replay(ctx, logger, src, dstCfg, mockDb, opts) if err != nil && err != io.EOF { utils.LogError(logger, err, "failed to decode the mysql message from the yaml") return err } return nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/recorder/conn.go---

--- Chunk 1---
Function handleInitialHandshake (start): func handleInitialHandshake(ctx context.Context, logger *zap.Logger, clientConn, destConn net.Conn, decodeCtx *wire.DecodeContext, opts models.OutgoingOptions) (handshakeRes, error) { res := handshakeRes{ req: make([]mysql.Request, 0), resp: make([]mysql.Response, 0), } // Read the initial handshake from the server (server-greetings) handshake, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { utils.LogError(logger, err, "failed to read initial handshake from server") return res, err } // Write the initial handshake to the client _, err = clientConn.Write(handshake) if err != nil { if ctx.Err() != nil { return res, ctx.Err() } utils.LogError(logger, err, "failed to write server greetings to the client") return res, err } // Set the timestamp of the initial request res.reqTimestamp = time.Now() // Decode server handshake packet handshakePkt, err := wire.DecodePayload(ctx, logger, handshake, clientConn, decodeCtx) if err != nil { utils
------------------

--- Chunk 2---
Function handleInitialHandshake (part 2): .LogError(logger, err, "failed to decode handshake packet") return res, err } // Set the intial request operation res.requestOperation = handshakePkt.Header.Type // Get the initial Plugin Name pluginName, err := wire.GetPluginName(handshakePkt.Message) if err != nil { utils.LogError(logger, err, "failed to get initial plugin name") return res, err } // Set the initial plugin name decodeCtx.PluginName = pluginName res.resp = append(res.resp, mysql.Response{ PacketBundle: *handshakePkt, }) // Handshake response from client (or SSL request) handshakeResponse, err := mysqlUtils.ReadPacketBuffer(ctx, logger, clientConn) if err != nil { if err == io.EOF { logger.Debug("received request buffer is empty in record mode for mysql call") return res, err } utils.LogError(logger, err, "failed to read handshake response from client") return res, err } _, err = destConn.Write(handshakeResponse) if err != nil { if ctx.Err() != nil { return res, ctx.Err()
------------------

--- Chunk 3---
Function handleInitialHandshake (part 3): } utils.LogError(logger, err, "failed to write handshake response to server") return res, err } // Decode client handshake response (or SSL) packet handshakeResponsePkt, err := wire.DecodePayload(ctx, logger, handshakeResponse, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to decode handshake response packet") return res, err } res.req = append(res.req, mysql.Request{ PacketBundle: *handshakeResponsePkt, }) // handle the SSL request if decodeCtx.UseSSL { reader := bufio.NewReader(clientConn) initialData := make([]byte, 5) // reading the initial data from the client connection to determine if the connection is a TLS handshake testBuffer, err := reader.Peek(len(initialData)) if err != nil { if err == io.EOF && len(testBuffer) == 0 { logger.Debug("received EOF, closing conn", zap.Error(err)) return res, nil } utils.LogError(logger, err, "failed to peek the mysql request message in proxy") return res, err } multiReader := io
------------------

--- Chunk 4---
Function handleInitialHandshake (part 4): .MultiReader(reader, clientConn) clientConn = &pUtils.Conn{ Conn: clientConn, Reader: multiReader, Logger: logger, } // handle the TLS connection and get the upgraded client connection isTLS := pTls.IsTLSHandshake(testBuffer) if isTLS { clientConn, err = pTls.HandleTLSConnection(ctx, logger, clientConn, opts.Backdate) if err != nil { utils.LogError(logger, err, "failed to handle TLS conn") return res, err } } // upgrade the destConn to TLS if the client connection is upgraded to TLS var tlsDestConn *tls.Conn if isTLS { remoteAddr := clientConn.RemoteAddr().(*net.TCPAddr) sourcePort := remoteAddr.Port url, ok := pTls.SrcPortToDstURL.Load(sourcePort) if !ok { utils.LogError(logger, err, "failed to fetch the destination url") return res, err } //type case the dstUrl to string dstURL, ok := url.(string) if !ok {
------------------

--- Chunk 5---
Function handleInitialHandshake (part 5): utils.LogError(logger, err, "failed to type cast the destination url") return res, err } addr := fmt.Sprintf("%v:%v", dstURL, opts.DstCfg.Port) tlsConfig := &tls.Config{ InsecureSkipVerify: true, ServerName: dstURL, } logger.Debug("Upgrading the destination connection to TLS", zap.String("Destination Addr", addr), zap.String("ServerName", tlsConfig.ServerName)) tlsDestConn = tls.Client(destConn, tlsConfig) err = tlsDestConn.Handshake() if err != nil { utils.LogError(logger, err, "failed to upgrade the destination connection to TLS for mysql") return res, err } logger.Debug("TLS connection established with the destination server", zap.Any("Destination Addr", destConn.RemoteAddr().String())) // Update the destination connection to TLS connection destConn = tlsDestConn } // Update this tls connection information in the handshake result res.tlsClientConn = clientConn res.tlsDestConn = destConn // Store (Reset) the last operation for the upgraded client connection,
------------------

--- Chunk 6---
Function handleInitialHandshake (part 6): because after ssl request the client will send the handshake response packet again. decodeCtx.LastOp.Store(clientConn, mysql.HandshakeV10) // Store the server greeting packet for the upgraded client connection sg, ok := handshakePkt.Message.(*mysql.HandshakeV10Packet) if !ok { return res, fmt.Errorf("failed to type assert handshake packet") } decodeCtx.ServerGreetings.Store(clientConn, sg) // Read the handshake response packet from the client handshakeResponse, err := mysqlUtils.ReadPacketBuffer(ctx, logger, clientConn) if err != nil { if err == io.EOF { logger.Debug("received request buffer is empty in record mode for mysql call") return res, err } utils.LogError(logger, err, "failed to read handshake response from client") return res, err } _, err = destConn.Write(handshakeResponse) if err != nil { if ctx.Err() != nil { return res, ctx.Err() } utils.LogError(logger, err, "failed to write handshake response to server") return res, err } // Decode
------------------

--- Chunk 7---
Function handleInitialHandshake (part 7): client handshake response packet handshakeResponsePkt, err := wire.DecodePayload(ctx, logger, handshakeResponse, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to decode handshake response packet") return res, err } res.req = append(res.req, mysql.Request{ PacketBundle: *handshakeResponsePkt, }) } // Read the next auth packet, // It can be either auth more data if authentication from both server and client are agreed.(caching_sha2_password) // or auth switch request if the server wants to switch the auth mechanism // or it can be OK packet in case of native password authData, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { if err == io.EOF { logger.Debug("received request buffer is empty in record mode for mysql call") return res, err } utils.LogError(logger, err, "failed to read auth or final response packet from server during handshake") return res, err } // AuthSwitchRequest: If the server sends an AuthSwitchRequest, then there must be a diff
------------------

--- Chunk 8---
Function handleInitialHandshake (part 8): auth type with its data // AuthMoreData: If the server sends an AuthMoreData, then it tells the auth mechanism type for the initial plugin name or for the auth switch request. // OK/ERR: If the server sends an OK/ERR packet, in case of native password. _, err = clientConn.Write(authData) if err != nil { if ctx.Err() != nil { return res, ctx.Err() } utils.LogError(logger, err, "failed to write auth packet to client during handshake") return res, err } // Decode auth or final response packet authDecider, err := wire.DecodePayload(ctx, logger, authData, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to decode auth packet during handshake") return res, err } // check if the authDecider is of type AuthSwitchRequestPacket. // AuthSwitchRequestPacket is sent by the server to the client to switch the auth mechanism if _, ok := authDecider.Message.(*mysql.AuthSwitchRequestPacket); ok { logger.Debug("Server is changing the auth mechanism by sending AuthSwitchRequestPacket") //save the
------------------

--- Chunk 9---
Function handleInitialHandshake (part 9): auth switch request packet res.resp = append(res.resp, mysql.Response{ PacketBundle: *authDecider, }) pkt := authDecider.Message.(*mysql.AuthSwitchRequestPacket) // Change the plugin name due to auth switch request decodeCtx.PluginName = pkt.PluginName // read the auth switch response from the client authSwitchResponse, err := mysqlUtils.ReadPacketBuffer(ctx, logger, clientConn) if err != nil { if err == io.EOF { logger.Debug("received request buffer is empty in record mode for mysql call") return res, err } utils.LogError(logger, err, "failed to read auth switch response from client") return res, err } _, err = destConn.Write(authSwitchResponse) if err != nil { if ctx.Err() != nil { return res, ctx.Err() } utils.LogError(logger, err, "failed to write auth switch response to server") return res, err } // Decode the auth switch response packet authSwithResp, err := mysqlUtils.BytesToMySQLPacket(authSwitchResponse) if err
------------------

--- Chunk 10---
Function handleInitialHandshake (part 10): != nil { utils.LogError(logger, err, "failed to parse MySQL packet") return res, err } authSwithRespPkt := &mysql.PacketBundle{ Header: &mysql.PacketInfo{ Header: &authSwithResp.Header, Type: mysql.AuthSwithResponse, // there is no specific identifier for AuthSwitchResponse }, Message: intgUtils.EncodeBase64(authSwithResp.Payload), } // save the auth switch response packet res.req = append(res.req, mysql.Request{ PacketBundle: *authSwithRespPkt, }) logger.Debug("Auth mechanism is switched successfully") // read the further auth packet, now it can be either auth more data or OK packet authData, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { if err == io.EOF { logger.Debug("received request buffer is empty in record mode for mysql call") return res, err } utils.LogError(logger, err, "failed to read auth data from the server after handling auth switch response") return res, err }
------------------

--- Chunk 11---
Function handleInitialHandshake (part 11): _, err = clientConn.Write(authData) if err != nil { if ctx.Err() != nil { return res, ctx.Err() } utils.LogError(logger, err, "failed to write auth data to client after handling auth switch response") return res, err } // It can be either auth more data or OK packet authDecider, err = wire.DecodePayload(ctx, logger, authData, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to decode auth data packet after handling auth switch response") return res, err } } var authRes handshakeRes switch authDecider.Message.(type) { case *mysql.AuthMoreDataPacket: authRes, err = handleAuth(ctx, logger, authDecider, clientConn, destConn, decodeCtx) if err != nil { return res, fmt.Errorf("failed to handle auth more data: %w", err) } case *mysql.OKPacket: authRes, err = handleAuth(ctx, logger, authDecider, clientConn, destConn, decodeCtx) if err != nil { return res,
------------------

--- Chunk 12---
Function handleInitialHandshake (end): fmt.Errorf("failed to handle ok packet: %w", err) } } setHandshakeResult(&res, authRes) return res, nil }
------------------

--- Chunk 13---
func setHandshakeResult(res *handshakeRes, authRes handshakeRes) { res.req = append(res.req, authRes.req...) res.resp = append(res.resp, authRes.resp...) res.responseOperation = authRes.responseOperation }
------------------

--- Chunk 14---
Function handleAuth (start): func handleAuth(ctx context.Context, logger *zap.Logger, authPkt *mysql.PacketBundle, clientConn, destConn net.Conn, decodeCtx *wire.DecodeContext) (handshakeRes, error) { res := handshakeRes{ req: make([]mysql.Request, 0), resp: make([]mysql.Response, 0), } switch mysql.AuthPluginName(decodeCtx.PluginName) { case mysql.Native: res.resp = append(res.resp, mysql.Response{ PacketBundle: *authPkt, }) res.responseOperation = authPkt.Header.Type logger.Debug("native password authentication is handled successfully") case mysql.CachingSha2: result, err := handleCachingSha2Password(ctx, logger, authPkt, clientConn, destConn, decodeCtx) if err != nil { return res, fmt.Errorf("failed to handle caching sha2 password: %w", err) } logger.Debug("caching sha2 password authentication is handled successfully") setHandshakeResult(&res, result) case mysql.Sha256: return res, fmt.Errorf("Sha256 Password authentication is not supported") default: return res, fmt.Errorf("unsupported authentication plugin
------------------

--- Chunk 15---
Function handleAuth (end): : %s", decodeCtx.PluginName) } return res, nil }
------------------

--- Chunk 16---
Function handleCachingSha2Password (start): func handleCachingSha2Password(ctx context.Context, logger *zap.Logger, authPkt *mysql.PacketBundle, clientConn, destConn net.Conn, decodeCtx *wire.DecodeContext) (handshakeRes, error) { res := handshakeRes{ req: make([]mysql.Request, 0), resp: make([]mysql.Response, 0), } var authMechanism string var err error var ok bool var authMorePkt *mysql.AuthMoreDataPacket // check if the authPkt is of type AuthMoreDataPacket if authMorePkt, ok = authPkt.Message.(*mysql.AuthMoreDataPacket); !ok { return res, fmt.Errorf("invalid packet type for caching sha2 password mechanism, expected: AuthMoreDataPacket, found: %T", authPkt.Message) } // Getting the string value of the caching_sha2_password mechanism authMechanism, err = wire.GetCachingSha2PasswordMechanism(authMorePkt.Data[0]) if err != nil { return res, fmt.Errorf("failed to get caching sha2 password mechanism: %w", err) } authMorePkt.Data = authMechanism // save the
------------------

--- Chunk 17---
Function handleCachingSha2Password (end): auth more data packet res.resp = append(res.resp, mysql.Response{ PacketBundle: *authPkt, }) auth, err := wire.StringToCachingSha2PasswordMechanism(authMechanism) if err != nil { return res, fmt.Errorf("failed to convert string to caching sha2 password mechanism: %w", err) } var result handshakeRes switch auth { case mysql.PerformFullAuthentication: result, err = handleFullAuth(ctx, logger, clientConn, destConn, decodeCtx) if err != nil { return res, fmt.Errorf("failed to handle caching sha2 password full auth: %w", err) } case mysql.FastAuthSuccess: result, err = handleFastAuthSuccess(ctx, logger, clientConn, destConn, decodeCtx) if err != nil { return res, fmt.Errorf("failed to handle caching sha2 password fast auth success: %w", err) } } setHandshakeResult(&res, result) return res, nil }
------------------

--- Chunk 18---
Function handleFastAuthSuccess (start): func handleFastAuthSuccess(ctx context.Context, logger *zap.Logger, clientConn, destConn net.Conn, decodeCtx *wire.DecodeContext) (handshakeRes, error) { res := handshakeRes{ req: make([]mysql.Request, 0), resp: make([]mysql.Response, 0), } //As per wire shark capture, during fast auth success, server sends OK packet just after auth more data // read the ok/err packet from the server after auth more data finalResp, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { if err == io.EOF { logger.Debug("received request buffer is empty in record mode for mysql call") return res, err } utils.LogError(logger, err, "failed to read final response packet from server") return res, err } // write the ok/err packet to the client _, err = clientConn.Write(finalResp) if err != nil { if ctx.Err() != nil { return res, ctx.Err() } utils.LogError(logger, err, "failed to write ok/err packet to client during fast auth mechanism") return res,
------------------

--- Chunk 19---
Function handleFastAuthSuccess (end): err } finalPkt, err := wire.DecodePayload(ctx, logger, finalResp, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to decode final response packet after auth data packet") return res, err } res.resp = append(res.resp, mysql.Response{ PacketBundle: *finalPkt, }) // Set the final response operation of the handshake res.responseOperation = finalPkt.Header.Type logger.Debug("fast auth success is handled successfully") return res, nil }
------------------

--- Chunk 20---
Function handleFullAuth (start): func handleFullAuth(ctx context.Context, logger *zap.Logger, clientConn, destConn net.Conn, decodeCtx *wire.DecodeContext) (handshakeRes, error) { res := handshakeRes{ req: make([]mysql.Request, 0), resp: make([]mysql.Response, 0), } // If the connection is using SSL, we don't need to exchange the public key and encrypted password, // we can directly handle the plain password. // This is because the SSL connection already provides a secure channel for the password exchange. if decodeCtx.UseSSL { logger.Debug("Handling caching_sha2_password full auth in SSL request, using plain password") res2, err := handlePlainPassword(ctx, logger, clientConn, destConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to handle plain password in caching_sha2_password(full auth) in ssl request") return res, fmt.Errorf("failed to handle plain password in caching_sha2_password full auth: %w", err) } // Set the final response operation of the handshake setHandshakeResult(&res, res2) return res, nil } // read
------------------

--- Chunk 21---
Function handleFullAuth (part 2): the public key request from the client publicKeyRequest, err := mysqlUtils.ReadPacketBuffer(ctx, logger, clientConn) if err != nil { utils.LogError(logger, err, "failed to read public key request from client") return res, err } _, err = destConn.Write(publicKeyRequest) if err != nil { if ctx.Err() != nil { return res, ctx.Err() } utils.LogError(logger, err, "failed to write public key request to server") return res, err } publicKeyReqPkt, err := wire.DecodePayload(ctx, logger, publicKeyRequest, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to decode public key request packet") return res, err } res.req = append(res.req, mysql.Request{ PacketBundle: *publicKeyReqPkt, }) // read the "public key" as response from the server pubKey, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { utils.LogError(logger, err, "failed to read public key from server") return res, err } _, err =
------------------

--- Chunk 22---
Function handleFullAuth (part 3): clientConn.Write(pubKey) if err != nil { if ctx.Err() != nil { return res, ctx.Err() } utils.LogError(logger, err, "failed to write public key response to client") return res, err } pubKeyPkt, err := wire.DecodePayload(ctx, logger, pubKey, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to decode public key packet") return res, err } pubKeyPkt.Meta = map[string]string{ "auth operation": "public key response", } res.resp = append(res.resp, mysql.Response{ PacketBundle: *pubKeyPkt, }) // read the encrypted password from the client encryptPass, err := mysqlUtils.ReadPacketBuffer(ctx, logger, clientConn) if err != nil { utils.LogError(logger, err, "failed to read encrypted password from client") return res, err } _, err = destConn.Write(encryptPass) if err != nil { if ctx.Err() != nil { return res, ctx.Err() } utils.LogError(logger, err, "failed to write encrypted password to
------------------

--- Chunk 23---
Function handleFullAuth (part 4): server") return res, err } encPass, err := mysqlUtils.BytesToMySQLPacket(encryptPass) if err != nil { utils.LogError(logger, err, "failed to parse MySQL packet") return res, err } encryptPassPkt := &mysql.PacketBundle{ Header: &mysql.PacketInfo{ Header: &encPass.Header, Type: mysql.EncryptedPassword, }, Message: intgUtils.EncodeBase64(encPass.Payload), } res.req = append(res.req, mysql.Request{ PacketBundle: *encryptPassPkt, }) // read the final response from the server (ok or error) finalServerResponse, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { utils.LogError(logger, err, "failed to read final response from server") return res, err } _, err = clientConn.Write(finalServerResponse) if err != nil { if ctx.Err() != nil { return res, ctx.Err() } utils.LogError(logger, err, "failed to write final response to client") return res, err } finalResPkt,
------------------

--- Chunk 24---
Function handleFullAuth (end): err := wire.DecodePayload(ctx, logger, finalServerResponse, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to decode final response packet during caching sha2 password full auth") return res, err } res.resp = append(res.resp, mysql.Response{ PacketBundle: *finalResPkt, }) // Set the final response operation of the handshake res.responseOperation = finalResPkt.Header.Type logger.Debug("full auth is handled successfully") return res, nil }
------------------

--- Chunk 25---
Function handlePlainPassword (start): func handlePlainPassword(ctx context.Context, logger *zap.Logger, clientConn, destConn net.Conn, decodeCtx *wire.DecodeContext) (handshakeRes, error) { res := handshakeRes{ req: make([]mysql.Request, 0), resp: make([]mysql.Response, 0), } // read the plain password from the client plainPassBuf, err := mysqlUtils.ReadPacketBuffer(ctx, logger, clientConn) if err != nil { utils.LogError(logger, err, "failed to read plain password from the client") return res, err } _, err = destConn.Write(plainPassBuf) if err != nil { if ctx.Err() != nil { return res, ctx.Err() } utils.LogError(logger, err, "failed to write plain password to the server") return res, err } plainPass, err := mysqlUtils.BytesToMySQLPacket(plainPassBuf) if err != nil { utils.LogError(logger, err, "failed to parse MySQL packet") return res, err } plainPassPkt := &mysql.PacketBundle{ Header: &mysql.PacketInfo{ Header: &plainPass
------------------

--- Chunk 26---
Function handlePlainPassword (part 2): .Header, Type: mysql.PlainPassword, }, Message: intgUtils.EncodeBase64(plainPass.Payload), } res.req = append(res.req, mysql.Request{ PacketBundle: *plainPassPkt, }) // read the final response from the server (ok or error) finalServerResponse, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { utils.LogError(logger, err, "failed to read final response from server") return res, err } _, err = clientConn.Write(finalServerResponse) if err != nil { if ctx.Err() != nil { return res, ctx.Err() } utils.LogError(logger, err, "failed to write final response to client") return res, err } finalResPkt, err := wire.DecodePayload(ctx, logger, finalServerResponse, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to decode final response packet during caching sha2 password full auth (plain password)") return res, err } res.resp = append(res.resp, mysql.Response{ PacketBundle: *finalResPkt,
------------------

--- Chunk 27---
Function handlePlainPassword (end): }) // Set the final response operation of the handshake res.responseOperation = finalResPkt.Header.Type logger.Debug("full auth (plain password) is handled successfully") return res, nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/recorder/query.go---

--- Chunk 1---
Function handleClientQueries (start): func handleClientQueries(ctx context.Context, logger *zap.Logger, clientConn, destConn net.Conn, mocks chan<- *models.Mock, decodeCtx *wire.DecodeContext) error { var ( requests []mysql.Request responses []mysql.Response ) //for keeping conn alive for { select { case <-ctx.Done(): return ctx.Err() default: // read the command from the client command, err := mysqlUtils.ReadPacketBuffer(ctx, logger, clientConn) if err != nil { if err != io.EOF { utils.LogError(logger, err, "failed to read command packet from client") } return err } // write the command to the destination server _, err = destConn.Write(command) if err != nil { utils.LogError(logger, err, "failed to write command to the server") return err } // Getting timestamp for the request reqTimestamp := time.Now() commandPkt, err := wire.DecodePayload(ctx, logger, command, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to decode the MySQL packet
------------------

--- Chunk 2---
Function handleClientQueries (part 2): from the client") return err } requests = append(requests, mysql.Request{ PacketBundle: *commandPkt, }) // handle no response commands like COM_STMT_CLOSE, COM_STMT_SEND_LONG_DATA, etc if wire.IsNoResponseCommand(commandPkt.Header.Type) { recordMock(ctx, requests, responses, "mocks", commandPkt.Header.Type, "NO Response Packet", mocks, reqTimestamp) // reset the requests and responses requests = []mysql.Request{} responses = []mysql.Response{} logger.Debug("No response command", zap.Any("packet", commandPkt.Header.Type)) continue } commandRespPkt, err := handleQueryResponse(ctx, logger, clientConn, destConn, decodeCtx) if err != nil { if err == io.EOF && commandPkt.Header.Type == mysql.CommandStatusToString(mysql.COM_QUIT) { logger.Debug("server closed the connection without any response") return err } utils.LogError(logger, err, "failed to handle the query response") return err } responses = append(responses, mysql.Response{ Packet
------------------

--- Chunk 3---
Function handleClientQueries (end): Bundle: *commandRespPkt, }) // record the mock recordMock(ctx, requests, responses, "mocks", commandPkt.Header.Type, commandRespPkt.Header.Type, mocks, reqTimestamp) // reset the requests and responses requests = []mysql.Request{} responses = []mysql.Response{} } } }
------------------

--- Chunk 4---
Function handleQueryResponse (start): func handleQueryResponse(ctx context.Context, logger *zap.Logger, clientConn, destConn net.Conn, decodeCtx *wire.DecodeContext) (*mysql.PacketBundle, error) { // read the command response from the destination server commandResp, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { if err != io.EOF { utils.LogError(logger, err, "failed to read command response from the server") } return nil, err } // write the command response to the client _, err = clientConn.Write(commandResp) if err != nil { utils.LogError(logger, err, "failed to write command response to the client") return nil, err } //decode the command response packet commandRespPkt, err := wire.DecodePayload(ctx, logger, commandResp, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to decode the command response packet") return nil, err } // check if the command response is an error or ok packet if commandRespPkt.Header.Type == mysql.StatusToString(mysql.ERR) || commandRespPkt.Header.Type == mysql.StatusToString(mysql.OK)
------------------

--- Chunk 5---
Function handleQueryResponse (part 2): { logger.Debug("command response packet", zap.Any("packet", commandRespPkt.Header.Type)) return commandRespPkt, nil } // Get the last operation in order to handle current packet if it is not an error or ok packet lastOp, ok := decodeCtx.LastOp.Load(clientConn) if !ok { return nil, fmt.Errorf("failed to get the last operation from the context while handling the query response") } var queryResponsePkt *mysql.PacketBundle switch lastOp { case mysql.COM_QUERY: logger.Debug("Handling text result set", zap.Any("lastOp", lastOp)) // handle the query response (TextResultSet) queryResponsePkt, err = handleTextResultSet(ctx, logger, clientConn, destConn, commandRespPkt, decodeCtx) if err != nil { return nil, fmt.Errorf("failed to handle the query response packet: %w", err) } case mysql.COM_STMT_PREPARE: logger.Debug("Handling prepare Statement Response OK", zap.Any("lastOp", lastOp)) // handle the prepared statement response (COM_STMT_PREPARE_OK) queryResponsePkt, err = handlePreparedStmt
------------------

--- Chunk 6---
Function handleQueryResponse (end): Response(ctx, logger, clientConn, destConn, commandRespPkt, decodeCtx) if err != nil { return nil, fmt.Errorf("failed to handle the prepared statement response: %w", err) } case mysql.COM_STMT_EXECUTE: logger.Debug("Handling binary protocol result set", zap.Any("lastOp", lastOp)) // handle the statment execute response (BinaryProtocolResultSet) queryResponsePkt, err = handleBinaryResultSet(ctx, logger, clientConn, destConn, commandRespPkt, decodeCtx) if err != nil { return nil, fmt.Errorf("failed to handle the statement execute response: %w", err) } default: return nil, fmt.Errorf("unsupported operation: %x", lastOp) } return queryResponsePkt, nil }
------------------

--- Chunk 7---
Function handlePreparedStmtResponse (start): func handlePreparedStmtResponse(ctx context.Context, logger *zap.Logger, clientConn, destConn net.Conn, commandRespPkt *mysql.PacketBundle, decodeCtx *wire.DecodeContext) (*mysql.PacketBundle, error) { //commandRespPkt is the response to prepare, there are parameters, intermediate EOF, columns, and EOF packets to be handled //ref: https://dev.mysql.com/doc/dev/mysql-server/latest/page_protocol_com_stmt_prepare.html#sect_protocol_com_stmt_prepare_response_ok responseOk, ok := commandRespPkt.Message.(*mysql.StmtPrepareOkPacket) if !ok { return nil, fmt.Errorf("expected StmtPrepareOkPacket, got %T", commandRespPkt.Message) } logger.Debug("Parsing the params and columns in the prepared statement response", zap.Any("responseOk", responseOk)) //See if there are any parameters if responseOk.NumParams > 0 { for i := uint16(0); i < responseOk.NumParams; i++ { // Read the column definition packet colData, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { if err != io.EOF { utils.LogError(logger,
------------------

--- Chunk 8---
Function handlePreparedStmtResponse (part 2): err, "failed to read column data for parameter definition") } return nil, err } // Write the column definition packet to the client _, err = clientConn.Write(colData) if err != nil { utils.LogError(logger, err, "failed to write column data for parameter definition") return nil, err } // Decode the column definition packet column, _, err := rowscols.DecodeColumn(ctx, logger, colData) if err != nil { return nil, fmt.Errorf("failed to decode column definition packet: %w", err) } responseOk.ParamDefs = append(responseOk.ParamDefs, column) } logger.Debug("ParamsDefs after parsing", zap.Any("ParamDefs", responseOk.ParamDefs)) // Read the EOF packet for parameter definition eofData, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { if err != io.EOF { utils.LogError(logger, err, "failed to read EOF packet for parameter definition") } return nil, err } // Write the EOF packet for parameter definition to the client
------------------

--- Chunk 9---
Function handlePreparedStmtResponse (part 3): _, err = clientConn.Write(eofData) if err != nil { utils.LogError(logger, err, "failed to write EOF packet for parameter definition to the client") return nil, err } // Validate the EOF packet for parameter definition if !mysqlUtils.IsEOFPacket(eofData) { return nil, fmt.Errorf("expected EOF packet for parameter definition, got %v", eofData) } responseOk.EOFAfterParamDefs = eofData logger.Debug("Eof after param defs", zap.Any("eofData", eofData)) } //See if there are any columns if responseOk.NumColumns > 0 { for i := uint16(0); i < responseOk.NumColumns; i++ { // Read the column definition packet colData, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { if err != io.EOF { utils.LogError(logger, err, "failed to read column data for column definition") } return nil, err } // Write the column definition packet to the client _, err = clientConn.Write
------------------

--- Chunk 10---
Function handlePreparedStmtResponse (part 4): (colData) if err != nil { utils.LogError(logger, err, "failed to write column data for column definition") return nil, err } // Decode the column definition packet column, _, err := rowscols.DecodeColumn(ctx, logger, colData) if err != nil { return nil, fmt.Errorf("failed to decode column definition packet: %w", err) } responseOk.ColumnDefs = append(responseOk.ColumnDefs, column) } logger.Debug("ColumnDefs after parsing", zap.Any("ColumnDefs", responseOk.ColumnDefs)) // Read the EOF packet for column definition eofData, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { if err != io.EOF { utils.LogError(logger, err, "failed to read EOF packet for column definition") } return nil, err } // Write the EOF packet for column definition to the client _, err = clientConn.Write(eofData) if err != nil { utils.LogError(logger, err, "failed to write EOF packet for column definition to the client") return nil, err
------------------

--- Chunk 11---
Function handlePreparedStmtResponse (end): } // Validate the EOF packet for column definition if !mysqlUtils.IsEOFPacket(eofData) { return nil, fmt.Errorf("expected EOF packet for column definition, got %v, while handling prepared statement response", eofData) } responseOk.EOFAfterColumnDefs = eofData logger.Debug("Eof after column defs", zap.Any("eofData", eofData)) } //set the lastOp to COM_STMT_PREPARE_OK decodeCtx.LastOp.Store(clientConn, mysql.OK) // commandRespPkt.Message = responseOk // need to check whether this is necessary return commandRespPkt, nil }
------------------

--- Chunk 12---
Function handleTextResultSet (start): func handleTextResultSet(ctx context.Context, logger *zap.Logger, clientConn, destConn net.Conn, textResultSetPkt *mysql.PacketBundle, decodeCtx *wire.DecodeContext) (*mysql.PacketBundle, error) { // colCountPkt is the first packet of the text result set, it is followed by column definition packets, intermediate eof, row data packets and final eof textResultSet, ok := textResultSetPkt.Message.(*mysql.TextResultSet) if !ok { return nil, fmt.Errorf("expected TextResultSet, got %T", textResultSetPkt.Message) } // Read the column count packet colCount := textResultSet.ColumnCount // Read the column definition packets for i := uint64(0); i < colCount; i++ { // Read the column definition packet colData, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { if err != io.EOF { utils.LogError(logger, err, "failed to read column definition packet") } return nil, err } // Write the column definition packet to the client _, err = clientConn.Write(colData) if err != nil
------------------

--- Chunk 13---
Function handleTextResultSet (part 2): { utils.LogError(logger, err, "failed to write column definition packet") return nil, err } // Decode the column definition packet column, _, err := rowscols.DecodeColumn(ctx, logger, colData) if err != nil { return nil, fmt.Errorf("failed to decode column definition packet: %w", err) } textResultSet.Columns = append(textResultSet.Columns, column) } if decodeCtx.ClientCapabilities&mysql.CLIENT_DEPRECATE_EOF == 0 { logger.Debug("EOF packet is not deprecated while handling textResultSet") // Read the EOF packet for column definition eofData, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { if err != io.EOF { utils.LogError(logger, err, "failed to read EOF packet for column definition") } return nil, err } // Write the EOF packet for column definition to the client _, err = clientConn.Write(eofData) if err != nil { utils.LogError(logger, err, "failed to write EOF packet for column definition to the client") return nil, err }
------------------

--- Chunk 14---
Function handleTextResultSet (part 3): // Validate the EOF packet for column definition if !mysqlUtils.IsEOFPacket(eofData) { return nil, fmt.Errorf("expected EOF packet for column definition, got %v, while handling textResultSet", eofData) } textResultSet.EOFAfterColumns = eofData } // Read the row data packets rowLoop: for { select { case <-ctx.Done(): return nil, ctx.Err() default: // Read the packet data, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { if err != io.EOF { utils.LogError(logger, err, "failed to read data packet while reading row data") } return nil, err } // Write the packet to the client _, err = clientConn.Write(data) if err != nil { utils.LogError(logger, err, "failed to write data packet while reading row data") return nil, err } // // Break if the data packet is a generic response // resp, ok := mysqlUtils.IsGenericResponse(data) // if ok {
------------------

--- Chunk 15---
Function handleTextResultSet (part 4): // textResultSet.FinalResponse = &mysql.GenericResponse{ // Data: data, // Type: resp, // } // break rowLoop // } // Break if the data packet is an EOF packet, But we need to check for generic response // Right now we are just checking for EOF packet as we couldn't differentiate between the generic response and row data packet if mysqlUtils.IsEOFPacket(data) { logger.Debug("Found EOF packet after row data in text resultset") textResultSet.FinalResponse = &mysql.GenericResponse{ Data: data, Type: mysql.StatusToString(mysql.EOF), } break rowLoop } // It must be a row data packet row, _, err := rowscols.DecodeTextRow(ctx, logger, data, textResultSet.Columns) if err != nil { return nil, fmt.Errorf("failed to decode row data packet: %w", err) } textResultSet.Rows = append(textResultSet.Rows, row) } } // reset the last OP decodeCtx.LastOp.Store(clientConn, wire.RESET) return text
------------------

--- Chunk 16---
Function handleTextResultSet (end): ResultSetPkt, nil }
------------------

--- Chunk 17---
Function handleBinaryResultSet (start): func handleBinaryResultSet(ctx context.Context, logger *zap.Logger, clientConn, destConn net.Conn, binaryResultSetPkt *mysql.PacketBundle, decodeCtx *wire.DecodeContext) (*mysql.PacketBundle, error) { // colCountPkt is the first packet of the binary result set, it is followed by column definition packets,intermediate eof, row data packets and final eof binaryResultSet, ok := binaryResultSetPkt.Message.(*mysql.BinaryProtocolResultSet) if !ok { return nil, fmt.Errorf("expected TextResultSet, got %T", binaryResultSetPkt.Message) } // Read the column count packet colCount := binaryResultSet.ColumnCount logger.Debug("ColCount in handleBinaryResultSet: ", zap.Any("ColCount", colCount)) // Read the column definition packets for i := uint64(0); i < colCount; i++ { // Read the column definition packet colData, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { if err != io.EOF { utils.LogError(logger, err, "failed to read column definition packet") } return nil, err } // Write the
------------------

--- Chunk 18---
Function handleBinaryResultSet (part 2): column definition packet to the client _, err = clientConn.Write(colData) if err != nil { utils.LogError(logger, err, "failed to write column definition packet") return nil, err } // Decode the column definition packet column, _, err := rowscols.DecodeColumn(ctx, logger, colData) if err != nil { return nil, fmt.Errorf("failed to decode column definition packet: %w", err) } binaryResultSet.Columns = append(binaryResultSet.Columns, column) } logger.Debug("Columns: ", zap.Any("Columns", binaryResultSet.Columns)) // Read the EOF packet for column definition eofData, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { if err != io.EOF { utils.LogError(logger, err, "failed to read EOF packet for column definition") } return nil, err } // Write the EOF packet for column definition to the client _, err = clientConn.Write(eofData) if err != nil { utils.LogError(logger, err, "failed to write EOF packet for column definition to the client") return nil, err
------------------

--- Chunk 19---
Function handleBinaryResultSet (part 3): } // Validate the EOF packet for column definition if !mysqlUtils.IsEOFPacket(eofData) { return nil, fmt.Errorf("expected EOF packet for column definition, got %v, while handling BinaryProtocolResultSet", eofData) } binaryResultSet.EOFAfterColumns = eofData // Read the row data packets rowLoop: for { select { case <-ctx.Done(): return nil, ctx.Err() default: // Read the packet data, err := mysqlUtils.ReadPacketBuffer(ctx, logger, destConn) if err != nil { if err != io.EOF { utils.LogError(logger, err, "failed to read data packet while reading row data") } return nil, err } // Write the packet to the client _, err = clientConn.Write(data) if err != nil { utils.LogError(logger, err, "failed to write data packet while reading row data") return nil, err } // Break if the data packet is a generic response // resp, ok := mysqlUtils.IsGenericResponse(data) // if ok { // binary
------------------

--- Chunk 20---
Function handleBinaryResultSet (part 4): ResultSet.FinalResponse = &mysql.GenericResponse{ // Data: data, // Type: resp, // } // //debug log // fmt.Println("Found generic response after row data") // break rowLoop // } // Break if the data packet is an EOF packet, But we need to check for generic response // Right now we are just checking for EOF packet as we couldn't differentiate between the generic response and row data packet if mysqlUtils.IsEOFPacket(data) { logger.Debug("Found EOF packet after row data in binary resultset") binaryResultSet.FinalResponse = &mysql.GenericResponse{ Data: data, Type: mysql.StatusToString(mysql.EOF), } break rowLoop } // It must be a row data packet row, _, err := rowscols.DecodeBinaryRow(ctx, logger, data, binaryResultSet.Columns) if err != nil { return nil, fmt.Errorf("failed to decode row data packet: %w", err) } binaryResultSet.Rows = append(binaryResultSet.Rows, row) }
------------------

--- Chunk 21---
Function handleBinaryResultSet (end): } logger.Debug("Rows: ", zap.Any("Rows", binaryResultSet.Rows)) // reset the last OP decodeCtx.LastOp.Store(clientConn, wire.RESET) return binaryResultSetPkt, nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/recorder/record.go---

--- Chunk 1---
Function Record (start): func Record(ctx context.Context, logger *zap.Logger, clientConn, destConn net.Conn, mocks chan<- *models.Mock, opts models.OutgoingOptions) error { var ( requests []mysql.Request responses []mysql.Response ) errCh := make(chan error, 1) //get the error group from the context g, ok := ctx.Value(models.ErrGroupKey).(*errgroup.Group) if !ok { return errors.New("failed to get the error group from the context") } g.Go(func() error { defer pUtil.Recover(logger, clientConn, destConn) defer close(errCh) // Helper struct for decoding packets decodeCtx := &wire.DecodeContext{ Mode: models.MODE_RECORD, // Map for storing last operation per connection LastOp: wire.NewLastOpMap(), // Map for storing server greetings (inc capabilities, auth plugin, etc) per initial handshake (per connection) ServerGreetings: wire.NewGreetings(), // Map for storing prepared statements per connection PreparedStatements: make(map[uint32]*mysql.StmtPrepareOkPacket), } decodeCtx.LastOp
------------------

--- Chunk 2---
Function Record (part 2): .Store(clientConn, wire.RESET) //resetting last command for new loop // handle the initial client-server handshake (connection phase) result, err := handleInitialHandshake(ctx, logger, clientConn, destConn, decodeCtx, opts) if err != nil { utils.LogError(logger, err, "failed to handle initial handshake") errCh <- err return nil } requests = append(requests, result.req...) responses = append(responses, result.resp...) reqTimestamp := result.reqTimestamp recordMock(ctx, requests, responses, "config", result.requestOperation, result.responseOperation, mocks, reqTimestamp) // reset the requests and responses requests = []mysql.Request{} responses = []mysql.Response{} if decodeCtx.UseSSL { if result.tlsClientConn == nil || result.tlsDestConn == nil { utils.LogError(logger, err, "Expected Tls connections are nil", zap.Any("tlsClientConn", result.tlsClientConn), zap.Any("tlsDestConn", result.tlsDestConn)) errCh <- errors.New("tls connection is not established") return nil } clientConn =
------------------

--- Chunk 3---
Function Record (end): result.tlsClientConn destConn = result.tlsDestConn } lstOp, _ := decodeCtx.LastOp.Load(clientConn) logger.Debug("last operation after initial handshake", zap.Any("last operation", lstOp)) // handle the client-server interaction (command phase) err = handleClientQueries(ctx, logger, clientConn, destConn, mocks, decodeCtx) if err != nil { if err != io.EOF { utils.LogError(logger, err, "failed to handle client queries") } errCh <- err return nil } return nil }) select { case <-ctx.Done(): return ctx.Err() case err := <-errCh: if err == io.EOF { return nil } return err } }
------------------

--- Chunk 4---
func recordMock(ctx context.Context, requests []mysql.Request, responses []mysql.Response, mockType, requestOperation, responseOperation string, mocks chan<- *models.Mock, reqTimestampMock time.Time) { meta := map[string]string{ "type": mockType, "requestOperation": requestOperation, "responseOperation": responseOperation, "connID": ctx.Value(models.ClientConnectionIDKey).(string), } mysqlMock := &models.Mock{ Version: models.GetVersion(), Kind: models.MySQL, Name: mockType, Spec: models.MockSpec{ Metadata: meta, MySQLRequests: requests, MySQLResponses: responses, Created: time.Now().Unix(), ReqTimestampMock: reqTimestampMock, ResTimestampMock: time.Now(), }, } mocks <- mysqlMock }
------------------

--- File: pkg/core/proxy/integrations/mysql/replayer/conn.go---

--- Chunk 1---
Function simulateInitialHandshake (start): func simulateInitialHandshake(ctx context.Context, logger *zap.Logger, clientConn net.Conn, mocks []*models.Mock, mockDb integrations.MockMemDb, decodeCtx *wire.DecodeContext, opts models.OutgoingOptions) (handshakeRes, error) { // Get the mock for initial handshake initialHandshakeMock := mocks[0] // Read the intial request and response for the handshake from the mocks resp := initialHandshakeMock.Spec.MySQLResponses req := initialHandshakeMock.Spec.MySQLRequests res := handshakeRes{} reqIdx, respIdx := 0, 0 if len(resp) == 0 || len(req) == 0 { utils.LogError(logger, nil, "no mysql mocks found for initial handshake") return res, nil } handshake, ok := resp[respIdx].Message.(*mysql.HandshakeV10Packet) if !ok { utils.LogError(logger, nil, "failed to assert handshake packet") return res, nil } // Store the server greetings decodeCtx.ServerGreetings.Store(clientConn, handshake) // Set the intial auth plugin decodeCtx.PluginName = handshake.AuthPluginName var err error // encode
------------------

--- Chunk 2---
Function simulateInitialHandshake (part 2): the response buf, err := wire.EncodeToBinary(ctx, logger, &resp[respIdx].PacketBundle, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to encode handshake packet") return res, err } // Write the initial handshake to the client _, err = clientConn.Write(buf) if err != nil { if ctx.Err() != nil { return res, ctx.Err() } utils.LogError(logger, err, "failed to write server greetings to the client") return res, err } respIdx++ // Read the client request, (handshake response or ssl request) handshakeResponseBuf, err := mysqlUtils.ReadPacketBuffer(ctx, logger, clientConn) if err != nil { utils.LogError(logger, err, "failed to read handshake response from client") return res, err } // Decode the handshakeResponse or sslRequest pkt, err := wire.DecodePayload(ctx, logger, handshakeResponseBuf, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to decode handshake response from client") return res, err } // handle the
------------------

--- Chunk 3---
Function simulateInitialHandshake (part 3): SSL request if decodeCtx.UseSSL { _, ok := pkt.Message.(*mysql.SSLRequestPacket) if !ok { utils.LogError(logger, nil, "failed to assert SSL request packet") return res, nil } // Get the SSL request from the mock _, ok = req[reqIdx].Message.(*mysql.SSLRequestPacket) if !ok { utils.LogError(logger, nil, "failed to assert mock SSL request packet", zap.Any("expected", req[reqIdx].Header.Type)) return res, nil } // Match the SSL request from the client with the mock err = matchSSLRequest(ctx, logger, req[reqIdx].PacketBundle, *pkt) if err != nil { utils.LogError(logger, err, "error while matching SSL request") return res, err } reqIdx++ // matched with the mock so increment the index // Upgrade the client connection to TLS reader := bufio.NewReader(clientConn) initialData := make([]byte, 5) // reading the initial data from the client connection to determine if the connection is a TLS handshake testBuffer,
------------------

--- Chunk 4---
Function simulateInitialHandshake (part 4): err := reader.Peek(len(initialData)) if err != nil { if err == io.EOF && len(testBuffer) == 0 { logger.Debug("received EOF, closing conn", zap.Error(err)) return res, nil } utils.LogError(logger, err, "failed to peek the mysql request message in proxy") return res, err } multiReader := io.MultiReader(reader, clientConn) clientConn = &pUtils.Conn{ Conn: clientConn, Reader: multiReader, Logger: logger, } // handle the TLS connection and get the upgraded client connection isTLS := pTls.IsTLSHandshake(testBuffer) if isTLS { clientConn, err = pTls.HandleTLSConnection(ctx, logger, clientConn, opts.Backdate) if err != nil { utils.LogError(logger, err, "failed to handle TLS conn") return res, err } } // Update this tls connection information in the handshake result res.tlsClientConn = clientConn // Store (Reset) the last operation for the upgraded client connection, because after ssl request the
------------------

--- Chunk 5---
Function simulateInitialHandshake (part 5): client will send the handshake response packet again. decodeCtx.LastOp.Store(clientConn, mysql.HandshakeV10) // Store the server greeting packet for the upgraded client connection decodeCtx.ServerGreetings.Store(clientConn, handshake) // read the actual handshake response packet handshakeResponseBuf, err := mysqlUtils.ReadPacketBuffer(ctx, logger, clientConn) if err != nil { utils.LogError(logger, err, "failed to read handshake response from client") return res, err } // Decode the handshakeResponse pkt, err = wire.DecodePayload(ctx, logger, handshakeResponseBuf, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to decode handshake response from client") return res, err } } _, ok = pkt.Message.(*mysql.HandshakeResponse41Packet) if !ok { utils.LogError(logger, nil, "failed to assert actual handshake response packet") return res, nil } // Get the handshake response from the mock _, ok = req[reqIdx].Message.(*mysql.HandshakeResponse41Packet) if !ok { utils.LogError(logger,
------------------

--- Chunk 6---
Function simulateInitialHandshake (part 6): nil, "failed to assert mock handshake response packet") return res, nil } // Match the handshake response from the client with the mock logger.Debug("matching handshake response", zap.Any("actual", pkt), zap.Any("mock", req[reqIdx].PacketBundle)) err = matchHanshakeResponse41(ctx, logger, req[reqIdx].PacketBundle, *pkt) if err != nil { utils.LogError(logger, err, "error while matching handshakeResponse41") return res, err } reqIdx++ // matched with the mock so increment the index // Get the next response in order to find the auth mechanism if len(resp) < respIdx+1 { utils.LogError(logger, nil, "no mysql mocks found for auth mechanism") return res, nil } // Get the next packet to decide the auth mechanism or auth switching // For Native password: next packet is Ok/Err // For CachingSha2 password: next packet is AuthMoreData authDecider := resp[respIdx].Header.Type // Check if the next packet is AuthSwitchRequest // Server sends AuthSwitchRequest when it wants to switch the auth mechanism
------------------

--- Chunk 7---
Function simulateInitialHandshake (part 7): if authDecider == mysql.AuthStatusToString(mysql.AuthSwitchRequest) { logger.Debug("Auth switch request found, switching the auth mechanism") // Get the AuthSwitchRequest packet authSwithReqPkt, ok := resp[respIdx].Message.(*mysql.AuthSwitchRequestPacket) if !ok { utils.LogError(logger, nil, "failed to assert auth switch request packet") return res, nil } // Change the auth plugin name decodeCtx.PluginName = authSwithReqPkt.PluginName // Encode the AuthSwitchRequest packet buf, err = wire.EncodeToBinary(ctx, logger, &resp[respIdx].PacketBundle, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to encode auth switch request packet") return res, err } // Write the AuthSwitchRequest packet to the client _, err = clientConn.Write(buf) if err != nil { if ctx.Err() != nil { return res, ctx.Err() } utils.LogError(logger, err, "failed to write auth switch request to the client") return res, err
------------------

--- Chunk 8---
Function simulateInitialHandshake (part 8): } respIdx++ // Read the auth switch response from the client authSwitchRespBuf, err := mysqlUtils.ReadPacketBuffer(ctx, logger, clientConn) if err != nil { utils.LogError(logger, err, "failed to read auth switch response from the client") return res, err } // Get the packet from the buffer authSwitchRespPkt, err := mysqlUtils.BytesToMySQLPacket(authSwitchRespBuf) if err != nil { utils.LogError(logger, err, "failed to convert auth switch response to packet") return res, err } if len(req) < reqIdx+1 { utils.LogError(logger, nil, "no mysql mocks found for auth switch response") return res, fmt.Errorf("no mysql mocks found for auth switch response") } // Get the auth switch response from the mock authSwitchRespMock := req[reqIdx].PacketBundle if authSwitchRespMock.Header.Type != mysql.AuthSwithResponse { utils.LogError(logger, nil, "expected auth switch response mock not found", zap.Any("found", authSwitchRespMock.Header.Type)) return res, fmt
------------------

--- Chunk 9---
Function simulateInitialHandshake (part 9): .Errorf("expected %s but found %s", mysql.AuthSwithResponse, authSwitchRespMock.Header.Type) } // Since auth switch response data can be different, we should just check the sequence number if authSwitchRespMock.Header.Header.SequenceID != authSwitchRespPkt.Header.SequenceID { utils.LogError(logger, nil, "sequence number mismatch for auth switch response", zap.Any("expected", authSwitchRespMock.Header.Header.SequenceID), zap.Any("actual", authSwitchRespPkt.Header.SequenceID)) return res, fmt.Errorf("sequence number mismatch for auth switch response") } logger.Debug("auth mechanism switched successfully") reqIdx++ // Get the next packet to decide the auth mechanism if len(resp) < respIdx+1 { utils.LogError(logger, nil, "no mysql mocks found for auth mechanism after auth switch request") return res, nil } authDecider = resp[respIdx].Header.Type } switch authDecider { case mysql.StatusToString(mysql.OK): var nativePassMocks reqResp nativePassMocks.resp = resp[respIdx:] // It means we need to simulate the native password err
------------------

--- Chunk 10---
Function simulateInitialHandshake (end): := simulateNativePassword(ctx, logger, clientConn, nativePassMocks, initialHandshakeMock, mockDb, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to simulate native password") return res, err } case mysql.AuthStatusToString(mysql.AuthMoreData): var cacheSha2PassMock reqResp cacheSha2PassMock.req = req[reqIdx:] cacheSha2PassMock.resp = resp[respIdx:] // It means we need to simulate the caching_sha2_password err := simulateCacheSha2Password(ctx, logger, clientConn, cacheSha2PassMock, initialHandshakeMock, mockDb, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to simulate caching_sha2_password") return res, err } } return res, nil }
------------------

--- Chunk 11---
Function simulateNativePassword (start): func simulateNativePassword(ctx context.Context, logger *zap.Logger, clientConn net.Conn, nativePassMocks reqResp, initialHandshakeMock *models.Mock, mockDb integrations.MockMemDb, decodeCtx *wire.DecodeContext) error { logger.Debug("final response for native password", zap.Any("response", nativePassMocks.resp[0].Header.Type)) // Send the final response (OK/Err) to the client buf, err := wire.EncodeToBinary(ctx, logger, &nativePassMocks.resp[0].PacketBundle, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to encode final response packet for native password") return err } _, err = clientConn.Write(buf) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(logger, err, "failed to write final response for native password to the client") return err } //update the config mock (since it can be reused in case of more connections compared to record mode) ok := updateMock(ctx, logger, initialHandshakeMock, mockDb) if !ok { utils.LogError(logger, nil, "failed to update the
------------------

--- Chunk 12---
Function simulateNativePassword (end): mock unfiltered mock during native password") } logger.Debug("native password completed successfully") return nil }
------------------

--- Chunk 13---
Function simulateCacheSha2Password (start): func simulateCacheSha2Password(ctx context.Context, logger *zap.Logger, clientConn net.Conn, cacheSha2PassMock reqResp, initialHandshakeMock *models.Mock, mockDb integrations.MockMemDb, decodeCtx *wire.DecodeContext) error { resp := cacheSha2PassMock.resp // Get the AuthMoreData if len(resp) < 1 { utils.LogError(logger, nil, "no mysql mocks found for auth more data") } //check if the response is of type AuthMoreData if _, ok := resp[0].Message.(*mysql.AuthMoreDataPacket); !ok { utils.LogError(logger, nil, "failed to assert auth more data packet") return fmt.Errorf("failed to get auth more data packet, expected %T but got %T", mysql.AuthMoreDataPacket{}, resp[0].Message) } // Get the auth more data packet pkt, ok := resp[0].Message.(*mysql.AuthMoreDataPacket) if !ok { utils.LogError(logger, nil, "failed to assert auth more data packet") return nil } CachingSha2PasswordMechanism := pkt.Data authBuf, err := wire.EncodeToBinary(ctx, logger,
------------------

--- Chunk 14---
Function simulateCacheSha2Password (part 2): &resp[0].PacketBundle, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to encode auth more data packet") return err } // Write the AuthMoreData packet to the client _, err = clientConn.Write(authBuf) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(logger, err, "failed to write auth more data or auth switch request to the client") return err } if len(cacheSha2PassMock.resp) < 2 { utils.LogError(logger, nil, "response mock not found for caching_sha2_password after auth more data") return fmt.Errorf("response mock not found for caching_sha2_password after auth more data") } //update the cacheSha2PassMock resp cacheSha2PassMock.resp = cacheSha2PassMock.resp[1:] //simulate the caching_sha2_password auth mechanism switch CachingSha2PasswordMechanism { case mysql.CachingSha2PasswordToString(mysql.PerformFullAuthentication): err := simulateFullAuth(ctx, logger, clientConn, cacheSha2PassMock, initialHandshakeMock, mockDb, decode
------------------

--- Chunk 15---
Function simulateCacheSha2Password (end): Ctx) if err != nil { utils.LogError(logger, err, "failed to simulate full auth") return err } case mysql.CachingSha2PasswordToString(mysql.FastAuthSuccess): err := simulateFastAuthSuccess(ctx, logger, clientConn, cacheSha2PassMock, initialHandshakeMock, mockDb, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to simulate fast auth success") return err } } return nil }
------------------

--- Chunk 16---
Function simulateFastAuthSuccess (start): func simulateFastAuthSuccess(ctx context.Context, logger *zap.Logger, clientConn net.Conn, fastAuthMocks reqResp, initialHandshakeMock *models.Mock, mockDb integrations.MockMemDb, decodeCtx *wire.DecodeContext) error { resp := fastAuthMocks.resp if len(resp) < 1 { utils.LogError(logger, nil, "final response mock not found for fast auth success") return fmt.Errorf("final response mock not found for fast auth success") } logger.Debug("final response for fast auth success", zap.Any("response", resp[0].Header.Type)) // Send the final response (OK/Err) to the client buf, err := wire.EncodeToBinary(ctx, logger, &resp[0].PacketBundle, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to encode final response packet for fast auth success") return err } _, err = clientConn.Write(buf) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(logger, err, "failed to write final response for fast auth success to the client") return err } //update the config mock
------------------

--- Chunk 17---
Function simulateFastAuthSuccess (end): (since it can be reused in case of more connections compared to record mode) //TODO: need to check when updateMock is unsuccessful ok := updateMock(ctx, logger, initialHandshakeMock, mockDb) if !ok { utils.LogError(logger, nil, "failed to update the mock unfiltered mock during fast auth success") } logger.Debug("fast auth success completed successfully") return nil }
------------------

--- Chunk 18---
Function simulateFullAuth (start): func simulateFullAuth(ctx context.Context, logger *zap.Logger, clientConn net.Conn, fullAuthMocks reqResp, initialHandshakeMock *models.Mock, mockDb integrations.MockMemDb, decodeCtx *wire.DecodeContext) error { resp := fullAuthMocks.resp req := fullAuthMocks.req if decodeCtx.UseSSL { logger.Debug("This is an ssl request, simulating plain password in caching_sha2_password full auth") err := simulatePlainPassword(ctx, logger, clientConn, fullAuthMocks, initialHandshakeMock, mockDb, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to simulate plain password in caching_sha2_password full auth") return err } return nil } // read the public key request from the client publicKeyRequestBuf, err := mysqlUtils.ReadPacketBuffer(ctx, logger, clientConn) if err != nil { utils.LogError(logger, err, "failed to read public key request from client") return err } // decode the public key request pkt, err := wire.DecodePayload(ctx, logger, publicKeyRequestBuf, clientConn, decodeCtx) if err != nil { utils.LogError(logger
------------------

--- Chunk 19---
Function simulateFullAuth (part 2): , err, "failed to decode public key request from client") return err } publicKey, ok := pkt.Message.(string) if !ok { utils.LogError(logger, nil, "failed to assert public key request packet") return nil } // Get the public key response from the mock if len(req) < 1 { utils.LogError(logger, nil, "no mysql mocks found for public key response") return fmt.Errorf("no mysql mocks found for public key response") } publicKeyMock, ok := req[0].Message.(string) if !ok { utils.LogError(logger, nil, "failed to assert public key response packet") return nil } // Match the header of the public key request ok = matchHeader(*req[0].Header.Header, *pkt.Header.Header) if !ok { utils.LogError(logger, nil, "header mismatch for public key request", zap.Any("expected", req[0].Header.Header), zap.Any("actual", pkt.Header.Header)) return nil } // Match the public key response from the client with the mock if publicKey != publicKeyMock { utils.LogError(logger, nil, "public key mismatch", zap.Any("
------------------

--- Chunk 20---
Function simulateFullAuth (part 3): actual", publicKey), zap.Any("expected", publicKeyMock)) return fmt.Errorf("public key mismatch") } // Get the AuthMoreData for sending the public key if len(resp) < 1 { utils.LogError(logger, nil, "no mysql mocks found for auth more data (public key)") return fmt.Errorf("no mysql mocks found for auth more data (public key)") } // Get the AuthMoreData packet _, ok = resp[0].Message.(*mysql.AuthMoreDataPacket) if !ok { utils.LogError(logger, nil, "failed to assert auth more data packet (public key)") return nil } // encode the public key response buf, err := wire.EncodeToBinary(ctx, logger, &resp[0].PacketBundle, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to encode public key response packet") return err } // Write the public key response to the client _, err = clientConn.Write(buf) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(logger, err, "failed to write public key response to the client
------------------

--- Chunk 21---
Function simulateFullAuth (part 4): ") return err } // Read the encrypted password from the client encryptedPasswordBuf, err := mysqlUtils.ReadPacketBuffer(ctx, logger, clientConn) if err != nil { utils.LogError(logger, err, "failed to read encrypted password from client") return err } // Get the packet from the buffer encryptedPassPkt, err := mysqlUtils.BytesToMySQLPacket(encryptedPasswordBuf) if err != nil { utils.LogError(logger, err, "failed to convert encrypted password to packet") return err } if len(req) < 2 { utils.LogError(logger, nil, "no mysql mocks found for encrypted password during full auth") return fmt.Errorf("no mysql mocks found for encrypted password during full auth") } // Get the encrypted password from the mock encryptedPassMock := req[1].PacketBundle if encryptedPassMock.Header.Type != mysql.EncryptedPassword { utils.LogError(logger, nil, "expected encrypted password mock not found", zap.Any("found", encryptedPassMock.Header.Type)) return fmt.Errorf("expected %s but found %s", mysql.EncryptedPassword, encryptedPassMock.Header.Type) } // Since encrypted password can be
------------------

--- Chunk 22---
Function simulateFullAuth (part 5): different, we should just check the sequence number if encryptedPassMock.Header.Header.SequenceID != encryptedPassPkt.Header.SequenceID { utils.LogError(logger, nil, "sequence number mismatch for encrypted password", zap.Any("expected", encryptedPassMock.Header.Header.SequenceID), zap.Any("actual", encryptedPassPkt.Header.SequenceID)) return fmt.Errorf("sequence number mismatch for encrypted password") } //Now send the final response (OK/Err) to the client if len(resp) < 2 { utils.LogError(logger, nil, "final response mock not found for full auth") return fmt.Errorf("final response mock not found for full auth") } logger.Debug("final response for full auth", zap.Any("response", resp[1].Header.Type)) // Get the final response (OK/Err) from the mock // Send the final response (OK/Err) to the client buf, err = wire.EncodeToBinary(ctx, logger, &resp[1].PacketBundle, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to encode final response packet for full auth") return err } _, err = clientConn.Write(buf) if err
------------------

--- Chunk 23---
Function simulateFullAuth (end): != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(logger, err, "failed to write final response for full auth to the client") return err } // FullAuth mechanism only comes for the first time unless COM_CHANGE_USER is called (that is not supported for now). // Afterwards only fast auth success is expected. So, we can delete this. ok = mockDb.DeleteUnFilteredMock(*initialHandshakeMock) // TODO: need to check what to do in this case if !ok { utils.LogError(logger, nil, "failed to delete unfiltered mock during full auth") } logger.Debug("full auth completed successfully") return nil }
------------------

--- Chunk 24---
Function simulatePlainPassword (start): func simulatePlainPassword(ctx context.Context, logger *zap.Logger, clientConn net.Conn, fullAuthMocks reqResp, initialHandshakeMock *models.Mock, mockDb integrations.MockMemDb, decodeCtx *wire.DecodeContext) error { req := fullAuthMocks.req resp := fullAuthMocks.resp // read the plain password from the client plainPassBuf, err := mysqlUtils.ReadPacketBuffer(ctx, logger, clientConn) if err != nil { utils.LogError(logger, err, "failed to read plain password from client") return err } // Get the packet from the buffer plainPassPkt, err := mysqlUtils.BytesToMySQLPacket(plainPassBuf) if err != nil { utils.LogError(logger, err, "failed to convert plain password to packet") return err } plainPass := string(intgUtils.EncodeBase64(plainPassPkt.Payload)) // Get the plain password from the mock if len(req) < 1 { utils.LogError(logger, nil, "no mysql mocks found for plain password") return fmt.Errorf("no mysql mocks found for plain password") } plainPassMock, ok := req[0].Message.(string)
------------------

--- Chunk 25---
Function simulatePlainPassword (part 2): if !ok { utils.LogError(logger, nil, "failed to assert plain password packet") return fmt.Errorf("failed to assert plain password packet") } // Match the header of the plain password ok = matchHeader(*req[0].Header.Header, plainPassPkt.Header) if !ok { utils.LogError(logger, nil, "header mismatch for plain password", zap.Any("expected", req[0].Header.Header), zap.Any("actual", plainPassPkt.Header)) return fmt.Errorf("header mismatch for plain password") } // Match the plain password from the client with the mock if plainPass != plainPassMock { utils.LogError(logger, nil, "plain password mismatch", zap.Any("actual", plainPass), zap.Any("expected", plainPassMock)) return fmt.Errorf("plain password mismatch") } //Now send the final response (OK/Err) to the client if len(resp) < 1 { utils.LogError(logger, nil, "final response mock not found for full auth (plain password)") return fmt.Errorf("final response mock not found for full auth (plain password)") } logger.Debug("final response for full auth(plain password)", zap.Any("response",
------------------

--- Chunk 26---
Function simulatePlainPassword (part 3): resp[0].Header.Type)) // Get the final response (OK/Err) from the mock // Send the final response (OK/Err) to the client buf, err := wire.EncodeToBinary(ctx, logger, &resp[0].PacketBundle, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to encode final response packet for full auth (plain password)") return err } _, err = clientConn.Write(buf) if err != nil { if ctx.Err() != nil { return ctx.Err() } utils.LogError(logger, err, "failed to write final response for full auth (plain password) to the client") return err } // FullAuth mechanism only comes for the first time unless COM_CHANGE_USER is called (that is not supported for now). // Afterwards only fast auth success is expected. So, we can delete this. ok = mockDb.DeleteUnFilteredMock(*initialHandshakeMock) // TODO: need to check what to do in this case if !ok { utils.LogError(logger, nil, "failed to delete unfiltered mock during full auth (plain password) in ssl request") }
------------------

--- Chunk 27---
Function simulatePlainPassword (end): logger.Debug("full auth (plain-password) in ssl request completed successfully") return nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/replayer/match.go---

--- Chunk 1---
func matchHeader(expected, actual mysql.Header) bool { // Match the payloadlength if actual.PayloadLength != expected.PayloadLength { return false } // Match the sequence number if actual.SequenceID != expected.SequenceID { return false } return true }
------------------

--- Chunk 2---
Function matchSSLRequest (start): func matchSSLRequest(_ context.Context, _ *zap.Logger, expected, actual mysql.PacketBundle) error { // Match the type if expected.Header.Type != actual.Header.Type { return fmt.Errorf("type mismatch for ssl request") } //Don't match the header, because the payload length can be different. // Match the payload expectedMessage, _ := expected.Message.(*mysql.SSLRequestPacket) actualMessage, _ := actual.Message.(*mysql.SSLRequestPacket) // Match the MaxPacketSize if expectedMessage.MaxPacketSize != actualMessage.MaxPacketSize { return fmt.Errorf("max packet size mismatch for ssl request, expected: %d, actual: %d", expectedMessage.MaxPacketSize, actualMessage.MaxPacketSize) } // Match the CharacterSet if expectedMessage.CharacterSet != actualMessage.CharacterSet { return fmt.Errorf("character set mismatch for ssl request, expected: %d, actual: %d", expectedMessage.CharacterSet, actualMessage.CharacterSet) } // Match the Filler if expectedMessage.Filler != actualMessage.Filler { return fmt.Errorf("filler mismatch for ssl request, expected: %v, actual: %v", expectedMessage.Filler, actual
------------------

--- Chunk 3---
Function matchSSLRequest (end): Message.Filler) } return nil }
------------------

--- Chunk 4---
Function matchHanshakeResponse41 (start): func matchHanshakeResponse41(_ context.Context, _ *zap.Logger, expected, actual mysql.PacketBundle) error { // Match the type if expected.Header.Type != actual.Header.Type { return fmt.Errorf("type mismatch for handshake response") } //Don't match the header, because the payload length can be different. // Match the payload //Get the packet type from both the packet bundles // we don't need to do type assertion because its already done in the caller function exp := expected.Message.(*mysql.HandshakeResponse41Packet) act := actual.Message.(*mysql.HandshakeResponse41Packet) // // Match the CapabilityFlags // if exp.CapabilityFlags != act.CapabilityFlags { // return fmt.Errorf("capability flags mismatch for handshake response, expected: %d, actual: %d", exp.CapabilityFlags, act.CapabilityFlags) // } // Match the MaxPacketSize if exp.MaxPacketSize != act.MaxPacketSize { return fmt.Errorf("max packet size mismatch for handshake response, expected: %d, actual: %d", exp.MaxPacketSize, act.MaxPacketSize) } // Match the CharacterSet if exp.CharacterSet != act
------------------

--- Chunk 5---
Function matchHanshakeResponse41 (part 2): .CharacterSet { return fmt.Errorf("character set mismatch for handshake response, expected: %d, actual: %d", exp.CharacterSet, act.CharacterSet) } // Match the Filler if exp.Filler != act.Filler { return fmt.Errorf("filler mismatch for handshake response, expected: %v, actual: %v", exp.Filler, act.Filler) } // Match the Username if exp.Username != act.Username { return fmt.Errorf("username mismatch for handshake response, expected: %s, actual: %s", exp.Username, act.Username) } // Match the AuthResponse if string(exp.AuthResponse) != string(act.AuthResponse) { return fmt.Errorf("auth response mismatch for handshake response, expected: %s, actual: %s", string(exp.AuthResponse), string(act.AuthResponse)) } // Match the Database if exp.Database != act.Database { return fmt.Errorf("database mismatch for handshake response, expected: %s, actual: %s", exp.Database, act.Database) } // Match the AuthPluginName if exp.AuthPluginName != act.AuthPluginName { return fmt.Errorf("auth plugin name mismatch for handshake response, expected: %
------------------

--- Chunk 6---
Function matchHanshakeResponse41 (end): s, actual: %s", exp.AuthPluginName, act.AuthPluginName) } // // Match the ConnectionAttributes // if len(exp.ConnectionAttributes) != len(act.ConnectionAttributes) { // return fmt.Errorf("connection attributes length mismatch for handshake response, expected: %d, actual: %d", len(exp.ConnectionAttributes), len(act.ConnectionAttributes)) // } // for key, value := range exp.ConnectionAttributes { // if act.ConnectionAttributes[key] != value && key != "_pid" { // return fmt.Errorf("connection attributes mismatch for handshake response, expected: %s, actual: %s", value, act.ConnectionAttributes[key]) // } // } // Match the ZstdCompressionLevel if exp.ZstdCompressionLevel != act.ZstdCompressionLevel { return fmt.Errorf("zstd compression level mismatch for handshake response") } return nil }
------------------

--- Chunk 7---
Function matchCommand (start): func matchCommand(ctx context.Context, logger *zap.Logger, req mysql.Request, mockDb integrations.MockMemDb, decodeCtx *wire.DecodeContext) (*mysql.Response, bool, error) { for { if ctx.Err() != nil { return nil, false, ctx.Err() } // Get the tcs mocks from the mockDb unfiltered, err := mockDb.GetUnFilteredMocks() if err != nil { if ctx.Err() != nil { return nil, false, ctx.Err() } utils.LogError(logger, err, "failed to get unfiltered mocks") return nil, false, err } // Get the mysql mocks mocks := intgUtil.GetMockByKind(unfiltered, "MySQL") if len(mocks) == 0 { if ctx.Err() != nil { return nil, false, ctx.Err() } utils.LogError(logger, nil, "no mysql mocks found") return nil, false, fmt.Errorf("no mysql mocks found") } var tcsMocks []*models.Mock // Ignore the "config" metadata mocks for _, mock := range mocks { if mock
------------------

--- Chunk 8---
Function matchCommand (part 2): .Spec.Metadata["type"] != "config" { tcsMocks = append(tcsMocks, mock) } } if len(tcsMocks) == 0 { if ctx.Err() != nil { return nil, false, ctx.Err() } // COM_QUIT packet can be handled separately, because there might be no mock for it if req.Header.Type == mysql.CommandStatusToString(mysql.COM_QUIT) { // If the command is quit, we should return EOF logger.Debug("Received quit command, closing the connection by sending EOF") return nil, false, io.EOF } utils.LogError(logger, nil, "no mysql mocks found for handling command phase") return nil, false, fmt.Errorf("no mysql mocks found for handling command phase") } var maxMatchedCount int var matchedResp *mysql.Response var matchedMock *models.Mock // Match the request with the mock for _, mock := range tcsMocks { if ctx.Err() != nil { return nil, false, ctx.Err() } for _, mockReq := range mock.Spec.MySQLRequests { if ctx.Err
------------------

--- Chunk 9---
Function matchCommand (part 3): () != nil { return nil, false, ctx.Err() } //debug log // logger.Debug("Matching the request with the mock", zap.Any("mock", mockReq), zap.Any("request", req)) switch req.Header.Type { //utiltiy commands case mysql.CommandStatusToString(mysql.COM_QUIT): matchCount := matchQuitPacket(ctx, logger, mockReq.PacketBundle, req.PacketBundle) if matchCount > maxMatchedCount { maxMatchedCount = matchCount matchedResp = &mysql.Response{} // in case if server closed the connection without sending any response if len(mock.Spec.MySQLResponses) > 0 { matchedResp = &mock.Spec.MySQLResponses[0] // if server responded with "error" packet } matchedMock = mock } case mysql.CommandStatusToString(mysql.COM_INIT_DB): matchCount := matchInitDbPacket(ctx, logger, mockReq.PacketBundle, req.PacketBundle) if matchCount > maxMatchedCount { maxMatchedCount = matchCount matchedResp = &mock.Spec.MySQLResponses[0] matchedMock =
------------------

--- Chunk 10---
Function matchCommand (part 4): mock } case mysql.CommandStatusToString(mysql.COM_STATISTICS): matchCount := matchStatisticsPacket(ctx, logger, mockReq.PacketBundle, req.PacketBundle) if matchCount > maxMatchedCount { maxMatchedCount = matchCount matchedResp = &mock.Spec.MySQLResponses[0] matchedMock = mock } case mysql.CommandStatusToString(mysql.COM_DEBUG): matchCount := matchDebugPacket(ctx, logger, mockReq.PacketBundle, req.PacketBundle) if matchCount > maxMatchedCount { maxMatchedCount = matchCount matchedResp = &mock.Spec.MySQLResponses[0] matchedMock = mock } case mysql.CommandStatusToString(mysql.COM_PING): matchCount := matchPingPacket(ctx, logger, mockReq.PacketBundle, req.PacketBundle) if matchCount > maxMatchedCount { maxMatchedCount = matchCount matchedResp = &mock.Spec.MySQLResponses[0] matchedMock = mock } // case mysql.CommandStatusToString(mysql.COM_CHANGE_USER): case mysql.CommandStatusToString(mysql.COM_RESET_CONNECTION): matchCount := matchReset
------------------

--- Chunk 11---
Function matchCommand (part 5): ConnectionPacket(ctx, logger, mockReq.PacketBundle, req.PacketBundle) if matchCount > maxMatchedCount { maxMatchedCount = matchCount matchedResp = &mock.Spec.MySQLResponses[0] matchedMock = mock } //query commands case mysql.CommandStatusToString(mysql.COM_STMT_CLOSE): matchCount := matchClosePacket(ctx, logger, mockReq.PacketBundle, req.PacketBundle) if matchCount > maxMatchedCount { maxMatchedCount = matchCount matchedResp = &mysql.Response{} matchedMock = mock } // case mysql.CommandStatusToString(mysql.COM_STMT_SEND_LONG_DATA): case mysql.CommandStatusToString(mysql.COM_QUERY): matchCount := matchQueryPacket(ctx, logger, mockReq.PacketBundle, req.PacketBundle) if matchCount > maxMatchedCount { maxMatchedCount = matchCount matchedResp = &mock.Spec.MySQLResponses[0] matchedMock = mock } case mysql.CommandStatusToString(mysql.COM_STMT_PREPARE): matchCount := matchPreparePacket(ctx, logger, mockReq.PacketBundle, req.PacketBundle) if
------------------

--- Chunk 12---
Function matchCommand (part 6): matchCount > maxMatchedCount { maxMatchedCount = matchCount matchedResp = &mock.Spec.MySQLResponses[0] matchedMock = mock } case mysql.CommandStatusToString(mysql.COM_STMT_EXECUTE): matchCount := matchStmtExecutePacket(ctx, logger, mockReq.PacketBundle, req.PacketBundle) if matchCount > maxMatchedCount { maxMatchedCount = matchCount matchedResp = &mock.Spec.MySQLResponses[0] matchedMock = mock } } } } if matchedResp == nil { logger.Debug("No matching mock found for the command", zap.Any("command", req)) // COM_QUIT packet can be handled separately, because there might be no mock for it if req.Header.Type == mysql.CommandStatusToString(mysql.COM_QUIT) { // If the command is quit, we should return EOF logger.Debug("Received quit command, closing the connection by sending EOF") return nil, false, io.EOF } return nil, false, nil } //if the req was prepared statement, we should store the prepared statement
------------------

--- Chunk 13---
Function matchCommand (end): response if req.Header.Type == mysql.CommandStatusToString(mysql.COM_STMT_PREPARE) { prepareOkResp, ok := matchedResp.Message.(*mysql.StmtPrepareOkPacket) if !ok { logger.Error("failed to type assert the StmtPrepareOkPacket") return nil, false, fmt.Errorf("failed to type assert the StmtPrepareOkPacket") } // This prepared statement will be used in the further execute statement packets decodeCtx.PreparedStatements[prepareOkResp.StatementID] = prepareOkResp } // Delete the matched mock from the mockDb ok := updateMock(ctx, logger, matchedMock, mockDb) if !ok { //TODO: see what to do in case of failed deletion logger.Debug("failed to update the matched mock") continue } return matchedResp, true, nil } }
------------------

--- Chunk 14---
func matchClosePacket(_ context.Context, _ *zap.Logger, expected, actual mysql.PacketBundle) int { matchCount := 0 // Match the type and return zero if the types are not equal if expected.Header.Type != actual.Header.Type { return 0 } // Match the header ok := matchHeader(*expected.Header.Header, *actual.Header.Header) if ok { matchCount += 2 } expectedMessage, _ := expected.Message.(*mysql.StmtClosePacket) actualMessage, _ := actual.Message.(*mysql.StmtClosePacket) // Match the statementID if expectedMessage.StatementID == actualMessage.StatementID { matchCount++ } return matchCount }
------------------

--- Chunk 15---
func matchQueryPacket(_ context.Context, _ *zap.Logger, expected, actual mysql.PacketBundle) int { matchCount := 0 // Match the type and return zero if the types are not equal if expected.Header.Type != actual.Header.Type { return 0 } // Match the header ok := matchHeader(*expected.Header.Header, *actual.Header.Header) if ok { matchCount += 2 } expectedMessage, _ := expected.Message.(*mysql.QueryPacket) actualMessage, _ := actual.Message.(*mysql.QueryPacket) // Match the query for query packet if expectedMessage.Query == actualMessage.Query { matchCount++ } return matchCount }
------------------

--- Chunk 16---
func matchPreparePacket(_ context.Context, _ *zap.Logger, expected, actual mysql.PacketBundle) int { matchCount := 0 // Match the type and return zero if the types are not equal if expected.Header.Type != actual.Header.Type { return 0 } // Match the header ok := matchHeader(*expected.Header.Header, *actual.Header.Header) if ok { matchCount += 2 } expectedMessage, _ := expected.Message.(*mysql.StmtPreparePacket) actualMessage, _ := actual.Message.(*mysql.StmtPreparePacket) // Match the query for prepare packet if expectedMessage.Query == actualMessage.Query { matchCount++ } return matchCount }
------------------

--- Chunk 17---
Function matchStmtExecutePacket (start): func matchStmtExecutePacket(_ context.Context, _ *zap.Logger, expected, actual mysql.PacketBundle) int { matchCount := 0 // Match the type and return zero if the types are not equal if expected.Header.Type != actual.Header.Type { return 0 } // Match the header if matchHeader(*expected.Header.Header, *actual.Header.Header) { matchCount += 2 } expectedMessage, _ := expected.Message.(*mysql.StmtExecutePacket) actualMessage, _ := actual.Message.(*mysql.StmtExecutePacket) // Match the status if expectedMessage.Status == actualMessage.Status { matchCount++ } // Match the statementID if expectedMessage.StatementID == actualMessage.StatementID { matchCount++ } // Match the flags if expectedMessage.Flags == actualMessage.Flags { matchCount++ } // Match the iteration count if expectedMessage.IterationCount == actualMessage.IterationCount { matchCount++ } // Match the parameter count if expectedMessage.ParameterCount == actualMessage.ParameterCount { matchCount++ } // Match the newParamsBindFlag if expectedMessage.NewParamsBindFlag == actualMessage.NewParamsBindFlag
------------------

--- Chunk 18---
Function matchStmtExecutePacket (end): { matchCount++ } // Match the parameters if len(expectedMessage.Parameters) == len(actualMessage.Parameters) { for i := range expectedMessage.Parameters { expectedParam := expectedMessage.Parameters[i] actualParam := actualMessage.Parameters[i] if expectedParam.Type == actualParam.Type && expectedParam.Name == actualParam.Name && expectedParam.Unsigned == actualParam.Unsigned && reflect.DeepEqual(expectedParam.Value, actualParam.Value) { matchCount++ } } } return matchCount }
------------------

--- Chunk 19---
func matchQuitPacket(_ context.Context, _ *zap.Logger, expected, actual mysql.PacketBundle) int { matchCount := 0 // Match the type and return zero if the types are not equal if expected.Header.Type != actual.Header.Type { return 0 } // Match the header if matchHeader(*expected.Header.Header, *actual.Header.Header) { matchCount += 2 } expectedMessage, _ := expected.Message.(*mysql.QuitPacket) actualMessage, _ := actual.Message.(*mysql.QuitPacket) // Match the command for quit packet if expectedMessage.Command == actualMessage.Command { matchCount++ } return matchCount }
------------------

--- Chunk 20---
func matchInitDbPacket(_ context.Context, _ *zap.Logger, expected, actual mysql.PacketBundle) int { matchCount := 0 // Match the type and return zero if the types are not equal if expected.Header.Type != actual.Header.Type { return 0 } // Match the header if matchHeader(*expected.Header.Header, *actual.Header.Header) { matchCount += 2 } expectedMessage, _ := expected.Message.(*mysql.InitDBPacket) actualMessage, _ := actual.Message.(*mysql.InitDBPacket) // Match the command for init db packet if expectedMessage.Command == actualMessage.Command { matchCount++ } // Match the schema for init db packet if expectedMessage.Schema == actualMessage.Schema { matchCount++ } return matchCount }
------------------

--- Chunk 21---
func matchStatisticsPacket(_ context.Context, _ *zap.Logger, expected, actual mysql.PacketBundle) int { matchCount := 0 // Match the type and return zero if the types are not equal if expected.Header.Type != actual.Header.Type { return 0 } // Match the header if matchHeader(*expected.Header.Header, *actual.Header.Header) { matchCount += 2 } expectedMessage, _ := expected.Message.(*mysql.StatisticsPacket) actualMessage, _ := actual.Message.(*mysql.StatisticsPacket) // Match the command for statistics packet if expectedMessage.Command == actualMessage.Command { matchCount++ } return matchCount }
------------------

--- Chunk 22---
func matchDebugPacket(_ context.Context, _ *zap.Logger, expected, actual mysql.PacketBundle) int { matchCount := 0 // Match the type and return zero if the types are not equal if expected.Header.Type != actual.Header.Type { return 0 } // Match the header if matchHeader(*expected.Header.Header, *actual.Header.Header) { matchCount += 2 } expectedMessage, _ := expected.Message.(*mysql.DebugPacket) actualMessage, _ := actual.Message.(*mysql.DebugPacket) // Match the command for debug packet if expectedMessage.Command == actualMessage.Command { matchCount++ } return matchCount }
------------------

--- Chunk 23---
func matchPingPacket(_ context.Context, _ *zap.Logger, expected, actual mysql.PacketBundle) int { matchCount := 0 // Match the type and return zero if the types are not equal if expected.Header.Type != actual.Header.Type { return 0 } // Match the header if matchHeader(*expected.Header.Header, *actual.Header.Header) { matchCount += 2 } expectedMessage, _ := expected.Message.(*mysql.PingPacket) actualMessage, _ := actual.Message.(*mysql.PingPacket) // Match the command for ping packet if expectedMessage.Command == actualMessage.Command { matchCount++ } return matchCount }
------------------

--- Chunk 24---
func matchResetConnectionPacket(_ context.Context, _ *zap.Logger, expected, actual mysql.PacketBundle) int { matchCount := 0 // Match the type and return zero if the types are not equal if expected.Header.Type != actual.Header.Type { return 0 } // Match the header if matchHeader(*expected.Header.Header, *actual.Header.Header) { matchCount += 2 } expectedMessage, _ := expected.Message.(*mysql.ResetConnectionPacket) actualMessage, _ := actual.Message.(*mysql.ResetConnectionPacket) // Match the command for reset connection packet if expectedMessage.Command == actualMessage.Command { matchCount++ } return matchCount }
------------------

--- Chunk 25---
func updateMock(_ context.Context, logger *zap.Logger, matchedMock *models.Mock, mockDb integrations.MockMemDb) bool { originalMatchedMock := *matchedMock matchedMock.TestModeInfo.IsFiltered = false matchedMock.TestModeInfo.SortOrder = pkg.GetNextSortNum() updated := mockDb.UpdateUnFilteredMock(&originalMatchedMock, matchedMock) if !updated { logger.Debug("failed to update matched mock") } return updated }
------------------

--- File: pkg/core/proxy/integrations/mysql/replayer/query.go---

--- Chunk 1---
Function simulateCommandPhase (start): func simulateCommandPhase(ctx context.Context, logger *zap.Logger, clientConn net.Conn, mockDb integrations.MockMemDb, decodeCtx *wire.DecodeContext, opts models.OutgoingOptions) error { for { select { case <-ctx.Done(): return ctx.Err() default: // Set a read deadline on the client connection readTimeout := 2 * time.Second * time.Duration(opts.SQLDelay) err := clientConn.SetReadDeadline(time.Now().Add(readTimeout)) if err != nil { utils.LogError(logger, err, "failed to set read deadline on client conn") return err } // read the command from the client command, err := mysqlUtils.ReadPacketBuffer(ctx, logger, clientConn) if err != nil { // when the read deadline is reached, we should close the connection if netErr, ok := err.(net.Error); ok && netErr.Timeout() { logger.Debug("closing the client connection since the read deadline is reached") return io.EOF } if err == io.EOF { logger.Debug("closing the client connection due to eof", zap.Error(err)) } else { utils.LogError(logger
------------------

--- Chunk 2---
Function simulateCommandPhase (part 2): , err, "failed to read command packet from client") } return err } // reset the read deadline err = clientConn.SetReadDeadline(time.Time{}) if err != nil { utils.LogError(logger, err, "failed to reset read deadline on client conn") return err } // Decode the command commandPkt, err := wire.DecodePayload(ctx, logger, command, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to decode the MySQL packet from the client") } req := mysql.Request{ PacketBundle: *commandPkt, } // Match the request with the mock resp, ok, err := matchCommand(ctx, logger, req, mockDb, decodeCtx) if err != nil { if err == io.EOF { logger.Debug("EOF error while matching the command, closing the connection") return io.EOF } utils.LogError(logger, err, "failed to match the command") return err } if !ok { utils.LogError(logger, nil, "No matching mock found for the command", zap
------------------

--- Chunk 3---
Function simulateCommandPhase (part 3): .Any("command", command)) return fmt.Errorf("error while simulating the command phase due to no matching mock found") } logger.Debug("Matched the command with the mock", zap.Any("mock", resp)) // We could have just returned before matching the command for no response commands. // But we need to remove the corresponding mock from the mockDb for no response commands. if wire.IsNoResponseCommand(commandPkt.Header.Type) { // No response for COM_STMT_CLOSE and COM_STMT_SEND_LONG_DATA logger.Debug("No response for the command", zap.Any("command", command)) continue } //Encode the matched resp buf, err := wire.EncodeToBinary(ctx, logger, &resp.PacketBundle, clientConn, decodeCtx) if err != nil { utils.LogError(logger, err, "failed to encode the response", zap.Any("response", resp)) return err } // Write the response to the client _, err = clientConn.Write(buf) if err != nil { if ctx.Err() != nil { logger.Debug("context done while writing the response to the client", zap.Error(ctx.Err()))
------------------

--- Chunk 4---
Function simulateCommandPhase (end): return ctx.Err() } utils.LogError(logger, err, "failed to write the response to the client") return err } logger.Debug("successfully wrote the response to the client", zap.Any("request", req.Header.Type)) } } }
------------------

--- File: pkg/core/proxy/integrations/mysql/replayer/replay.go---

--- Chunk 1---
Function Replay (start): func Replay(ctx context.Context, logger *zap.Logger, clientConn net.Conn, _ *models.ConditionalDstCfg, mockDb integrations.MockMemDb, opts models.OutgoingOptions) error { errCh := make(chan error, 1) unfiltered, err := mockDb.GetUnFilteredMocks() if err != nil { utils.LogError(logger, err, "failed to get unfiltered mocks") return err } // Get the mysql mocks mocks := intgUtil.GetMockByKind(unfiltered, "MySQL") if len(mocks) == 0 { utils.LogError(logger, nil, "no mysql mocks found") return nil } var configMocks []*models.Mock // Get the mocks having "config" metadata for _, mock := range mocks { if mock.Spec.Metadata["type"] == "config" { configMocks = append(configMocks, mock) } } if len(configMocks) == 0 { utils.LogError(logger, nil, "no mysql config mocks found for handshake") } go func(errCh chan error, configMocks []*models.Mock, mockDb integrations.MockMemDb, opts models.OutgoingOptions) { defer pUtil.Recover(logger, client
------------------

--- Chunk 2---
Function Replay (part 2): Conn, nil) defer close(errCh) // Helper struct for decoding packets decodeCtx := &wire.DecodeContext{ Mode: models.MODE_TEST, // Map for storing last operation per connection LastOp: wire.NewLastOpMap(), // Map for storing server greetings (inc capabilities, auth plugin, etc) per initial handshake (per connection) ServerGreetings: wire.NewGreetings(), // Map for storing prepared statements per connection PreparedStatements: make(map[uint32]*mysql.StmtPrepareOkPacket), PluginName: string(mysql.CachingSha2), // usually a default plugin in newer versions of MySQL } decodeCtx.LastOp.Store(clientConn, wire.RESET) //resetting last command for new loop // Simulate the initial client-server handshake (connection phase) res, err := simulateInitialHandshake(ctx, logger, clientConn, configMocks, mockDb, decodeCtx, opts) if err != nil { utils.LogError(logger, err, "failed to simulate initial handshake") errCh <- err return } if decodeCtx.UseSSL { if res.tlsClient
------------------

--- Chunk 3---
Function Replay (end): Conn == nil { logger.Error("SSL is enabled but could not get the tls client connection") errCh <- nil return } clientConn = res.tlsClientConn } logger.Debug("Initial handshake completed successfully") // Simulate the client-server interaction (command phase) err = simulateCommandPhase(ctx, logger, clientConn, mockDb, decodeCtx, opts) if err != nil { if err != io.EOF { utils.LogError(logger, err, "failed to simulate command phase") } errCh <- err return } }(errCh, configMocks, mockDb, opts) select { case <-ctx.Done(): return ctx.Err() case err := <-errCh: if err == io.EOF { return nil } return err } }
------------------

--- File: pkg/core/proxy/integrations/mysql/utils/util.go---

--- Chunk 1---
func ReadFirstBuffer(ctx context.Context, logger *zap.Logger, clientConn, destConn net.Conn) ([]byte, string, error) { // Attempt to read from destConn first buf, err := util.ReadBytes(ctx, logger, destConn) // If there is data from destConn, return it if err == nil { return buf, "destination", nil } // If the error is a timeout, try to read from clientConn if netErr, ok := err.(net.Error); ok && netErr.Timeout() { buf, err = util.ReadBytes(ctx, logger, clientConn) // If there is data from clientConn, return it if err == nil { return buf, "client", nil } // Return any error from reading clientConn return nil, "", err } // Return any other error from reading destConn return nil, "", err }
------------------

--- Chunk 2---
func ReadPacketStream(ctx context.Context, logger *zap.Logger, conn net.Conn, bufferChannel chan []byte, errChannel chan error) { for { select { case <-ctx.Done(): // errChannel <- ctx.Err() return default: if conn == nil { logger.Debug("the conn is nil") } buffer, err := ReadPacketBuffer(ctx, logger, conn) if err != nil { if ctx.Err() != nil { // to avoid sending buffer to closed channel if the context is cancelled return } if err != io.EOF { utils.LogError(logger, err, "failed to read mysql packet buffer") } errChannel <- err return } if ctx.Err() != nil { // to avoid sending buffer to closed channel if the context is cancelled return } bufferChannel <- buffer } } }
------------------

--- Chunk 3---
func ReadPacketBuffer(ctx context.Context, logger *zap.Logger, conn net.Conn) ([]byte, error) { var packetBuffer []byte // first read the header length header, err := util.ReadRequiredBytes(ctx, logger, conn, 4) if err != nil { if err == io.EOF { return nil, err } // return packetBuffer, fmt.Errorf("failed to read mysql packet header: %w", err) return packetBuffer, err } packetBuffer = append(packetBuffer, header...) // read the payload length payloadLength := GetPayloadLength(header[:3]) if payloadLength > 0 { payload, err := util.ReadRequiredBytes(ctx, logger, conn, int(payloadLength)) if err != nil { if err == io.EOF { return nil, err } // return packetBuffer, fmt.Errorf("failed to read mysql packet payload: %w", err) return packetBuffer, err } packetBuffer = append(packetBuffer, payload...) } return packetBuffer, nil }
------------------

--- Chunk 4---
func BytesToMySQLPacket(buffer []byte) (mysql.Packet, error) { if len(buffer) < 4 { return mysql.Packet{}, errors.New("buffer is nil or too short to be a valid MySQL packet") } tempBuffer := make([]byte, 4) copy(tempBuffer, buffer[:3]) length := binary.LittleEndian.Uint32(tempBuffer) sequenceID := buffer[3] payload := buffer[4:] return mysql.Packet{ Header: mysql.Header{ PayloadLength: length, SequenceID: sequenceID, }, Payload: payload, }, nil }
------------------

--- Chunk 5---
func GetPayloadLength(src []byte) (length uint32) { length = uint32(src[0]) | uint32(src[1])<<8 | uint32(src[2])<<16 return length }
------------------

--- Chunk 6---
Function ReadLengthEncodedInteger (start): func ReadLengthEncodedInteger(b []byte) (num uint64, isNull bool, n int) { if len(b) == 0 { return 0, true, 0 } switch b[0] { // 251: NULL case 0xfb: return 0, true, 1 // 252: value of following 2 case 0xfc: return uint64(b[1]) | uint64(b[2])<<8, false, 3 // 253: value of following 3 case 0xfd: return uint64(b[1]) | uint64(b[2])<<8 | uint64(b[3])<<16, false, 4 // 254: value of following 8 case 0xfe: return uint64(b[1]) | uint64(b[2])<<8 | uint64(b[3])<<16 | uint64(b[4])<<24 | uint64(b[5])<<32 | uint64(b[6])<<40 | uint64(b[7])<<48 | uint64(b[8])<<56, false, 9
------------------

--- Chunk 7---
Function ReadLengthEncodedInteger (end): } // 0-250: value of first byte return uint64(b[0]), false, 1 }
------------------

--- Chunk 8---
func IsEOFPacket(data []byte) bool { if len(data) < 5 { return false // Packet is too short to be valid } // Check if the first byte is 5 or 7 if data[0] != 5 && data[0] != 7 { return false } // Check if the packet contains the EOF marker 0xFE return len(data) > 0 && data[4] == 0xFE }
------------------

--- Chunk 9---
func IsERRPacket(data []byte) bool { return len(data) > 9 && data[4] == mysql.ERR }
------------------

--- Chunk 10---
func IsOKPacket(data []byte) bool { return len(data) > 7 && data[4] == mysql.OK }
------------------

--- Chunk 11---
func IsGenericResponse(data []byte) (string, bool) { if IsOKPacket(data) { return "OK", true } if IsERRPacket(data) { return "ERR", true } if IsEOFPacket(data) { return "EOF", true } return "", false }
------------------

--- Chunk 12---
func ReadUint24(b []byte) uint32 { return uint32(b[0]) | uint32(b[1])<<8 | uint32(b[2])<<16 }
------------------

--- Chunk 13---
func ReadLengthEncodedString(b []byte) ([]byte, bool, int, error) { // Get length num, isNull, n := ReadLengthEncodedInteger(b) if num < 1 { return b[n:n], isNull, n, nil } n += int(num) // Check data length if len(b) >= n { return b[n-int(num) : n : n], false, n, nil } return nil, false, n, io.EOF }
------------------

--- Chunk 14---
func ReadNullTerminatedString(b []byte) ([]byte, int, error) { i := bytes.IndexByte(b, 0x00) if i == -1 { return nil, 0, io.EOF } return b[:i], i + 1, nil }
------------------

--- Chunk 15---
func WriteStream(ctx context.Context, logger *zap.Logger, conn net.Conn, buff [][]byte) error { for _, b := range buff { if ctx.Err() != nil { return ctx.Err() } _, err := conn.Write(b) if err != nil { utils.LogError(logger, err, "failed to write to connection") return err } } return nil }
------------------

--- Chunk 16---
func WriteLengthEncodedString(buf *bytes.Buffer, s string) error { length := len(s) if err := WriteLengthEncodedInteger(buf, uint64(length)); err != nil { return err } if _, err := buf.WriteString(s); err != nil { return err } return nil }
------------------

--- Chunk 17---
func WriteLengthEncodedInteger(buf *bytes.Buffer, num uint64) error { switch { case num <= 250: if err := buf.WriteByte(byte(num)); err != nil { return err } case num <= 0xFFFF: if err := buf.WriteByte(0xFC); err != nil { return err } if err := binary.Write(buf, binary.LittleEndian, uint16(num)); err != nil { return err } case num <= 0xFFFFFF: if err := buf.WriteByte(0xFD); err != nil { return err } num24 := []byte{byte(num), byte(num >> 8), byte(num >> 16)} if _, err := buf.Write(num24); err != nil { return err } default: if err := buf.WriteByte(0xFE); err != nil { return err } if err := binary.Write(buf, binary.LittleEndian, num); err != nil { return err } } return nil }
------------------

--- Chunk 18---
func WriteUint24(buf *bytes.Buffer, value uint32) error { if value > 0xFFFFFF { return errors.New("value exceeds 24 bits") } buf.WriteByte(byte(value)) buf.WriteByte(byte(value >> 8)) buf.WriteByte(byte(value >> 16)) return nil }
------------------

--- Chunk 19---
func ParseBinaryDate(b []byte) (interface{}, int, error) { if len(b) == 0 { return nil, 0, nil } length := b[0] if length == 0 { return nil, 1, nil } year := binary.LittleEndian.Uint16(b[1:3]) month := b[3] day := b[4] return fmt.Sprintf("%04d-%02d-%02d", year, month, day), int(length) + 1, nil }
------------------

--- Chunk 20---
func ParseBinaryDateTime(b []byte) (interface{}, int, error) { if len(b) == 0 { return nil, 0, nil } length := b[0] if length == 0 { return nil, 1, nil } year := binary.LittleEndian.Uint16(b[1:3]) month := b[3] day := b[4] hour := b[5] minute := b[6] second := b[7] if length > 7 { microsecond := binary.LittleEndian.Uint32(b[8:12]) return fmt.Sprintf("%04d-%02d-%02d %02d:%02d:%02d.%06d", year, month, day, hour, minute, second, microsecond), int(length) + 1, nil } return fmt.Sprintf("%04d-%02d-%02d %02d:%02d:%02d", year, month, day, hour, minute, second), int(length) + 1, nil }
------------------

--- Chunk 21---
func ParseBinaryTime(b []byte) (interface{}, int, error) { if len(b) == 0 { return nil, 0, nil } length := b[0] if length == 0 { return nil, 1, nil } isNegative := b[1] == 1 days := binary.LittleEndian.Uint32(b[2:6]) hours := b[6] minutes := b[7] seconds := b[8] var microseconds uint32 if length > 8 { microseconds = binary.LittleEndian.Uint32(b[9:13]) } timeString := fmt.Sprintf("%d %02d:%02d:%02d.%06d", days, hours, minutes, seconds, microseconds) if isNegative { timeString = "-" + timeString } return timeString, int(length) + 1, nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/decode.go---

--- Chunk 1---
Function DecodePayload (start): func DecodePayload(ctx context.Context, logger *zap.Logger, data []byte, clientConn net.Conn, decodeCtx *DecodeContext) (*mysql.PacketBundle, error) { //Parse the data into mysql header and payload packet, err := utils.BytesToMySQLPacket(data) if err != nil { return &mysql.PacketBundle{}, fmt.Errorf("failed to parse MySQL packet: %w", err) } if len(packet.Payload) < 1 { return &mysql.PacketBundle{}, fmt.Errorf("invalid packet, payload is empty") } lastOp, ok := decodeCtx.LastOp.Load(clientConn) if !ok { logger.Debug("Last operation not found in DecodePayload") lastOp = 0x00 } logger.Debug("Last operation in DecodePayload", zap.String("operation", fmt.Sprintf("%#x", lastOp)), zap.Any("header", packet.Header)) logger.Debug("Mode", zap.Any("Mode", decodeCtx.Mode)) if (lastOp == mysql.COM_QUERY || lastOp == mysql.COM_STMT_EXECUTE) && decodeCtx.Mode == models.MODE_RECORD { return handleQueryStmtResponse(ctx, logger, packet, clientConn, lastOp, decodeCtx) } parsedPacket, err := decodePacket(ctx
------------------

--- Chunk 2---
Function DecodePayload (end): , logger, packet, clientConn, lastOp, decodeCtx) if err != nil { return &mysql.PacketBundle{}, fmt.Errorf("failed to decode packet: %w", err) } return parsedPacket, nil }
------------------

--- Chunk 3---
Function handleQueryStmtResponse (start): func handleQueryStmtResponse(ctx context.Context, logger *zap.Logger, packet mysql.Packet, clientConn net.Conn, lastOp byte, decodeCtx *DecodeContext) (*mysql.PacketBundle, error) { //Get the Header & payload of the packet header := packet.Header payload := packet.Payload parsedPacket := &mysql.PacketBundle{ Header: &mysql.PacketInfo{ Header: &header, }, } payloadType := payload[0] sg, ok := decodeCtx.ServerGreetings.Load(clientConn) if !ok { return parsedPacket, fmt.Errorf("server Greetings not found") } logger.Debug("Last operation when handling client query", zap.Any("last operation", mysql.CommandStatusToString(lastOp))) switch payloadType { case mysql.OK: pkt, err := phase.DecodeOk(ctx, payload, sg.CapabilityFlags) if err != nil { return parsedPacket, fmt.Errorf("failed to decode OK packet: %w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.StatusToString(mysql.OK), clientConn, RESET, decodeCtx) case mysql.ERR: pkt, err := phase.DecodeERR(ctx, payload, sg.CapabilityFlags)
------------------

--- Chunk 4---
Function handleQueryStmtResponse (part 2): if err != nil { return parsedPacket, fmt.Errorf("failed to decode ERR packet: %w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.StatusToString(mysql.ERR), clientConn, RESET, decodeCtx) case mysql.EOF: pkt, err := phase.DecodeEOF(ctx, payload, sg.CapabilityFlags) if err != nil { return parsedPacket, fmt.Errorf("failed to decode EOF packet: %w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.StatusToString(mysql.EOF), clientConn, RESET, decodeCtx) case mysql.LocalInFile: parsedPacket.Header.Type = "LocalInFile" decodeCtx.LastOp.Store(clientConn, RESET) //reset the last operation return parsedPacket, fmt.Errorf("LocalInFile not supported") default: //If the packet is not OK, ERR, EOF or LocalInFile, then it is a result set var pktType string var rowType query.RowType if lastOp == mysql.COM_STMT_EXECUTE { rowType = query.Binary pktType = string(mysql.Binary) } else { rowType = query.Text
------------------

--- Chunk 5---
Function handleQueryStmtResponse (end): pktType = string(mysql.Text) } pkt, err := query.DecodeResultSetMetadata(ctx, logger, payload, rowType) if err != nil { return parsedPacket, fmt.Errorf("failed to decode result set: %w", err) } // Do not change the last operation if the packet is a result set, it will be changed when the result set is fully received setPacketInfo(ctx, parsedPacket, pkt, pktType, clientConn, lastOp, decodeCtx) } return parsedPacket, nil }
------------------

--- Chunk 6---
Function decodePacket (start): func decodePacket(ctx context.Context, logger *zap.Logger, packet mysql.Packet, clientConn net.Conn, lastOp byte, decodeCtx *DecodeContext) (*mysql.PacketBundle, error) { //Get the Header & payload of the packet header := packet.Header payload := packet.Payload parsedPacket := &mysql.PacketBundle{ Header: &mysql.PacketInfo{ Header: &header, }, } payloadType := payload[0] var sg *mysql.HandshakeV10Packet var ok bool // No need to find the server greetings in the map if the payload is HandshakeV10 because it is the first packet and going to be stored in the map if payloadType != mysql.HandshakeV10 { sg, ok = decodeCtx.ServerGreetings.Load(clientConn) if !ok { return parsedPacket, fmt.Errorf("server Greetings not found") } } logger.Debug("payload info", zap.Any("last operation", lastOp), zap.Any("payload type", payloadType)) // Handle handshakeResponse41 separately, because its status is not defined and can be changed with the client capabilities. if lastOp == mysql.HandshakeV10 { logger.Debug("Hand
------------------

--- Chunk 7---
Function decodePacket (part 2): shakeResponse41/SSL Request packet", zap.Any("Type", payloadType)) pkt, err := connection.DecodeHandshakeResponse(ctx, logger, payload) if err != nil { return parsedPacket, fmt.Errorf("failed to decode HandshakeResponse41 packet: %w", err) } var pktType string switch pkt := pkt.(type) { case *mysql.HandshakeResponse41Packet: // Store the client capabilities to use it later decodeCtx.ClientCapabilities = pkt.CapabilityFlags pktType = mysql.HandshakeResponse41 lastOp = payloadType case *mysql.SSLRequestPacket: // Store the client capabilities to use it later decodeCtx.ClientCapabilities = pkt.CapabilityFlags pktType = mysql.SSLRequest decodeCtx.UseSSL = true logger.Info("SSL Request packet detected") // Don't change the last operation if the packet is an SSL Request } setPacketInfo(ctx, parsedPacket, pkt, pktType, clientConn, lastOp, decodeCtx) logger.Debug("HandshakeResponse41/SSL Request decoded", zap.Any("parsed packet", parsedPacket
------------------

--- Chunk 8---
Function decodePacket (part 3): )) return parsedPacket, nil } switch { // generic response packets case payloadType == mysql.EOF && len(payload) == 5: //assuming that the payload is always 5 bytes logger.Debug("EOF packet", zap.Any("Type", payloadType)) pkt, err := phase.DecodeEOF(ctx, payload, sg.CapabilityFlags) if err != nil { return parsedPacket, fmt.Errorf("failed to decode EOF packet: %w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.StatusToString(mysql.EOF), clientConn, mysql.EOF, decodeCtx) logger.Debug("EOF decoded", zap.Any("parsed packet", parsedPacket)) case payloadType == mysql.ERR: logger.Debug("ERR packet", zap.Any("Type", payloadType)) pkt, err := phase.DecodeERR(ctx, payload, sg.CapabilityFlags) if err != nil { return parsedPacket, fmt.Errorf("failed to decode ERR packet: %w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.StatusToString(mysql.ERR), clientConn, mysql.ERR, decodeCtx) logger.Debug("ERR decoded", zap.Any("parsed packet", parsedPacket))
------------------

--- Chunk 9---
Function decodePacket (part 4): case payloadType == mysql.OK: if lastOp == mysql.COM_STMT_PREPARE { logger.Debug("COM_STMT_PREPARE_OK packet", zap.Any("Type", payloadType)) pkt, err := preparedstmt.DecodePrepareOk(ctx, logger, payload) if err != nil { return parsedPacket, fmt.Errorf("failed to decode COM_STMT_PREPARE_OK packet: %w", err) } // Do not change the last operation if the packet is a prepared statement, it will be changed when the prepared statement is fully received setPacketInfo(ctx, parsedPacket, pkt, "COM_STMT_PREPARE_OK", clientConn, lastOp, decodeCtx) // Store the prepared statement to use it later decodeCtx.PreparedStatements[pkt.StatementID] = pkt logger.Debug("Prepared statement stored", zap.Any("statementId", pkt.StatementID), zap.Any("prepared statement", pkt)) logger.Debug("COM_STMT_PREPARE_OK decoded", zap.Any("parsed packet", parsedPacket)) } else { logger.Debug("OK packet", zap.Any("Type", payloadType)) pkt, err := phase.DecodeOk(ctx, payload, sg.Cap
------------------

--- Chunk 10---
Function decodePacket (part 5): abilityFlags) if err != nil { return parsedPacket, fmt.Errorf("failed to decode OK packet: %w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.StatusToString(mysql.OK), clientConn, mysql.OK, decodeCtx) logger.Debug("OK decoded", zap.Any("parsed packet", parsedPacket)) } // auth packets case payloadType == 0x01: if len(payload) == 1 { logger.Debug("COM_QUIT packet", zap.Any("Type", payloadType)) pkt := &mysql.QuitPacket{ Command: payloadType, } setPacketInfo(ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_QUIT), clientConn, mysql.COM_QUIT, decodeCtx) logger.Debug("COM_QUIT decoded", zap.Any("parsed packet", parsedPacket)) } else { //otherwise it is a AuthMoreData packet logger.Debug("AuthMoreData packet", zap.Any("Type", payloadType)) pkt, err := connection.DecodeAuthMoreData(ctx, payload) if err != nil { return parsedPacket, fmt.Errorf("failed to decode AuthMoreData packet: %
------------------

--- Chunk 11---
Function decodePacket (part 6): w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.AuthStatusToString(mysql.AuthMoreData), clientConn, mysql.AuthMoreData, decodeCtx) logger.Debug("AuthMoreData decoded", zap.Any("parsed packet", parsedPacket)) } case payloadType == mysql.AuthSwitchRequest && len(payload) > 5: //conflicting with EOF packet, assuming that the payload is always greater than 5 bytes logger.Debug("AuthSwitchRequest packet", zap.Any("Type", payloadType)) pkt, err := connection.DecodeAuthSwitchRequest(ctx, payload) if err != nil { return parsedPacket, fmt.Errorf("failed to decode AuthSwitchRequest packet: %w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.AuthStatusToString(mysql.AuthSwitchRequest), clientConn, mysql.AuthSwitchRequest, decodeCtx) logger.Debug("AuthSwitchRequest decoded", zap.Any("parsed packet", parsedPacket)) case payloadType == 0x02: if len(payload) == 1 { logger.Debug(("Request public key detected")) setPacketInfo(ctx, parsedPacket, "request_public_key", mysql.CachingSha2PasswordToString(mysql.RequestPublicKey
------------------

--- Chunk 12---
Function decodePacket (part 7): ), clientConn, byte(mysql.RequestPublicKey), decodeCtx) logger.Debug("Request public key decoded", zap.Any("parsed packet", parsedPacket)) } else { logger.Debug("AuthNextFactor packet", zap.Any("Type", payloadType)) pkt, err := connection.DecodeAuthNextFactor(ctx, payload) if err != nil { return parsedPacket, fmt.Errorf("failed to decode AuthNextFactor packet: %w", err) } logger.Warn("AuthNextFactor packet not supported, further flow can be affected") setPacketInfo(ctx, parsedPacket, pkt, mysql.AuthStatusToString(mysql.AuthNextFactor), clientConn, mysql.AuthNextFactor, decodeCtx) logger.Debug("AuthNextFactor decoded", zap.Any("parsed packet", parsedPacket)) } case payloadType == mysql.HandshakeV10: logger.Debug("HandshakeV10 packet", zap.Any("Type", payloadType)) pkt, err := connection.DecodeHandshakeV10(ctx, logger, payload) if err != nil { return parsedPacket, fmt.Errorf("failed to decode HandshakeV10 packet: %w", err) } // Store the server greetings to use it later
------------------

--- Chunk 13---
Function decodePacket (part 8): decodeCtx.ServerGreetings.Store(clientConn, pkt) setPacketInfo(ctx, parsedPacket, pkt, mysql.AuthStatusToString(mysql.HandshakeV10), clientConn, mysql.HandshakeV10, decodeCtx) logger.Debug("HandshakeV10 decoded", zap.Any("parsed packet", parsedPacket)) // utility packets case payloadType == mysql.COM_QUIT: logger.Debug("COM_QUIT packet", zap.Any("Type", payloadType)) pkt := &mysql.QuitPacket{ Command: payloadType, } setPacketInfo(ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_QUIT), clientConn, mysql.COM_QUIT, decodeCtx) logger.Debug("COM_QUIT decoded", zap.Any("parsed packet", parsedPacket)) case payloadType == mysql.COM_INIT_DB: logger.Debug("COM_INIT_DB packet", zap.Any("Type", payloadType)) pkt, err := utility.DecodeInitDb(ctx, payload) if err != nil { return parsedPacket, fmt.Errorf("failed to decode COM_INIT_DB packet: %w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_INIT_DB), clientConn, mysql
------------------

--- Chunk 14---
Function decodePacket (part 9): .COM_INIT_DB, decodeCtx) logger.Debug("COM_INIT_DB decoded", zap.Any("parsed packet", parsedPacket)) case payloadType == mysql.COM_STATISTICS: logger.Debug("COM_STATISTICS packet", zap.Any("Type", payloadType)) pkt := &mysql.StatisticsPacket{ Command: payloadType, } setPacketInfo(ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_STATISTICS), clientConn, mysql.COM_STATISTICS, decodeCtx) logger.Debug("COM_STATISTICS decoded", zap.Any("parsed packet", parsedPacket)) case payloadType == mysql.COM_DEBUG: logger.Debug("COM_DEBUG packet", zap.Any("Type", payloadType)) pkt := &mysql.DebugPacket{ Command: payloadType, } setPacketInfo(ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_DEBUG), clientConn, mysql.COM_DEBUG, decodeCtx) logger.Debug("COM_DEBUG decoded", zap.Any("parsed packet", parsedPacket)) case payloadType == mysql.COM_PING: logger.Debug("COM_PING packet", zap.Any("Type", payloadType)) pkt := &mysql.PingPacket{ Command: payloadType, } setPacketInfo
------------------

--- Chunk 15---
Function decodePacket (part 10): (ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_PING), clientConn, mysql.COM_PING, decodeCtx) logger.Debug("COM_PING decoded", zap.Any("parsed packet", parsedPacket)) case payloadType == mysql.COM_CHANGE_USER: logger.Debug("COM_CHANGE_USER packet", zap.Any("Type", payloadType)) pkt := &mysql.ChangeUserPacket{ Command: payloadType, } logger.Warn("COM_CHANGE_USER packet not supported, further flow can be affected") setPacketInfo(ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_CHANGE_USER), clientConn, mysql.COM_CHANGE_USER, decodeCtx) logger.Debug("COM_CHANGE_USER decoded", zap.Any("parsed packet", parsedPacket)) case payloadType == mysql.COM_RESET_CONNECTION: logger.Debug("COM_RESET_CONNECTION packet", zap.Any("Type", payloadType)) pkt := &mysql.ResetConnectionPacket{ Command: payloadType, } setPacketInfo(ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_RESET_CONNECTION), clientConn, mysql.COM_RESET_CONNECTION, decodeCtx) logger.Debug("COM_RESET_CONNECTION decoded", zap.Any("parsed packet", parsedPacket)) // case payloadType ==
------------------

--- Chunk 16---
Function decodePacket (part 11): mysql.COM_SET_OPTION: // logger.Debug("COM_SET_OPTION packet", zap.Any("Type", payloadType)) // pkt, err := utility.DecodeSetOption(ctx, payload) // if err != nil { // return parsedPacket, fmt.Errorf("failed to decode COM_SET_OPTION packet: %w", err) // } // setPacketInfo(ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_SET_OPTION), mysql.COM_SET_OPTION, decodeCtx) // command packets case payloadType == mysql.COM_QUERY: logger.Debug("COM_QUERY packet", zap.Any("Type", payloadType)) pkt, err := query.DecodeQuery(ctx, payload) if err != nil { return parsedPacket, fmt.Errorf("failed to decode COM_QUERY packet: %w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_QUERY), clientConn, mysql.COM_QUERY, decodeCtx) lstOp, _ := decodeCtx.LastOp.Load(clientConn) logger.Debug("COM_QUERY decoded", zap.Any("parsed packet", parsedPacket), zap.Any("last operation", lstOp)) case payloadType == mysql.COM_STMT_PREP
------------------

--- Chunk 17---
Function decodePacket (part 12): ARE: logger.Debug("COM_STMT_PREPARE packet", zap.Any("Type", payloadType)) pkt, err := preparedstmt.DecodeStmtPrepare(ctx, payload) if err != nil { return parsedPacket, fmt.Errorf("failed to decode COM_STMT_PREPARE packet: %w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_STMT_PREPARE), clientConn, mysql.COM_STMT_PREPARE, decodeCtx) logger.Debug("COM_STMT_PREPARE decoded", zap.Any("parsed packet", parsedPacket)) case payloadType == mysql.COM_STMT_EXECUTE: logger.Debug("COM_STMT_EXECUTE packet", zap.Any("Type", payloadType)) pkt, err := preparedstmt.DecodeStmtExecute(ctx, logger, payload, decodeCtx.PreparedStatements) if err != nil { return parsedPacket, fmt.Errorf("failed to decode COM_STMT_EXECUTE packet: %w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_STMT_EXECUTE), clientConn, mysql.COM_STMT_EXECUTE, decodeCtx) logger.Debug("COM_STMT_EXECUTE decoded", zap.Any("parsed packet", parsedPacket)) // case payloadType
------------------

--- Chunk 18---
Function decodePacket (part 13): == mysql.COM_STMT_FETCH: case payloadType == mysql.COM_STMT_CLOSE: logger.Debug("COM_STMT_CLOSE packet", zap.Any("Type", payloadType)) pkt, err := preparedstmt.DecoderStmtClose(ctx, payload) if err != nil { return parsedPacket, fmt.Errorf("failed to decode COM_STMT_CLOSE packet: %w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_STMT_CLOSE), clientConn, mysql.COM_STMT_CLOSE, decodeCtx) logger.Debug("COM_STMT_CLOSE decoded", zap.Any("parsed packet", parsedPacket)) case payloadType == mysql.COM_STMT_RESET: logger.Debug("COM_STMT_RESET packet", zap.Any("Type", payloadType)) pkt, err := preparedstmt.DecodeStmtReset(ctx, payload) if err != nil { return parsedPacket, fmt.Errorf("failed to decode COM_STMT_RESET packet: %w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_STMT_RESET), clientConn, mysql.COM_STMT_RESET, decodeCtx) logger.Debug("COM_STMT_RESET decoded", zap.Any("parsed packet", parsedPacket)) case payloadType == mysql.COM_STMT_SEND_LONG
------------------

--- Chunk 19---
Function decodePacket (end): _DATA: logger.Debug("COM_STMT_SEND_LONG_DATA packet", zap.Any("Type", payloadType)) pkt, err := preparedstmt.DecodeStmtSendLongData(ctx, payload) if err != nil { return parsedPacket, fmt.Errorf("failed to decode COM_STMT_SEND_LONG_DATA packet: %w", err) } setPacketInfo(ctx, parsedPacket, pkt, mysql.CommandStatusToString(mysql.COM_STMT_SEND_LONG_DATA), clientConn, mysql.COM_STMT_SEND_LONG_DATA, decodeCtx) logger.Debug("COM_STMT_SEND_LONG_DATA decoded", zap.Any("parsed packet", parsedPacket)) default: logger.Warn("Unknown packet type", zap.String("PacketType", fmt.Sprintf("%#x", payloadType)), zap.Any("payload", payload), zap.Any("last operation", lastOp)) setPacketInfo(ctx, parsedPacket, itgUtils.EncodeBase64(payload), fmt.Sprintf("%#x", payloadType), clientConn, RESET, decodeCtx) } return parsedPacket, nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/encode.go---

--- Chunk 1---
Function EncodeToBinary (start): func EncodeToBinary(ctx context.Context, logger *zap.Logger, packet *mysql.PacketBundle, clientConn net.Conn, decodeCtx *DecodeContext) ([]byte, error) { var data []byte var err error //Get the server greeting from the decode context serverGreeting, ok := decodeCtx.ServerGreetings.Load(clientConn) if !ok { return nil, fmt.Errorf("server greeting not found for connection %s", clientConn.RemoteAddr().String()) } switch packet.Message.(type) { // generic response packets case *mysql.EOFPacket: pkt, ok := packet.Message.(*mysql.EOFPacket) if !ok { return nil, fmt.Errorf("expected EOFPacket, got %T", packet.Message) } data, err = phase.EncodeEOF(ctx, pkt, serverGreeting.CapabilityFlags) if err != nil { return nil, fmt.Errorf("error encoding EOF packet: %v", err) } decodeCtx.LastOp.Store(clientConn, mysql.EOF) case *mysql.ERRPacket: pkt, ok := packet.Message.(*mysql.ERRPacket) if !ok { return nil, fmt.Errorf("expected ERRPacket, got
------------------

--- Chunk 2---
Function EncodeToBinary (part 2): %T", packet.Message) } data, err = phase.EncodeErr(ctx, pkt, serverGreeting.CapabilityFlags) if err != nil { return nil, fmt.Errorf("error encoding ERR packet: %v", err) } decodeCtx.LastOp.Store(clientConn, mysql.ERR) case *mysql.OKPacket: pkt, ok := packet.Message.(*mysql.OKPacket) if !ok { return nil, fmt.Errorf("expected OKPacket, got %T", packet.Message) } data, err = phase.EncodeOk(ctx, pkt, serverGreeting.CapabilityFlags) if err != nil { return nil, fmt.Errorf("error encoding OK packet: %v", err) } decodeCtx.LastOp.Store(clientConn, mysql.OK) // connection phase packets case *mysql.AuthMoreDataPacket: pkt, ok := packet.Message.(*mysql.AuthMoreDataPacket) if !ok { return nil, fmt.Errorf("expected AuthMoreDataPacket, got %T", packet.Message) } data, err = conn.EncodeAuthMoreData(ctx, pkt) if err != nil { return nil, fmt.Errorf("error encoding
------------------

--- Chunk 3---
Function EncodeToBinary (part 3): AuthMoreData packet: %v", err) } decodeCtx.LastOp.Store(clientConn, mysql.AuthMoreData) case *mysql.AuthSwitchRequestPacket: pkt, ok := packet.Message.(*mysql.AuthSwitchRequestPacket) if !ok { return nil, fmt.Errorf("expected AuthSwitchRequestPacket, got %T", packet.Message) } data, err = conn.EncodeAuthSwitchRequest(ctx, pkt) if err != nil { return nil, fmt.Errorf("error encoding AuthSwitchRequest packet: %v", err) } decodeCtx.LastOp.Store(clientConn, mysql.AuthSwitchRequest) case *mysql.HandshakeV10Packet: pkt, ok := packet.Message.(*mysql.HandshakeV10Packet) if !ok { return nil, fmt.Errorf("expected HandshakeV10Packet, got %T", packet.Message) } data, err = conn.EncodeHandshakeV10(ctx, logger, pkt) if err != nil { return nil, fmt.Errorf("error encoding HandshakeV10 packet: %v", err) } decodeCtx.LastOp.Store(clientConn, mysql.HandshakeV10) // command phase
------------------

--- Chunk 4---
Function EncodeToBinary (part 4): packets case *mysql.StmtPrepareOkPacket: pkt, ok := packet.Message.(*mysql.StmtPrepareOkPacket) if !ok { return nil, fmt.Errorf("expected StmtPrepareOkPacket, got %T", packet.Message) } data, err = preparedstmt.EncodePrepareOk(ctx, logger, pkt) if err != nil { return nil, fmt.Errorf("error encoding StmtPrepareOkPacket: %v", err) } decodeCtx.LastOp.Store(clientConn, mysql.COM_STMT_PREPARE) case *mysql.TextResultSet: pkt, ok := packet.Message.(*mysql.TextResultSet) if !ok { return nil, fmt.Errorf("expected TextResultSet, got %T", packet.Message) } data, err = query.EncodeTextResultSet(ctx, logger, pkt) if err != nil { return nil, fmt.Errorf("error encoding TextResultSet: %v", err) } case *mysql.BinaryProtocolResultSet: pkt, ok := packet.Message.(*mysql.BinaryProtocolResultSet) if !ok { return nil, fmt.Errorf("expected BinaryProtocolResultSet, got %T", packet.Message) } data, err = query
------------------

--- Chunk 5---
Function EncodeToBinary (end): .EncodeBinaryResultSet(ctx, logger, pkt) if err != nil { return nil, fmt.Errorf("error encoding BinaryProtocolResultSet: %v", err) } } // Encode the header for the packet header := make([]byte, 4) binary.LittleEndian.PutUint32(header, uint32(packet.Header.Header.PayloadLength)) header[3] = packet.Header.Header.SequenceID data = append(header, data...) logger.Debug("Encoded Packet", zap.String("packet", packet.Header.Type), zap.ByteString("data", data)) return data, nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/conn/authMoreDataPacket.go---

--- Chunk 1---
func DecodeAuthMoreData(_ context.Context, data []byte) (*mysql.AuthMoreDataPacket, error) { return &mysql.AuthMoreDataPacket{ StatusTag: data[0], Data: string(data[1:]), }, nil }
------------------

--- Chunk 2---
func EncodeAuthMoreData(_ context.Context, packet *mysql.AuthMoreDataPacket) ([]byte, error) { buf := new(bytes.Buffer) // Write StatusTag if err := buf.WriteByte(packet.StatusTag); err != nil { return nil, fmt.Errorf("failed to write StatusTag for AuthMoreData packet: %w", err) } switch packet.Data { case mysql.CachingSha2PasswordToString(mysql.PerformFullAuthentication): packet.Data = string(mysql.PerformFullAuthentication) case mysql.CachingSha2PasswordToString(mysql.FastAuthSuccess): packet.Data = string(mysql.FastAuthSuccess) } // Write Data if _, err := buf.WriteString(packet.Data); err != nil { return nil, fmt.Errorf("failed to write Data for authMoreData packet: %w", err) } return buf.Bytes(), nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/conn/authNextFactorPacket.go---

--- Chunk 1---
func DecodeAuthNextFactor(_ context.Context, data []byte) (*mysql.AuthNextFactorPacket, error) { packet := &mysql.AuthNextFactorPacket{ PacketType: data[0], } data, idx, err := utils.ReadNullTerminatedString(data[1:]) if err != nil { return nil, fmt.Errorf("malformed handshake response packet: missing null terminator for PluginName") } packet.PluginName = string(data) packet.PluginData = string(data[idx:]) return packet, nil }
------------------

--- Chunk 2---
func EncodeAuthNextFactor(_ context.Context, packet *mysql.AuthNextFactorPacket) ([]byte, error) { buf := new(bytes.Buffer) // Write PacketType if err := buf.WriteByte(packet.PacketType); err != nil { return nil, errors.New("failed to write PacketType") } // Write PluginName followed by a null terminator if _, err := buf.WriteString(packet.PluginName); err != nil { return nil, errors.New("failed to write PluginName for AuthNextFactor packet") } if err := buf.WriteByte(0x00); err != nil { return nil, errors.New("failed to write null terminator for PluginName for AuthNextFactor packet") } // Write PluginData if _, err := buf.WriteString(packet.PluginData); err != nil { return nil, errors.New("failed to write PluginData for AuthNextFactor packet") } return buf.Bytes(), nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/conn/authSwitchRequestPacket.go---

--- Chunk 1---
func DecodeAuthSwitchRequest(_ context.Context, data []byte) (*mysql.AuthSwitchRequestPacket, error) { packet := &mysql.AuthSwitchRequestPacket{ StatusTag: data[0], } // Splitting data by null byte to get plugin name and auth data parts := bytes.SplitN(data[1:], []byte{0x00}, 2) packet.PluginName = string(parts[0]) if len(parts) > 1 { packet.PluginData = base64.RawStdEncoding.EncodeToString(parts[1]) } return packet, nil }
------------------

--- Chunk 2---
func EncodeAuthSwitchRequest(_ context.Context, packet *mysql.AuthSwitchRequestPacket) ([]byte, error) { buf := new(bytes.Buffer) // Write StatusTag if err := buf.WriteByte(packet.StatusTag); err != nil { return nil, errors.New("failed to write StatusTag") } // Write PluginName followed by a null terminator if _, err := buf.WriteString(packet.PluginName); err != nil { return nil, errors.New("failed to write PluginName for AuthSwitchRequest packet") } if err := buf.WriteByte(0x00); err != nil { return nil, errors.New("failed to write null terminator for PluginName for AuthSwitchRequest packet") } pluginData, err := base64.RawStdEncoding.DecodeString(packet.PluginData) if err != nil { return nil, errors.New("failed to decode PluginData for AuthSwitchRequest packet") } // Write PluginData if _, err := buf.WriteString(string(pluginData)); err != nil { return nil, errors.New("failed to write PluginData for AuthSwitchRequest packet") } return buf.Bytes(), nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/conn/authSwitchResponsePacket.go---

--- Chunk 1---
func DecodeAuthSwitchResponse(_ context.Context, data []byte) (*mysql.AuthSwitchResponsePacket, error) { return &mysql.AuthSwitchResponsePacket{ Data: base64.StdEncoding.EncodeToString(data), }, nil }
------------------

--- Chunk 2---
func EncodeAuthSwitchResponse(_ context.Context, packet *mysql.AuthSwitchResponsePacket) ([]byte, error) { buf := new(bytes.Buffer) // Write Data if _, err := buf.WriteString(packet.Data); err != nil { return nil, errors.New("failed to write Data for AuthSwitchResponse packet") } return buf.Bytes(), nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/conn/handshakeResponse41Packet.go---

--- Chunk 1---
Function DecodeHandshakeResponse (start): func DecodeHandshakeResponse(_ context.Context, logger *zap.Logger, data []byte) (interface{}, error) { if len(data) < 32 { return nil, errors.New("handshake response packet too short") } origData := data packet := &mysql.HandshakeResponse41Packet{} packet.CapabilityFlags = binary.LittleEndian.Uint32(data[:4]) data = data[4:] if packet.CapabilityFlags&mysql.CLIENT_PROTOCOL_41 == 0 { return nil, errors.New("CLIENT_PROTOCOL_41 compatible client is required") } packet.MaxPacketSize = binary.LittleEndian.Uint32(data[:4]) data = data[4:] packet.CharacterSet = data[0] data = data[1:] copy(packet.Filler[:], data[:23]) data = data[23:] // Check if it is a SSL Request Packet if len(origData) == (4 + 4 + 1 + 23) { if packet.CapabilityFlags&mysql.CLIENT_SSL != 0 { logger.Debug("Client requested SSL connection") return &mysql.SSLRequestPacket{ CapabilityFlags: packet.CapabilityFlags, MaxPacketSize: packet.MaxPacketSize,
------------------

--- Chunk 2---
Function DecodeHandshakeResponse (part 2): CharacterSet: packet.CharacterSet, Filler: packet.Filler, }, nil } } idx := bytes.IndexByte(data, 0x00) if idx == -1 { return nil, errors.New("malformed handshake response packet: missing null terminator for Username") } packet.Username = string(data[:idx]) data = data[idx+1:] if packet.CapabilityFlags&mysql.CLIENT_PLUGIN_AUTH_LENENC_CLIENT_DATA != 0 { length := int(data[0]) data = data[1:] if length > 0 { if len(data) < length { return nil, errors.New("handshake response packet too short for auth data") } packet.AuthResponse = data[:length] data = data[length:] } } else { authLen := int(data[0]) data = data[2:] packet.AuthResponse = data[:authLen] } if packet.CapabilityFlags&mysql.CLIENT_CONNECT_WITH_DB != 0 { idx = bytes.IndexByte(data, 0x00) if idx != -1 { packet.Database = string(data[:idx]) data = data[idx+1:] } } if
------------------

--- Chunk 3---
Function DecodeHandshakeResponse (part 3): packet.CapabilityFlags&mysql.CLIENT_PLUGIN_AUTH != 0 { idx = bytes.IndexByte(data, 0x00) if idx == -1 { return nil, errors.New("malformed handshake response packet: missing null terminator for AuthPluginName") } packet.AuthPluginName = string(data[:idx]) data = data[idx+1:] } if packet.CapabilityFlags&mysql.CLIENT_CONNECT_ATTRS != 0 { if len(data) < 4 { return nil, errors.New("handshake response packet too short for connection attributes") } totalLength, isNull, n := utils.ReadLengthEncodedInteger(data) if isNull || n == 0 { return nil, errors.New("error decoding total length of connection attributes") } data = data[n:] attributesData := data[:totalLength] data = data[totalLength:] packet.ConnectionAttributes = make(map[string]string) for len(attributesData) > 0 { keyLength, isNull, n := utils.ReadLengthEncodedInteger(attributesData) if isNull { return nil, errors.New("malformed handshake response packet: null length encoded integer for connection attribute key")
------------------

--- Chunk 4---
Function DecodeHandshakeResponse (end): } attributesData = attributesData[n:] key := string(attributesData[:keyLength]) attributesData = attributesData[keyLength:] valueLength, isNull, n := utils.ReadLengthEncodedInteger(attributesData) if isNull { return nil, errors.New("malformed handshake response packet: null length encoded integer for connection attribute value") } attributesData = attributesData[n:] value := string(attributesData[:valueLength]) attributesData = attributesData[valueLength:] packet.ConnectionAttributes[key] = value } } if len(data) > 0 { if packet.CapabilityFlags&mysql.CLIENT_ZSTD_COMPRESSION_ALGORITHM != 0 { if len(data) < 1 { return nil, errors.New("handshake response packet too short for ZSTD compression level") } packet.ZstdCompressionLevel = data[0] } } return packet, nil }
------------------

--- Chunk 5---
Function EncodeHandshakeResponse41 (start): func EncodeHandshakeResponse41(_ context.Context, _ *zap.Logger, packet *mysql.HandshakeResponse41Packet) ([]byte, error) { buf := new(bytes.Buffer) // Write Capability Flags if err := binary.Write(buf, binary.LittleEndian, packet.CapabilityFlags); err != nil { return nil, fmt.Errorf("failed to write CapabilityFlags for HandshakeResponse41Packet: %w", err) } // Write Max Packet Size if err := binary.Write(buf, binary.LittleEndian, packet.MaxPacketSize); err != nil { return nil, fmt.Errorf("failed to write MaxPacketSize for HandshakeResponse41Packet: %w", err) } // Write Character Set if err := buf.WriteByte(packet.CharacterSet); err != nil { return nil, fmt.Errorf("failed to write CharacterSet for HandshakeResponse41Packet: %w", err) } // Write Filler if _, err := buf.Write(packet.Filler[:]); err != nil { return nil, fmt.Errorf("failed to write Filler for HandshakeResponse41Packet: %w", err) } // Write Username if _, err := buf.WriteString(packet.Username); err != nil { return
------------------

--- Chunk 6---
Function EncodeHandshakeResponse41 (part 2): nil, fmt.Errorf("failed to write Username for HandshakeResponse41Packet: %w", err) } if err := buf.WriteByte(0x00); err != nil { return nil, fmt.Errorf("failed to write null terminator for Username for HandshakeResponse41Packet: %w", err) } // Write Auth Response if packet.CapabilityFlags&mysql.CLIENT_PLUGIN_AUTH_LENENC_CLIENT_DATA != 0 { if err := buf.WriteByte(byte(len(packet.AuthResponse))); err != nil { return nil, fmt.Errorf("failed to write length of AuthResponse for HandshakeResponse41Packet: %w", err) } if _, err := buf.Write(packet.AuthResponse); err != nil { return nil, fmt.Errorf("failed to write AuthResponse for HandshakeResponse41Packet: %w", err) } } else { if err := buf.WriteByte(byte(len(packet.AuthResponse))); err != nil { return nil, fmt.Errorf("failed to write length of AuthResponse for HandshakeResponse41Packet: %w", err) } if _, err := buf.Write(packet.AuthResponse); err != nil { return nil, fmt.Errorf("failed to write AuthResponse for HandshakeResponse
------------------

--- Chunk 7---
Function EncodeHandshakeResponse41 (part 3): 41Packet: %w", err) } } // Write Database if packet.CapabilityFlags&mysql.CLIENT_CONNECT_WITH_DB != 0 { if _, err := buf.WriteString(packet.Database); err != nil { return nil, fmt.Errorf("failed to write Database for HandshakeResponse41Packet: %w", err) } if err := buf.WriteByte(0x00); err != nil { return nil, fmt.Errorf("failed to write null terminator for Database for HandshakeResponse41Packet: %w", err) } } // Write Auth Plugin Name if packet.CapabilityFlags&mysql.CLIENT_PLUGIN_AUTH != 0 { if _, err := buf.WriteString(packet.AuthPluginName); err != nil { return nil, fmt.Errorf("failed to write AuthPluginName for HandshakeResponse41Packet: %w", err) } if err := buf.WriteByte(0x00); err != nil { return nil, fmt.Errorf("failed to write null terminator for AuthPluginName for HandshakeResponse41Packet: %w", err) } } // Write Connection Attributes if packet.CapabilityFlags&mysql.CLIENT_CONNECT_ATTRS != 0 { totalLength
------------------

--- Chunk 8---
Function EncodeHandshakeResponse41 (part 4): := 0 for key, value := range packet.ConnectionAttributes { totalLength += len(key) + len(value) + 2 // 2 bytes for length-encoded integer prefixes } if err := utils.WriteLengthEncodedInteger(buf, uint64(totalLength)); err != nil { return nil, fmt.Errorf("failed to write total length of ConnectionAttributes for HandshakeResponse41Packet: %w", err) } for key, value := range packet.ConnectionAttributes { if err := utils.WriteLengthEncodedString(buf, key); err != nil { return nil, fmt.Errorf("failed to write ConnectionAttribute key for HandshakeResponse41Packet: %w", err) } if err := utils.WriteLengthEncodedString(buf, value); err != nil { return nil, fmt.Errorf("failed to write ConnectionAttribute value for HandshakeResponse41Packet: %w", err) } } } // Write Zstd Compression Level if packet.CapabilityFlags&mysql.CLIENT_ZSTD_COMPRESSION_ALGORITHM != 0 { if err := buf.WriteByte(packet.ZstdCompressionLevel); err != nil { return nil, fmt.Errorf("failed to write ZstdCompressionLevel for Hand
------------------

--- Chunk 9---
Function EncodeHandshakeResponse41 (end): shakeResponse41Packet: %w", err) } } return buf.Bytes(), nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/conn/handshakeV10Packet.go---

--- Chunk 1---
Function DecodeHandshakeV10 (start): func DecodeHandshakeV10(_ context.Context, _ *zap.Logger, data []byte) (*mysql.HandshakeV10Packet, error) { if len(data) < 4 { return nil, fmt.Errorf("handshake packet too short") } packet := &mysql.HandshakeV10Packet{} packet.ProtocolVersion = data[0] idx := bytes.IndexByte(data[1:], 0x00) if idx == -1 { return nil, fmt.Errorf("malformed handshake packet: missing null terminator for ServerVersion") } packet.ServerVersion = string(data[1 : 1+idx]) data = data[1+idx+1:] if len(data) < 4 { return nil, fmt.Errorf("handshake packet too short for ConnectionID") } packet.ConnectionID = binary.LittleEndian.Uint32(data[:4]) data = data[4:] if len(data) < 9 { // 8 bytes of AuthPluginData + 1 byte filler return nil, fmt.Errorf("handshake packet too short for AuthPluginData") } packet.AuthPluginData = append([]byte{}, data[:8]...) packet.Filler = data[8] data = data[9:] // Skip 8 bytes
------------------

--- Chunk 2---
Function DecodeHandshakeV10 (part 2): of AuthPluginData and 1 byte filler if len(data) < 5 { // Capability flags (2 bytes), character set (1 byte), status flags (2 bytes) return nil, fmt.Errorf("handshake packet too short for flags") } capabilityFlagsLower := binary.LittleEndian.Uint16(data[:2]) data = data[2:] packet.CharacterSet = data[0] data = data[1:] packet.StatusFlags = binary.LittleEndian.Uint16(data[:2]) data = data[2:] capabilityFlagsUpper := binary.LittleEndian.Uint16(data[:2]) data = data[2:] packet.CapabilityFlags = uint32(capabilityFlagsLower) | uint32(capabilityFlagsUpper)<<16 var authPluginDataLen int packet.CapabilityFlags = uint32(capabilityFlagsLower) | uint32(capabilityFlagsUpper)<<16 if packet.CapabilityFlags&mysql.CLIENT_PLUGIN_AUTH != 0 { authPluginDataLen = int(data[0]) data = data[1:] // Skip 1 byte AuthPluginDataLen } else { data = data[1:] // constant 0x00 } data = data[10:] // Skip 10 bytes
------------------

--- Chunk 3---
Function DecodeHandshakeV10 (end): reserved (all 0s) if authPluginDataLen > 8 { lenToRead := min(authPluginDataLen-8, len(data)) packet.AuthPluginData = append(packet.AuthPluginData, data[:lenToRead]...) data = data[lenToRead:] } if len(data) == 0 { return nil, fmt.Errorf("handshake packet too short for AuthPluginName") } if packet.CapabilityFlags&mysql.CLIENT_PLUGIN_AUTH != 0 { idx = bytes.IndexByte(data, 0x00) if idx == -1 { return nil, fmt.Errorf("malformed handshake packet: missing null terminator for AuthPluginName") } packet.AuthPluginName = string(data[:idx]) } return packet, nil }
------------------

--- Chunk 4---
Function EncodeHandshakeV10 (start): func EncodeHandshakeV10(_ context.Context, _ *zap.Logger, packet *mysql.HandshakeV10Packet) ([]byte, error) { buf := new(bytes.Buffer) // Protocol version buf.WriteByte(packet.ProtocolVersion) // Server version buf.WriteString(packet.ServerVersion) buf.WriteByte(0x00) // Null terminator // Connection ID if err := binary.Write(buf, binary.LittleEndian, packet.ConnectionID); err != nil { return nil, err } // Auth-plugin-data-part-1 (first 8 bytes) if len(packet.AuthPluginData) < 8 { return nil, errors.New("auth plugin data too short") } buf.Write(packet.AuthPluginData[:8]) // Filler buf.WriteByte(packet.Filler) // Capability flags (lower 2 bytes) if err := binary.Write(buf, binary.LittleEndian, uint16(packet.CapabilityFlags&0xFFFF)); err != nil { return nil, err } // Character set buf.WriteByte(packet.CharacterSet) // Status flags if err := binary.Write(buf, binary.LittleEndian, packet.StatusFlags); err != nil { return nil, err } // Capability flags (upper
------------------

--- Chunk 5---
Function EncodeHandshakeV10 (end): 2 bytes) if err := binary.Write(buf, binary.LittleEndian, uint16((packet.CapabilityFlags>>16)&0xFFFF)); err != nil { return nil, err } // Length of auth-plugin-data if packet.CapabilityFlags&mysql.CLIENT_PLUGIN_AUTH != 0 && len(packet.AuthPluginData) >= 21 { buf.WriteByte(byte(len(packet.AuthPluginData))) // Length of entire auth plugin data } else { buf.WriteByte(0x00) } // Reserved (10 zero bytes) buf.Write(make([]byte, 10)) // Auth-plugin-data-part-2 (remaining auth data) if packet.CapabilityFlags&mysql.CLIENT_PLUGIN_AUTH != 0 && len(packet.AuthPluginData) > 8 { buf.Write(packet.AuthPluginData[8:]) // Write all remaining bytes of auth plugin data } // Auth-plugin name if packet.CapabilityFlags&mysql.CLIENT_PLUGIN_AUTH != 0 { buf.WriteString(packet.AuthPluginName) buf.WriteByte(0x00) // Null terminator } return buf.Bytes(), nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/generic.go---

--- Chunk 1---
func DecodeEOF(_ context.Context, data []byte, capabilities uint32) (*mysql.EOFPacket, error) { if len(data) > 5 { return nil, fmt.Errorf("EOF packet too long for EOF") } packet := &mysql.EOFPacket{ Header: data[0], } if capabilities&uint32(mysql.CLIENT_PROTOCOL_41) > 0 { packet.Warnings = binary.LittleEndian.Uint16(data[1:3]) packet.StatusFlags = binary.LittleEndian.Uint16(data[3:5]) } return packet, nil }
------------------

--- Chunk 2---
func EncodeEOF(_ context.Context, packet *mysql.EOFPacket, capabilities uint32) ([]byte, error) { buf := new(bytes.Buffer) // Write the header if err := buf.WriteByte(packet.Header); err != nil { return nil, fmt.Errorf("failed to write header: %w", err) } // Write the warnings and status flags if CLIENT_PROTOCOL_41 is set if capabilities&uint32(mysql.CLIENT_PROTOCOL_41) > 0 { if err := binary.Write(buf, binary.LittleEndian, packet.Warnings); err != nil { return nil, fmt.Errorf("failed to write warnings for eof packet: %w", err) } if err := binary.Write(buf, binary.LittleEndian, packet.StatusFlags); err != nil { return nil, fmt.Errorf("failed to write status flags for eof packet: %w", err) } } return buf.Bytes(), nil }
------------------

--- Chunk 3---
func DecodeERR(_ context.Context, data []byte, capabilities uint32) (*mysql.ERRPacket, error) { if len(data) < 9 { return nil, fmt.Errorf("ERR packet too short") } packet := &mysql.ERRPacket{ Header: data[0], } pos := 1 packet.ErrorCode = binary.LittleEndian.Uint16(data[pos : pos+2]) pos += 2 if capabilities&uint32(mysql.CLIENT_PROTOCOL_41) > 0 { if data[pos] != '#' { return nil, fmt.Errorf("invalid SQL state marker: %c", data[pos]) } packet.SQLStateMarker = string(data[pos]) pos++ packet.SQLState = string(data[pos : pos+5]) pos += 5 } packet.ErrorMessage = string(data[pos:]) return packet, nil }
------------------

--- Chunk 4---
Function EncodeErr (start): func EncodeErr(_ context.Context, packet *mysql.ERRPacket, capabilities uint32) ([]byte, error) { buf := new(bytes.Buffer) // Write the header if err := buf.WriteByte(packet.Header); err != nil { return nil, fmt.Errorf("failed to write header: %w", err) } // Write the error code if err := binary.Write(buf, binary.LittleEndian, packet.ErrorCode); err != nil { return nil, fmt.Errorf("failed to write error code: %w", err) } // Write the SQL state marker and SQL state if CLIENT_PROTOCOL_41 is set if capabilities&uint32(mysql.CLIENT_PROTOCOL_41) > 0 { if len(packet.SQLStateMarker) != 1 || len(packet.SQLState) != 5 { return nil, fmt.Errorf("invalid SQL state marker or SQL state length") } if err := buf.WriteByte(packet.SQLStateMarker[0]); err != nil { return nil, fmt.Errorf("failed to write SQL state marker: %w", err) } if _, err := buf.WriteString(packet.SQLState); err != nil { return nil, fmt.Errorf("failed to write SQL state: %w", err
------------------

--- Chunk 5---
Function EncodeErr (end): ) } } // Write the error message if _, err := buf.WriteString(packet.ErrorMessage); err != nil { return nil, fmt.Errorf("failed to write error message: %w", err) } return buf.Bytes(), nil }
------------------

--- Chunk 6---
func DecodeOk(_ context.Context, data []byte, capabilities uint32) (*mysql.OKPacket, error) { if len(data) < 7 { return nil, fmt.Errorf("OK packet too short") } packet := &mysql.OKPacket{ Header: data[0], } var n int var pos = 1 packet.AffectedRows, _, n = utils.ReadLengthEncodedInteger(data[pos:]) pos += n packet.LastInsertID, _, n = utils.ReadLengthEncodedInteger(data[pos:]) pos += n if capabilities&uint32(mysql.CLIENT_PROTOCOL_41) > 0 { packet.StatusFlags = binary.LittleEndian.Uint16(data[pos:]) pos += 2 packet.Warnings = binary.LittleEndian.Uint16(data[pos:]) pos += 2 } else if capabilities&uint32(mysql.CLIENT_TRANSACTIONS) > 0 { packet.StatusFlags = binary.LittleEndian.Uint16(data[pos:]) pos += 2 } // new ok package will check CLIENT_SESSION_TRACK too, but it is not supported in this version if pos < len(data) { packet.Info = string(data[pos:]) } return packet, nil }
------------------

--- Chunk 7---
Function EncodeOk (start): func EncodeOk(_ context.Context, packet *mysql.OKPacket, capabilities uint32) ([]byte, error) { buf := new(bytes.Buffer) // Write Header if err := buf.WriteByte(packet.Header); err != nil { return nil, fmt.Errorf("failed to write Header: %w", err) } // Write Affected Rows if err := utils.WriteLengthEncodedInteger(buf, packet.AffectedRows); err != nil { return nil, fmt.Errorf("failed to write AffectedRows for OK packet: %w", err) } // Write Last Insert ID if err := utils.WriteLengthEncodedInteger(buf, packet.LastInsertID); err != nil { return nil, fmt.Errorf("failed to write LastInsertID for OK packet: %w", err) } // Write Status Flags and Warnings if capabilities&uint32(mysql.CLIENT_PROTOCOL_41) > 0 { if err := binary.Write(buf, binary.LittleEndian, packet.StatusFlags); err != nil { return nil, fmt.Errorf("failed to write StatusFlags for OK packet: %w", err) } if err := binary.Write(buf, binary.LittleEndian, packet.Warnings); err != nil {
------------------

--- Chunk 8---
Function EncodeOk (end): return nil, fmt.Errorf("failed to write Warnings for OK packet: %w", err) } } else if capabilities&uint32(mysql.CLIENT_TRANSACTIONS) > 0 { if err := binary.Write(buf, binary.LittleEndian, packet.StatusFlags); err != nil { return nil, fmt.Errorf("failed to write StatusFlags for OK packet: %w", err) } } // Write Info if packet.Info != "" { if _, err := buf.WriteString(packet.Info); err != nil { return nil, fmt.Errorf("failed to write Info for OK packet: %w", err) } } return buf.Bytes(), nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/ResultSetPacket.go---

--- Chunk 1---
func DecodeResultSetMetadata(ctx context.Context, logger *zap.Logger, data []byte, rowType RowType) (interface{}, error) { // Decode the column count (No need to get the header as well as it is already decoded by the caller function) colCount, err := rowscols.DecodeColumnCount(ctx, logger, data) if err != nil { return nil, fmt.Errorf("failed to decode column count packet: %w", err) } switch rowType { case Binary: return &mysql.BinaryProtocolResultSet{ ColumnCount: colCount, }, nil case Text: return &mysql.TextResultSet{ ColumnCount: colCount, }, nil } return nil, nil }
------------------

--- Chunk 2---
Function EncodeTextResultSet (start): func EncodeTextResultSet(ctx context.Context, logger *zap.Logger, resultSet *mysql.TextResultSet) ([]byte, error) { buf := new(bytes.Buffer) // Encode the column count if err := utils.WriteLengthEncodedInteger(buf, resultSet.ColumnCount); err != nil { return nil, fmt.Errorf("failed to write column count for text resultset: %w", err) } // Encode the column definition packets for _, column := range resultSet.Columns { columnBytes, err := rowscols.EncodeColumn(ctx, logger, column) if err != nil { return nil, fmt.Errorf("failed to encode column for text resultset: %w", err) } if _, err := buf.Write(columnBytes); err != nil { return nil, fmt.Errorf("failed to write column for text resultset: %w", err) } } // Write the EOF packet after columns if present if len(resultSet.EOFAfterColumns) != 0 { if _, err := buf.Write(resultSet.EOFAfterColumns); err != nil { return nil, fmt.Errorf("failed to write EOF packet after columns for text resultset: %w", err) } } // Encode
------------------

--- Chunk 3---
Function EncodeTextResultSet (end): each row data packet for _, row := range resultSet.Rows { rowBytes, err := rowscols.EncodeTextRow(ctx, logger, row, resultSet.Columns) if err != nil { return nil, fmt.Errorf("failed to encode row for text resultset: %w", err) } if _, err := buf.Write(rowBytes); err != nil { return nil, fmt.Errorf("failed to write row for text resultset: %w", err) } } // Write the final EOF packet if present if resultSet.FinalResponse != nil && utils.IsEOFPacket(resultSet.FinalResponse.Data) { if _, err := buf.Write(resultSet.FinalResponse.Data); err != nil { return nil, fmt.Errorf("failed to write final EOF packet: %w", err) } } return buf.Bytes(), nil }
------------------

--- Chunk 4---
Function EncodeBinaryResultSet (start): func EncodeBinaryResultSet(ctx context.Context, logger *zap.Logger, resultSet *mysql.BinaryProtocolResultSet) ([]byte, error) { buf := new(bytes.Buffer) // Encode the column count if err := utils.WriteLengthEncodedInteger(buf, resultSet.ColumnCount); err != nil { return nil, fmt.Errorf("failed to write column count: %w", err) } // Encode the column definition packets for _, column := range resultSet.Columns { columnBytes, err := rowscols.EncodeColumn(ctx, logger, column) if err != nil { return nil, fmt.Errorf("failed to encode column: %w", err) } if _, err := buf.Write(columnBytes); err != nil { return nil, fmt.Errorf("failed to write column: %w", err) } } // Write the EOF packet after columns if _, err := buf.Write(resultSet.EOFAfterColumns); err != nil { return nil, fmt.Errorf("failed to write EOF packet after columns: %w", err) } // Encode each row data packet for _, row := range resultSet.Rows { rowBytes, err := rowscols.EncodeBinaryRow(ctx, logger, row, resultSet.Columns)
------------------

--- Chunk 5---
Function EncodeBinaryResultSet (end): if err != nil { return nil, fmt.Errorf("failed to encode row: %w", err) } if _, err := buf.Write(rowBytes); err != nil { return nil, fmt.Errorf("failed to write row: %w", err) } } // Write the final EOF packet if present if resultSet.FinalResponse != nil && utils.IsEOFPacket(resultSet.FinalResponse.Data) { if _, err := buf.Write(resultSet.FinalResponse.Data); err != nil { return nil, fmt.Errorf("failed to write final EOF packet: %w", err) } } return buf.Bytes(), nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/preparedstmt/StmtPrepareOkPacket.go---

--- Chunk 1---
func DecodePrepareOk(_ context.Context, _ *zap.Logger, data []byte) (*mysql.StmtPrepareOkPacket, error) { if len(data) < 12 { return nil, errors.New("data length is not enough for COM_STMT_PREPARE_OK") } offset := 0 response := &mysql.StmtPrepareOkPacket{} response.Status = data[offset] offset++ response.StatementID = binary.LittleEndian.Uint32(data[offset : offset+4]) offset += 4 response.NumColumns = binary.LittleEndian.Uint16(data[offset : offset+2]) offset += 2 response.NumParams = binary.LittleEndian.Uint16(data[offset : offset+2]) offset += 2 //data[10] is reserved byte ([00] filler) response.Filler = data[offset] offset++ response.WarningCount = binary.LittleEndian.Uint16(data[offset : offset+2]) // offset += 2 return response, nil }
------------------

--- Chunk 2---
Function EncodePrepareOk (start): func EncodePrepareOk(ctx context.Context, logger *zap.Logger, packet *mysql.StmtPrepareOkPacket) ([]byte, error) { buf := new(bytes.Buffer) // Encode the Prepare OK packet prepareOkBytes, err := EncodePreparedStmtResponse(ctx, logger, packet) if err != nil { return nil, fmt.Errorf("failed to encode StmtPrepareOkPacket: %w", err) } if _, err := buf.Write(prepareOkBytes); err != nil { return nil, fmt.Errorf("failed to write StmtPrepareOkPacket: %w", err) } // Encode parameter definitions if present for _, paramDef := range packet.ParamDefs { paramBytes, err := rowscols.EncodeColumn(ctx, logger, paramDef) if err != nil { return nil, fmt.Errorf("failed to encode parameter definition: %w", err) } if _, err := buf.Write(paramBytes); err != nil { return nil, fmt.Errorf("failed to write parameter definition: %w", err) } } // Write EOF packet after parameter definitions if packet.NumParams > 0 { if _, err := buf.Write(packet.EOFAfterParamDefs); err
------------------

--- Chunk 3---
Function EncodePrepareOk (end): != nil { return nil, fmt.Errorf("failed to write EOF packet after parameter definitions: %w", err) } } // Encode column definitions if present for _, columnDef := range packet.ColumnDefs { columnBytes, err := rowscols.EncodeColumn(ctx, logger, columnDef) if err != nil { return nil, fmt.Errorf("failed to encode column definition: %w", err) } if _, err := buf.Write(columnBytes); err != nil { return nil, fmt.Errorf("failed to write column definition: %w", err) } } // Write EOF packet after column definitions if packet.NumColumns > 0 { if _, err := buf.Write(packet.EOFAfterColumnDefs); err != nil { return nil, fmt.Errorf("failed to write EOF packet after column definitions: %w", err) } } return buf.Bytes(), nil }
------------------

--- Chunk 4---
Function EncodePreparedStmtResponse (start): func EncodePreparedStmtResponse(_ context.Context, _ *zap.Logger, packet *mysql.StmtPrepareOkPacket) ([]byte, error) { buf := new(bytes.Buffer) // Write Status if err := buf.WriteByte(packet.Status); err != nil { return nil, fmt.Errorf("failed to write Status: %w", err) } // Write Statement ID if err := binary.Write(buf, binary.LittleEndian, packet.StatementID); err != nil { return nil, fmt.Errorf("failed to write StatementID: %w", err) } // Write Number of Columns if err := binary.Write(buf, binary.LittleEndian, packet.NumColumns); err != nil { return nil, fmt.Errorf("failed to write NumColumns: %w", err) } // Write Number of Parameters if err := binary.Write(buf, binary.LittleEndian, packet.NumParams); err != nil { return nil, fmt.Errorf("failed to write NumParams: %w", err) } // Write Filler if err := buf.WriteByte(packet.Filler); err != nil { return nil, fmt.Errorf("failed to write Filler: %w", err) } // Write Warning Count
------------------

--- Chunk 5---
Function EncodePreparedStmtResponse (end): if err := binary.Write(buf, binary.LittleEndian, packet.WarningCount); err != nil { return nil, fmt.Errorf("failed to write WarningCount: %w", err) } return buf.Bytes(), nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/preparedstmt/stmtClosePacket.go---

--- Chunk 1---
func DecoderStmtClose(_ context.Context, data []byte) (*mysql.StmtClosePacket, error) { if len(data) != 5 { return nil, errors.New("invalid packet for COM_STMT_CLOSE") } packet := &mysql.StmtClosePacket{ Status: data[0], StatementID: binary.LittleEndian.Uint32(data[1:5]), } return packet, nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/preparedstmt/stmtExecutePacket.go---

--- Chunk 1---
Function DecodeStmtExecute (start): func DecodeStmtExecute(_ context.Context, _ *zap.Logger, data []byte, preparedStmts map[uint32]*mysql.StmtPrepareOkPacket) (*mysql.StmtExecutePacket, error) { if len(data) < 10 { return &mysql.StmtExecutePacket{}, fmt.Errorf("packet length too short for COM_STMT_EXECUTE") } pos := 0 packet := &mysql.StmtExecutePacket{} // Read Status if pos+1 > len(data) { return nil, io.ErrUnexpectedEOF } //data[0] is COM_STMT_EXECUTE (0x17) packet.Status = data[pos] pos++ // Read StatementID if pos+4 > len(data) { return nil, io.ErrUnexpectedEOF } packet.StatementID = binary.LittleEndian.Uint32(data[pos : pos+4]) pos += 4 numParams, ok := preparedStmts[packet.StatementID] if !ok && numParams == nil { return nil, fmt.Errorf("prepared statement with ID %d not found", packet.StatementID) } packet.ParameterCount = int(numParams.NumParams) // Read Flags if pos+1 > len(data) { return nil, io
------------------

--- Chunk 2---
Function DecodeStmtExecute (part 2): .ErrUnexpectedEOF } packet.Flags = data[pos] pos++ // Read IterationCount if pos+4 > len(data) { return nil, io.ErrUnexpectedEOF } packet.IterationCount = binary.LittleEndian.Uint32(data[pos : pos+4]) pos += 4 if packet.ParameterCount <= 0 { return packet, nil } // Read Parameters only if there are any // Read NULL bitmap nullBitmapLength := (packet.ParameterCount + 7) / 8 if pos+nullBitmapLength > len(data) { return nil, io.ErrUnexpectedEOF } packet.NullBitmap = data[pos : pos+nullBitmapLength] pos += int(nullBitmapLength) // Read NewParamsBindFlag if pos+1 > len(data) { return nil, io.ErrUnexpectedEOF } packet.NewParamsBindFlag = data[pos] pos++ // Read Parameters if NewParamsBindFlag is set if packet.NewParamsBindFlag == 1 { packet.Parameters = make([]mysql.Parameter, packet.ParameterCount) for i := 0; i < packet.ParameterCount; i++ { if pos+2 > len(data) { return
------------------

--- Chunk 3---
Function DecodeStmtExecute (part 3): nil, io.ErrUnexpectedEOF } packet.Parameters[i].Type = binary.LittleEndian.Uint16(data[pos : pos+2]) packet.Parameters[i].Unsigned = (data[pos+1] & 0x80) != 0 // Check if the highest bit is set pos += 2 } } // Read Parameter Values for i := 0; i < packet.ParameterCount; i++ { if pos >= len(data) { return nil, io.ErrUnexpectedEOF } // Process Parameter based on its type param := &packet.Parameters[i] // Handle length-encoded values (only for types that require variable-length data) switch mysql.FieldType(param.Type) { case mysql.FieldTypeString, mysql.FieldTypeVarString, mysql.FieldTypeVarChar, mysql.FieldTypeBLOB, mysql.FieldTypeTinyBLOB, mysql.FieldTypeMediumBLOB, mysql.FieldTypeLongBLOB, mysql.FieldTypeJSON: // Read the length of the parameter value length, _, n := utils.ReadLengthEncodedInteger(data[pos:]) pos += n if pos+int(length) > len(data) { return nil, io.ErrUnexpected
------------------

--- Chunk 4---
Function DecodeStmtExecute (part 4): EOF } if intUtil.IsASCII(string(data[pos : pos+int(length)])) { param.Value = string(data[pos : pos+int(length)]) } else { param.Value = intUtil.EncodeBase64(data[pos : pos+int(length)]) } pos += int(length) case mysql.FieldTypeLong: if len(data[pos:]) < 4 { return nil, fmt.Errorf("malformed FieldTypeLong value") } if param.Unsigned { param.Value = uint32(binary.LittleEndian.Uint32(data[pos : pos+4])) } else { param.Value = int32(binary.LittleEndian.Uint32(data[pos : pos+4])) } pos += 4 case mysql.FieldTypeTiny: if len(data[pos:]) < 1 { return nil, fmt.Errorf("malformed FieldTypeTiny value") } if param.Unsigned { param.Value = uint8(data[pos]) } else { param.Value = int8(data[pos]) } pos += 1 case mysql.FieldTypeShort, mysql.FieldTypeYear: if len(data[pos:]) < 2 { return nil, fmt.Errorf
------------------

--- Chunk 5---
Function DecodeStmtExecute (part 5): ("malformed FieldTypeShort value") } if param.Unsigned { param.Value = uint16(binary.LittleEndian.Uint16(data[pos : pos+2])) } else { param.Value = int16(binary.LittleEndian.Uint16(data[pos : pos+2])) } pos += 2 case mysql.FieldTypeLongLong: if len(data[pos:]) < 8 { return nil, fmt.Errorf("malformed FieldTypeLongLong value") } if param.Unsigned { param.Value = uint64(binary.LittleEndian.Uint64(data[pos : pos+8])) } else { param.Value = int64(binary.LittleEndian.Uint64(data[pos : pos+8])) } pos += 8 case mysql.FieldTypeFloat: if len(data[pos:]) < 4 { return nil, fmt.Errorf("malformed FieldTypeFloat value") } param.Value = float32(binary.LittleEndian.Uint32(data[pos : pos+4])) pos += 4 case mysql.FieldTypeDouble: if len(data[pos:]) < 8 { return nil, fmt.Errorf("malformed FieldTypeDouble value") } param.Value =
------------------

--- Chunk 6---
Function DecodeStmtExecute (end): float64(binary.LittleEndian.Uint64(data[pos : pos+8])) pos += 8 case mysql.FieldTypeDate, mysql.FieldTypeNewDate: value, _, err := utils.ParseBinaryDate(data[pos:]) if err != nil { return nil, err } param.Value = value pos += len(param.Value.(string)) // Assuming date parsing returns a string case mysql.FieldTypeTimestamp, mysql.FieldTypeDateTime: value, _, err := utils.ParseBinaryDateTime(data[pos:]) if err != nil { return nil, err } param.Value = value pos += len(param.Value.(string)) // Assuming datetime parsing returns a string case mysql.FieldTypeTime: value, _, err := utils.ParseBinaryTime(data[pos:]) if err != nil { return nil, err } param.Value = value pos += len(param.Value.(string)) // Assuming time parsing returns a string default: return nil, fmt.Errorf("unsupported parameter type: %d", param.Type) } } return packet, nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/preparedstmt/stmtFetchPacket.go---

--- Chunk 1---
func DecodeStmtFetch(_ context.Context, _ *zap.Logger, data []byte) (*mysql.StmtFetchPacket, error) { if len(data) < 9 { return &mysql.StmtFetchPacket{}, errors.New("data too short for COM_STMT_FETCH") } packet := &mysql.StmtFetchPacket{ Status: data[0], } packet.StatementID = binary.LittleEndian.Uint32(data[1:5]) packet.NumRows = binary.LittleEndian.Uint32(data[5:9]) return packet, nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/preparedstmt/stmtPreparePacket.go---

--- Chunk 1---
func DecodeStmtPrepare(_ context.Context, data []byte) (*mysql.StmtPreparePacket, error) { packet := &mysql.StmtPreparePacket{ Command: data[0], } query := string(data[1:]) packet.Query = strings.ReplaceAll(query, "\t", "") return packet, nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/preparedstmt/stmtResetPacket.go---

--- Chunk 1---
func DecodeStmtReset(_ context.Context, data []byte) (*mysql.StmtResetPacket, error) { if len(data) != 5 { return nil, fmt.Errorf("invalid COM_STMT_RESET packet") } packet := &mysql.StmtResetPacket{ Status: data[0], StatementID: binary.LittleEndian.Uint32(data[1:5]), } return packet, nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/preparedstmt/stmtSendLongDataPacket.go---

--- Chunk 1---
func DecodeStmtSendLongData(_ context.Context, data []byte) (*mysql.StmtSendLongDataPacket, error) { if len(data) < 7 || data[0] != 0x18 { return &mysql.StmtSendLongDataPacket{}, fmt.Errorf("invalid COM_STMT_SEND_LONG_DATA packet") } packet := &mysql.StmtSendLongDataPacket{ Status: data[0], StatementID: binary.LittleEndian.Uint32(data[1:5]), ParameterID: binary.LittleEndian.Uint16(data[5:7]), Data: data[7:], } return packet, nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/queryPacket.go---

--- Chunk 1---
func DecodeQuery(_ context.Context, data []byte) (*mysql.QueryPacket, error) { if len(data) < 2 { return nil, fmt.Errorf("query packet too short") } packet := &mysql.QueryPacket{ Command: data[0], Query: replaceTabsWithSpaces(string(data[1:])), } return packet, nil }
------------------

--- Chunk 2---
func replaceTabsWithSpaces(query string) string { return strings.ReplaceAll(query, "\t", " ") }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/rowscols/binaryProtocolRowPacket.go---

--- Chunk 1---
Function DecodeBinaryRow (start): func DecodeBinaryRow(_ context.Context, _ *zap.Logger, data []byte, columns []*mysql.ColumnDefinition41) (*mysql.BinaryRow, int, error) { offset := 0 row := &mysql.BinaryRow{ Header: mysql.Header{ PayloadLength: utils.ReadUint24(data[offset : offset+3]), SequenceID: data[offset+3], }, } offset += 4 if data[offset] != 0x00 { return nil, offset, errors.New("malformed binary row packet") } row.OkAfterRow = true offset++ nullBitmapLen := (len(columns) + 7 + 2) / 8 nullBitmap := data[offset : offset+nullBitmapLen] row.RowNullBuffer = nullBitmap offset += nullBitmapLen for i, col := range columns { if isNull(nullBitmap, i) { // This Null doesn't progress the offset row.Values = append(row.Values, mysql.ColumnEntry{ Type: mysql.FieldType(col.Type), Name: col.Name, Value: nil, }) continue } res, n, err := readBinaryValue(data[offset:], col)
------------------

--- Chunk 2---
Function DecodeBinaryRow (end): if err != nil { return nil, offset, err } row.Values = append(row.Values, mysql.ColumnEntry{ Type: mysql.FieldType(col.Type), Name: col.Name, Value: res.value, Unsigned: res.isUnsigned, }) offset += n } return row, offset, nil }
------------------

--- Chunk 3---
func isNull(nullBitmap []byte, index int) bool { bytePos := (index + 2) / 8 bitPos := (index + 2) % 8 return nullBitmap[bytePos]&(1<<bitPos) != 0 }
------------------

--- Chunk 4---
Function readBinaryValue (start): func readBinaryValue(data []byte, col *mysql.ColumnDefinition41) (*binaryValueResult, int, error) { isUnsigned := col.Flags&mysql.UNSIGNED_FLAG != 0 res := &binaryValueResult{ isUnsigned: isUnsigned, } switch mysql.FieldType(col.Type) { case mysql.FieldTypeLong: if len(data) < 4 { return nil, 0, errors.New("malformed FieldTypeLong value") } if isUnsigned { res.value = uint32(binary.LittleEndian.Uint32(data[:4])) return res, 4, nil } res.value = int32(binary.LittleEndian.Uint32(data[:4])) return res, 4, nil case mysql.FieldTypeString, mysql.FieldTypeVarString, mysql.FieldTypeVarChar, mysql.FieldTypeBLOB, mysql.FieldTypeTinyBLOB, mysql.FieldTypeMediumBLOB, mysql.FieldTypeLongBLOB, mysql.FieldTypeJSON: value, _, n, err := utils.ReadLengthEncodedString(data) res.value = string(value) return res, n, err case mysql.FieldTypeTiny: if isUnsigned { res.value = uint8(data[0])
------------------

--- Chunk 5---
Function readBinaryValue (part 2): return res, 1, nil } res.value = int8(data[0]) return res, 1, nil case mysql.FieldTypeShort, mysql.FieldTypeYear: if len(data) < 2 { return nil, 0, errors.New("malformed FieldTypeShort value") } if isUnsigned { res.value = uint16(binary.LittleEndian.Uint16(data[:2])) return res, 2, nil } res.value = int16(binary.LittleEndian.Uint16(data[:2])) return res, 2, nil case mysql.FieldTypeLongLong: if len(data) < 8 { return nil, 0, errors.New("malformed FieldTypeLongLong value") } if isUnsigned { res.value = uint64(binary.LittleEndian.Uint64(data[:8])) return res, 8, nil } res.value = int64(binary.LittleEndian.Uint64(data[:8])) return res, 8, nil case mysql.FieldTypeFloat: if len(data) < 4 { return nil, 0, errors.New("malformed FieldTypeFloat value") }
------------------

--- Chunk 6---
Function readBinaryValue (end): res.value = float32(binary.LittleEndian.Uint32(data[:4])) return res, 4, nil case mysql.FieldTypeDouble: if len(data) < 8 { return nil, 0, errors.New("malformed FieldTypeDouble value") } res.value = float64(binary.LittleEndian.Uint64(data[:8])) return res, 8, nil case mysql.FieldTypeDate, mysql.FieldTypeNewDate: value, n, err := utils.ParseBinaryDate(data) res.value = value return res, n, err case mysql.FieldTypeTimestamp, mysql.FieldTypeDateTime: value, n, err := utils.ParseBinaryDateTime(data) res.value = value return res, n, err case mysql.FieldTypeTime: value, n, err := utils.ParseBinaryTime(data) res.value = value return res, n, err default: return nil, 0, fmt.Errorf("unsupported column type: %v", col.Type) } }
------------------

--- Chunk 7---
Function EncodeBinaryRow (start): func EncodeBinaryRow(_ context.Context, logger *zap.Logger, row *mysql.BinaryRow, columns []*mysql.ColumnDefinition41) ([]byte, error) { buf := new(bytes.Buffer) // Write the packet header if err := utils.WriteUint24(buf, row.Header.PayloadLength); err != nil { return nil, fmt.Errorf("failed to write PayloadLength: %w", err) } if err := buf.WriteByte(row.Header.SequenceID); err != nil { return nil, fmt.Errorf("failed to write SequenceID: %w", err) } // Write the row's OK byte if err := buf.WriteByte(0x00); err != nil { return nil, fmt.Errorf("failed to write OK byte: %w", err) } // Write the row's NULL bitmap if _, err := buf.Write(row.RowNullBuffer); err != nil { return nil, fmt.Errorf("failed to write NULL bitmap: %w", err) } // Write each column's value for i, col := range columns { logger.Debug("encoding column", zap.String("name", col.Name), zap.Any("value", row.Values[i].Value)) if isNull(row.RowNullBuffer, i
------------------

--- Chunk 8---
Function EncodeBinaryRow (part 2): ) { continue } columnEntry := row.Values[i] switch columnEntry.Type { case mysql.FieldTypeLong: var val any if columnEntry.Unsigned { val = uint32(columnEntry.Value.(int)) } else { val = int32(columnEntry.Value.(int)) } if err := binary.Write(buf, binary.LittleEndian, val); err != nil { return nil, fmt.Errorf("failed to write %T value: %w", val, err) } case mysql.FieldTypeString, mysql.FieldTypeVarString, mysql.FieldTypeVarChar, mysql.FieldTypeBLOB, mysql.FieldTypeTinyBLOB, mysql.FieldTypeMediumBLOB, mysql.FieldTypeLongBLOB, mysql.FieldTypeJSON: strValue, ok := columnEntry.Value.(string) if !ok { return nil, fmt.Errorf("invalid value type for string field") } if err := utils.WriteLengthEncodedString(buf, strValue); err != nil { return nil, fmt.Errorf("failed to write length-encoded string: %w", err) } case mysql.FieldTypeTiny: var val any if columnEntry.Unsigned
------------------

--- Chunk 9---
Function EncodeBinaryRow (part 3): { val = uint8(columnEntry.Value.(int)) } else { val = int8(columnEntry.Value.(int)) } if err := binary.Write(buf, binary.LittleEndian, val); err != nil { return nil, fmt.Errorf("failed to write %T value: %w", val, err) } case mysql.FieldTypeShort, mysql.FieldTypeYear: var val any if columnEntry.Unsigned { val = uint16(columnEntry.Value.(int)) } else { val = int16(columnEntry.Value.(int)) } if err := binary.Write(buf, binary.LittleEndian, val); err != nil { return nil, fmt.Errorf("failed to write int16 value: %w", err) } case mysql.FieldTypeLongLong: var val any if columnEntry.Unsigned { val = uint64(columnEntry.Value.(int)) } else { val = int64(columnEntry.Value.(int)) } if err := binary.Write(buf, binary.LittleEndian, val); err != nil { return nil, fmt.Errorf("failed to write %T value: %w", val
------------------

--- Chunk 10---
Function EncodeBinaryRow (part 4): , err) } case mysql.FieldTypeFloat: floatValue, ok := columnEntry.Value.(float32) if !ok { return nil, fmt.Errorf("invalid value type for float field") } if err := binary.Write(buf, binary.LittleEndian, floatValue); err != nil { return nil, fmt.Errorf("failed to write float32 value: %w", err) } case mysql.FieldTypeDouble: doubleValue, ok := columnEntry.Value.(float64) if !ok { return nil, fmt.Errorf("invalid value type for double field") } if err := binary.Write(buf, binary.LittleEndian, doubleValue); err != nil { return nil, fmt.Errorf("failed to write float64 value: %w", err) } case mysql.FieldTypeDate, mysql.FieldTypeNewDate, mysql.FieldTypeTimestamp, mysql.FieldTypeDateTime, mysql.FieldTypeTime: dateTimeBytes, err := encodeBinaryDateTime(row.Values[i].Type, columnEntry.Value) if err != nil { return nil, fmt.Errorf("failed to encode date/time value: %w", err) } if _, err := buf.Write
------------------

--- Chunk 11---
Function EncodeBinaryRow (end): (dateTimeBytes); err != nil { return nil, fmt.Errorf("failed to write date/time value: %w", err) } default: return nil, fmt.Errorf("unsupported column type: %v", row.Values[i].Type) } } return buf.Bytes(), nil }
------------------

--- Chunk 12---
func encodeBinaryDateTime(fieldType mysql.FieldType, value interface{}) ([]byte, error) { switch fieldType { case mysql.FieldTypeDate, mysql.FieldTypeNewDate: // Date format: YYYY-MM-DD return encodeDate(value) case mysql.FieldTypeTimestamp, mysql.FieldTypeDateTime: // DateTime format: YYYY-MM-DD HH:MM:SS[.ffffff] return encodeDateTime(value) case mysql.FieldTypeTime: // Time format: [-]HH:MM:SS[.ffffff] return encodeTime(value) default: return nil, fmt.Errorf("unsupported date/time field type: %v", fieldType) } }
------------------

--- Chunk 13---
func encodeDate(value interface{}) ([]byte, error) { dateStr, ok := value.(string) if !ok { return nil, fmt.Errorf("invalid value type for date field") } var year, month, day int _, err := fmt.Sscanf(dateStr, "%04d-%02d-%02d", &year, &month, &day) if err != nil { return nil, fmt.Errorf("failed to parse date string: %w", err) } buf := new(bytes.Buffer) err = buf.WriteByte(byte(4)) if err != nil { return nil, fmt.Errorf("failed to write date length: %w", err) } err = binary.Write(buf, binary.LittleEndian, uint16(year)) if err != nil { return nil, fmt.Errorf("failed to write year: %w", err) } err = buf.WriteByte(byte(month)) if err != nil { return nil, fmt.Errorf("failed to write month: %w", err) } err = buf.WriteByte(byte(day)) if err != nil { return nil, fmt.Errorf("failed to write day: %w", err) } return buf.Bytes(), nil }
------------------

--- Chunk 14---
Function encodeDateTime (start): func encodeDateTime(value interface{}) ([]byte, error) { dateTimeStr, ok := value.(string) if !ok { return nil, fmt.Errorf("invalid value type for datetime field") } var ( year, month, day, hour, minute, second, microsecond int length byte ) if strings.Contains(dateTimeStr, ".") { _, err := fmt.Sscanf(dateTimeStr, "%04d-%02d-%02d %02d:%02d:%02d.%06d", &year, &month, &day, &hour, &minute, &second, &microsecond) if err != nil { return nil, fmt.Errorf("failed to parse datetime string: %w", err) } length = 11 } else { _, err := fmt.Sscanf(dateTimeStr, "%04d-%02d-%02d %02d:%02d:%02d", &year, &month, &day, &hour, &minute, &second) if err != nil { return nil, fmt.Errorf("failed to parse datetime string: %w", err) } length = 7
------------------

--- Chunk 15---
Function encodeDateTime (part 2): } buf := new(bytes.Buffer) err := buf.WriteByte(length) if err != nil { return nil, fmt.Errorf("failed to write datetime length: %w", err) } err = binary.Write(buf, binary.LittleEndian, uint16(year)) if err != nil { return nil, fmt.Errorf("failed to write year: %w", err) } err = buf.WriteByte(byte(month)) if err != nil { return nil, fmt.Errorf("failed to write month: %w", err) } err = buf.WriteByte(byte(day)) if err != nil { return nil, fmt.Errorf("failed to write day: %w", err) } err = buf.WriteByte(byte(hour)) if err != nil { return nil, fmt.Errorf("failed to write hour: %w", err) } err = buf.WriteByte(byte(minute)) if err != nil { return nil, fmt.Errorf("failed to write minute: %w", err) } err = buf.WriteByte(byte(second)) if err != nil { return nil, fmt.Errorf("failed to write second: %w", err) } if length == 11 { err = binary.Write(buf, binary.LittleEndian, uint32(microsecond
------------------

--- Chunk 16---
Function encodeDateTime (end): )) if err != nil { return nil, fmt.Errorf("failed to write microseconds: %w", err) } } return buf.Bytes(), nil }
------------------

--- Chunk 17---
Function encodeTime (start): func encodeTime(value interface{}) ([]byte, error) { timeStr, ok := value.(string) if !ok { return nil, fmt.Errorf("invalid value type for time field") } var ( isNegative bool days, hours, minutes, seconds, microseconds int length byte ) if timeStr[0] == '-' { isNegative = true timeStr = timeStr[1:] } if strings.Contains(timeStr, ".") { _, err := fmt.Sscanf(timeStr, "%d %02d:%02d:%02d.%06d", &days, &hours, &minutes, &seconds, &microseconds) if err != nil { return nil, fmt.Errorf("failed to parse time string: %w", err) } length = 12 } else { _, err := fmt.Sscanf(timeStr, "%d %02d:%02d:%02d", &days, &hours, &minutes, &seconds) if err != nil { return nil, fmt.Errorf("failed to parse time string: %w", err) } length = 8
------------------

--- Chunk 18---
Function encodeTime (end): } buf := new(bytes.Buffer) err := buf.WriteByte(length) if err != nil { return nil, fmt.Errorf("failed to write time length: %w", err) } if isNegative { buf.WriteByte(1) } else { buf.WriteByte(0) } err = binary.Write(buf, binary.LittleEndian, uint32(days)) if err != nil { return nil, fmt.Errorf("failed to write days: %w", err) } err = buf.WriteByte(byte(hours)) if err != nil { return nil, fmt.Errorf("failed to write hours: %w", err) } err = buf.WriteByte(byte(minutes)) if err != nil { return nil, fmt.Errorf("failed to write minutes: %w", err) } err = buf.WriteByte(byte(seconds)) if err != nil { return nil, fmt.Errorf("failed to write seconds: %w", err) } if length == 12 { err = binary.Write(buf, binary.LittleEndian, uint32(microseconds)) if err != nil { return nil, fmt.Errorf("failed to write microseconds: %w", err) } } return buf.Bytes(), nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/rowscols/columnCountPacket.go---

--- Chunk 1---
func DecodeColumnCount(_ context.Context, _ *zap.Logger, data []byte) (uint64, error) { // offset := 0 // pkt := &mysql.ColumnCount{ // Header: mysql.Header{ // PayloadLength: utils.GetPayloadLength(data[:3]), // SequenceID: data[3], // }, // } // offset += 4 // data = data[offset:] // Parse the column count packet columnCount, _, n := utils.ReadLengthEncodedInteger(data) if n == 0 { return 0, errors.New("invalid column count") } return columnCount, nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/rowscols/columnPacket.go---

--- Chunk 1---
Function DecodeColumn (start): func DecodeColumn(_ context.Context, _ *zap.Logger, b []byte) (*mysql.ColumnDefinition41, int, error) { packet := &mysql.ColumnDefinition41{ Header: mysql.Header{}, } if len(b) < 4 { return nil, 0, fmt.Errorf("invalid column definition packet") } var pos = 0 // Read packet header packet.Header.PayloadLength = utils.ReadUint24(b[pos : pos+3]) packet.Header.SequenceID = uint8(b[pos+3]) pos += 4 //catalog catalog, _, n, err := utils.ReadLengthEncodedString(b[pos:]) if err != nil { return nil, pos, err } packet.Catalog = string(catalog) pos += n //schema schema, _, n, err := utils.ReadLengthEncodedString(b[pos:]) if err != nil { return nil, pos, err } packet.Schema = string(schema) pos += n //table table, _, n, err := utils.ReadLengthEncodedString(b[pos:]) if err != nil { return nil, pos, err } packet.Table = string(table) pos += n //org_table org
------------------

--- Chunk 2---
Function DecodeColumn (part 2): Table, _, n, err := utils.ReadLengthEncodedString(b[pos:]) if err != nil { return nil, pos, err } packet.OrgTable = string(orgTable) pos += n //name name, _, n, err := utils.ReadLengthEncodedString(b[pos:]) if err != nil { return nil, pos, err } packet.Name = string(name) pos += n //org_name orgName, _, n, err := utils.ReadLengthEncodedString(b[pos:]) if err != nil { return nil, pos, err } packet.OrgName = string(orgName) pos += n // skip [0x0c] (length of fixed-length fields) packet.FixedLength = 0x0c pos++ //character_set packet.CharacterSet = binary.LittleEndian.Uint16(b[pos:]) pos += 2 //column_length packet.ColumnLength = binary.LittleEndian.Uint32(b[pos:]) pos += 4 //type packet.Type = b[pos] pos++ // flag packet.Flags = binary.LittleEndian.Uint16(b[pos:]) pos += 2 // decimals 1 packet.Decimals = b[pos]
------------------

--- Chunk 3---
Function DecodeColumn (end): pos++ //filler [0x00][0x00] packet.Filler = b[pos : pos+2] pos += 2 //if more data, command was field list if packet.Header.PayloadLength > uint32(pos) { //length of default value lenenc-int defaultValueLength, _, n := utils.ReadLengthEncodedInteger(b[pos:]) pos += n if pos+int(defaultValueLength) > len(b) { return nil, pos, fmt.Errorf("malformed packet: %v", err) } //default value string[$len] packet.DefaultValue = string(b[pos:(pos + int(defaultValueLength))]) pos-- } return packet, pos, nil }
------------------

--- Chunk 4---
Function EncodeColumn (start): func EncodeColumn(_ context.Context, _ *zap.Logger, packet *mysql.ColumnDefinition41) ([]byte, error) { buf := new(bytes.Buffer) // Write packet header if err := utils.WriteUint24(buf, packet.Header.PayloadLength); err != nil { return nil, fmt.Errorf("failed to write PayloadLength: %w", err) } if err := buf.WriteByte(packet.Header.SequenceID); err != nil { return nil, fmt.Errorf("failed to write SequenceID: %w", err) } // Write Catalog if err := utils.WriteLengthEncodedString(buf, packet.Catalog); err != nil { return nil, fmt.Errorf("failed to write Catalog: %w", err) } // Write Schema if err := utils.WriteLengthEncodedString(buf, packet.Schema); err != nil { return nil, fmt.Errorf("failed to write Schema: %w", err) } // Write Table if err := utils.WriteLengthEncodedString(buf, packet.Table); err != nil { return nil, fmt.Errorf("failed to write Table: %w", err) } // Write OrgTable if err := utils.WriteLengthEncodedString(buf, packet.OrgTable); err !=
------------------

--- Chunk 5---
Function EncodeColumn (part 2): nil { return nil, fmt.Errorf("failed to write OrgTable: %w", err) } // Write Name if err := utils.WriteLengthEncodedString(buf, packet.Name); err != nil { return nil, fmt.Errorf("failed to write Name: %w", err) } // Write OrgName if err := utils.WriteLengthEncodedString(buf, packet.OrgName); err != nil { return nil, fmt.Errorf("failed to write OrgName: %w", err) } // Write FixedLength (0x0c) if err := buf.WriteByte(packet.FixedLength); err != nil { return nil, fmt.Errorf("failed to write FixedLength: %w", err) } // Write CharacterSet if err := binary.Write(buf, binary.LittleEndian, packet.CharacterSet); err != nil { return nil, fmt.Errorf("failed to write CharacterSet: %w", err) } // Write ColumnLength if err := binary.Write(buf, binary.LittleEndian, packet.ColumnLength); err != nil { return nil, fmt.Errorf("failed to write ColumnLength: %w", err) } // Write Type if err := buf.WriteByte(packet.Type
------------------

--- Chunk 6---
Function EncodeColumn (end): ); err != nil { return nil, fmt.Errorf("failed to write Type: %w", err) } // Write Flags if err := binary.Write(buf, binary.LittleEndian, packet.Flags); err != nil { return nil, fmt.Errorf("failed to write Flags: %w", err) } // Write Decimals if err := buf.WriteByte(packet.Decimals); err != nil { return nil, fmt.Errorf("failed to write Decimals: %w", err) } // Write Filler if _, err := buf.Write(packet.Filler); err != nil { return nil, fmt.Errorf("failed to write Filler: %w", err) } // Write DefaultValue if it exists if packet.DefaultValue != "" { if err := utils.WriteLengthEncodedString(buf, packet.DefaultValue); err != nil { return nil, fmt.Errorf("failed to write DefaultValue: %w", err) } } return buf.Bytes(), nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/rowscols/textRowPacket.go---

--- Chunk 1---
Function DecodeTextRow (start): func DecodeTextRow(_ context.Context, _ *zap.Logger, data []byte, columns []*mysql.ColumnDefinition41) (*mysql.TextRow, int, error) { offset := 0 row := &mysql.TextRow{ Header: mysql.Header{ PayloadLength: utils.ReadUint24(data[offset : offset+3]), SequenceID: data[offset+3], }, } offset += 4 for _, col := range columns { dataLength := data[offset] if dataLength == 0xfb { // NULL row.Values = append(row.Values, mysql.ColumnEntry{ Type: mysql.FieldType(col.Type), Name: col.Name, Value: nil, }) offset++ continue } value, _, n, err := utils.ReadLengthEncodedString(data[offset:]) if err != nil { return nil, offset, fmt.Errorf("failed to read length-encoded string: %w", err) } row.Values = append(row.Values, mysql.ColumnEntry{ Type: mysql.FieldType(col.Type), Name: col.Name, Value: string(value), }) offset += n } return row,
------------------

--- Chunk 2---
Function DecodeTextRow (end): offset, nil }
------------------

--- Chunk 3---
Function EncodeTextRow (start): func EncodeTextRow(_ context.Context, _ *zap.Logger, row *mysql.TextRow, columns []*mysql.ColumnDefinition41) ([]byte, error) { buf := new(bytes.Buffer) // Write the packet header if err := utils.WriteUint24(buf, row.Header.PayloadLength); err != nil { return nil, fmt.Errorf("failed to write PayloadLength: %w", err) } if err := buf.WriteByte(row.Header.SequenceID); err != nil { return nil, fmt.Errorf("failed to write SequenceID: %w", err) } // Write each column's value for i, col := range columns { value := row.Values[i].Value if value == nil { // Write NULL value if err := buf.WriteByte(0xfb); err != nil { return nil, fmt.Errorf("failed to write NULL value: %w", err) } continue } // Write length-encoded string strValue, ok := value.(string) if !ok { return nil, fmt.Errorf("invalid value type for column %s", col.Name) } if err := utils.WriteLengthEncodedString(buf, strValue); err !=
------------------

--- Chunk 4---
Function EncodeTextRow (end): nil { return nil, fmt.Errorf("failed to write length-encoded string: %w", err) } } if row.Header.PayloadLength != uint32(buf.Len()-4) { return nil, fmt.Errorf("PayloadLength mismatch: expected %d, got %d for row: %v", row.Header.PayloadLength, buf.Len()-4, row) } return buf.Bytes(), nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/utility/initDbPacket.go---

--- Chunk 1---
func DecodeInitDb(_ context.Context, data []byte) (*mysql.InitDBPacket, error) { packet := &mysql.InitDBPacket{ Command: data[0], Schema: string(data[1:]), } return packet, nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/phase/query/utility/setOptionPacket.go---

--- Chunk 1---
func DecodeSetOption(_ context.Context, data []byte) (*mysql.SetOptionPacket, error) { if len(data) < 3 { return nil, fmt.Errorf("set option packet too short") } packet := &mysql.SetOptionPacket{ Status: data[0], Option: binary.LittleEndian.Uint16(data[1:3]), } return packet, nil }
------------------

--- File: pkg/core/proxy/integrations/mysql/wire/util.go---

--- Chunk 1---
func NewLastOpMap() *LastOperation { return &LastOperation{ operations: make(map[net.Conn]byte), } }
------------------

--- Chunk 2---
func (lo *LastOperation) Load(key net.Conn) (value byte, ok bool) { lo.RLock() result, ok := lo.operations[key] lo.RUnlock() return result, ok }
------------------

--- Chunk 3---
func (lo *LastOperation) Store(key net.Conn, value byte) { lo.Lock() lo.operations[key] = value lo.Unlock() }
------------------

--- Chunk 4---
func NewGreetings() *ServerGreetings { return &ServerGreetings{ handshakes: make(map[net.Conn]*mysql.HandshakeV10Packet), } }
------------------

--- Chunk 5---
func (sg *ServerGreetings) Load(key net.Conn) (*mysql.HandshakeV10Packet, bool) { sg.RLock() result, ok := sg.handshakes[key] sg.RUnlock() return result, ok }
------------------

--- Chunk 6---
func (sg *ServerGreetings) Store(key net.Conn, value *mysql.HandshakeV10Packet) { sg.Lock() sg.handshakes[key] = value sg.Unlock() }
------------------

--- Chunk 7---
func setPacketInfo(_ context.Context, parsedPacket *mysql.PacketBundle, pkt interface{}, pktType string, clientConn net.Conn, lastOp byte, decodeCtx *DecodeContext) { parsedPacket.Header.Type = pktType parsedPacket.Message = pkt decodeCtx.LastOp.Store(clientConn, lastOp) }
------------------

--- Chunk 8---
func GetPluginName(buf interface{}) (string, error) { switch v := buf.(type) { case *mysql.HandshakeV10Packet: return v.AuthPluginName, nil case *mysql.AuthSwitchRequestPacket: return v.PluginName, nil default: return "", fmt.Errorf("invalid packet type to get plugin name") } }
------------------

--- Chunk 9---
func GetCachingSha2PasswordMechanism(data byte) (string, error) { switch data { case byte(mysql.PerformFullAuthentication): return mysql.CachingSha2PasswordToString(mysql.PerformFullAuthentication), nil case byte(mysql.FastAuthSuccess): return mysql.CachingSha2PasswordToString(mysql.FastAuthSuccess), nil default: einval := fmt.Sprintf("invalid caching_sha2_password mechanism, found:%02x ", data) return "", fmt.Errorf("%s", einval) } }
------------------

--- Chunk 10---
func StringToCachingSha2PasswordMechanism(data string) (mysql.CachingSha2Password, error) { switch data { case "PerformFullAuthentication": return mysql.PerformFullAuthentication, nil case "FastAuthSuccess": return mysql.FastAuthSuccess, nil default: einval := fmt.Sprintf("invalid caching_sha2_password mechanism, found:%s ", data) return 0, fmt.Errorf("%s", einval) } }
------------------

--- Chunk 11---
func IsGenericResponsePkt(packet *mysql.PacketBundle) bool { if packet == nil { return false } switch packet.Message.(type) { case *mysql.OKPacket, *mysql.ERRPacket, *mysql.EOFPacket: return true default: return false } }
------------------

--- Chunk 12---
func IsNoResponseCommand(command string) bool { switch command { case mysql.CommandStatusToString(mysql.COM_STMT_CLOSE), mysql.CommandStatusToString(mysql.COM_STMT_SEND_LONG_DATA): return true default: return false } }
------------------

--- Chunk 13---
func PrintByteArray(name string, b []byte) { fmt.Printf("%s:\n", name) var i = 1 for _, byte := range b { fmt.Printf(" %02x", byte) i++ if i%16 == 0 { fmt.Println() } } fmt.Println() }
------------------

--- File: pkg/core/proxy/integrations/postgres/v1/decode.go---

--- Chunk 1---
Function decodePostgres (start): func decodePostgres(ctx context.Context, logger *zap.Logger, reqBuf []byte, clientConn net.Conn, dstCfg *models.ConditionalDstCfg, mockDb integrations.MockMemDb, _ models.OutgoingOptions) error { pgRequests := [][]byte{reqBuf} errCh := make(chan error, 1) go func(errCh chan error, pgRequests [][]byte) { defer pUtil.Recover(logger, clientConn, nil) // close should be called from the producer of the channel defer close(errCh) for { // Since protocol packets have to be parsed for checking stream end, // clientConnection have deadline for read to determine the end of stream. err := clientConn.SetReadDeadline(time.Now().Add(10 * time.Millisecond)) if err != nil && err != io.EOF && strings.Contains(err.Error(), "use of closed network connection") { utils.LogError(logger, err, "failed to set the read deadline for the pg client conn") errCh <- err } // To read the stream of request packets from the client for { buffer, err := pUtil.ReadBytes(ctx, logger, clientConn) if err !=
------------------

--- Chunk 2---
Function decodePostgres (part 2): nil { // Applied this nolint to ignore the staticcheck error here because of readability // nolint:staticcheck if netErr, ok := err.(net.Error); !(ok && netErr.Timeout()) { if err == io.EOF { logger.Debug("EOF error received from client. Closing conn in postgres !!") errCh <- err } logger.Debug("failed to read the request message in proxy for postgres dependency") errCh <- err } } if netErr, ok := err.(net.Error); ok && netErr.Timeout() { break } pgRequests = append(pgRequests, buffer) } if len(pgRequests) == 0 { continue } var mutex sync.Mutex matched, pgResponses, err := matchingReadablePG(ctx, logger, &mutex, pgRequests, mockDb) if err != nil { errCh <- fmt.Errorf("error while matching tcs mocks %v", err) return } if !matched { logger.Debug("MISMATCHED REQ is" + string(pgRequests[0])) _, err = pUtil
------------------

--- Chunk 3---
Function decodePostgres (part 3): .PassThrough(ctx, logger, clientConn, dstCfg, pgRequests) if err != nil { utils.LogError(logger, err, "failed to pass the request", zap.Any("request packets", len(pgRequests))) errCh <- err } continue } for _, pgResponse := range pgResponses { encoded, err := util.DecodeBase64(pgResponse.Payload) if len(pgResponse.PacketTypes) > 0 && len(pgResponse.Payload) == 0 { encoded, err = postgresDecoderFrontend(pgResponse) } if err != nil { utils.LogError(logger, err, "failed to decode the response message in proxy for postgres dependency") errCh <- err } _, err = clientConn.Write(encoded) if err != nil && err != io.EOF && strings.Contains(err.Error(), "use of closed network connection") { utils.LogError(logger, err, "failed to write the response message to the client application") errCh <- err } } // Clear the buffer for the next dependency call pgRequests = [][]byte{} } }(errCh, pgRequests) select { case <-
------------------

--- Chunk 4---
Function decodePostgres (end): ctx.Done(): return ctx.Err() case err := <-errCh: if err == io.EOF { return nil } return err } }
------------------

--- Chunk 5---
Function getRecordPrepStatement (start): func getRecordPrepStatement(allMocks []*models.Mock) PrepMap { preparedstatement := make(PrepMap) for _, v := range allMocks { if v.Kind != "Postgres" { continue } for _, req := range v.Spec.PostgresRequests { var querydata []QueryData psMap := make(map[string]string) if len(req.PacketTypes) > 0 && req.PacketTypes[0] != "p" && req.Identfier != "StartupRequest" { p := 0 for _, header := range req.PacketTypes { if header == "P" { if strings.Contains(req.Parses[p].Name, "S_") || strings.Contains(req.Parses[p].Name, "s") { psMap[req.Parses[p].Query] = req.Parses[p].Name querydata = append(querydata, QueryData{PrepIdentifier: req.Parses[p].Name, Query: req.Parses[p].Query, }) } p++ } } } // also append the query data for the prepared statement if len(query
------------------

--- Chunk 6---
Function getRecordPrepStatement (end): data) > 0 { preparedstatement[v.ConnectionID] = append(preparedstatement[v.ConnectionID], querydata...) } } } return preparedstatement }
------------------

--- File: pkg/core/proxy/integrations/postgres/v1/encode.go---

--- Chunk 1---
Function encodePostgres (start): func encodePostgres(ctx context.Context, logger *zap.Logger, reqBuf []byte, clientConn, destConn net.Conn, mocks chan<- *models.Mock, _ models.OutgoingOptions) error { logger.Debug("Inside the encodePostgresOutgoing function") var pgRequests []models.Backend bufStr := util.EncodeBase64(reqBuf) pg := NewBackend() _, err := pg.decodeStartupMessage(reqBuf) if err != nil { utils.LogError(logger, err, "failed to decode startup message server") } if bufStr != "" { pgRequests = append(pgRequests, models.Backend{ PacketTypes: pg.BackendWrapper.PacketTypes, Identfier: "StartupRequest", Length: uint32(len(reqBuf)), Payload: bufStr, Bind: pg.BackendWrapper.Bind, PasswordMessage: pg.BackendWrapper.PasswordMessage, CancelRequest: pg.BackendWrapper.CancelRequest, Close: pg.BackendWrapper.Close, CopyData: pg.BackendWrapper.CopyData, CopyDone: pg.BackendWrapper.CopyDone, CopyFail: pg.BackendWrapper.Copy
------------------

--- Chunk 2---
Function encodePostgres (part 2): Fail, Describe: pg.BackendWrapper.Describe, Execute: pg.BackendWrapper.Execute, Flush: pg.BackendWrapper.Flush, FunctionCall: pg.BackendWrapper.FunctionCall, GssEncRequest: pg.BackendWrapper.GssEncRequest, Parse: pg.BackendWrapper.Parse, Query: pg.BackendWrapper.Query, SSlRequest: pg.BackendWrapper.SSlRequest, StartupMessage: pg.BackendWrapper.StartupMessage, SASLInitialResponse: pg.BackendWrapper.SASLInitialResponse, SASLResponse: pg.BackendWrapper.SASLResponse, Sync: pg.BackendWrapper.Sync, Terminate: pg.BackendWrapper.Terminate, MsgType: pg.BackendWrapper.MsgType, AuthType: pg.BackendWrapper.AuthType, }) logger.Debug("Before for loop pg request starts", zap.Any("pgReqs", len(pgRequests))) } _, err = destConn.Write(reqBuf) if err != nil { utils.LogError(logger, err, "failed to write request message to the destination server
------------------

--- Chunk 3---
Function encodePostgres (part 3): ") return err } var pgResponses []models.Frontend clientBuffChan := make(chan []byte) destBuffChan := make(chan []byte) errChan := make(chan error, 1) //get the error group from the context g := ctx.Value(models.ErrGroupKey).(*errgroup.Group) // read requests from client g.Go(func() error { defer pUtil.Recover(logger, clientConn, destConn) defer close(clientBuffChan) pUtil.ReadBuffConn(ctx, logger, clientConn, clientBuffChan, errChan) return nil }) // read responses from destination g.Go(func() error { defer pUtil.Recover(logger, clientConn, destConn) defer close(destBuffChan) pUtil.ReadBuffConn(ctx, logger, destConn, destBuffChan, errChan) return nil }) go func() { defer pUtil.Recover(logger, clientConn, destConn) err := g.Wait() if err != nil { logger.Info("error group is returning an error", zap.Error(err)) } close(errChan) }() prevChunkWasReq := false logger.Debug("the iteration for
------------------

--- Chunk 4---
Function encodePostgres (part 4): the pg request starts", zap.Any("pgReqs", len(pgRequests)), zap.Any("pgResps", len(pgResponses))) reqTimestampMock := time.Now() var resTimestampMock time.Time for { select { case <-ctx.Done(): if !prevChunkWasReq && len(pgRequests) > 0 && len(pgResponses) > 0 { metadata := make(map[string]string) metadata["type"] = "config" metadata["connID"] = ctx.Value(models.ClientConnectionIDKey).(string) // Save the mock mocks <- &models.Mock{ Version: models.GetVersion(), Name: "mocks", Kind: models.Postgres, Spec: models.MockSpec{ PostgresRequests: pgRequests, PostgresResponses: pgResponses, ReqTimestampMock: reqTimestampMock, ResTimestampMock: resTimestampMock, Metadata: metadata, }, ConnectionID: ctx.Value(models.ClientConnectionIDKey).(string), } return ctx.Err() } case buffer := <-clientBuffChan: // Write the request message to the destination
------------------

--- Chunk 5---
Function encodePostgres (part 5): _, err := destConn.Write(buffer) if err != nil { utils.LogError(logger, err, "failed to write request message to the destination server") return err } logger.Debug("the iteration for the pg request ends with no of pgReqs:" + strconv.Itoa(len(pgRequests)) + " and pgResps: " + strconv.Itoa(len(pgResponses))) if !prevChunkWasReq && len(pgRequests) > 0 && len(pgResponses) > 0 { metadata := make(map[string]string) metadata["type"] = "config" metadata["connID"] = ctx.Value(models.ClientConnectionIDKey).(string) // Save the mock mocks <- &models.Mock{ Version: models.GetVersion(), Name: "mocks", Kind: models.Postgres, Spec: models.MockSpec{ PostgresRequests: pgRequests, PostgresResponses: pgResponses, ReqTimestampMock: reqTimestampMock, ResTimestampMock: resTimestampMock, Metadata: metadata, }, ConnectionID: ctx.Value(models.ClientConnectionIDKey).(string),
------------------

--- Chunk 6---
Function encodePostgres (part 6): } pgRequests = []models.Backend{} pgResponses = []models.Frontend{} } bufStr := util.EncodeBase64(buffer) if bufStr != "" { pg := NewBackend() var msg pgproto3.FrontendMessage if !isStartupPacket(buffer) && len(buffer) > 5 { bufferCopy := buffer for i := 0; i < len(bufferCopy)-5; { pg.BackendWrapper.BodyLen = int(binary.BigEndian.Uint32(buffer[i+1:])) - 4 if len(buffer) < (i + pg.BackendWrapper.BodyLen + 5) { utils.LogError(logger, nil, "failed to translate the postgres request message due to shorter network packet buffer. Length of buffer is "+fmt.Sprint(len(buffer))+" buffer value :"+string(buffer)+" and pg.BackendWrapper.BodyLen is "+fmt.Sprint(pg.BackendWrapper.BodyLen)) break } pg.BackendWrapper.MsgType = buffer[i] msg, err = pg.translateToReadableBackend(buffer[i:(i + pg.BackendWrapper.BodyLen + 5)]) if err != nil && buffer[i] !=
------------------

--- Chunk 7---
Function encodePostgres (part 7): 112 { utils.LogError(logger, err, "failed to translate the request message to readable") } if pg.BackendWrapper.MsgType == 'p' { pg.BackendWrapper.PasswordMessage = *msg.(*pgproto3.PasswordMessage) } if pg.BackendWrapper.MsgType == 'P' { pg.BackendWrapper.Parse = *msg.(*pgproto3.Parse) pg.BackendWrapper.Parses = append(pg.BackendWrapper.Parses, pg.BackendWrapper.Parse) } if pg.BackendWrapper.MsgType == 'B' { pg.BackendWrapper.Bind = *msg.(*pgproto3.Bind) pg.BackendWrapper.Binds = append(pg.BackendWrapper.Binds, pg.BackendWrapper.Bind) } if pg.BackendWrapper.MsgType == 'E' { pg.BackendWrapper.Execute = *msg.(*pgproto3.Execute) pg.BackendWrapper.Executes = append(pg.BackendWrapper.Executes, pg.BackendWrapper.Execute) } pg.BackendWrapper.PacketTypes = append(pg.BackendWrapper.PacketTypes, string(pg.BackendWrapper.MsgType)) i += 5 + pg
------------------

--- Chunk 8---
Function encodePostgres (part 8): .BackendWrapper.BodyLen } pgMock := &models.Backend{ PacketTypes: pg.BackendWrapper.PacketTypes, Identfier: "ClientRequest", Length: uint32(len(reqBuf)), // Payload: bufStr, Bind: pg.BackendWrapper.Bind, Binds: pg.BackendWrapper.Binds, PasswordMessage: pg.BackendWrapper.PasswordMessage, CancelRequest: pg.BackendWrapper.CancelRequest, Close: pg.BackendWrapper.Close, CopyData: pg.BackendWrapper.CopyData, CopyDone: pg.BackendWrapper.CopyDone, CopyFail: pg.BackendWrapper.CopyFail, Describe: pg.BackendWrapper.Describe, Execute: pg.BackendWrapper.Execute, Executes: pg.BackendWrapper.Executes, Flush: pg.BackendWrapper.Flush, FunctionCall: pg.BackendWrapper.FunctionCall, GssEncRequest: pg.BackendWrapper.GssEncRequest, Parse: pg.BackendWrapper.Parse, Parses: pg.BackendWrapper
------------------

--- Chunk 9---
Function encodePostgres (part 9): .Parses, Query: pg.BackendWrapper.Query, SSlRequest: pg.BackendWrapper.SSlRequest, StartupMessage: pg.BackendWrapper.StartupMessage, SASLInitialResponse: pg.BackendWrapper.SASLInitialResponse, SASLResponse: pg.BackendWrapper.SASLResponse, Sync: pg.BackendWrapper.Sync, Terminate: pg.BackendWrapper.Terminate, MsgType: pg.BackendWrapper.MsgType, AuthType: pg.BackendWrapper.AuthType, } afterEncoded, err := postgresDecoderBackend(*pgMock) if err != nil { logger.Debug("failed to decode the response message in proxy for postgres dependency", zap.Error(err)) } if len(afterEncoded) != len(buffer) && len(pgMock.PacketTypes) > 0 && pgMock.PacketTypes[0] != "p" { logger.Debug("the length of the encoded buffer is not equal to the length of the original buffer", zap.Any("after_encoded", len(afterEncoded)), zap.Any("buffer", len(buffer))) pgMock.Payload = bufStr }
------------------

--- Chunk 10---
Function encodePostgres (part 10): pgRequests = append(pgRequests, *pgMock) } if isStartupPacket(buffer) { pgMock := &models.Backend{ Identfier: "StartupRequest", Payload: bufStr, } pgRequests = append(pgRequests, *pgMock) } } prevChunkWasReq = true case buffer := <-destBuffChan: if prevChunkWasReq { // store the request timestamp reqTimestampMock = time.Now() } // Write the response message to the client _, err := clientConn.Write(buffer) if err != nil { utils.LogError(logger, err, "failed to write response message to the client") return err } bufStr := util.EncodeBase64(buffer) if bufStr != "" { pg := NewFrontend() if !isStartupPacket(buffer) && len(buffer) > 5 && bufStr != "Tg==" { bufferCopy := buffer //Saving list of packets in case of multiple packets in a single buffer steam ps := make([]pgproto3.ParameterStatus, 0)
------------------

--- Chunk 11---
Function encodePostgres (part 11): var dataRows []pgproto3.DataRow for i := 0; i < len(bufferCopy)-5; { pg.FrontendWrapper.MsgType = buffer[i] pg.FrontendWrapper.BodyLen = int(binary.BigEndian.Uint32(buffer[i+1:])) - 4 msg, err := pg.translateToReadableResponse(logger, buffer[i:(i+pg.FrontendWrapper.BodyLen+5)]) if err != nil { utils.LogError(logger, err, "failed to translate the response message to readable") break } pg.FrontendWrapper.PacketTypes = append(pg.FrontendWrapper.PacketTypes, string(pg.FrontendWrapper.MsgType)) i += 5 + pg.FrontendWrapper.BodyLen if pg.FrontendWrapper.ParameterStatus.Name != "" { ps = append(ps, pg.FrontendWrapper.ParameterStatus) } if pg.FrontendWrapper.MsgType == 'C' { pg.FrontendWrapper.CommandComplete = *msg.(*pgproto3.CommandComplete) // empty the command tag pg.FrontendWrapper.CommandComplete.CommandTag = []byte{} pg.FrontendWrapper
------------------

--- Chunk 12---
Function encodePostgres (part 12): .CommandCompletes = append(pg.FrontendWrapper.CommandCompletes, pg.FrontendWrapper.CommandComplete) } if pg.FrontendWrapper.MsgType == 'D' && pg.FrontendWrapper.DataRow.RowValues != nil { // Create a new slice for each DataRow valuesCopy := make([]string, len(pg.FrontendWrapper.DataRow.RowValues)) copy(valuesCopy, pg.FrontendWrapper.DataRow.RowValues) row := pgproto3.DataRow{ RowValues: valuesCopy, // Use the copy of the values Values: pg.FrontendWrapper.DataRow.Values, } dataRows = append(dataRows, row) } } if len(ps) > 0 { pg.FrontendWrapper.ParameterStatusCombined = ps } if len(dataRows) > 0 { pg.FrontendWrapper.DataRows = dataRows } // from here take the msg and append its readable form to the pgResponses pgMock := &models.Frontend{ PacketTypes: pg.FrontendWrapper.PacketTypes, Identfier: "Server
------------------

--- Chunk 13---
Function encodePostgres (part 13): Response", Length: uint32(len(reqBuf)), // Payload: bufStr, AuthenticationOk: pg.FrontendWrapper.AuthenticationOk, AuthenticationCleartextPassword: pg.FrontendWrapper.AuthenticationCleartextPassword, AuthenticationMD5Password: pg.FrontendWrapper.AuthenticationMD5Password, AuthenticationGSS: pg.FrontendWrapper.AuthenticationGSS, AuthenticationGSSContinue: pg.FrontendWrapper.AuthenticationGSSContinue, AuthenticationSASL: pg.FrontendWrapper.AuthenticationSASL, AuthenticationSASLContinue: pg.FrontendWrapper.AuthenticationSASLContinue, AuthenticationSASLFinal: pg.FrontendWrapper.AuthenticationSASLFinal, BackendKeyData: pg.FrontendWrapper.BackendKeyData, BindComplete: pg.FrontendWrapper.BindComplete, CloseComplete: pg.FrontendWrapper.CloseComplete, CommandComplete: pg.FrontendWrapper.CommandComplete, CommandCompletes: pg.FrontendWrapper.CommandCompletes, CopyData: pg.FrontendWrapper.CopyData, Copy
------------------

--- Chunk 14---
Function encodePostgres (part 14): Done: pg.FrontendWrapper.CopyDone, CopyInResponse: pg.FrontendWrapper.CopyInResponse, CopyOutResponse: pg.FrontendWrapper.CopyOutResponse, DataRow: pg.FrontendWrapper.DataRow, DataRows: pg.FrontendWrapper.DataRows, EmptyQueryResponse: pg.FrontendWrapper.EmptyQueryResponse, ErrorResponse: pg.FrontendWrapper.ErrorResponse, FunctionCallResponse: pg.FrontendWrapper.FunctionCallResponse, NoData: pg.FrontendWrapper.NoData, NoticeResponse: pg.FrontendWrapper.NoticeResponse, NotificationResponse: pg.FrontendWrapper.NotificationResponse, ParameterDescription: pg.FrontendWrapper.ParameterDescription, ParameterStatusCombined: pg.FrontendWrapper.ParameterStatusCombined, ParseComplete: pg.FrontendWrapper.ParseComplete, PortalSuspended: pg.FrontendWrapper.PortalSuspended, ReadyForQuery: pg.FrontendWrapper.ReadyForQuery, RowDescription: pg.FrontendWrapper.RowDescription, MsgType: pg.F
------------------

--- Chunk 15---
Function encodePostgres (part 15): rontendWrapper.MsgType, AuthType: pg.FrontendWrapper.AuthType, } afterEncoded, err := postgresDecoderFrontend(*pgMock) if err != nil { logger.Debug("failed to decode the response message in proxy for postgres dependency", zap.Error(err)) } if len(afterEncoded) != len(buffer) && len(pgMock.PacketTypes) > 0 && pgMock.PacketTypes[0] != "R" { logger.Debug("the length of the encoded buffer is not equal to the length of the original buffer", zap.Any("after_encoded", len(afterEncoded)), zap.Any("buffer", len(buffer))) pgMock.Payload = bufStr } pgResponses = append(pgResponses, *pgMock) } if bufStr == "Tg==" || len(buffer) <= 5 { pgMock := &models.Frontend{ Payload: bufStr, } pgResponses = append(pgResponses, *pgMock) } } resTimestampMock = time.Now() logger.Debug("the iteration for the postgres response ends with no of postgresReqs:" + strconv.Itoa(len(pgRequests
------------------

--- Chunk 16---
Function encodePostgres (end): )) + " and pgResps: " + strconv.Itoa(len(pgResponses))) prevChunkWasReq = false case err := <-errChan: if err == io.EOF { return nil } return err } } }
------------------

--- File: pkg/core/proxy/integrations/postgres/v1/match.go---

--- Chunk 1---
Function getTestPS (start): func getTestPS(reqBuff [][]byte, logger *zap.Logger, ConnectionID string) { // maintain a map of current prepared statements and their corresponding connection id // if it's the prepared statement match the query with the recorded prepared statement and return the response of that matched prepared statement at that connection // so if parse is coming save to a same map actualPgReq := decodePgRequest(reqBuff[0], logger) if actualPgReq == nil { return } testmap2 := make(TestPrepMap) if testmap != nil { testmap2 = testmap } querydata := make([]QueryData, 0) if len(actualPgReq.PacketTypes) > 0 && actualPgReq.PacketTypes[0] != "p" && actualPgReq.Identfier != "StartupRequest" { p := 0 for _, header := range actualPgReq.PacketTypes { if header == "P" { if (strings.Contains(actualPgReq.Parses[p].Name, "S_") || strings.Contains(actualPgReq.Parses[p].Name, "s")) && !IsValuePresent(ConnectionID, actualPgReq.Parses[p].Name)
------------------

--- Chunk 2---
Function getTestPS (end): { querydata = append(querydata, QueryData{PrepIdentifier: actualPgReq.Parses[p].Name, Query: actualPgReq.Parses[p].Query}) } p++ } } } // also append the query data for the prepared statement if len(querydata) > 0 { testmap2[ConnectionID] = append(testmap2[ConnectionID], querydata...) // logger.Debug("Test Prepared statement Map", testmap2) testmap = testmap2 } }
------------------

--- Chunk 3---
func IsValuePresent(connectionid string, value string) bool { if testmap != nil { for _, v := range testmap[connectionid] { if v.PrepIdentifier == value { return true } } } return false }
------------------

--- Chunk 4---
Function matchingReadablePG (start): func matchingReadablePG(ctx context.Context, logger *zap.Logger, mutex *sync.Mutex, requestBuffers [][]byte, mockDb integrations.MockMemDb) (bool, []models.Frontend, error) { OuterLoop: for { select { case <-ctx.Done(): return false, nil, ctx.Err() default: mocks, err := mockDb.GetUnFilteredMocks() var tcsMocks []*models.Mock for _, mock := range mocks { if mock.Kind != "Postgres" { continue } tcsMocks = append(tcsMocks, mock) } if err != nil { return false, nil, fmt.Errorf("error while getting tcs mocks %v", err) } ConnectionID := ctx.Value(models.ClientConnectionIDKey).(string) recordedPrep := getRecordPrepStatement(tcsMocks) reqGoingOn := decodePgRequest(requestBuffers[0], logger) if reqGoingOn != nil { logger.Debug("PacketTypes", zap.Any("PacketTypes", reqGoingOn.PacketTypes)) // fmt.Println("REQUEST GOING ON - ", reqGoingOn) logger.Debug("ConnectionId-", zap.String("
------------------

--- Chunk 5---
Function matchingReadablePG (part 2): ConnectionId", ConnectionID)) logger.Debug("TestMap*****", zap.Any("TestMap", testmap)) } // merge all the streaming requests into 1 for matching newRq := mergePgRequests(requestBuffers, logger) if len(newRq) > 0 { requestBuffers = newRq } var sortFlag = true var sortedTcsMocks []*models.Mock var matchedMock *models.Mock for _, mock := range tcsMocks { if ctx.Err() != nil { return false, nil, ctx.Err() } if mock == nil { continue } mutex.Lock() if sortFlag { if !mock.TestModeInfo.IsFiltered { sortFlag = false } else { sortedTcsMocks = append(sortedTcsMocks, mock) } } mutex.Unlock() initMock := *mock if len(initMock.Spec.PostgresRequests) == len(requestBuffers) { for requestIndex, reqBuff := range requestBuffers { bufStr := base64.StdEncoding.EncodeToString(reqBuff) encodedMock, err := postgresDecoderBackend(init
------------------

--- Chunk 6---
Function matchingReadablePG (part 3): Mock.Spec.PostgresRequests[requestIndex]) if err != nil { logger.Debug("Error while decoding postgres request", zap.Error(err)) } switch { case bufStr == "AAAACATSFi8=": ssl := models.Frontend{ Payload: "Tg==", } return true, []models.Frontend{ssl}, nil case initMock.Spec.PostgresRequests[requestIndex].Identfier == "StartupRequest" && isStartupPacket(reqBuff) && initMock.Spec.PostgresRequests[requestIndex].Payload != "AAAACATSFi8=" && initMock.Spec.PostgresResponses[requestIndex].AuthType == 10: logger.Debug("CHANGING TO MD5 for Response", zap.String("mock", initMock.Name), zap.String("Req", bufStr)) res := make([]models.Frontend, len(initMock.Spec.PostgresResponses)) copy(res, initMock.Spec.PostgresResponses) res[requestIndex].AuthType = 5 newInitMock := initMock newInitMock.TestModeInfo.IsFiltered = false newInitMock.TestModeInfo.SortOrder = pkg.GetNextSortNum() is
------------------

--- Chunk 7---
Function matchingReadablePG (part 4): Updated := mockDb.UpdateUnFilteredMock(&initMock, &newInitMock) if !isUpdated { logger.Debug("failed to update matched mock", zap.Error(err)) continue OuterLoop } return true, res, nil case len(encodedMock) > 0 && encodedMock[0] == 'p' && initMock.Spec.PostgresRequests[requestIndex].PacketTypes[0] == "p" && reqBuff[0] == 'p': logger.Debug("CHANGING TO MD5 for Request and Response", zap.String("mock", initMock.Name), zap.String("Req", bufStr)) res := make([]models.Frontend, len(initMock.Spec.PostgresResponses)) copy(res, initMock.Spec.PostgresResponses) res[requestIndex].PacketTypes = []string{"R", "S", "S", "S", "S", "S", "S", "S", "S", "S", "S", "S", "K", "Z"} res[requestIndex].AuthType = 0 res[requestIndex].BackendKeyData = pgproto3.BackendKeyData{ ProcessID: 2613,
------------------

--- Chunk 8---
Function matchingReadablePG (part 5): SecretKey: 824670820, } res[requestIndex].ReadyForQuery.TxStatus = 73 res[requestIndex].ParameterStatusCombined = []pgproto3.ParameterStatus{ { Name: "application_name", Value: "", }, { Name: "client_encoding", Value: "UTF8", }, { Name: "DateStyle", Value: "ISO, MDY", }, { Name: "integer_datetimes", Value: "on", }, { Name: "IntervalStyle", Value: "postgres", }, { Name: "is_superuser", Value: "UTF8", }, { Name: "server_version", Value: "13.12 (Debian 13.12-1.pgdg120+1)", }, { Name: "session_authorization", Value: "keploy-user", }, { Name: "standard_conforming_strings", Value: "on", }, { Name:
------------------

--- Chunk 9---
Function matchingReadablePG (part 6): "TimeZone", Value: "Etc/UTC", }, { Name: "TimeZone", Value: "Etc/UTC", }, } newInitMock := initMock newInitMock.TestModeInfo.IsFiltered = false newInitMock.TestModeInfo.SortOrder = pkg.GetNextSortNum() isUpdated := mockDb.UpdateUnFilteredMock(&initMock, &newInitMock) if !isUpdated { logger.Debug("failed to update matched mock", zap.Error(err)) continue OuterLoop } return true, res, nil } } } // maintain test prepare statement map for each connection id getTestPS(requestBuffers, logger, ConnectionID) } logger.Debug("Sorted Mocks inside pg parser: ", zap.Any("Len of sortedTcsMocks", len(sortedTcsMocks))) var matched, sorted bool var idx int //use findBinaryMatch twice one for sorted and another for unsorted // give more priority to sorted like if you find more than 0.5 in sorted then return that if len(sortedTcs
------------------

--- Chunk 10---
Function matchingReadablePG (part 7): Mocks) > 0 { sorted = true idx1, newMock := findPGStreamMatch(sortedTcsMocks, requestBuffers, logger, sorted, ConnectionID, recordedPrep) if idx1 != -1 { matched = true matchedMock = tcsMocks[idx1] if newMock != nil { matchedMock = newMock } logger.Debug("Matched In Sorted PG Matching Stream", zap.String("mock", matchedMock.Name)) } if !matched { idx = findBinaryStreamMatch(logger, sortedTcsMocks, requestBuffers, sorted) if idx != -1 { matched = true matchedMock = tcsMocks[idx] } } } if !matched { sorted = false idx1, newMock := findPGStreamMatch(tcsMocks, requestBuffers, logger, sorted, ConnectionID, recordedPrep) if idx1 != -1 { matched = true matchedMock = tcsMocks[idx1] if newMock != nil { matchedMock = newMock } logger.Debug("Matched In Un
------------------

--- Chunk 11---
Function matchingReadablePG (part 8): sorted PG Matching Stream", zap.String("mock", matchedMock.Name)) } if !matched { idx = findBinaryStreamMatch(logger, tcsMocks, requestBuffers, sorted) // check if the validate the query with the matched mock // if the query is same then return the response of that mock var isValid = true if idx != -1 && len(sortedTcsMocks) != 0 { isValid, newMock = validateMock(tcsMocks, idx, requestBuffers, logger) logger.Debug("Is Valid", zap.Bool("Is Valid", isValid)) } if idx != -1 { matched = true matchedMock = tcsMocks[idx] if newMock != nil && !isValid { matchedMock = newMock } logger.Debug("Matched In Binary Matching for Unsorted", zap.String("mock", matchedMock.Name)) } } } if matched { logger.Debug("Matched mock", zap.String("mock", matchedMock.Name)) originalMatchedMock := *matchedMock matchedMock.TestModeInfo.IsFiltered = false matchedMock.TestMode
------------------

--- Chunk 12---
Function matchingReadablePG (end): Info.SortOrder = pkg.GetNextSortNum() updated := mockDb.UpdateUnFilteredMock(&originalMatchedMock, matchedMock) if !updated { logger.Debug("failed to update matched mock", zap.Error(err)) } return true, matchedMock.Spec.PostgresResponses, nil } return false, nil, nil } } }
------------------

--- Chunk 13---
Function findBinaryStreamMatch (start): func findBinaryStreamMatch(logger *zap.Logger, tcsMocks []*models.Mock, requestBuffers [][]byte, sorted bool) int { mxSim := -1.0 mxIdx := -1 for idx, mock := range tcsMocks { // merging the mocks as well before comparing mock.Spec.PostgresRequests = mergeMocks(mock.Spec.PostgresRequests, logger) if len(mock.Spec.PostgresRequests) == len(requestBuffers) { for requestIndex, reqBuf := range requestBuffers { expectedPgReq := mock.Spec.PostgresRequests[requestIndex] encoded, err := postgresDecoderBackend(expectedPgReq) if err != nil { logger.Debug("Error while decoding postgres request", zap.Error(err)) } var encoded64 []byte if expectedPgReq.Payload != "" { encoded64, err = util.DecodeBase64(mock.Spec.PostgresRequests[requestIndex].Payload) if err != nil { logger.Debug("Error while decoding postgres request", zap.Error(err)) return -1 } } var similarity1, similarity2 float64 if len(encoded) > 0 { similarity1 = fuzzyCheck(encoded,
------------------

--- Chunk 14---
Function findBinaryStreamMatch (end): reqBuf) } if len(encoded64) > 0 { similarity2 = fuzzyCheck(encoded64, reqBuf) } // calculate the jaccard similarity between the two buffers one with base64 encoding and another via that //find the max similarity between the two similarity := math.Max(similarity1, similarity2) if mxSim < similarity { mxSim = similarity mxIdx = idx continue } } } } if sorted { if mxIdx != -1 && mxSim >= 0.78 { logger.Debug("Matched with Sorted Stream", zap.Float64("similarity", mxSim)) } else { mxIdx = -1 } } else { if mxIdx != -1 { logger.Debug("Matched with Unsorted Stream", zap.Float64("similarity", mxSim)) } } return mxIdx }
------------------

--- Chunk 15---
func fuzzyCheck(encoded, reqBuf []byte) float64 { k := util.AdaptiveK(len(reqBuf), 3, 8, 5) shingles1 := util.CreateShingles(encoded, k) shingles2 := util.CreateShingles(reqBuf, k) similarity := util.JaccardSimilarity(shingles1, shingles2) return similarity }
------------------

--- Chunk 16---
Function findPGStreamMatch (start): func findPGStreamMatch(tcsMocks []*models.Mock, requestBuffers [][]byte, logger *zap.Logger, isSorted bool, connectionID string, recordedPrep PrepMap) (int, *models.Mock) { mxIdx := -1 match := false // loop for the exact match of the request for idx, mock := range tcsMocks { // merging the mocks as well before comparing mock.Spec.PostgresRequests = mergeMocks(mock.Spec.PostgresRequests, logger) if len(mock.Spec.PostgresRequests) == len(requestBuffers) { for _, reqBuff := range requestBuffers { actualPgReq := decodePgRequest(reqBuff, logger) if actualPgReq == nil { return -1, nil } // here handle cases of prepared statement very carefully match, err := compareExactMatch(mock, actualPgReq, logger) if err != nil { logger.Error("Error while matching exact match", zap.Error(err)) continue } if match { return idx, nil } } } } if !isSorted { return mxIdx, nil } // loop for the ps match
------------------

--- Chunk 17---
Function findPGStreamMatch (part 2): of the request if !match { for idx, mock := range tcsMocks { // merging the mocks as well before comparing mock.Spec.PostgresRequests = mergeMocks(mock.Spec.PostgresRequests, logger) if len(mock.Spec.PostgresRequests) == len(requestBuffers) { for _, reqBuff := range requestBuffers { actualPgReq := decodePgRequest(reqBuff, logger) if actualPgReq == nil { return -1, nil } // just matching the corresponding PS in this case there is no need to edit the mock match, newBindPs, err := PreparedStatementMatch(mock, actualPgReq, logger, connectionID, recordedPrep) if err != nil { logger.Error("Error while matching prepared statements", zap.Error(err)) } if match { logger.Debug("New Bind Prepared Statement", zap.Any("New Bind Prepared Statement", newBindPs), zap.String("ConnectionId", connectionID), zap.String("Mock Name", mock.Name)) return idx, nil } // just check the query if reflect.DeepEqual(actualPgReq.PacketTypes, []string{"P", "B", "D", "E"})
------------------

--- Chunk 18---
Function findPGStreamMatch (part 3): && reflect.DeepEqual(mock.Spec.PostgresRequests[0].PacketTypes, []string{"P", "B", "D", "E"}) { if mock.Spec.PostgresRequests[0].Parses[0].Query == actualPgReq.Parses[0].Query { return idx, nil } } } } } } if !match { for idx, mock := range tcsMocks { // merging the mocks as well before comparing mock.Spec.PostgresRequests = mergeMocks(mock.Spec.PostgresRequests, logger) if len(mock.Spec.PostgresRequests) == len(requestBuffers) { for _, reqBuff := range requestBuffers { actualPgReq := decodePgRequest(reqBuff, logger) if actualPgReq == nil { return -1, nil } // have to ignore first parse message of begin read only // should compare only query in the parse message if len(actualPgReq.PacketTypes) != len(mock.Spec.PostgresRequests[0].PacketTypes) { //check for begin read only if len(actualPgReq.PacketTypes) > 0 && len(mock.Spec.Postgres
------------------

--- Chunk 19---
Function findPGStreamMatch (end): Requests[0].PacketTypes) > 0 { ischanged, newMock := changeResToPS(mock, actualPgReq, logger, connectionID) if ischanged { return idx, newMock } continue } } } } } } return mxIdx, nil }
------------------

--- Chunk 20---
Function changeResToPS (start): func changeResToPS(mock *models.Mock, actualPgReq *models.Backend, logger *zap.Logger, connectionID string) (bool, *models.Mock) { actualpackets := actualPgReq.PacketTypes mockPackets := mock.Spec.PostgresRequests[0].PacketTypes // [P, B, E, P, B, D, E] => [B, E, B, E] // write code that of packet is ["B", "E"] and mockPackets ["P", "B", "D", "E"] handle it in case1 // and if packet is [B, E, B, E] and mockPackets [P, B, E, P, B, D, E] handle it in case2 ischanged := false var newMock *models.Mock // [B E P D B E] // [P, B, E, P, B, D, E] -> [B, E, P, B, D, E] if (reflect.DeepEqual(actualpackets, []string{"B", "E", "P", "D", "B", "E"}) || reflect.DeepEqual(actualpackets, []string{"B
------------------

--- Chunk 21---
Function changeResToPS (part 2): ", "E", "P", "B", "D", "E"})) && reflect.DeepEqual(mockPackets, []string{"P", "B", "E", "P", "B", "D", "E"}) { // logger.Debug("Handling Case 1 for mock", mock.Name) // handleCase1(packets, mockPackets) // also check if the second query is same or not // logger.Debug("ActualPgReq", actualPgReq.Parses[0].Query, "MOCK REQ 1", mock.Spec.PostgresRequests[0].Parses[0].Query, "MOCK REQ 2", mock.Spec.PostgresRequests[0].Parses[1].Query) if actualPgReq.Parses[0].Query != mock.Spec.PostgresRequests[0].Parses[1].Query { return false, nil } newMock = sliceCommandTag(mock, logger, testmap[connectionID], actualPgReq, 1) return true, newMock } // case 2 var ps string if reflect.DeepEqual(actualpackets, []string{"B", "E"}) && reflect
------------------

--- Chunk 22---
Function changeResToPS (part 3): .DeepEqual(mockPackets, []string{"P", "B", "D", "E"}) { // logger.Debug("Handling Case 2 for mock", mock.Name) ps = actualPgReq.Binds[0].PreparedStatement for _, v := range testmap[connectionID] { if v.Query == mock.Spec.PostgresRequests[0].Parses[0].Query && v.PrepIdentifier == ps { ischanged = true break } } } if ischanged { // if strings.Contains(ps, "S_") { // logger.Debug("Inside Prepared Statement") newMock = sliceCommandTag(mock, logger, testmap[connectionID], actualPgReq, 2) // } return true, newMock } // packets = []string{"B", "E", "B", "E"} // mockPackets = []string{"P", "B", "E", "P", "B", "D", "E"} // Case 3 if reflect.DeepEqual(actualpackets, []string{"B", "E", "B", "E"}) && reflect.DeepEqual(mockPackets, []string{"
------------------

--- Chunk 23---
Function changeResToPS (part 4): P", "B", "E", "P", "B", "D", "E"}) { // logger.Debug("Handling Case 3 for mock", mock.Name) ischanged1 := false ps1 := actualPgReq.Binds[0].PreparedStatement for _, v := range testmap[connectionID] { if v.Query == mock.Spec.PostgresRequests[0].Parses[0].Query && v.PrepIdentifier == ps1 { ischanged1 = true break } } //Matched In Binary Matching for Unsorted mock-222 ischanged2 := false ps2 := actualPgReq.Binds[1].PreparedStatement for _, v := range testmap[connectionID] { if v.Query == mock.Spec.PostgresRequests[0].Parses[1].Query && v.PrepIdentifier == ps2 { ischanged2 = true break } } if ischanged1 && ischanged2 { newMock = sliceCommandTag(mock, logger, testmap[connectionID], actualPgReq, 2) return true, newMock
------------------

--- Chunk 24---
Function changeResToPS (end): } } // Case 4 if reflect.DeepEqual(actualpackets, []string{"B", "E", "B", "E"}) && reflect.DeepEqual(mockPackets, []string{"B", "E", "P", "B", "D", "E"}) { // logger.Debug("Handling Case 4 for mock", mock.Name) // get the query for the prepared statement of test mode ischanged := false ps := actualPgReq.Binds[1].PreparedStatement for _, v := range testmap[connectionID] { if v.Query == mock.Spec.PostgresRequests[0].Parses[0].Query && v.PrepIdentifier == ps { ischanged = true break } } if ischanged { newMock = sliceCommandTag(mock, logger, testmap[connectionID], actualPgReq, 2) return true, newMock } } return false, nil }
------------------

--- Chunk 25---
Function PreparedStatementMatch (start): func PreparedStatementMatch(mock *models.Mock, actualPgReq *models.Backend, logger *zap.Logger, ConnectionID string, recordedPrep PrepMap) (bool, []string, error) { // logger.Debug("Inside PreparedStatementMatch") if !reflect.DeepEqual(mock.Spec.PostgresRequests[0].PacketTypes, actualPgReq.PacketTypes) { logger.Debug("mock and actual packet types are unequal", zap.Any("mock name", mock.Name)) return false, nil, nil } // get all the binds from the actualPgReq binds := actualPgReq.Binds newBinPreparedStatement := make([]string, 0) mockBinds := mock.Spec.PostgresRequests[0].Binds // If the client sent a different number of Bind messages than the mock // recorded, the two batches canâ€™t possibly align, so we can return early // instead of walking the loop and risking panic due to outâ€‘ofâ€‘bounds. if len(binds) != len(mockBinds) { logger.Debug("len of binds in actual request is not equal to len of binds in mock", zap.String("mock name", mock.Name)) return false, nil, nil } mockConn := mock
------------------

--- Chunk 26---
Function PreparedStatementMatch (part 2): .ConnectionID var foo = false for idx, bind := range binds { currentPs := bind.PreparedStatement currentQuerydata := testmap[ConnectionID] currentQuery := "" // check in the map that what's the current query for this preparedstatement // then will check what is the recorded prepared statement for this query for _, v := range currentQuerydata { if v.PrepIdentifier == currentPs { // logger.Debug("Current query for this identifier is ", v.Query) currentQuery = v.Query break } } // this means that the bind is preceeded by a parse with name field empty // we can say that the name field (identifier) was empty that's why it didn't get inserted in testMap. // skip it, as it doesn't use already cached query, instead parsing followed by binding is done in the same query. if currentQuery == "" { continue } logger.Debug("Current Query for this prepared statement", zap.String("Query", currentQuery), zap.String("Identifier", currentPs)) foo = false // check if the query for mock ps (v
------------------

--- Chunk 27---
Function PreparedStatementMatch (part 3): .PreparedStatement) is same as the current query for _, querydata := range recordedPrep[mockConn] { if querydata.Query == currentQuery && mockBinds[idx].PreparedStatement == querydata.PrepIdentifier { logger.Debug("Matched with the recorded prepared statement with Identifier and connectionID is", zap.String("Identifier", querydata.PrepIdentifier), zap.String("ConnectionId", mockConn), zap.String("Current Identifier", currentPs), zap.String("Query", currentQuery)) foo = true break } } // this means we are unable to find the query in recordedPrep or the prepared statement is not same if !foo { break } } if !foo { return false, nil, nil } parses := actualPgReq.Parses mockParses := mock.Spec.PostgresRequests[0].Parses // If the client sent a different number of Parse messages than the mock // recorded, the two batches canâ€™t possibly align, so we can return early // instead of walking the loop and risking panic due to outâ€‘ofâ€‘bounds. if len(parses) != len(mock
------------------

--- Chunk 28---
Function PreparedStatementMatch (end): Parses) { logger.Debug("len of parse in actual request is not equal to len of parse in mock", zap.String("mock name", mock.Name)) return false, nil, nil } foo = true // check if all parse queries in pg request is same for the corresponding query in mock for idx, parse := range parses { if parse.Query != mockParses[idx].Query { logger.Debug(fmt.Sprintf("parse query for actual request is not equal to parse query for mock name: %s, at index: %d", mock.Name, idx)) foo = false // if any parse query is not same then break, mock didn't match break } } if foo { return true, newBinPreparedStatement, nil } return false, nil, nil }
------------------

--- Chunk 29---
Function compareExactMatch (start): func compareExactMatch(mock *models.Mock, actualPgReq *models.Backend, logger *zap.Logger) (bool, error) { logger.Debug("Inside CompareExactMatch") // have to ignore first parse message of begin read only // should compare only query in the parse message if len(actualPgReq.PacketTypes) != len(mock.Spec.PostgresRequests[0].PacketTypes) { return false, nil } // call a separate function for matching prepared statements for idx, v := range actualPgReq.PacketTypes { if v != mock.Spec.PostgresRequests[0].PacketTypes[idx] { return false, nil } } // IsPreparedStatement(mock, actualPgReq, logger, ConnectionId) // this will give me the var ( p, b, e = 0, 0, 0 ) for i := 0; i < len(actualPgReq.PacketTypes); i++ { switch actualPgReq.PacketTypes[i] { case "P": // logger.Debug("Inside P") p++ if actualPgReq.Parses[p-1].Query != mock.Spec.PostgresRequests[0].Parses[p-
------------------

--- Chunk 30---
Function compareExactMatch (part 2): 1].Query { return false, nil } if actualPgReq.Parses[p-1].Name != mock.Spec.PostgresRequests[0].Parses[p-1].Name { return false, nil } if len(actualPgReq.Parses[p-1].ParameterOIDs) != len(mock.Spec.PostgresRequests[0].Parses[p-1].ParameterOIDs) { return false, nil } for j := 0; j < len(actualPgReq.Parses[p-1].ParameterOIDs); j++ { if actualPgReq.Parses[p-1].ParameterOIDs[j] != mock.Spec.PostgresRequests[0].Parses[p-1].ParameterOIDs[j] { return false, nil } } case "B": // logger.Debug("Inside B") b++ if actualPgReq.Binds[b-1].DestinationPortal != mock.Spec.PostgresRequests[0].Binds[b-1].DestinationPortal { return false, nil } if actualPgReq.Binds[b-1].PreparedStatement != mock.Spec.PostgresRequests[0
------------------

--- Chunk 31---
Function compareExactMatch (part 3): ].Binds[b-1].PreparedStatement { return false, nil } if len(actualPgReq.Binds[b-1].ParameterFormatCodes) != len(mock.Spec.PostgresRequests[0].Binds[b-1].ParameterFormatCodes) { return false, nil } for j := 0; j < len(actualPgReq.Binds[b-1].ParameterFormatCodes); j++ { if actualPgReq.Binds[b-1].ParameterFormatCodes[j] != mock.Spec.PostgresRequests[0].Binds[b-1].ParameterFormatCodes[j] { return false, nil } } if len(actualPgReq.Binds[b-1].Parameters) != len(mock.Spec.PostgresRequests[0].Binds[b-1].Parameters) { return false, nil } for j := 0; j < len(actualPgReq.Binds[b-1].Parameters); j++ { // parameter represents a timestamp value do not compare it just continue if isTimestamp(actualPgReq.Binds[b-1].Parameters[j]) { logger.Debug("found a timestamp value") continue } if isB
------------------

--- Chunk 32---
Function compareExactMatch (part 4): cryptHash(actualPgReq.Binds[b-1].Parameters[j]) { logger.Debug("found a bcrypt hash") continue } for i, v := range actualPgReq.Binds[b-1].Parameters[j] { if v != mock.Spec.PostgresRequests[0].Binds[b-1].Parameters[j][i] { return false, nil } } } if len(actualPgReq.Binds[b-1].ResultFormatCodes) != len(mock.Spec.PostgresRequests[0].Binds[b-1].ResultFormatCodes) { return false, nil } for j := 0; j < len(actualPgReq.Binds[b-1].ResultFormatCodes); j++ { if actualPgReq.Binds[b-1].ResultFormatCodes[j] != mock.Spec.PostgresRequests[0].Binds[b-1].ResultFormatCodes[j] { return false, nil } } case "E": // logger.Debug("Inside E") e++ if actualPgReq.Executes[e-1].Portal != mock.Spec.PostgresRequests[0].Executes[e-1].Portal {
------------------

--- Chunk 33---
Function compareExactMatch (end): return false, nil } if actualPgReq.Executes[e-1].MaxRows != mock.Spec.PostgresRequests[0].Executes[e-1].MaxRows { return false, nil } case "c": if actualPgReq.CopyDone != mock.Spec.PostgresRequests[0].CopyDone { return false, nil } case "H": if actualPgReq.CopyFail.Message != mock.Spec.PostgresRequests[0].CopyFail.Message { return false, nil } case "Q": if actualPgReq.Query.String != mock.Spec.PostgresRequests[0].Query.String { if LaevensteinDistance(actualPgReq.Query.String, mock.Spec.PostgresRequests[0].Query.String) { logger.Debug("The strings are more than 90%% similar.") } return false, nil } default: return false, nil } } return true, nil }
------------------

--- Chunk 34---
func LaevensteinDistance(str1, str2 string) bool { // Compute the Levenshtein distance distance := levenshtein.ComputeDistance(str1, str2) maxLength := max(len(str1), len(str2)) similarity := (1 - float64(distance)/float64(maxLength)) * 100 // Check if similarity is greater than 90% return similarity > 90 }
------------------

--- Chunk 35---
Function validateMock (start): func validateMock(tcsMocks []*models.Mock, idx int, requestBuffers [][]byte, logger *zap.Logger) (bool, *models.Mock) { actualPgReq := decodePgRequest(requestBuffers[0], logger) if actualPgReq == nil { return true, nil } mock := tcsMocks[idx].Spec.PostgresRequests[0] if len(mock.PacketTypes) == len(actualPgReq.PacketTypes) { if reflect.DeepEqual(tcsMocks[idx].Spec.PostgresRequests[0].PacketTypes, []string{"B", "E", "P", "B", "D", "E"}) { if mock.Parses[0].Query == actualPgReq.Parses[0].Query { return true, nil } } if reflect.DeepEqual(mock.PacketTypes, []string{"B", "E", "B", "E"}) { // logger.Debug("Inside Validate Mock for B, E, B, E") return true, nil } if reflect.DeepEqual(mock.PacketTypes, []string{"B", "E"}) { // logger.Debug("Inside Validate Mock for B, E") copyMock := *tcsMocks[idx] copy
------------------

--- Chunk 36---
Function validateMock (part 2): Mock.Spec.PostgresResponses[0].PacketTypes = []string{"2", "C", "Z"} copyMock.Spec.PostgresResponses[0].Payload = "" return false, &copyMock } if reflect.DeepEqual(mock.PacketTypes, []string{"P", "B", "D", "E"}) { // logger.Debug("Inside Validate Mock for P, B, D, E") copyMock := *tcsMocks[idx] copyMock.Spec.PostgresResponses[0].PacketTypes = []string{"1", "2", "T", "C", "Z"} copyMock.Spec.PostgresResponses[0].Payload = "" return false, &copyMock } } else { // [B, E, P, B, D, E] => [ P, B, D, E] if reflect.DeepEqual(mock.PacketTypes, []string{"B", "E", "P", "B", "D", "E"}) && reflect.DeepEqual(actualPgReq.PacketTypes, []string{"P", "B", "D", "E"}) { // logger.Debug("Inside Validate Mock for B, E, B, E") if mock.Pars
------------------

--- Chunk 37---
Function validateMock (end): es[0].Query == actualPgReq.Parses[0].Query { // no need to do anything copyMock := *tcsMocks[idx] copyMock.Spec.PostgresResponses[0].PacketTypes = []string{"1", "2", "T", "C", "Z"} copyMock.Spec.PostgresResponses[0].Payload = "" copyMock.Spec.PostgresResponses[0].CommandCompletes = copyMock.Spec.PostgresResponses[0].CommandCompletes[1:] return false, &copyMock } } } return true, nil }
------------------

--- Chunk 38---
func isTimestamp(byteArray []byte) bool { // Convert byte array to string s := string(byteArray) // Define a regex for ISO 8601 timestamps timestampRegex := regexp.MustCompile(`\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}(.\d+)?(Z)?`) return timestampRegex.MatchString(s) }
------------------

--- Chunk 39---
func isBcryptHash(byteArray []byte) bool { // Convert byte array to string s := string(byteArray) // Define a regex for bcrypt hashes bcryptRegex := regexp.MustCompile(`^\$2[aby]\$\d{2}\$[./A-Za-z0-9]{53}$`) return bcryptRegex.MatchString(s) }
------------------

--- File: pkg/core/proxy/integrations/postgres/v1/postgres.go---

--- Chunk 1---
func init() { integrations.Register(integrations.POSTGRES_V1, &integrations.Parsers{ Initializer: New, Priority: 100, }) }
------------------

--- Chunk 2---
func New(logger *zap.Logger) integrations.Integrations { return &PostgresV1{ logger: logger, } }
------------------

--- Chunk 3---
func (p *PostgresV1) MatchType(_ context.Context, reqBuf []byte) bool { const ProtocolVersion = 0x00030000 // Protocol version 3.0 if len(reqBuf) < 8 { // Not enough data for a complete header return false } // The first four bytes are the message length, but we don't need to check those // The next four bytes are the protocol version version := binary.BigEndian.Uint32(reqBuf[4:8]) if version == 80877103 { return true } return version == ProtocolVersion }
------------------

--- Chunk 4---
func (p *PostgresV1) RecordOutgoing(ctx context.Context, src net.Conn, dst net.Conn, mocks chan<- *models.Mock, opts models.OutgoingOptions) error { logger := p.logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", src.RemoteAddr().String())) reqBuf, err := util.ReadInitialBuf(ctx, logger, src) if err != nil { utils.LogError(logger, err, "failed to read the initial postgres message") return err } err = encodePostgres(ctx, logger, reqBuf, src, dst, mocks, opts) if err != nil { // TODO: why debug log? logger.Debug("failed to encode the postgres message into the yaml") return err } return nil }
------------------

--- Chunk 5---
func (p *PostgresV1) MockOutgoing(ctx context.Context, src net.Conn, dstCfg *models.ConditionalDstCfg, mockDb integrations.MockMemDb, opts models.OutgoingOptions) error { logger := p.logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", src.RemoteAddr().String())) reqBuf, err := util.ReadInitialBuf(ctx, logger, src) if err != nil { utils.LogError(logger, err, "failed to read the initial postgres message") return err } err = decodePostgres(ctx, logger, reqBuf, src, dstCfg, mockDb, opts) if err != nil { logger.Debug("failed to decode the postgres message from the yaml") return err } return nil }
------------------

--- File: pkg/core/proxy/integrations/postgres/v1/transcoder.go---

--- Chunk 1---
func NewBackend() *BackendWrapper { return &BackendWrapper{} }
------------------

--- Chunk 2---
func NewFrontend() *FrontendWrapper { return &FrontendWrapper{} }
------------------

--- Chunk 3---
Function translateToReadableBackend (start): func (b *BackendWrapper) translateToReadableBackend(msgBody []byte) (pgproto3.FrontendMessage, error) { // fmt.Println("msgType", b.BackendWrapper.MsgType) var msg pgproto3.FrontendMessage switch b.BackendWrapper.MsgType { case 'B': msg = &b.BackendWrapper.Bind case 'C': msg = &b.BackendWrapper.Close case 'D': msg = &b.BackendWrapper.Describe case 'E': msg = &b.BackendWrapper.Execute case 'F': msg = &b.BackendWrapper.FunctionCall case 'f': msg = &b.BackendWrapper.CopyFail case 'd': msg = &b.BackendWrapper.CopyData case 'c': msg = &b.BackendWrapper.CopyDone case 'H': msg = &b.BackendWrapper.Flush case 'P': msg = &b.BackendWrapper.Parse case 'p': switch b.BackendWrapper.AuthType { case pgproto3.AuthTypeSASL: msg = &pgproto3.SASLInitialResponse{} case pgproto3.AuthTypeSASLContinue:
------------------

--- Chunk 4---
Function translateToReadableBackend (end): msg = &pgproto3.SASLResponse{} case pgproto3.AuthTypeSASLFinal: msg = &pgproto3.SASLResponse{} case pgproto3.AuthTypeGSS, pgproto3.AuthTypeGSSCont: msg = &pgproto3.GSSResponse{} case pgproto3.AuthTypeCleartextPassword, pgproto3.AuthTypeMD5Password: fallthrough default: // to maintain backwards compatability msg = &pgproto3.PasswordMessage{} } case 'Q': msg = &b.BackendWrapper.Query case 'S': msg = &b.BackendWrapper.Sync case 'X': msg = &b.BackendWrapper.Terminate default: return nil, fmt.Errorf("unknown message type: %c", b.BackendWrapper.MsgType) } err := msg.Decode(msgBody[5:]) if b.BackendWrapper.MsgType == 'P' { *msg.(*pgproto3.Parse) = b.BackendWrapper.Parse } return msg, err }
------------------

--- Chunk 5---
Function translateToReadableResponse (start): func (f *FrontendWrapper) translateToReadableResponse(logger *zap.Logger, msgBody []byte) (pgproto3.BackendMessage, error) { f.FrontendWrapper.BodyLen = int(binary.BigEndian.Uint32(msgBody[1:])) - 4 f.FrontendWrapper.MsgType = msgBody[0] var msg pgproto3.BackendMessage switch f.FrontendWrapper.MsgType { case '1': msg = &f.FrontendWrapper.ParseComplete case '2': msg = &f.FrontendWrapper.BindComplete case '3': msg = &f.FrontendWrapper.CloseComplete case 'A': msg = &f.FrontendWrapper.NotificationResponse case 'c': msg = &f.FrontendWrapper.CopyDone case 'C': msg = &f.FrontendWrapper.CommandComplete case 'd': msg = &f.FrontendWrapper.CopyData case 'D': msg = &f.FrontendWrapper.DataRow logger.Debug("Data Row", zap.String("data", string(msgBody))) case 'E': msg = &f.FrontendWrapper.ErrorResponse case 'G': msg = &
------------------

--- Chunk 6---
Function translateToReadableResponse (part 2): f.FrontendWrapper.CopyInResponse case 'H': msg = &f.FrontendWrapper.CopyOutResponse case 'I': msg = &f.FrontendWrapper.EmptyQueryResponse case 'K': msg = &f.FrontendWrapper.BackendKeyData case 'n': msg = &f.FrontendWrapper.NoData case 'N': msg = &f.FrontendWrapper.NoticeResponse case 'R': var err error msg, err = f.findAuthMsgType(msgBody) if err != nil { return nil, err } case 's': msg = &f.FrontendWrapper.PortalSuspended case 'S': msg = &f.FrontendWrapper.ParameterStatus case 't': msg = &f.FrontendWrapper.ParameterDescription case 'T': msg = &f.FrontendWrapper.RowDescription case 'V': msg = &f.FrontendWrapper.FunctionCallResponse case 'W': msg = &f.FrontendWrapper.CopyBothResponse case 'Z': msg = &f.FrontendWrapper.ReadyForQuery default: return nil, fmt
------------------

--- Chunk 7---
Function translateToReadableResponse (end): .Errorf("unknown message type: %c", f.FrontendWrapper.MsgType) } logger.Debug("msgFrontend", zap.String("msgFrontend", string(msgBody))) err := msg.Decode(msgBody[5:]) if err != nil { utils.LogError(logger, err, "Error from decoding request message") } bits := msg.Encode([]byte{}) // println("Length of bits", len(bits), "Length of msgBody", len(msgBody)) if len(bits) != len(msgBody) { logger.Debug("Encoded Data doesn't match the original data ..") } return msg, err }
------------------

--- Chunk 8---
Function decodeStartupMessage (start): func (b *BackendWrapper) decodeStartupMessage(buf []byte) (pgproto3.FrontendMessage, error) { reader := pgproto3.NewByteReader(buf) buf, err := reader.Next(4) if err != nil { return nil, err } msgSize := int(binary.BigEndian.Uint32(buf) - 4) if msgSize < minStartupPacketLen || msgSize > maxStartupPacketLen { return nil, fmt.Errorf("invalid length of startup packet: %d", msgSize) } buf, err = reader.Next(msgSize) if err != nil { return nil, fmt.Errorf("invalid length of startup packet: %d", msgSize) } code := binary.BigEndian.Uint32(buf) switch code { case ProtocolVersionNumber: err := b.BackendWrapper.StartupMessage.Decode(buf) if err != nil { return nil, err } return &b.BackendWrapper.StartupMessage, nil case sslRequestNumber: err := b.BackendWrapper.SSlRequest.Decode(buf) if err != nil { return nil, err } return &b.BackendWrapper.SSlRequest, nil case cancelRequestCode: err :=
------------------

--- Chunk 9---
Function decodeStartupMessage (end): b.BackendWrapper.CancelRequest.Decode(buf) if err != nil { return nil, err } return &b.BackendWrapper.CancelRequest, nil case gssEncReqNumber: err := b.BackendWrapper.GssEncRequest.Decode(buf) if err != nil { return nil, err } return &b.BackendWrapper.GssEncRequest, nil default: return nil, fmt.Errorf("unknown startup message code: %d", code) } }
------------------

--- Chunk 10---
Function findAuthMsgType (start): func (f *FrontendWrapper) findAuthMsgType(src []byte) (pgproto3.BackendMessage, error) { if len(src) < 4 { return nil, errors.New("authentication message too short") } authType, err := parseAuthType(src) if err != nil { return nil, err } f.FrontendWrapper.AuthType = authType switch f.FrontendWrapper.AuthType { case pgproto3.AuthTypeOk: return &f.FrontendWrapper.AuthenticationOk, nil case pgproto3.AuthTypeCleartextPassword: return &f.FrontendWrapper.AuthenticationCleartextPassword, nil case pgproto3.AuthTypeMD5Password: return &f.FrontendWrapper.AuthenticationMD5Password, nil case pgproto3.AuthTypeSCMCreds: return nil, errors.New("AuthTypeSCMCreds is unimplemented") case pgproto3.AuthTypeGSS: return &f.FrontendWrapper.AuthenticationGSS, nil case pgproto3.AuthTypeGSSCont: return &f.FrontendWrapper.AuthenticationGSSContinue, nil case pgproto3.AuthTypeSSPI: return nil, errors.New
------------------

--- Chunk 11---
Function findAuthMsgType (end): ("AuthTypeSSPI is unimplemented") case pgproto3.AuthTypeSASL: return &f.FrontendWrapper.AuthenticationSASL, nil case pgproto3.AuthTypeSASLContinue: return &f.FrontendWrapper.AuthenticationSASLContinue, nil case pgproto3.AuthTypeSASLFinal: return &f.FrontendWrapper.AuthenticationSASLFinal, nil default: return nil, fmt.Errorf("unknown authentication type: %d", f.FrontendWrapper.AuthType) } }
------------------

--- Chunk 12---
func parseAuthType(buffer []byte) (int32, error) { // Create a bytes reader from the buffer reader := bytes.NewReader(buffer) // Skip the message type (1 byte) as you know it's 'R' _, err := reader.Seek(1, 0) if err != nil { return 0, err } // Read the length of the message (4 bytes) var length int32 err = binary.Read(reader, binary.BigEndian, &length) if err != nil { return 0, err } // Read the auth type code (4 bytes) var authType int32 err = binary.Read(reader, binary.BigEndian, &authType) if err != nil { return 0, err } return authType, nil }
------------------

--- Chunk 13---
func isStartupPacket(packet []byte) bool { protocolVersion := binary.BigEndian.Uint32(packet[4:8]) // printStartupPacketDetails(packet) return protocolVersion == 196608 // 3.0 in PostgreSQL }
------------------

--- File: pkg/core/proxy/integrations/postgres/v1/util.go---

--- Chunk 1---
Function postgresDecoderFrontend (start): func postgresDecoderFrontend(response models.Frontend) ([]byte, error) { var resbuffer []byte // list of packets available in the buffer packets := response.PacketTypes var cc, dtr, ps = 0, 0, 0 for _, packet := range packets { var msg pgproto3.BackendMessage switch packet { case string('1'): msg = &pgproto3.ParseComplete{} case string('2'): msg = &pgproto3.BindComplete{} case string('3'): msg = &pgproto3.CloseComplete{} case string('A'): msg = &pgproto3.NotificationResponse{ PID: response.NotificationResponse.PID, Channel: response.NotificationResponse.Channel, Payload: response.NotificationResponse.Payload, } case string('c'): msg = &pgproto3.CopyDone{} case string('C'): if len(response.CommandCompletes) == 0 { cc++ continue } msg = &pgproto3.CommandComplete{ CommandTag: response.CommandCompletes[cc].CommandTag, CommandTagType: response.CommandCompletes[cc].CommandTag
------------------

--- Chunk 2---
Function postgresDecoderFrontend (part 2): Type, } cc++ case string('d'): msg = &pgproto3.CopyData{ Data: response.CopyData.Data, } case string('D'): msg = &pgproto3.DataRow{ RowValues: response.DataRows[dtr].RowValues, Values: response.DataRows[dtr].Values, } dtr++ case string('E'): msg = &pgproto3.ErrorResponse{ Severity: response.ErrorResponse.Severity, Code: response.ErrorResponse.Code, Message: response.ErrorResponse.Message, Detail: response.ErrorResponse.Detail, Hint: response.ErrorResponse.Hint, Position: response.ErrorResponse.Position, InternalPosition: response.ErrorResponse.InternalPosition, InternalQuery: response.ErrorResponse.InternalQuery, Where: response.ErrorResponse.Where, SchemaName: response.ErrorResponse.SchemaName, TableName: response.ErrorResponse.TableName, ColumnName: response.ErrorResponse.ColumnName, DataTypeName: response.ErrorResponse.DataTypeName, ConstraintName: response.ErrorResponse.ConstraintName, File: response.Error
------------------

--- Chunk 3---
Function postgresDecoderFrontend (part 3): Response.File, Line: response.ErrorResponse.Line, Routine: response.ErrorResponse.Routine, } case string('G'): msg = &pgproto3.CopyInResponse{ OverallFormat: response.CopyInResponse.OverallFormat, ColumnFormatCodes: response.CopyInResponse.ColumnFormatCodes, } case string('H'): msg = &pgproto3.CopyOutResponse{ OverallFormat: response.CopyOutResponse.OverallFormat, ColumnFormatCodes: response.CopyOutResponse.ColumnFormatCodes, } case string('I'): msg = &pgproto3.EmptyQueryResponse{} case string('K'): msg = &pgproto3.BackendKeyData{ ProcessID: response.BackendKeyData.ProcessID, SecretKey: response.BackendKeyData.SecretKey, } case string('n'): msg = &pgproto3.NoData{} case string('N'): msg = &pgproto3.NoticeResponse{ Severity: response.NoticeResponse.Severity, Code: response.NoticeResponse.Code, Message: response.NoticeResponse.Message, Detail
------------------

--- Chunk 4---
Function postgresDecoderFrontend (part 4): : response.NoticeResponse.Detail, Hint: response.NoticeResponse.Hint, Position: response.NoticeResponse.Position, InternalPosition: response.NoticeResponse.InternalPosition, InternalQuery: response.NoticeResponse.InternalQuery, Where: response.NoticeResponse.Where, SchemaName: response.NoticeResponse.SchemaName, TableName: response.NoticeResponse.TableName, ColumnName: response.NoticeResponse.ColumnName, DataTypeName: response.NoticeResponse.DataTypeName, ConstraintName: response.NoticeResponse.ConstraintName, File: response.NoticeResponse.File, Line: response.NoticeResponse.Line, Routine: response.NoticeResponse.Routine, } case string('R'): switch response.AuthType { case AuthTypeOk: msg = &pgproto3.AuthenticationOk{} case AuthTypeCleartextPassword: msg = &pgproto3.AuthenticationCleartextPassword{} case AuthTypeMD5Password: msg = &pgproto3.AuthenticationMD5Password{} case AuthTypeSCMCreds: return nil, errors.New("AuthTypeSCMCreds is
------------------

--- Chunk 5---
Function postgresDecoderFrontend (part 5): unimplemented") case AuthTypeGSS: return nil, errors.New("AuthTypeGSS is unimplemented") case AuthTypeGSSCont: msg = &pgproto3.AuthenticationGSSContinue{} case AuthTypeSSPI: return nil, errors.New("AuthTypeSSPI is unimplemented") case AuthTypeSASL: msg = &pgproto3.AuthenticationSASL{} case AuthTypeSASLContinue: msg = &pgproto3.AuthenticationSASLContinue{} case AuthTypeSASLFinal: msg = &pgproto3.AuthenticationSASLFinal{} default: return nil, fmt.Errorf("unknown authentication type: %d", response.AuthType) } case string('s'): msg = &pgproto3.PortalSuspended{} case string('S'): msg = &pgproto3.ParameterStatus{ Name: response.ParameterStatusCombined[ps].Name, Value: response.ParameterStatusCombined[ps].Value, } ps++ case string('t'): msg = &pgproto3.ParameterDescription{ ParameterOIDs: response.ParameterDescription.ParameterOIDs, } case string('
------------------

--- Chunk 6---
Function postgresDecoderFrontend (end): T'): msg = &pgproto3.RowDescription{ Fields: response.RowDescription.Fields, } case string('V'): msg = &pgproto3.FunctionCallResponse{ Result: response.FunctionCallResponse.Result, } case string('W'): msg = &pgproto3.CopyBothResponse{ OverallFormat: response.CopyBothResponse.OverallFormat, ColumnFormatCodes: response.CopyBothResponse.ColumnFormatCodes, } case string('Z'): msg = &pgproto3.ReadyForQuery{ TxStatus: response.ReadyForQuery.TxStatus, } default: return nil, fmt.Errorf("unknown message type: %q", packet) } encoded := msg.Encode([]byte{}) resbuffer = append(resbuffer, encoded...) } return resbuffer, nil }
------------------

--- Chunk 7---
Function postgresDecoderBackend (start): func postgresDecoderBackend(request models.Backend) ([]byte, error) { // take each object , try to make it frontend or backend message so that it can call it's corresponding encode function // and then append it to the buffer, for a particular mock .. var reqbuffer []byte // list of packets available in the buffer var b, e, p = 0, 0, 0 packets := request.PacketTypes for _, packet := range packets { var msg pgproto3.FrontendMessage switch packet { case string('B'): msg = &pgproto3.Bind{ DestinationPortal: request.Binds[b].DestinationPortal, PreparedStatement: request.Binds[b].PreparedStatement, ParameterFormatCodes: request.Binds[b].ParameterFormatCodes, Parameters: request.Binds[b].Parameters, ResultFormatCodes: request.Binds[b].ResultFormatCodes, } b++ case string('C'): msg = &pgproto3.Close{ Object_Type: request.Close.Object_Type, Name: request.Close.Name, } case string('D'): msg = &pgproto3.Describe{
------------------

--- Chunk 8---
Function postgresDecoderBackend (part 2): ObjectType: request.Describe.ObjectType, Name: request.Describe.Name, } case string('E'): msg = &pgproto3.Execute{ Portal: request.Executes[e].Portal, MaxRows: request.Executes[e].MaxRows, } e++ case string('F'): // *msg.(*pgproto3.Flush) = request.Flush msg = &pgproto3.Flush{} case string('f'): // *msg.(*pgproto3.FunctionCall) = request.FunctionCall msg = &pgproto3.FunctionCall{ Function: request.FunctionCall.Function, Arguments: request.FunctionCall.Arguments, ArgFormatCodes: request.FunctionCall.ArgFormatCodes, ResultFormatCode: request.FunctionCall.ResultFormatCode, } case string('d'): msg = &pgproto3.CopyData{ Data: request.CopyData.Data, } case string('c'): msg = &pgproto3.CopyDone{} case string('H'): msg = &pgproto3.CopyFail{ Message: request.CopyFail.Message, } case string('P'): msg
------------------

--- Chunk 9---
Function postgresDecoderBackend (part 3): = &pgproto3.Parse{ Name: request.Parses[p].Name, Query: request.Parses[p].Query, ParameterOIDs: request.Parses[p].ParameterOIDs, } p++ case string('p'): switch request.AuthType { case pgproto3.AuthTypeSASL: msg = &pgproto3.SASLInitialResponse{ AuthMechanism: request.SASLInitialResponse.AuthMechanism, Data: request.SASLInitialResponse.Data, } case pgproto3.AuthTypeSASLContinue: msg = &pgproto3.SASLResponse{ Data: request.SASLResponse.Data, } case pgproto3.AuthTypeSASLFinal: msg = &pgproto3.SASLResponse{ Data: request.SASLResponse.Data, } case pgproto3.AuthTypeGSS, pgproto3.AuthTypeGSSCont: msg = &pgproto3.GSSResponse{ Data: []byte{}, // TODO: implement } case pgproto3.AuthTypeCleartextPassword, pgproto3.AuthType
------------------

--- Chunk 10---
Function postgresDecoderBackend (end): MD5Password: fallthrough default: // to maintain backwards compatability msg = &pgproto3.PasswordMessage{Password: request.PasswordMessage.Password} } case string('Q'): msg = &pgproto3.Query{ String: request.Query.String, } case string('S'): msg = &pgproto3.Sync{} case string('X'): // *msg.(*pgproto3.Terminate) = request.Terminate msg = &pgproto3.Terminate{} default: return nil, fmt.Errorf("unknown message type: %q", packet) } if msg == nil { return nil, errors.New("msg is nil") } encoded := msg.Encode([]byte{}) reqbuffer = append(reqbuffer, encoded...) } return reqbuffer, nil }
------------------

--- Chunk 11---
func checkIfps(array []string) bool { n := len(array) if n%2 != 0 { // If the array length is odd, it cannot match the pattern return false } for i := 0; i < n; i += 2 { // Check if consecutive elements are "B" and "E" if array[i] != "B" || array[i+1] != "E" { return false } } return true }
------------------

--- Chunk 12---
Function sliceCommandTag (start): func sliceCommandTag(mock *models.Mock, logger *zap.Logger, prep []QueryData, actualPgReq *models.Backend, psCase int) *models.Mock { logger.Debug("Inside Slice Command Tag for ", zap.Int("psCase", psCase)) logger.Debug("Prep Query Data", zap.Any("prep", prep)) switch psCase { case 1: copyMock := *mock // fmt.Println("Inside Slice Command Tag for ", psCase) mockPackets := copyMock.Spec.PostgresResponses[0].PacketTypes for idx, v := range mockPackets { if v == "1" { mockPackets = append(mockPackets[:idx], mockPackets[idx+1:]...) } } copyMock.Spec.PostgresResponses[0].Payload = "" copyMock.Spec.PostgresResponses[0].PacketTypes = mockPackets return &copyMock case 2: // ["2", D, C, Z] copyMock := *mock // fmt.Println("Inside Slice Command Tag for ", psCase) mockPackets := copyMock.Spec.PostgresResponses[0].PacketTypes for idx, v
------------------

--- Chunk 13---
Function sliceCommandTag (end): := range mockPackets { if v == "1" || v == "T" { mockPackets = append(mockPackets[:idx], mockPackets[idx+1:]...) } } copyMock.Spec.PostgresResponses[0].Payload = "" copyMock.Spec.PostgresResponses[0].PacketTypes = mockPackets rsFormat := actualPgReq.Bind.ResultFormatCodes for idx, datarow := range copyMock.Spec.PostgresResponses[0].DataRows { for column, rowVal := range datarow.RowValues { // fmt.Println("datarow.RowValues", len(datarow.RowValues)) if rsFormat[column] == 1 { // datarows := make([]byte, 4) newRow, _ := getChandedDataRow(rowVal) // logger.Info("New Row Value", zap.String("newRow", newRow)) copyMock.Spec.PostgresResponses[0].DataRows[idx].RowValues[column] = newRow } } } return &copyMock default: } return nil }
------------------

--- Chunk 14---
func getChandedDataRow(input string) (string, error) { // Convert input1 (integer input as string) to integer buffer := make([]byte, 4) if uintValue, err := strconv.ParseUint(input, 10, 32); err == nil { binary.BigEndian.PutUint32(buffer, uint32(uintValue)) return "b64:" + util.EncodeBase64(buffer), nil } else if dateValue, err := time.Parse("2006-01-02", input); err == nil { // Perform additional operations on the date epoch := time.Date(2000, 1, 1, 0, 0, 0, 0, time.UTC) difference := dateValue.Sub(epoch).Hours() / 24 // fmt.Printf("Difference in days from epoch: %.2f days\n", difference) binary.BigEndian.PutUint32(buffer, uint32(difference)) return "b64:" + util.EncodeBase64(buffer), nil } return "b64:AAAAAA==", errors.New("invalid input") }
------------------

--- Chunk 15---
Function decodePgRequest (start): func decodePgRequest(buffer []byte, logger *zap.Logger) *models.Backend { pg := NewBackend() if !isStartupPacket(buffer) && len(buffer) > 5 { bufferCopy := buffer for i := 0; i < len(bufferCopy)-5; { pg.BackendWrapper.MsgType = buffer[i] pg.BackendWrapper.BodyLen = int(binary.BigEndian.Uint32(buffer[i+1:])) - 4 if len(buffer) < (i + pg.BackendWrapper.BodyLen + 5) { logger.Debug("failed to translate the postgres request message due to shorter network packet buffer") break } msg, err := pg.translateToReadableBackend(buffer[i:(i + pg.BackendWrapper.BodyLen + 5)]) if err != nil && buffer[i] != 112 { logger.Debug("failed to translate the request message to readable", zap.Error(err)) } if pg.BackendWrapper.MsgType == 'p' { pg.BackendWrapper.PasswordMessage = *msg.(*pgproto3.PasswordMessage) } if pg.BackendWrapper.MsgType == 'P' { pg.BackendWrapper.Parse = *
------------------

--- Chunk 16---
Function decodePgRequest (part 2): msg.(*pgproto3.Parse) pg.BackendWrapper.Parses = append(pg.BackendWrapper.Parses, pg.BackendWrapper.Parse) } if pg.BackendWrapper.MsgType == 'B' { pg.BackendWrapper.Bind = *msg.(*pgproto3.Bind) pg.BackendWrapper.Binds = append(pg.BackendWrapper.Binds, pg.BackendWrapper.Bind) } if pg.BackendWrapper.MsgType == 'E' { pg.BackendWrapper.Execute = *msg.(*pgproto3.Execute) pg.BackendWrapper.Executes = append(pg.BackendWrapper.Executes, pg.BackendWrapper.Execute) } pg.BackendWrapper.PacketTypes = append(pg.BackendWrapper.PacketTypes, string(pg.BackendWrapper.MsgType)) i += 5 + pg.BackendWrapper.BodyLen } pgMock := &models.Backend{ PacketTypes: pg.BackendWrapper.PacketTypes, Identfier: "ClientRequest", Length: uint32(len(buffer)), // Payload: bufStr, Bind: pg.BackendWrapper.Bind, Binds: pg.Back
------------------

--- Chunk 17---
Function decodePgRequest (part 3): endWrapper.Binds, PasswordMessage: pg.BackendWrapper.PasswordMessage, CancelRequest: pg.BackendWrapper.CancelRequest, Close: pg.BackendWrapper.Close, CopyData: pg.BackendWrapper.CopyData, CopyDone: pg.BackendWrapper.CopyDone, CopyFail: pg.BackendWrapper.CopyFail, Describe: pg.BackendWrapper.Describe, Execute: pg.BackendWrapper.Execute, Executes: pg.BackendWrapper.Executes, Flush: pg.BackendWrapper.Flush, FunctionCall: pg.BackendWrapper.FunctionCall, GssEncRequest: pg.BackendWrapper.GssEncRequest, Parse: pg.BackendWrapper.Parse, Parses: pg.BackendWrapper.Parses, Query: pg.BackendWrapper.Query, SSlRequest: pg.BackendWrapper.SSlRequest, StartupMessage: pg.BackendWrapper.StartupMessage, SASLInitialResponse: pg.BackendWrapper.SASLInitialResponse, SASLResponse: pg.BackendWrapper.SASLResponse, Sync:
------------------

--- Chunk 18---
Function decodePgRequest (end): pg.BackendWrapper.Sync, Terminate: pg.BackendWrapper.Terminate, MsgType: pg.BackendWrapper.MsgType, AuthType: pg.BackendWrapper.AuthType, } return pgMock } return nil }
------------------

--- Chunk 19---
func mergePgRequests(requestBuffers [][]byte, logger *zap.Logger) [][]byte { // Check for PBDE first var mergeBuff []byte for _, v := range requestBuffers { backend := decodePgRequest(v, logger) if backend == nil { logger.Debug("Rerurning nil while merging ") break } buf, _ := postgresDecoderBackend(*backend) mergeBuff = append(mergeBuff, buf...) } if len(mergeBuff) > 0 { return [][]byte{mergeBuff} } return requestBuffers }
------------------

--- Chunk 20---
func mergeMocks(pgmocks []models.Backend, logger *zap.Logger) []models.Backend { if len(pgmocks) == 0 { return pgmocks } // Check for PBDE first if len(pgmocks[0].PacketTypes) == 0 || pgmocks[0].PacketTypes[0] != "P" { return pgmocks } var mergeBuff []byte for _, v := range pgmocks { buf, _ := postgresDecoderBackend(v) mergeBuff = append(mergeBuff, buf...) } if len(mergeBuff) > 0 { return []models.Backend{*decodePgRequest(mergeBuff, logger)} } return pgmocks }
------------------

--- File: pkg/core/proxy/integrations/redis/decode.go---

--- Chunk 1---
Function decodeRedis (start): func decodeRedis(ctx context.Context, logger *zap.Logger, reqBuf []byte, clientConn net.Conn, dstCfg *models.ConditionalDstCfg, mockDb integrations.MockMemDb, _ models.OutgoingOptions) error { redisRequests := [][]byte{reqBuf} logger.Debug("Into the redis parser in test mode") errCh := make(chan error, 1) go func(errCh chan error, redisRequests [][]byte) { defer pUtil.Recover(logger, clientConn, nil) defer close(errCh) for { // Read the stream of request packets from the client for len(redisRequests) == 0 { err := clientConn.SetReadDeadline(time.Now().Add(10 * time.Millisecond)) if err != nil { utils.LogError(logger, err, "failed to set the read deadline for the client conn") return } buffer, err := pUtil.ReadBytes(ctx, logger, clientConn) // Applied this nolint to ignore the staticcheck error here because of readability // nolint:staticcheck if netErr, ok := err.(net.Error); !(ok && netErr.Timeout()) && err != nil && err.Error
------------------

--- Chunk 2---
Function decodeRedis (part 2): () != "EOF" { logger.Debug("failed to read the request message in proxy for redis dependency") return } if netErr, ok := err.(net.Error); (ok && netErr.Timeout()) || (err != nil && err.Error() == "EOF") { logger.Debug("timeout for client read in redis or EOF") break } if len(buffer) > 0 { redisRequests = append(redisRequests, buffer) break } } if len(redisRequests) == 0 { logger.Debug("redis request buffer is empty") continue } // Fuzzy match to get the best matched redis mock matched, redisResponses, err := fuzzyMatch(ctx, redisRequests, mockDb) if err != nil { utils.LogError(logger, err, "error while matching redis mocks") } if !matched { err := clientConn.SetReadDeadline(time.Time{}) if err != nil { utils.LogError(logger, err, "failed to set the read deadline for the client conn") return } logger.Debug("redisRequests before pass through:", zap.Any("length", len(redisRequests
------------------

--- Chunk 3---
Function decodeRedis (part 3): ))) for _, redReq := range redisRequests { logger.Debug("redisRequests:", zap.Any("h", string(redReq))) } reqBuffer, err := pUtil.PassThrough(ctx, logger, clientConn, dstCfg, redisRequests) if err != nil { utils.LogError(logger, err, "failed to passthrough the redis request") return } redisRequests = [][]byte{} logger.Debug("request buffer after pass through in redis:", zap.Any("buffer", string(reqBuffer))) if len(reqBuffer) > 0 { redisRequests = [][]byte{reqBuffer} } logger.Debug("length of redisRequests after passThrough:", zap.Any("length", len(redisRequests))) continue } for _, redisResponse := range redisResponses { encoded := []byte(redisResponse.Message[0].Data) if redisResponse.Message[0].Type != models.String { encoded, err = util.DecodeBase64(redisResponse.Message[0].Data) if err != nil { utils.LogError(logger, err, "failed to decode the base64 response") return } } _, err := clientConn.Write(encoded
------------------

--- Chunk 4---
Function decodeRedis (end): ) if err != nil { if ctx.Err() != nil { return } utils.LogError(logger, err, "failed to write the response message to the client application") return } } // Clear the redisRequests buffer for the next dependency call redisRequests = [][]byte{} logger.Debug("redisRequests after the iteration:", zap.Any("length", len(redisRequests))) } }(errCh, redisRequests) select { case <-ctx.Done(): return ctx.Err() case err := <-errCh: if err == io.EOF { return nil } return err } }
------------------

--- File: pkg/core/proxy/integrations/redis/encode.go---

--- Chunk 1---
Function encodeRedis (start): func encodeRedis(ctx context.Context, logger *zap.Logger, reqBuf []byte, clientConn, destConn net.Conn, mocks chan<- *models.Mock, _ models.OutgoingOptions) error { var redisRequests []models.Payload var redisResponses []models.Payload bufStr := string(reqBuf) dataType := models.String if bufStr != "" { redisRequests = append(redisRequests, models.Payload{ Origin: models.FromClient, Message: []models.OutputBinary{ { Type: dataType, Data: bufStr, }, }, }) } _, err := destConn.Write(reqBuf) if err != nil { utils.LogError(logger, err, "failed to write request message to the destination server") return err } errCh := make(chan error, 1) g, ok := ctx.Value(models.ErrGroupKey).(*errgroup.Group) if !ok { return errors.New("failed to get the error group from the context") } reqTimestampMock := time.Now() // Read and process responses from the destination server g.Go(func() error { defer pUtil.Recover(logger, clientConn, destConn) defer close(errCh)
------------------

--- Chunk 2---
Function encodeRedis (part 2): for { // Read the response from the destination server resp, err := pUtil.ReadBytes(ctx, logger, destConn) if err != nil { if err == io.EOF { logger.Debug("Response complete, exiting the loop.") // if there is any buffer left before EOF, we must send it to the client and save this as mock if len(resp) != 0 { resTimestampMock := time.Now() _, err = clientConn.Write(resp) if err != nil { utils.LogError(logger, err, "failed to write response message to the client") errCh <- err return nil } processBuffer(resp, models.FromServer, &redisResponses) saveMock(ctx, redisRequests, redisResponses, reqTimestampMock, resTimestampMock, mocks) } break } utils.LogError(logger, err, "failed to read the response message from the destination server") errCh <- err return nil } // Write the response message to the client _, err = clientConn.Write(resp) if err != nil { utils.LogError(logger, err, "failed to write response message
------------------

--- Chunk 3---
Function encodeRedis (part 3): to the client") errCh <- err return nil } resTimestampMock := time.Now() processBuffer(resp, models.FromServer, &redisResponses) // Save the mock with both request and response if len(redisRequests) > 0 && len(redisResponses) > 0 { saveMock(ctx, redisRequests, redisResponses, reqTimestampMock, resTimestampMock, mocks) redisRequests = []models.Payload{} redisResponses = []models.Payload{} } // Read the next request from the client reqBuf, err = pUtil.ReadBytes(ctx, logger, clientConn) if err != nil { if err != io.EOF { utils.LogError(logger, err, "failed to read the request message from the client") errCh <- err return nil } errCh <- err return nil } bufStr := string(reqBuf) dataType := models.String if bufStr != "" { redisRequests = append(redisRequests, models.Payload{ Origin: models.FromClient, Message: []models.OutputBinary{ { Type: dataType, Data: buf
------------------

--- Chunk 4---
Function encodeRedis (end): Str, }, }, }) } _, err = destConn.Write(reqBuf) if err != nil { utils.LogError(logger, err, "failed to write request message to the destination server") errCh <- err return nil } reqTimestampMock = time.Now() } return nil }) select { case <-ctx.Done(): return ctx.Err() case err := <-errCh: if err == io.EOF { return nil } return err } }
------------------

--- Chunk 5---
func processBuffer(buffer []byte, origin models.OriginType, payloads *[]models.Payload) { bufStr := string(buffer) buffDataType := models.String if bufStr != "" { *payloads = append(*payloads, models.Payload{ Origin: origin, Message: []models.OutputBinary{ { Type: buffDataType, Data: bufStr, }, }, }) } }
------------------

--- Chunk 6---
func saveMock(ctx context.Context, requests, responses []models.Payload, reqTimestampMock, resTimestampMock time.Time, mocks chan<- *models.Mock) { redisRequestsCopy := make([]models.Payload, len(requests)) redisResponsesCopy := make([]models.Payload, len(responses)) copy(redisResponsesCopy, responses) copy(redisRequestsCopy, requests) metadata := make(map[string]string) metadata["type"] = "config" metadata["connID"] = ctx.Value(models.ClientConnectionIDKey).(string) mocks <- &models.Mock{ Version: models.GetVersion(), Name: "mocks", Kind: models.REDIS, Spec: models.MockSpec{ RedisRequests: redisRequestsCopy, RedisResponses: redisResponsesCopy, ReqTimestampMock: reqTimestampMock, ResTimestampMock: resTimestampMock, Metadata: metadata, }, } }
------------------

--- File: pkg/core/proxy/integrations/redis/match.go---

--- Chunk 1---
Function fuzzyMatch (start): func fuzzyMatch(ctx context.Context, reqBuff [][]byte, mockDb integrations.MockMemDb) (bool, []models.Payload, error) { for { select { case <-ctx.Done(): return false, nil, ctx.Err() default: mocks, err := mockDb.GetUnFilteredMocks() if err != nil { return false, nil, fmt.Errorf("error while getting unfiltered mocks %v", err) } var filteredMocks []*models.Mock var unfilteredMocks []*models.Mock for _, mock := range mocks { if mock.Kind != "Redis" { continue } if mock.TestModeInfo.IsFiltered { filteredMocks = append(filteredMocks, mock) } else { unfilteredMocks = append(unfilteredMocks, mock) } } index := findExactMatch(filteredMocks, reqBuff) if index == -1 { index = findBinaryMatch(filteredMocks, reqBuff, 0.9) } if index != -1 { responseMock := make([]models.Payload, len(filteredMocks[index].Spec.RedisResponses)) copy(responseMock, filteredMocks[index].Spec.RedisResponses)
------------------

--- Chunk 2---
Function fuzzyMatch (part 2): originalFilteredMock := *filteredMocks[index] filteredMocks[index].TestModeInfo.IsFiltered = false filteredMocks[index].TestModeInfo.SortOrder = pkg.GetNextSortNum() isUpdated := mockDb.UpdateUnFilteredMock(&originalFilteredMock, filteredMocks[index]) if !isUpdated { continue } return true, responseMock, nil } index = findExactMatch(unfilteredMocks, reqBuff) if index != -1 { responseMock := make([]models.Payload, len(unfilteredMocks[index].Spec.RedisResponses)) copy(responseMock, unfilteredMocks[index].Spec.RedisResponses) return true, responseMock, nil } totalMocks := append(filteredMocks, unfilteredMocks...) index = findBinaryMatch(totalMocks, reqBuff, 0.4) if index != -1 { responseMock := make([]models.Payload, len(totalMocks[index].Spec.RedisResponses)) copy(responseMock, totalMocks[index].Spec.RedisResponses) originalFilteredMock := *totalMocks[index] if totalMocks[index].TestModeInfo.IsFiltered { totalMocks[index].TestModeInfo.IsFiltered = false totalMocks
------------------

--- Chunk 3---
Function fuzzyMatch (end): [index].TestModeInfo.SortOrder = pkg.GetNextSortNum() isUpdated := mockDb.UpdateUnFilteredMock(&originalFilteredMock, totalMocks[index]) if !isUpdated { continue } } return true, responseMock, nil } return false, nil, nil } } }
------------------

--- Chunk 4---
func findBinaryMatch(tcsMocks []*models.Mock, reqBuffs [][]byte, mxSim float64) int { // TODO: need find a proper similarity index to set a benchmark for matching or need to find another way to do approximate matching mxIdx := -1 for idx, mock := range tcsMocks { if len(mock.Spec.RedisRequests) == len(reqBuffs) { for requestIndex, reqBuff := range reqBuffs { mockReq, err := util.DecodeBase64(mock.Spec.RedisRequests[requestIndex].Message[0].Data) if err != nil { mockReq = []byte(mock.Spec.RedisRequests[requestIndex].Message[0].Data) } similarity := fuzzyCheck(mockReq, reqBuff) if mxSim < similarity { mxSim = similarity mxIdx = idx } } } } return mxIdx }
------------------

--- Chunk 5---
func fuzzyCheck(encoded, reqBuf []byte) float64 { k := util.AdaptiveK(len(reqBuf), 3, 8, 5) shingles1 := util.CreateShingles(encoded, k) shingles2 := util.CreateShingles(reqBuf, k) similarity := util.JaccardSimilarity(shingles1, shingles2) return similarity }
------------------

--- Chunk 6---
func findExactMatch(tcsMocks []*models.Mock, reqBuffs [][]byte) int { for idx, mock := range tcsMocks { if len(mock.Spec.RedisRequests) == len(reqBuffs) { matched := true // Flag to track if all requests match for requestIndex, reqBuff := range reqBuffs { bufStr := string(reqBuff) // Compare the encoded data if mock.Spec.RedisRequests[requestIndex].Message[0].Data != bufStr { matched = false break // Exit the loop if any request doesn't match } } if matched { return idx } } } return -1 }
------------------

--- File: pkg/core/proxy/integrations/redis/redis.go---

--- Chunk 1---
func New(logger *zap.Logger) integrations.Integrations { return &Redis{ logger: logger, } }
------------------

--- Chunk 2---
func (r *Redis) MatchType(_ context.Context, buf []byte) bool { if len(buf) == 0 { return false } // Check the first byte to determine the RESP data type switch buf[0] { case '+', '-', ':', '$', '*', '_', '#', ',', '(', '!', '=', '%', '~', '>': return true default: return false } }
------------------

--- Chunk 3---
func (r *Redis) RecordOutgoing(ctx context.Context, src net.Conn, dst net.Conn, mocks chan<- *models.Mock, opts models.OutgoingOptions) error { logger := r.logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", src.RemoteAddr().String())) reqBuf, err := util.ReadInitialBuf(ctx, logger, src) if err != nil { utils.LogError(logger, err, "failed to read the initial redis message") return err } err = encodeRedis(ctx, logger, reqBuf, src, dst, mocks, opts) if err != nil { utils.LogError(logger, err, "failed to encode the redis message into the yaml") return err } return nil }
------------------

--- Chunk 4---
func (r *Redis) MockOutgoing(ctx context.Context, src net.Conn, dstCfg *models.ConditionalDstCfg, mockDb integrations.MockMemDb, opts models.OutgoingOptions) error { logger := r.logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", src.RemoteAddr().String())) reqBuf, err := util.ReadInitialBuf(ctx, logger, src) if err != nil { utils.LogError(logger, err, "failed to read the initial redis message") return err } err = decodeRedis(ctx, logger, reqBuf, src, dstCfg, mockDb, opts) if err != nil { utils.LogError(logger, err, "failed to decode the redis message") return err } return nil }
------------------

--- File: pkg/core/proxy/integrations/scram/scram.go---

--- Chunk 1---
Function GenerateServerFinalMessage (start): func GenerateServerFinalMessage(authMessage, mechanism, password, salt string, itr int, logger *zap.Logger) (string, error) { var ( // Declare a variable to hold the hash generation function based on the chosen mechanism. hashGen scram.HashGeneratorFcn // normalised password is used in the salted password passwordDigest string ) username, err := extractUsername(authMessage) if err != nil { return "", err } // Switch based on the provided mechanism to determine the hash function to be used. switch mechanism { case util.SCRAM_SHA_1: hashGen = scram.SHA1 passwordDigest = mongoPasswordDigest(username, password) case util.SCRAM_SHA_256: hashGen = scram.SHA256 passwordDigest, err = stringprep.SASLprep.Prepare(password) if err != nil { return "", fmt.Errorf("error SASLprepping password for SCRAM-SHA-256 with password: %s. error: %v", password, err.Error()) } default: // If the mechanism isn't supported, return an error. return "", errors.New("unsupported authentication mechanism by keploy")
------------------

--- Chunk 2---
Function GenerateServerFinalMessage (part 2): } // Get the hash function instance based on the determined generator. h := hashGen() // Compute the salted password using the PBKDF2 function with the provided salt and iteration count. // It uses the given password. This is the key derivation step. logger.Debug("the input for generating the salted password", zap.Any("normalised password", passwordDigest), zap.Any("salt", salt), zap.Any("iteration", itr), zap.Any("hash size", h.Size()), zap.Any("mechanism", mechanism)) saltedPassword := pbkdf2.Key([]byte(passwordDigest), []byte(salt), itr, h.Size(), hashGen) logger.Debug("after generating the salted password", zap.Any("salted password", saltedPassword)) // Compute the server key using HMAC with the derived salted password and the string "Server Key". serverKey := computeHMAC(hashGen, saltedPassword, []byte("Server Key")) logger.Debug("generating the server using the salted password", zap.Any("server key", serverKey)) // Compute the server signature (server proof) using HMAC with the server key and the provided authMessage. serverSignature := computeHMAC(hashGen, serverKey, []byte
------------------

--- Chunk 3---
Function GenerateServerFinalMessage (end): (authMessage)) logger.Debug("the new server proof for the second auth request", zap.Any("server signature", base64.StdEncoding.EncodeToString(serverSignature)), zap.Any("derived from auth message", authMessage)) return base64.StdEncoding.EncodeToString(serverSignature), nil }
------------------

--- Chunk 4---
func GenerateServerFirstMessage(recordedRequestMsg, receivedRequestMsg, firstResponseMsg []byte, logger *zap.Logger) (string, error) { expectedNonce, err := extractClientNonce(string(recordedRequestMsg)) if err != nil { utils.LogError(logger, err, "failed to extract the client nonce from the recorded first message") return "", err } actualNonce, err := extractClientNonce(string(receivedRequestMsg)) if err != nil { utils.LogError(logger, err, "failed to extract the client nonce from the received first message") return "", err } // Since, the nonce are randomlly generated string. so, each session have unique nonce. // Thus, the mocked server response should be updated according to the current nonce updatedResponse := strings.ReplaceAll(string(firstResponseMsg), expectedNonce, actualNonce) logger.Debug("Updated server first message after nonce substitution", zap.String("updatedResponse", updatedResponse)) return updatedResponse, nil }
------------------

--- Chunk 5---
func GenerateAuthMessage(firstRequest, firstResponse string, logger *zap.Logger) string { gs2, err := extractAuthID(firstRequest) if err != nil { utils.LogError(logger, err, "failed to extract the client gs2 header from the received first message") return "" } authMsg := firstRequest[len(gs2):] + "," + firstResponse + "," nonce, err := extractClientNonce(firstResponse) if err != nil { utils.LogError(logger, err, "failed to extract the client nonce from the recorded first message") return "" } authMsg += fmt.Sprintf( "c=%s,r=%s", base64.StdEncoding.EncodeToString([]byte(gs2)), nonce, ) return authMsg }
------------------

--- File: pkg/core/proxy/integrations/scram/util.go---

--- Chunk 1---
func extractClientNonce(firstMsg string) (string, error) { // Split the string based on "," parts := strings.Split(firstMsg, ",") // Iterate over the parts to find the one starting with "r=" for _, part := range parts { if strings.HasPrefix(part, "r=") { // Split based on "=" and get the value of "r" // value := strings.Split(part, "=")[1] value := strings.TrimPrefix(part, "r=") if value == part { return "", fmt.Errorf("error parsing '%s' for fetching client nonce", part) } return value, nil } } return "", errors.New("nonce not found") }
------------------

--- Chunk 2---
func computeHMAC(hg scram.HashGeneratorFcn, key, data []byte) []byte { mac := hmac.New(hg, key) mac.Write(data) return mac.Sum(nil) }
------------------

--- Chunk 3---
func mongoPasswordDigest(username, password string) string { // Ignore gosec warning "Use of weak cryptographic primitive". We need to use MD5 here to // implement the SCRAM specification. /* #nosec G401 */ h := md5.New() _, _ = io.WriteString(h, username) _, _ = io.WriteString(h, ":mongo:") _, _ = io.WriteString(h, password) return fmt.Sprintf("%x", h.Sum(nil)) }
------------------

--- Chunk 4---
func extractUsername(authMessage string) (string, error) { parts := strings.Split(authMessage, ",") for _, part := range parts { if strings.HasPrefix(part, "n=") { nValue := strings.TrimPrefix(part, "n=") return nValue, nil } } return "", fmt.Errorf("no username found in the auth message") }
------------------

--- Chunk 5---
func extractAuthID(input string) (string, error) { re := regexp.MustCompile(`n,([^,]*),`) // Regular expression to match "n,," or "n,SOMETHING," matches := re.FindStringSubmatch(input) if len(matches) >= 2 { return "n," + matches[1] + ",", nil } return "", fmt.Errorf("no match found") }
------------------

--- File: pkg/core/proxy/integrations/util/util.go---

--- Chunk 1---
func IsASCII(s string) bool { for _, r := range s { if r > unicode.MaxASCII { return false } } return true }
------------------

--- Chunk 2---
func DecodeBase64(encoded string) ([]byte, error) { // Decode the base64 encoded string to buffer data, err := base64.StdEncoding.DecodeString(encoded) if err != nil { return nil, err } return data, nil }
------------------

--- Chunk 3---
func EncodeBase64(decoded []byte) string { // Encode the []byte string to encoded string return base64.StdEncoding.EncodeToString(decoded) }
------------------

--- Chunk 4---
func AdaptiveK(length, min, max, N int) int { k := length / N if k < min { return min } else if k > max { return max } return k }
------------------

--- Chunk 5---
func CreateShingles(data []byte, k int) map[string]struct{} { shingles := make(map[string]struct{}) for i := 0; i < len(data)-k+1; i++ { shingle := string(data[i : i+k]) shingles[shingle] = struct{}{} } return shingles }
------------------

--- Chunk 6---
func JaccardSimilarity(setA, setB map[string]struct{}) float64 { intersectionSize := 0 for k := range setA { if _, exists := setB[k]; exists { intersectionSize++ } } unionSize := len(setA) + len(setB) - intersectionSize if unionSize == 0 { return 0.0 } return float64(intersectionSize) / float64(unionSize) }
------------------

--- Chunk 7---
func GetMockByKind(mocks []*models.Mock, kind string) []*models.Mock { var filteredMocks []*models.Mock for _, mock := range mocks { if mock.Kind == models.Kind(kind) { filteredMocks = append(filteredMocks, mock) } } return filteredMocks }
------------------

--- File: pkg/core/proxy/mockmanager.go---

--- Chunk 1---
func NewMockManager(filtered, unfiltered *TreeDb, logger *zap.Logger) *MockManager { return &MockManager{ filtered: filtered, unfiltered: unfiltered, logger: logger, consumedMocks: sync.Map{}, } }
------------------

--- Chunk 2---
func (m *MockManager) SetFilteredMocks(mocks []*models.Mock) { m.filtered.deleteAll() for index, mock := range mocks { // if the sortOrder is already set (!= 0) then we shouldn't override it, // as this would be a consequence of the mock being matched in previous testcases, // which is done to put the mock in the last when we are processing the mock list for getting a match. if mock.TestModeInfo.SortOrder == 0 { mock.TestModeInfo.SortOrder = int64(index) + 1 } mock.TestModeInfo.ID = index m.filtered.insert(mock.TestModeInfo, mock) } }
------------------

--- Chunk 3---
func (m *MockManager) SetUnFilteredMocks(mocks []*models.Mock) { m.unfiltered.deleteAll() for index, mock := range mocks { // if the sortOrder is already set (!= 0) then we shouldn't override it, // as this would be a consequence of the mock being matched in previous testcases, // which is done to put the mock in the last when we are processing the mock list for getting a match. if mock.TestModeInfo.SortOrder == 0 { mock.TestModeInfo.SortOrder = int64(index) + 1 } mock.TestModeInfo.ID = index m.unfiltered.insert(mock.TestModeInfo, mock) } }
------------------

--- Chunk 4---
func (m *MockManager) GetFilteredMocks() ([]*models.Mock, error) { var tcsMocks []*models.Mock mocks := m.filtered.getAll() //sending copy of mocks instead of actual mocks mockCopy, err := localMock(mocks) if err != nil { return nil, fmt.Errorf("expected mock instance, got %v", m) } for _, m := range mockCopy { tcsMocks = append(tcsMocks, &m) } return tcsMocks, nil }
------------------

--- Chunk 5---
func (m *MockManager) GetUnFilteredMocks() ([]*models.Mock, error) { var configMocks []*models.Mock mocks := m.unfiltered.getAll() //sending copy of mocks instead of actual mocks mockCopy, err := localMock(mocks) if err != nil { return nil, fmt.Errorf("expected mock instance, got %v", m) } for _, m := range mockCopy { configMocks = append(configMocks, &m) } return configMocks, nil }
------------------

--- Chunk 6---
func (m *MockManager) UpdateUnFilteredMock(old *models.Mock, new *models.Mock) bool { updated := m.unfiltered.update(old.TestModeInfo, new.TestModeInfo, new) if updated { // mark the unfiltered mock as used for the current simulated test-case if err := m.flagMockAsUsed(models.MockState{ Name: (*new).Name, Usage: models.Updated, IsFiltered: (*new).TestModeInfo.IsFiltered, SortOrder: (*new).TestModeInfo.SortOrder, }); err != nil { m.logger.Error("failed to flag mock as used", zap.Error(err)) } } return updated }
------------------

--- Chunk 7---
func (m *MockManager) flagMockAsUsed(mock models.MockState) error { if mock.Name == "" { return fmt.Errorf("mock is empty") } m.consumedMocks.Store(mock.Name, mock) return nil }
------------------

--- Chunk 8---
func (m *MockManager) DeleteFilteredMock(mock models.Mock) bool { isDeleted := m.filtered.delete(mock.TestModeInfo) if isDeleted { if err := m.flagMockAsUsed(models.MockState{ Name: mock.Name, Usage: models.Deleted, IsFiltered: mock.TestModeInfo.IsFiltered, SortOrder: mock.TestModeInfo.SortOrder, }); err != nil { m.logger.Error("failed to flag mock as used", zap.Error(err)) } } return isDeleted }
------------------

--- Chunk 9---
func (m *MockManager) DeleteUnFilteredMock(mock models.Mock) bool { isDeleted := m.unfiltered.delete(mock.TestModeInfo) if isDeleted { if err := m.flagMockAsUsed(models.MockState{ Name: mock.Name, Usage: models.Deleted, IsFiltered: mock.TestModeInfo.IsFiltered, SortOrder: mock.TestModeInfo.SortOrder, }); err != nil { m.logger.Error("failed to flag mock as used", zap.Error(err)) } } return isDeleted }
------------------

--- Chunk 10---
func (m *MockManager) GetConsumedMocks() []models.MockState { var keys []models.MockState m.consumedMocks.Range(func(key, val interface{}) bool { if _, ok := key.(string); ok { keys = append(keys, val.(models.MockState)) m.consumedMocks.Delete(key) } return true }) sort.Slice(keys, func(i, j int) bool { numI, _ := strconv.Atoi(strings.Split(keys[i].Name, "-")[1]) numJ, _ := strconv.Atoi(strings.Split(keys[j].Name, "-")[1]) return numI < numJ }) for key := range keys { m.consumedMocks.Delete(key) } return keys }
------------------

--- File: pkg/core/proxy/proxy.go---

--- Chunk 1---
func New(logger *zap.Logger, info core.DestInfo, opts *config.Config) *Proxy { return &Proxy{ logger: logger, Port: opts.ProxyPort, // default: 16789 DNSPort: opts.DNSPort, // default: 26789 IP4: "127.0.0.1", // default: "127.0.0.1" <-> (2130706433) IP6: "::1", //default: "::1" <-> ([4]uint32{0000, 0000, 0000, 0001}) ipMutex: &sync.Mutex{}, connMutex: &sync.Mutex{}, DestInfo: info, sessions: core.NewSessions(), MockManagers: sync.Map{}, Integrations: make(map[integrations.IntegrationType]integrations.Integrations), } }
------------------

--- Chunk 2---
func (p *Proxy) InitIntegrations(_ context.Context) error { // initialize the integrations for parserType, parser := range integrations.Registered { logger := p.logger.With(zap.Any("Type", parserType)) prs := parser.Initializer(logger) p.Integrations[parserType] = prs p.integrationsPriority = append(p.integrationsPriority, ParserPriority{Priority: parser.Priority, ParserType: parserType}) } sort.Slice(p.integrationsPriority, func(i, j int) bool { return p.integrationsPriority[i].Priority > p.integrationsPriority[j].Priority }) return nil }
------------------

--- Chunk 3---
Function StartProxy (start): func (p *Proxy) StartProxy(ctx context.Context, opts core.ProxyOptions) error { //first initialize the integrations err := p.InitIntegrations(ctx) if err != nil { utils.LogError(p.logger, err, "failed to initialize the integrations") return err } // set up the CA for tls connections err = pTls.SetupCA(ctx, p.logger) if err != nil { // log the error and continue p.logger.Warn("failed to setup CA", zap.Error(err)) } g, ok := ctx.Value(models.ErrGroupKey).(*errgroup.Group) if !ok { return errors.New("failed to get the error group from the context") } // Create a channel to signal readiness of each server readyChan := make(chan error, 1) // start the proxy server g.Go(func() error { defer utils.Recover(p.logger) err := p.start(ctx, readyChan) readyChan <- err if err != nil { utils.LogError(p.logger, err, "error while running the proxy server") return err } return nil }) //change the ip4 and ip
------------------

--- Chunk 4---
Function StartProxy (part 2): 6 if provided in the opts in case of docker environment if len(opts.DNSIPv4Addr) != 0 { p.IP4 = opts.DNSIPv4Addr } if len(opts.DNSIPv6Addr) != 0 { p.IP6 = opts.DNSIPv6Addr } // start the TCP DNS server p.logger.Debug("Starting Tcp Dns Server for handling Dns queries over TCP") g.Go(func() error { defer utils.Recover(p.logger) errCh := make(chan error, 1) go func(errCh chan error) { defer utils.Recover(p.logger) err := p.startTCPDNSServer(ctx) if err != nil { errCh <- err } }(errCh) select { case <-ctx.Done(): err := p.TCPDNSServer.Shutdown() if err != nil { utils.LogError(p.logger, err, "failed to shutdown tcp dns server") return err } return nil case err := <-errCh: return err } }) // start the UDP DNS server p.logger.Debug("Starting Udp Dns Server for handling
------------------

--- Chunk 5---
Function StartProxy (end): Dns queries over UDP") g.Go(func() error { defer utils.Recover(p.logger) errCh := make(chan error, 1) go func(errCh chan error) { defer utils.Recover(p.logger) err := p.startUDPDNSServer(ctx) if err != nil { errCh <- err } }(errCh) select { case <-ctx.Done(): err := p.UDPDNSServer.Shutdown() if err != nil { utils.LogError(p.logger, err, "failed to shutdown tcp dns server") return err } return nil case err := <-errCh: return err } }) // Wait for the proxy server to be ready or fail err = <-readyChan if err != nil { return err } p.logger.Info("Keploy has taken control of the DNS resolution mechanism, your application may misbehave if you have provided wrong domain name in your application code.") p.logger.Info(fmt.Sprintf("Proxy started at port:%v", p.Port)) return nil }
------------------

--- Chunk 6---
Function start (start): func (p *Proxy) start(ctx context.Context, readyChan chan<- error) error { // It will listen on all the interfaces listener, err := net.Listen("tcp", fmt.Sprintf(":%v", p.Port)) if err != nil { utils.LogError(p.logger, err, fmt.Sprintf("failed to start proxy on port:%v", p.Port)) // Notify failure readyChan <- err return err } p.Listener = listener p.logger.Debug(fmt.Sprintf("Proxy server is listening on %s", fmt.Sprintf(":%v", listener.Addr()))) // Signal that the server is ready readyChan <- nil defer func(listener net.Listener) { err := listener.Close() if err != nil { p.logger.Error("failed to close the listener", zap.Error(err)) } p.logger.Info("proxy stopped...") }(listener) clientConnCtx, clientConnCancel := context.WithCancel(ctx) clientConnErrGrp, _ := errgroup.WithContext(clientConnCtx) defer func() { clientConnCancel() err := clientConnErrGrp.Wait() if err != nil { p.logger.Debug("failed to handle the client connection", zap.Error(err
------------------

--- Chunk 7---
Function start (part 2): )) } //closing all the mock channels (if any in record mode) for _, mc := range p.sessions.GetAllMC() { if mc != nil { close(mc) } } if string(p.nsswitchData) != "" { // reset the hosts config in nsswitch.conf of the system (in test mode) err = p.resetNsSwitchConfig() if err != nil { utils.LogError(p.logger, err, "failed to reset the nsswitch config") } } }() for { clientConnCh := make(chan net.Conn, 1) errCh := make(chan error, 1) go func() { defer utils.Recover(p.logger) conn, err := listener.Accept() if err != nil { if strings.Contains(err.Error(), "use of closed network connection") { errCh <- nil return } utils.LogError(p.logger, err, "failed to accept connection to the proxy") errCh <- err return } clientConnCh <- conn }() select { case <-ctx.Done(): return nil case err :=
------------------

--- Chunk 8---
Function start (end): <-errCh: return err // handle the client connection case clientConn := <-clientConnCh: clientConnErrGrp.Go(func() error { defer util.Recover(p.logger, clientConn, nil) err := p.handleConnection(clientConnCtx, clientConn) if err != nil && err != io.EOF { utils.LogError(p.logger, err, "failed to handle the client connection") } return nil }) } } }
------------------

--- Chunk 9---
Function handleConnection (start): func (p *Proxy) handleConnection(ctx context.Context, srcConn net.Conn) error { //checking how much time proxy takes to execute the flow. start := time.Now() // making a new client connection id for each client connection clientConnID := util.GetNextID() defer func(start time.Time) { duration := time.Since(start) p.logger.Debug("time taken by proxy to execute the flow", zap.Any("Client ConnectionID", clientConnID), zap.Any("Duration(ms)", duration.Milliseconds())) }(start) // dstConn stores conn with actual destination for the outgoing network call var dstConn net.Conn //Dialing for tls conn destConnID := util.GetNextID() remoteAddr := srcConn.RemoteAddr().(*net.TCPAddr) sourcePort := remoteAddr.Port p.logger.Debug("Inside handleConnection of proxyServer", zap.Any("source port", sourcePort), zap.Any("Time", time.Now().Unix())) destInfo, err := p.DestInfo.Get(ctx, uint16(sourcePort)) if err != nil { utils.LogError(p.logger, err, "failed to fetch the destination info", zap.Any("Source port", sourcePort)) return err }
------------------

--- Chunk 10---
Function handleConnection (part 2): // releases the occupied source port when done fetching the destination info err = p.DestInfo.Delete(ctx, uint16(sourcePort)) if err != nil { utils.LogError(p.logger, err, "failed to delete the destination info", zap.Any("Source port", sourcePort)) return err } //get the session rule rule, ok := p.sessions.Get(destInfo.AppID) if !ok { utils.LogError(p.logger, nil, "failed to fetch the session rule", zap.Any("AppID", destInfo.AppID)) return err } var dstAddr string switch destInfo.Version { case 4: p.logger.Debug("the destination is ipv4") dstAddr = fmt.Sprintf("%v:%v", util.ToIP4AddressStr(destInfo.IPv4Addr), destInfo.Port) p.logger.Debug("", zap.Any("DestIp4", destInfo.IPv4Addr), zap.Any("DestPort", destInfo.Port)) case 6: p.logger.Debug("the destination is ipv6") dstAddr = fmt.Sprintf("[%v]:%v", util.ToIPv6AddressStr(destInfo.IPv6Addr), destInfo.Port) p.logger.Debug("", zap.Any("Dest
------------------

--- Chunk 11---
Function handleConnection (part 3): Ip6", destInfo.IPv6Addr), zap.Any("DestPort", destInfo.Port)) } // This is used to handle the parser errors parserErrGrp, parserCtx := errgroup.WithContext(ctx) parserCtx = context.WithValue(parserCtx, models.ErrGroupKey, parserErrGrp) parserCtx = context.WithValue(parserCtx, models.ClientConnectionIDKey, fmt.Sprint(clientConnID)) parserCtx = context.WithValue(parserCtx, models.DestConnectionIDKey, fmt.Sprint(destConnID)) parserCtx, parserCtxCancel := context.WithCancel(parserCtx) defer func() { parserCtxCancel() if srcConn != nil { err := srcConn.Close() if err != nil { utils.LogError(p.logger, err, "failed to close the source connection", zap.Any("clientConnID", clientConnID)) return } } if dstConn != nil { err = dstConn.Close() if err != nil { // Use string matching as a last resort to check for the specific error if !strings.Contains(err.Error(), "use of closed network connection") { // Log other errors utils.LogError(p.logger, err
------------------

--- Chunk 12---
Function handleConnection (part 4): , "failed to close the destination connection") } return } } err = parserErrGrp.Wait() if err != nil { utils.LogError(p.logger, err, "failed to handle the parser cleanUp") } }() //check for global passthrough in test mode if !rule.Mocking && rule.Mode == models.MODE_TEST { dstConn, err = net.Dial("tcp", dstAddr) if err != nil { utils.LogError(p.logger, err, "failed to dial the conn to destination server", zap.Any("proxy port", p.Port), zap.Any("server address", dstAddr)) return err } err = p.globalPassThrough(parserCtx, srcConn, dstConn) if err != nil { utils.LogError(p.logger, err, "failed to handle the global pass through") return err } return nil } //checking for the destination port of "mysql" if destInfo.Port == 3306 { if rule.Mode != models.MODE_TEST { dstConn, err = net.Dial("tcp", dstAddr) if err != nil { utils.LogError(p.logger, err, "failed
------------------

--- Chunk 13---
Function handleConnection (part 5): to dial the conn to destination server", zap.Any("proxy port", p.Port), zap.Any("server address", dstAddr)) return err } dstCfg := &models.ConditionalDstCfg{ Port: uint(destInfo.Port), } rule.DstCfg = dstCfg // Record the outgoing message into a mock err := p.Integrations[integrations.MYSQL].RecordOutgoing(parserCtx, srcConn, dstConn, rule.MC, rule.OutgoingOptions) if err != nil { utils.LogError(p.logger, err, "failed to record the outgoing message") return err } return nil } m, ok := p.MockManagers.Load(destInfo.AppID) if !ok { utils.LogError(p.logger, nil, "failed to fetch the mock manager", zap.Any("AppID", destInfo.AppID)) return err } //mock the outgoing message err := p.Integrations[integrations.MYSQL].MockOutgoing(parserCtx, srcConn, &models.ConditionalDstCfg{Addr: dstAddr}, m.(*MockManager), rule.OutgoingOptions) if err !=
------------------

--- Chunk 14---
Function handleConnection (part 6): nil { utils.LogError(p.logger, err, "failed to mock the outgoing message") return err } return nil } reader := bufio.NewReader(srcConn) initialData := make([]byte, 5) // reading the initial data from the client connection to determine if the connection is a TLS handshake testBuffer, err := reader.Peek(len(initialData)) if err != nil { if err == io.EOF && len(testBuffer) == 0 { p.logger.Debug("received EOF, closing conn", zap.Any("connectionID", clientConnID), zap.Error(err)) return nil } utils.LogError(p.logger, err, "failed to peek the request message in proxy", zap.Any("proxy port", p.Port)) return err } multiReader := io.MultiReader(reader, srcConn) srcConn = &util.Conn{ Conn: srcConn, Reader: multiReader, Logger: p.logger, } isTLS := pTls.IsTLSHandshake(testBuffer) if isTLS { srcConn, err = pTls.HandleTLSConnection(ctx, p.logger, srcConn, rule.Backdate) if err != nil { utils.LogError
------------------

--- Chunk 15---
Function handleConnection (part 7): (p.logger, err, "failed to handle TLS conn") return err } } clientID, ok := parserCtx.Value(models.ClientConnectionIDKey).(string) if !ok { utils.LogError(p.logger, err, "failed to fetch the client connection id") return err } destID, ok := parserCtx.Value(models.DestConnectionIDKey).(string) if !ok { utils.LogError(p.logger, err, "failed to fetch the destination connection id") return err } logger := p.logger.With(zap.Any("Client ConnectionID", clientID), zap.Any("Destination ConnectionID", destID), zap.Any("Destination IP Address", dstAddr), zap.Any("Client IP Address", srcConn.RemoteAddr().String())) var initialBuf []byte // attempt to read conn until buffer is either filled or conn is closed initialBuf, err = util.ReadInitialBuf(parserCtx, p.logger, srcConn) if err != nil { utils.LogError(logger, err, "failed to read the initial buffer") return err } if util.IsHTTPReq(initialBuf) && !util.HasCompleteHTTPHeaders(initialBuf) { // HTTP headers are never chunked according to the HTTP
------------------

--- Chunk 16---
Function handleConnection (part 8): protocol, // but at the TCP layer, we cannot be sure if we have received the entire // header in the first buffer chunk. This is why we check if the headers are complete // and read more data if needed. // Some HTTP requests, like AWS SQS, may require special handling in Keploy Enterprise. // These cases may send partial headers in multiple chunks, so we need to read until // we get the complete headers. logger.Debug("Partial HTTP headers detected, reading more data to get complete headers") // Read more data from the TCP connection to get the complete HTTP headers. headerBuf, err := util.ReadHTTPHeadersUntilEnd(parserCtx, p.logger, srcConn) if err != nil { // Log the error if we fail to read the complete HTTP headers. utils.LogError(logger, err, "failed to read the complete HTTP headers from client") return err } // Append the additional data to the initial buffer. initialBuf = append(initialBuf, headerBuf...) } //update the src connection to have the initial buffer srcConn = &util.Conn{ Conn: src
------------------

--- Chunk 17---
Function handleConnection (part 9): Conn, Reader: io.MultiReader(bytes.NewReader(initialBuf), srcConn), Logger: p.logger, } dstCfg := &models.ConditionalDstCfg{ Port: uint(destInfo.Port), } //make new connection to the destination server if isTLS { // get the destinationUrl from the map for the tls connection url, ok := pTls.SrcPortToDstURL.Load(sourcePort) if !ok { utils.LogError(logger, err, "failed to fetch the destination url") return err } //type case the dstUrl to string dstURL, ok := url.(string) if !ok { utils.LogError(logger, err, "failed to type cast the destination url") return err } logger.Debug("the external call is tls-encrypted", zap.Any("isTLS", isTLS)) cfg := &tls.Config{ InsecureSkipVerify: true, ServerName: dstURL, } addr := fmt.Sprintf("%v:%v", dstURL, destInfo.Port) if rule.Mode != models.MODE_TEST { dstConn, err = tls.Dial("tcp", addr, cfg)
------------------

--- Chunk 18---
Function handleConnection (part 10): if err != nil { utils.LogError(logger, err, "failed to dial the conn to destination server", zap.Any("proxy port", p.Port), zap.Any("server address", dstAddr)) return err } } dstCfg.TLSCfg = cfg dstCfg.Addr = addr } else { if rule.Mode != models.MODE_TEST { dstConn, err = net.Dial("tcp", dstAddr) if err != nil { utils.LogError(logger, err, "failed to dial the conn to destination server", zap.Any("proxy port", p.Port), zap.Any("server address", dstAddr)) return err } } dstCfg.Addr = dstAddr } // get the mock manager for the current app m, ok := p.MockManagers.Load(destInfo.AppID) if !ok { utils.LogError(logger, err, "failed to fetch the mock manager", zap.Any("AppID", destInfo.AppID)) return err } generic := true var matchedParser integrations.Integrations var parserType integrations.IntegrationType //Checking for all the parsers according to their priority. for _, parserPair
------------------

--- Chunk 19---
Function handleConnection (part 11): := range p.integrationsPriority { // Iterate over ordered priority list parser, exists := p.Integrations[parserPair.ParserType] if !exists { continue // Skip if parser not found } p.logger.Debug("Checking for the parser", zap.Any("ParserType", parserPair.ParserType)) if parser.MatchType(parserCtx, initialBuf) { matchedParser = parser parserType = parserPair.ParserType generic = false break } } if !generic { p.logger.Debug("The external dependency is supported. Hence using the parser", zap.Any("ParserType", parserType)) switch rule.Mode { case models.MODE_RECORD: err := matchedParser.RecordOutgoing(parserCtx, srcConn, dstConn, rule.MC, rule.OutgoingOptions) if err != nil { utils.LogError(logger, err, "failed to record the outgoing message") return err } case models.MODE_TEST: err := matchedParser.MockOutgoing(parserCtx, srcConn, dstCfg, m.(*MockManager), rule.OutgoingOptions) if err != nil && err != io.EOF { utils.LogError(logger, err, "
------------------

--- Chunk 20---
Function handleConnection (end): failed to mock the outgoing message") return err } } } if generic { logger.Debug("The external dependency is not supported. Hence using generic parser") if rule.Mode == models.MODE_RECORD { err := p.Integrations[integrations.GENERIC].RecordOutgoing(parserCtx, srcConn, dstConn, rule.MC, rule.OutgoingOptions) if err != nil { utils.LogError(logger, err, "failed to record the outgoing message") return err } } else { err := p.Integrations[integrations.GENERIC].MockOutgoing(parserCtx, srcConn, dstCfg, m.(*MockManager), rule.OutgoingOptions) if err != nil { utils.LogError(logger, err, "failed to mock the outgoing message") return err } } } return nil }
------------------

--- Chunk 21---
func (p *Proxy) StopProxyServer(ctx context.Context) { <-ctx.Done() p.logger.Info("stopping proxy server...") p.connMutex.Lock() for _, clientConn := range p.clientConnections { err := clientConn.Close() if err != nil { return } } p.connMutex.Unlock() if p.Listener != nil { err := p.Listener.Close() if err != nil { utils.LogError(p.logger, err, "failed to stop proxy server") } } // stop dns servers err := p.stopDNSServers(ctx) if err != nil { utils.LogError(p.logger, err, "failed to stop the dns servers") return } p.logger.Info("proxy stopped...") }
------------------

--- Chunk 22---
func (p *Proxy) Record(_ context.Context, id uint64, mocks chan<- *models.Mock, opts models.OutgoingOptions) error { p.sessions.Set(id, &core.Session{ ID: id, Mode: models.MODE_RECORD, MC: mocks, OutgoingOptions: opts, }) p.MockManagers.Store(id, NewMockManager(NewTreeDb(customComparator), NewTreeDb(customComparator), p.logger)) ////set the new proxy ip:port for a new session //err := p.setProxyIP(opts.DnsIPv4Addr, opts.DnsIPv6Addr) //if err != nil { // return errors.New("failed to record the outgoing message") //} return nil }
------------------

--- Chunk 23---
func (p *Proxy) Mock(_ context.Context, id uint64, opts models.OutgoingOptions) error { p.sessions.Set(id, &core.Session{ ID: id, Mode: models.MODE_TEST, OutgoingOptions: opts, }) p.MockManagers.Store(id, NewMockManager(NewTreeDb(customComparator), NewTreeDb(customComparator), p.logger)) if !opts.Mocking { p.logger.Info("ðŸ”€ Mocking is disabled, the response will be fetched from the actual service") } if string(p.nsswitchData) == "" { // setup the nsswitch config to redirect the DNS queries to the proxy err := p.setupNsswitchConfig() if err != nil { utils.LogError(p.logger, err, "failed to setup nsswitch config") return errors.New("failed to mock the outgoing message") } } ////set the new proxy ip:port for a new session //err := p.setProxyIP(opts.DnsIPv4Addr, opts.DnsIPv6Addr) //if err != nil { // return errors.New("failed to mock the outgoing message") //} return nil }
------------------

--- Chunk 24---
func (p *Proxy) SetMocks(_ context.Context, id uint64, filtered []*models.Mock, unFiltered []*models.Mock) error { //session, ok := p.sessions.Get(id) //if !ok { // return fmt.Errorf("session not found") //} m, ok := p.MockManagers.Load(id) if ok { m.(*MockManager).SetFilteredMocks(filtered) m.(*MockManager).SetUnFilteredMocks(unFiltered) } return nil }
------------------

--- Chunk 25---
func (p *Proxy) GetConsumedMocks(_ context.Context, id uint64) ([]models.MockState, error) { m, ok := p.MockManagers.Load(id) if !ok { return nil, fmt.Errorf("mock manager not found to get consumed filtered mocks") } return m.(*MockManager).GetConsumedMocks(), nil }
------------------

--- File: pkg/core/proxy/tls/ca.go---

--- Chunk 1---
func commandExists(cmd string) bool { _, err := exec.LookPath(cmd) return err == nil }
------------------

--- Chunk 2---
func updateCaStore(ctx context.Context) error { commandRun := false for _, cmd := range caStoreUpdateCmd { if commandExists(cmd) { commandRun = true c := exec.CommandContext(ctx, cmd) _, err := c.CombinedOutput() if err != nil { select { case <-ctx.Done(): return ctx.Err() default: return err } } } } if !commandRun { return fmt.Errorf("no valid CA store tools command found") } return nil }
------------------

--- Chunk 3---
func getCaPaths() ([]string, error) { var caPaths []string for _, dir := range caStorePath { if util.IsDirectoryExist(dir) { caPaths = append(caPaths, dir) } } if len(caPaths) == 0 { return nil, fmt.Errorf("no valid CA store path found") } return caPaths, nil }
------------------

--- Chunk 4---
func extractCertToTemp() (string, error) { tempFile, err := os.CreateTemp("", "ca.crt") if err != nil { return "", err } defer func(tempFile *os.File) { err := tempFile.Close() if err != nil { return } }(tempFile) // Change the file permissions to allow read access for all users err = os.Chmod(tempFile.Name(), 0666) if err != nil { return "", err } // Write to the file _, err = tempFile.Write(caCrt) if err != nil { return "", err } // Close the file err = tempFile.Close() if err != nil { return "", err } return tempFile.Name(), nil }
------------------

--- Chunk 5---
func isJavaCAExist(ctx context.Context, alias, storepass, cacertsPath string) bool { cmd := exec.CommandContext(ctx, "keytool", "-list", "-keystore", cacertsPath, "-storepass", storepass, "-alias", alias) err := cmd.Run() select { case <-ctx.Done(): return false default: } return err == nil }
------------------

--- Chunk 6---
Function installJavaCA (start): func installJavaCA(ctx context.Context, logger *zap.Logger, caPath string) error { // check if java is installed if util.IsJavaInstalled() { logger.Debug("checking java path from default java home") javaHome, err := util.GetJavaHome(ctx) if err != nil { utils.LogError(logger, err, "Java detected but failed to find JAVA_HOME") return err } // Assuming modern Java structure (without /jre/) cacertsPath := fmt.Sprintf("%s/lib/security/cacerts", javaHome) // You can modify these as per your requirements storePass := "changeit" alias := "keployCA" logger.Debug("", zap.Any("java_home", javaHome), zap.Any("caCertsPath", cacertsPath), zap.Any("caPath", caPath)) if isJavaCAExist(ctx, alias, storePass, cacertsPath) { logger.Debug("Java detected and CA already exists", zap.String("path", cacertsPath)) return nil } cmd := exec.CommandContext(ctx, "keytool", "-import", "-trustcacerts", "-keystore", cacertsPath,
------------------

--- Chunk 7---
Function installJavaCA (end): "-storepass", storePass, "-noprompt", "-alias", alias, "-file", caPath) cmdOutput, err := cmd.CombinedOutput() if err != nil { select { case <-ctx.Done(): return ctx.Err() default: utils.LogError(logger, err, "Java detected but failed to import CA", zap.String("output", string(cmdOutput))) return err } } logger.Debug("Java detected and successfully imported CA", zap.String("path", cacertsPath), zap.String("output", string(cmdOutput))) logger.Debug("Successfully imported CA", zap.Any("", cmdOutput)) } else { logger.Debug("Java is not installed on the system") } return nil }
------------------

--- Chunk 8---
Function SetupCA (start): func SetupCA(ctx context.Context, logger *zap.Logger) error { caPaths, err := getCaPaths() if err != nil { utils.LogError(logger, err, "Failed to find the CA store path") return err } for _, path := range caPaths { caPath := filepath.Join(path, "ca.crt") fs, err := os.Create(caPath) if err != nil { utils.LogError(logger, err, "Failed to create path for ca certificate", zap.Any("root store path", path)) return err } _, err = fs.Write(caCrt) if err != nil { utils.LogError(logger, err, "Failed to write custom ca certificate", zap.Any("root store path", path)) return err } // install CA in the java keystore if java is installed err = installJavaCA(ctx, logger, caPath) if err != nil { utils.LogError(logger, err, "Failed to install CA in the java keystore") return err } } // Update the trusted CAs store err = updateCaStore(ctx) if err != nil { utils.LogError(logger, err
------------------

--- Chunk 9---
Function SetupCA (end): , "Failed to update the CA store") return err } tempCertPath, err := extractCertToTemp() if err != nil { utils.LogError(logger, err, "Failed to extract certificate to tmp folder") return err } // for node err = os.Setenv("NODE_EXTRA_CA_CERTS", tempCertPath) if err != nil { utils.LogError(logger, err, "Failed to set environment variable NODE_EXTRA_CA_CERTS") return err } // for python err = os.Setenv("REQUESTS_CA_BUNDLE", tempCertPath) if err != nil { utils.LogError(logger, err, "Failed to set environment variable REQUESTS_CA_BUNDLE") return err } return nil }
------------------

--- Chunk 10---
Function CertForClient (start): func CertForClient(logger *zap.Logger, clientHello *tls.ClientHelloInfo, caPrivKey any, caCertParsed *x509.Certificate, backdate time.Time) (*tls.Certificate, error) { // Ensure log level is set only once /* * Since multiple goroutines can call this function concurrently, we need to ensure that the log level is set only once. */ setLogLevelOnce.Do(func() { // * Set the log level to error to avoid unnecessary logs. like below... // 2025/03/18 20:54:25 [INFO] received CSR // 2025/03/18 20:54:25 [INFO] generating key: ecdsa-256 // 2025/03/18 20:54:25 [INFO] received CSR // 2025/03/18 20:54:25 [INFO] generating key: ecdsa-256 // 2025/03/18 20:54:25 [INFO] encoded CSR // 2025/03/18 20:54:25 [INFO] encoded CSR //
------------------

--- Chunk 11---
Function CertForClient (part 2): 2025/03/18 20:54:25 [INFO] signed certificate with serial number 435398774381835435678674951099961010543769077102 cfsslLog.Level = cfsslLog.LevelError }) // Generate a new server certificate and private key for the given hostname dstURL := clientHello.ServerName remoteAddr := clientHello.Conn.RemoteAddr().(*net.TCPAddr) sourcePort := remoteAddr.Port SrcPortToDstURL.Store(sourcePort, dstURL) serverReq := &csr.CertificateRequest{ //Make the name accordng to the ip of the request CN: clientHello.ServerName, Hosts: []string{ clientHello.ServerName, }, KeyRequest: csr.NewKeyRequest(), } serverCsr, serverKey, err := csr.ParseRequest(serverReq) if err != nil { return nil, fmt.Errorf("failed to create server CSR: %v", err) } cryptoSigner, ok := caPrivKey.(crypto.Signer) if !ok { return nil, fmt.Errorf("failed to typecast the caPrivKey") } signerd, err := local.New
------------------

--- Chunk 12---
Function CertForClient (part 3): Signer(cryptoSigner, caCertParsed, signer.DefaultSigAlgo(cryptoSigner), nil) if err != nil { return nil, fmt.Errorf("failed to create signer: %v", err) } if backdate.IsZero() { logger.Debug("backdate is zero, using current time") backdate = time.Now() } // Case: time freezing (an Ent. feature) is enabled, // If application time is frozen in past, and the certificate is signed today, then the certificate will be invalid. // This results in a certificate error during tls handshake. // To avoid this, we set the certificateâ€™s validity period (NotBefore and NotAfter) // by referencing the testcase request time of the application (backdate) instead of the current real time. // // Note: If you have recorded test cases before April 20, 2024 (http://www.sslchecker.com/certdecoder?su=269725513dfeb137f6f29b8488f17ca9) // and are using time freezing, please reach out to us if you get tls handshake error. signReq := signer.SignRequest{ Hosts: serverReq.Host
------------------

--- Chunk 13---
Function CertForClient (end): s, Request: string(serverCsr), Profile: "web", NotBefore: backdate.AddDate(-1, 0, 0), NotAfter: time.Now().AddDate(1, 0, 0), } serverCert, err := signerd.Sign(signReq) if err != nil { return nil, fmt.Errorf("failed to sign server certificate: %v", err) } logger.Debug("signed the certificate for a duration of 2 years", zap.Any("notBefore", signReq.NotBefore.String()), zap.Any("notAfter", signReq.NotAfter.String())) // Load the server certificate and private key serverTLSCert, err := tls.X509KeyPair(serverCert, serverKey) if err != nil { return nil, fmt.Errorf("failed to load server certificate and key: %v", err) } return &serverTLSCert, nil }
------------------

--- File: pkg/core/proxy/tls/tls.go---

--- Chunk 1---
func IsTLSHandshake(data []byte) bool { if len(data) < 5 { return false } return data[0] == 0x16 && data[1] == 0x03 && (data[2] == 0x00 || data[2] == 0x01 || data[2] == 0x02 || data[2] == 0x03) }
------------------

--- Chunk 2---
Function HandleTLSConnection (start): func HandleTLSConnection(_ context.Context, logger *zap.Logger, conn net.Conn, backdate time.Time) (net.Conn, error) { //Load the CA certificate and private key caPrivKey, err := helpers.ParsePrivateKeyPEM(caPKey) if err != nil { utils.LogError(logger, err, "Failed to parse CA private key") return nil, err } caCertParsed, err := helpers.ParseCertificatePEM(caCrt) if err != nil { utils.LogError(logger, err, "Failed to parse CA certificate") return nil, err } // Create a TLS configuration config := &tls.Config{ GetCertificate: func(clientHello *tls.ClientHelloInfo) (*tls.Certificate, error) { return CertForClient(logger, clientHello, caPrivKey, caCertParsed, backdate) }, } // Wrap the TCP conn with TLS tlsConn := tls.Server(conn, config) // Perform the handshake err = tlsConn.Handshake() if err != nil { utils.LogError(logger, err, "failed to complete TLS handshake with the client") return nil, err } // Use the tlsConn for further
------------------

--- Chunk 3---
Function HandleTLSConnection (end): communication // For example, you can read and write data using tlsConn.Read() and tlsConn.Write() // Here, we simply close the conn return tlsConn, nil }
------------------

--- File: pkg/core/proxy/treedb.go---

--- Chunk 1---
func NewTreeDb(comparator func(a, b interface{}) int) *TreeDb { return &TreeDb{ rbt: redblacktree.NewWith(comparator), mutex: &sync.Mutex{}, } }
------------------

--- Chunk 2---
func (db *TreeDb) insert(key interface{}, obj interface{}) { db.mutex.Lock() defer db.mutex.Unlock() db.rbt.Put(key, obj) }
------------------

--- Chunk 3---
func (db *TreeDb) delete(key interface{}) bool { db.mutex.Lock() defer db.mutex.Unlock() _, found := db.rbt.Get(key) if !found { return false } db.rbt.Remove(key) return true }
------------------

--- Chunk 4---
func (db *TreeDb) update(oldKey interface{}, newKey interface{}, newObj interface{}) bool { db.mutex.Lock() defer db.mutex.Unlock() _, found := db.rbt.Get(oldKey) if !found { return false } db.rbt.Remove(oldKey) db.rbt.Put(newKey, newObj) return true }
------------------

--- Chunk 5---
func (db *TreeDb) deleteAll() { db.mutex.Lock() defer db.mutex.Unlock() db.rbt.Clear() }
------------------

--- Chunk 6---
func (db *TreeDb) getAll() []interface{} { db.mutex.Lock() defer db.mutex.Unlock() return db.rbt.Values() }
------------------

--- File: pkg/core/proxy/util.go---

--- Chunk 1---
func writeNsswitchConfig(logger *zap.Logger, nsSwitchConfig string, data []byte, perm os.FileMode) error { err := os.WriteFile(nsSwitchConfig, data, perm) if err != nil { logger.Error("failed to write the configuration to the nsswitch.conf file to redirect the DNS queries to proxy", zap.Error(err)) return err } return nil }
------------------

--- Chunk 2---
Function globalPassThrough (start): func (p *Proxy) globalPassThrough(ctx context.Context, client, dest net.Conn) error { logger := p.logger.With(zap.Any("Client ConnectionID", ctx.Value(models.ClientConnectionIDKey).(string)), zap.Any("Destination ConnectionID", ctx.Value(models.DestConnectionIDKey).(string)), zap.Any("Client IP Address", client.RemoteAddr().String())) clientBuffChan := make(chan []byte) destBuffChan := make(chan []byte) errChan := make(chan error, 2) // read requests from client err := pUtil.ReadFromPeer(ctx, logger, client, clientBuffChan, errChan, pUtil.Client) if err != nil { return fmt.Errorf("error reading from client:%v", err) } // read responses from destination err = pUtil.ReadFromPeer(ctx, logger, dest, destBuffChan, errChan, pUtil.Destination) if err != nil { return fmt.Errorf("error reading from destination:%v", err) } //write the request or response buffer to the respective destination for { select { case <-ctx.Done(): return ctx.Err() case buffer := <-clientBuffChan: // Write the request message to the destination
------------------

--- Chunk 3---
Function globalPassThrough (end): _, err := dest.Write(buffer) if err != nil { utils.LogError(logger, err, "failed to write request message to the destination server") return fmt.Errorf("error writing to destination") } case buffer := <-destBuffChan: // Write the response message to the client _, err := client.Write(buffer) if err != nil { utils.LogError(logger, err, "failed to write response message to the client") return fmt.Errorf("error writing to client") } case err := <-errChan: if err == io.EOF { return nil } return err } } }
------------------

--- Chunk 4---
func localMock(copyMock []interface{}) ([]models.Mock, error) { var copiedMocks []models.Mock for _, m := range copyMock { if mock, ok := m.(*models.Mock); ok { copiedMocks = append(copiedMocks, *mock) } else { return nil, fmt.Errorf("expected mock instance, got %v", m) } } return copiedMocks, nil }
------------------

--- File: pkg/core/proxy/util/util.go---

--- Chunk 1---
func GetNextID() int64 { return atomic.AddInt64(&idCounter, 1) }
------------------

--- Chunk 2---
func (c *Conn) Read(p []byte) (int, error) { c.mu.Lock() defer c.mu.Unlock() if len(p) == 0 { c.Logger.Debug("the length is 0 for the reading from customConn") } return c.Reader.Read(p) }
------------------

--- Chunk 3---
func HasCompleteHTTPHeaders(buf []byte) bool { // Check for the presence of the end of headers sequence "\r\n\r\n" endOfHeaders := []byte("\r\n\r\n") if len(buf) < len(endOfHeaders) { return false } // Check if the buffer contains the end of headers sequence return bytes.Contains(buf, endOfHeaders) }
------------------

--- Chunk 4---
func IsHTTPReq(buf []byte) bool { isHTTP := bytes.HasPrefix(buf[:], []byte("HTTP/")) || bytes.HasPrefix(buf[:], []byte("GET ")) || bytes.HasPrefix(buf[:], []byte("POST ")) || bytes.HasPrefix(buf[:], []byte("PUT ")) || bytes.HasPrefix(buf[:], []byte("PATCH ")) || bytes.HasPrefix(buf[:], []byte("DELETE ")) || bytes.HasPrefix(buf[:], []byte("OPTIONS ")) || bytes.HasPrefix(buf[:], []byte("HEAD ")) || bytes.HasPrefix(buf[:], []byte("CONNECT ")) return isHTTP }
------------------

--- Chunk 5---
func ReadBuffConn(ctx context.Context, logger *zap.Logger, conn net.Conn, bufferChannel chan []byte, errChannel chan error) { //TODO: where to close the errChannel for { select { case <-ctx.Done(): // errChannel <- ctx.Err() return default: if conn == nil { logger.Debug("the conn is nil") } buffer, err := ReadBytes(ctx, logger, conn) if err != nil { if ctx.Err() != nil { // to avoid sending buffer to closed channel if the context is cancelled return } if err != io.EOF { utils.LogError(logger, err, "failed to read the packet message in proxy") } errChannel <- err return } if ctx.Err() != nil { // to avoid sending buffer to closed channel if the context is cancelled return } bufferChannel <- buffer } } }
------------------

--- Chunk 6---
Function ReadHTTPHeadersUntilEnd (start): func ReadHTTPHeadersUntilEnd(ctx context.Context, logger *zap.Logger, conn net.Conn) ([]byte, error) { readErr := errors.New("failed to read HTTP headers") // Read the incoming data (headers) initialBuf, err := ReadBytes(ctx, logger, conn) // Early return if we receive EOF with no data if err == io.EOF && len(initialBuf) == 0 { logger.Debug("received EOF, closing conn", zap.Error(err)) return nil, readErr } // Handle errors other than EOF if err != nil && err != io.EOF { utils.LogError(logger, err, "failed to read HTTP headers") return nil, readErr } // Check if the initial buffer already contains complete headers if HasCompleteHTTPHeaders(initialBuf) { logger.Debug("received complete HTTP headers in initial buffer", zap.Any("size", len(initialBuf)), zap.Any("headers", string(initialBuf))) return initialBuf, nil } // If not, continue reading until we find the end of headers var buffer []byte buffer = append(buffer, initialBuf...) for { select { case <-ctx.Done(): return buffer, ctx.Err()
------------------

--- Chunk 7---
Function ReadHTTPHeadersUntilEnd (end): default: // Check if the connection is nil if conn == nil { logger.Debug("the conn is nil") return nil, readErr } // Read more data until we find the header end sequence part, err := ReadBytes(ctx, logger, conn) if err != nil { if err == io.EOF && len(part) == 0 { break // EOF reached, but nothing more to read } utils.LogError(logger, err, "error while reading HTTP headers") return nil, readErr } // Append the new data to the buffer buffer = append(buffer, part...) // Check if we reached the end of headers if HasCompleteHTTPHeaders(buffer) { logger.Debug("received complete HTTP headers", zap.Any("size", len(buffer)), zap.Any("headers", string(buffer))) return buffer, nil } } } }
------------------

--- Chunk 8---
func ReadInitialBuf(ctx context.Context, logger *zap.Logger, conn net.Conn) ([]byte, error) { readErr := errors.New("failed to read the initial request buffer") initialBuf, err := ReadBytes(ctx, logger, conn) if err == io.EOF && len(initialBuf) == 0 { logger.Debug("received EOF, closing conn", zap.Error(err)) return nil, readErr } if err != nil && err != io.EOF { utils.LogError(logger, err, "failed to read the request message in proxy") return nil, readErr } logger.Debug("received initial buffer", zap.Any("size", len(initialBuf)), zap.Any("initial buffer", initialBuf)) return initialBuf, nil }
------------------

--- Chunk 9---
Function ReadBytes (start): func ReadBytes(ctx context.Context, logger *zap.Logger, reader io.Reader) ([]byte, error) { var buffer []byte const maxEmptyReads = 5 emptyReads := 0 // Channel to communicate read results readResult := make(chan struct { n int err error buf []byte }) g, ctx := errgroup.WithContext(ctx) defer func() { err := g.Wait() if err != nil { utils.LogError(logger, err, "failed to read the request message in proxy") } close(readResult) }() for { // Start a goroutine to perform the read operation g.Go(func() error { defer Recover(logger, nil, nil) buf := make([]byte, 1024) n, err := reader.Read(buf) if ctx.Err() != nil { return nil } readResult <- struct { n int err error buf []byte }{n, err, buf} return nil }) // Use a select statement to wait for either the read result or context cancellation select { case <-ctx.Done
------------------

--- Chunk 10---
Function ReadBytes (end): (): return buffer, ctx.Err() case result := <-readResult: if result.n > 0 { buffer = append(buffer, result.buf[:result.n]...) emptyReads = 0 // Reset the counter because we got some data } if result.err != nil { if result.err == io.EOF { emptyReads++ if emptyReads >= maxEmptyReads { return buffer, result.err // Multiple EOFs in a row, probably a true EOF } time.Sleep(time.Millisecond * 100) // Sleep before trying again continue } return buffer, result.err } if result.n < len(result.buf) { return buffer, nil } } } }
------------------

--- Chunk 11---
Function ReadRequiredBytes (start): func ReadRequiredBytes(ctx context.Context, logger *zap.Logger, reader io.Reader, numBytes int) ([]byte, error) { var buffer []byte const maxEmptyReads = 5 emptyReads := 0 // Channel to communicate read results readResult := make(chan struct { n int err error buf []byte }) g, ctx := errgroup.WithContext(ctx) defer func() { err := g.Wait() if err != nil { utils.LogError(logger, err, "failed to read the request message in proxy") } close(readResult) }() for numBytes > 0 { // Start a goroutine to perform the read operation g.Go(func() error { defer Recover(logger, nil, nil) buf := make([]byte, numBytes) n, err := reader.Read(buf) if ctx.Err() != nil { return nil } readResult <- struct { n int err error buf []byte }{n, err, buf} return nil }) // Use a select statement to wait for either the read result or context cancellation
------------------

--- Chunk 12---
Function ReadRequiredBytes (end): with timeout select { case <-ctx.Done(): return buffer, ctx.Err() // case <-time.After(5 * time.Second): // logger.Error("timeout occurred while reading the packet") // return buffer, context.DeadlineExceeded case result := <-readResult: if result.n > 0 { buffer = append(buffer, result.buf[:result.n]...) numBytes -= result.n emptyReads = 0 // Reset the counter because we got some data } if result.err != nil { if result.err == io.EOF { emptyReads++ if emptyReads >= maxEmptyReads { return buffer, result.err // Multiple EOFs in a row, probably a true EOF } time.Sleep(time.Millisecond * 100) // Sleep before trying again continue } return buffer, result.err } if numBytes == 0 { return buffer, nil } } } return buffer, nil }
------------------

--- Chunk 13---
func ReadFromPeer(ctx context.Context, logger *zap.Logger, conn net.Conn, buffChan chan []byte, errChan chan error, peer Peer) error { //get the error group from the context g, ok := ctx.Value(models.ErrGroupKey).(*errgroup.Group) if !ok { return errors.New("failed to get the error group from the context while reading from peer") } var client, dest net.Conn if peer == Client { client = conn } else { dest = conn } g.Go(func() error { defer Recover(logger, client, dest) defer close(buffChan) ReadBuffConn(ctx, logger, conn, buffChan, errChan) return nil }) return nil }
------------------

--- Chunk 14---
Function PassThrough (start): func PassThrough(ctx context.Context, logger *zap.Logger, clientConn net.Conn, dstCfg *models.ConditionalDstCfg, requestBuffer [][]byte) ([]byte, error) { logger.Debug("passing through the network traffic to the destination server", zap.Any("Destination Addr", dstCfg.Addr)) // making destConn var destConn net.Conn var err error if dstCfg.TLSCfg != nil { logger.Debug("trying to establish a TLS connection with the destination server", zap.Any("Destination Addr", dstCfg.Addr)) destConn, err = tls.Dial("tcp", dstCfg.Addr, dstCfg.TLSCfg) if err != nil { utils.LogError(logger, err, "failed to dial the conn to destination server", zap.Any("server address", dstCfg.Addr)) return nil, err } logger.Debug("TLS connection established with the destination server", zap.Any("Destination Addr", destConn.RemoteAddr().String())) } else { logger.Debug("trying to establish a connection with the destination server", zap.Any("Destination Addr", dstCfg.Addr)) destConn, err = net.Dial("tcp", dstCfg.Addr) if err != nil { utils.LogError(logger, err
------------------

--- Chunk 15---
Function PassThrough (part 2): , "failed to dial the destination server") return nil, err } logger.Debug("connection established with the destination server", zap.Any("Destination Addr", destConn.RemoteAddr().String())) } logger.Debug("trying to forward requests to target", zap.Any("Destination Addr", destConn.RemoteAddr().String())) for _, v := range requestBuffer { _, err := destConn.Write(v) if err != nil { utils.LogError(logger, err, "failed to write request message to the destination server", zap.Any("Destination Addr", destConn.RemoteAddr().String())) return nil, err } } // channels for writing messages from proxy to destination or client destBufferChannel := make(chan []byte) errChannel := make(chan error, 1) go func() { defer Recover(logger, clientConn, nil) defer close(destBufferChannel) defer close(errChannel) defer func(destConn net.Conn) { err := destConn.Close() if err != nil { utils.LogError(logger, err, "failed to close the destination connection") } }(destConn) ReadBuffConn(ctx, logger, destConn, destBufferChannel, errChannel)
------------------

--- Chunk 16---
Function PassThrough (end): }() select { case buffer := <-destBufferChannel: // Write the response message to the client _, err := clientConn.Write(buffer) if err != nil { if ctx.Err() != nil { return nil, ctx.Err() } utils.LogError(logger, err, "failed to write response to the client") return nil, err } logger.Debug("the iteration for the generic response ends with responses:"+strconv.Itoa(len(buffer)), zap.Any("buffer", buffer)) case err := <-errChannel: // Applied this nolint to ignore the staticcheck error here because of readability // nolint:staticcheck if netErr, ok := err.(net.Error); !(ok && netErr.Timeout()) && err != nil { return nil, err } return nil, nil case <-ctx.Done(): return nil, ctx.Err() } return nil, nil }
------------------

--- Chunk 17---
func ToIP4AddressStr(ip uint32) string { // convert the IP address to a 32-bit binary number ipBinary := fmt.Sprintf("%032b", ip) // divide the binary number into four 8-bit segments firstByte, _ := strconv.ParseUint(ipBinary[0:8], 2, 64) secondByte, _ := strconv.ParseUint(ipBinary[8:16], 2, 64) thirdByte, _ := strconv.ParseUint(ipBinary[16:24], 2, 64) fourthByte, _ := strconv.ParseUint(ipBinary[24:32], 2, 64) // concatenate the four decimal segments with a dot separator to form the dot-decimal string return fmt.Sprintf("%d.%d.%d.%d", firstByte, secondByte, thirdByte, fourthByte) }
------------------

--- Chunk 18---
func ToIPv6AddressStr(ip [4]uint32) string { // construct a byte slice ipBytes := make([]byte, 16) // IPv6 address is 128 bits or 16 bytes long for i := 0; i < 4; i++ { // for each uint32, extract its four bytes and put them into the byte slice ipBytes[i*4] = byte(ip[i] >> 24) ipBytes[i*4+1] = byte(ip[i] >> 16) ipBytes[i*4+2] = byte(ip[i] >> 8) ipBytes[i*4+3] = byte(ip[i]) } // net.IP is a byte slice, so it can be directly used to construct an IPv6 address ipv6Addr := net.IP(ipBytes) return ipv6Addr.String() }
------------------

--- Chunk 19---
func GetLocalIPv4() (net.IP, error) { ifaces, err := net.Interfaces() if err != nil { return nil, err } for _, iface := range ifaces { addrs, err := iface.Addrs() if err != nil { return nil, err } for _, addr := range addrs { ipNet, ok := addr.(*net.IPNet) if ok && !ipNet.IP.IsLoopback() && ipNet.IP.To4() != nil { return ipNet.IP, nil } } } return nil, fmt.Errorf("no valid IP address found") }
------------------

--- Chunk 20---
func ToIPV4(ip net.IP) (uint32, bool) { ipv4 := ip.To4() if ipv4 == nil { return 0, false // Return 0 or handle the error accordingly } return uint32(ipv4[0])<<24 | uint32(ipv4[1])<<16 | uint32(ipv4[2])<<8 | uint32(ipv4[3]), true }
------------------

--- Chunk 21---
func GetLocalIPv6() (net.IP, error) { ifaces, err := net.Interfaces() if err != nil { return nil, err } for _, iface := range ifaces { addrs, err := iface.Addrs() if err != nil { return nil, err } for _, addr := range addrs { ipNet, ok := addr.(*net.IPNet) if ok && !ipNet.IP.IsLoopback() && ipNet.IP.To4() == nil && ipNet.IP.To16() != nil { return ipNet.IP, nil } } } return nil, fmt.Errorf("no valid IPv6 address found") }
------------------

--- Chunk 22---
func IPv6ToUint32Array(ip net.IP) ([4]uint32, error) { ip = ip.To16() if ip == nil { return [4]uint32{}, errors.New("invalid IPv6 address") } return [4]uint32{ binary.BigEndian.Uint32(ip[0:4]), binary.BigEndian.Uint32(ip[4:8]), binary.BigEndian.Uint32(ip[8:12]), binary.BigEndian.Uint32(ip[12:16]), }, nil }
------------------

--- Chunk 23---
func IPToDotDecimal(ip net.IP) string { ipStr := ip.String() if ip.To4() != nil { ipStr = ip.To4().String() } return ipStr }
------------------

--- Chunk 24---
func IsDirectoryExist(path string) bool { info, err := os.Stat(path) if os.IsNotExist(err) { return false } return info.IsDir() }
------------------

--- Chunk 25---
func IsJava(input string) bool { // Convert the input string and the search term "java" to lowercase for a case-insensitive comparison. inputLower := strings.ToLower(input) searchTerm := "java" searchTermLower := strings.ToLower(searchTerm) // Use strings.Contains to check if the lowercase input contains the lowercase search term. return strings.Contains(inputLower, searchTermLower) }
------------------

--- Chunk 26---
func IsJavaInstalled() bool { _, err := exec.LookPath("java") return err == nil }
------------------

--- Chunk 27---
func GetJavaHome(ctx context.Context) (string, error) { cmd := exec.CommandContext(ctx, "java", "-XshowSettings:properties", "-version") var out bytes.Buffer cmd.Stderr = &out // The output we need is printed to STDERR err := cmd.Run() if err != nil { select { case <-ctx.Done(): return "", ctx.Err() default: return "", err } } for _, line := range strings.Split(out.String(), "\n") { if strings.Contains(line, "java.home") { parts := strings.Split(line, "=") if len(parts) > 1 { return strings.TrimSpace(parts[1]), nil } } } return "", fmt.Errorf("java.home not found in command output") }
------------------

--- Chunk 28---
Function Recover (start): func Recover(logger *zap.Logger, client, dest net.Conn) { if logger == nil { fmt.Println(Emoji + "Failed to recover from panic. Logger is nil.") return } sentry.Flush(2 * time.Second) if r := recover(); r != nil { logger.Error("Recovered from panic in parser, closing active connections") if client != nil { err := client.Close() if err != nil { // Use string matching as a last resort to check for the specific error if !strings.Contains(err.Error(), "use of closed network connection") { // Log other errors utils.LogError(logger, err, "failed to close the client connection") } } } if dest != nil { err := dest.Close() if err != nil { // Use string matching as a last resort to check for the specific error if !strings.Contains(err.Error(), "use of closed network connection") { // Log other errors utils.LogError(logger, err, "failed to close the destination connection") } } } utils.HandleRecovery(logger, r, "Recovered from panic") sentry.Flush(time
------------------

--- Chunk 29---
Function Recover (end): .Second * 2) } }
------------------

--- File: pkg/core/record.go---

--- Chunk 1---
func (c *Core) GetIncoming(ctx context.Context, id uint64, opts models.IncomingOptions) (<-chan *models.TestCase, error) { return c.Hooks.Record(ctx, id, opts) }
------------------

--- Chunk 2---
func (c *Core) GetOutgoing(ctx context.Context, id uint64, opts models.OutgoingOptions) (<-chan *models.Mock, error) { m := make(chan *models.Mock, 500) err := c.Proxy.Record(ctx, id, m, opts) if err != nil { return nil, err } return m, nil }
------------------

--- File: pkg/core/replay.go---

--- Chunk 1---
func (c *Core) MockOutgoing(ctx context.Context, id uint64, opts models.OutgoingOptions) error { err := c.Mock(ctx, id, opts) if err != nil { return err } return nil }
------------------

--- File: pkg/core/service.go---

--- Chunk 1---
func NewSessions() *Sessions { return &Sessions{ sessions: sync.Map{}, } }
------------------

--- Chunk 2---
func (s *Sessions) Get(id uint64) (*Session, bool) { v, ok := s.sessions.Load(id) if !ok { return nil, false } return v.(*Session), true }
------------------

--- Chunk 3---
func (s *Sessions) Set(id uint64, session *Session) { s.sessions.Store(id, session) }
------------------

--- Chunk 4---
func (s *Sessions) Delete(id uint64) { s.sessions.Delete(id) }
------------------

--- Chunk 5---
func (s *Sessions) getAll() map[uint64]*Session { sessions := map[uint64]*Session{} s.sessions.Range(func(k, v interface{}) bool { sessions[k.(uint64)] = v.(*Session) return true }) return sessions }
------------------

--- Chunk 6---
func (s *Sessions) GetAllMC() []chan<- *models.Mock { sessions := s.getAll() var mc []chan<- *models.Mock for _, session := range sessions { mc = append(mc, session.MC) } return mc }
------------------

--- File: pkg/core/tester/tester.go---

--- Chunk 1---
func New(logger *zap.Logger, testBenchInfo core.TestBenchInfo) *Tester { return &Tester{ logger: logger, testBenchInfo: testBenchInfo, } }
------------------

--- Chunk 2---
func (t *Tester) Setup(ctx context.Context, opts models.TestingOptions) error { t.logger.Info("ðŸ§ª setting up environment for testing keploy with itself") if opts.Mode == models.MODE_TEST { err := t.setupReplay(ctx) if err != nil { return err } return nil } err := t.setupRecord(ctx) if err != nil { return err } return nil }
------------------

--- Chunk 3---
Function setupReplay (start): func (t *Tester) setupReplay(ctx context.Context) error { setUpErr := errors.New("failed to setup the keploy replay testing") recordPid, err := utils.GetPIDFromPort(ctx, t.logger, recordPort) if err != nil { t.logger.Error("failed to get the keployRecord pid", zap.Error(err)) utils.LogError(t.logger, err, "failed to get the keployRecord pid from port", zap.Any("port", recordPort)) return setUpErr } t.logger.Debug(fmt.Sprintf("keployRecord pid:%v", recordPid)) // err = t.testBenchInfo.SendKeployPids(models.RecordKey, recordPid) // if err != nil { // utils.LogError(t.logger, err, fmt.Sprintf("failed to send keploy %v server pid to the epbf program", models.MODE_RECORD), zap.Any("Keploy Pid", recordPid)) // return setUpErr // } // err = t.testBenchInfo.SendKeployPorts(models.RecordKey, recordPort) // if err != nil { // utils.LogError(t.logger, err, fmt.Sprintf("failed to send keploy %v server port
------------------

--- Chunk 4---
Function setupReplay (end): to the epbf program", models.MODE_RECORD), zap.Any("Keploy server port", recordPort)) // return setUpErr // } // err = t.testBenchInfo.SendKeployPorts(models.TestKey, testPort) // if err != nil { // utils.LogError(t.logger, err, fmt.Sprintf("failed to send keploy %v server port to the epbf program", models.MODE_TEST), zap.Any("Keploy server port", testPort)) // return setUpErr // } // to get the pid of keployTest binary in keployRecord binary, we have to wait for some time till the proxy server is started // TODO: find other way to filter child process (keployTest) pid in parent process binary (keployRecord) time.Sleep(10 * time.Second) // just for test bench. return nil }
------------------

--- Chunk 5---
Function setupRecord (start): func (t *Tester) setupRecord(ctx context.Context) error { go func() { defer utils.Recover(t.logger) timeout := 30 * time.Second startTime := time.Now() ticker := time.NewTicker(500 * time.Millisecond) defer ticker.Stop() for { select { case <-ticker.C: testPid, err := utils.GetPIDFromPort(ctx, t.logger, testPort) if err != nil { t.logger.Debug("failed to get the keploytest pid", zap.Error(err)) continue } if testPid == 0 { continue } t.logger.Debug("keploytest pid", zap.Uint32("pid", testPid)) // // sending keploytest binary pid in keployrecord binary to filter out ingress/egress calls related to keploytest binary. // err = t.testBenchInfo.SendKeployPids(models.TestKey, testPid) // if err != nil { // utils.LogError(t.logger, err, fmt.Sprintf("failed to send keploy %v server pid to the epbf program", models.MODE_TEST), zap.Any("Keploy Pid
------------------

--- Chunk 6---
Function setupRecord (end): ", testPid)) // } return case <-time.After(timeout - time.Since(startTime)): t.logger.Info("Timeout reached, exiting loop from setupRecordTesting") return // Exit the goroutine case <-ctx.Done(): t.logger.Debug("Context cancelled, exiting loop from setupRecordTesting") return // Exit the goroutine } } }() return nil }
------------------

--- File: pkg/http2.go---

--- Chunk 1---
Function ExtractHTTP2Frame (start): func ExtractHTTP2Frame(data []byte) (http2.Frame, int, error) { if len(data) < 9 { // Minimum frame size return nil, 0, fmt.Errorf("incomplete frame: got %d bytes, need at least 9", len(data)) } // First, read the frame header to determine the full frame length // Length is a 24-bit unsigned integer length := (uint32(data[0]) << 16) | (uint32(data[1]) << 8) | uint32(data[2]) // Validate length before proceeding if length > MaxFrameSize { return nil, 0, fmt.Errorf("frame length %d exceeds maximum allowed size %d", length, MaxFrameSize) } // Check if we have the complete frame totalSize := int(length) + 9 // frame header (9 bytes) + payload if len(data) < totalSize { return nil, 0, fmt.Errorf("incomplete frame: got %d bytes, need %d", len(data), totalSize) } // Create a reader for just this frame frameReader := bytes.NewReader(data[:totalSize]) framer := http2
------------------

--- Chunk 2---
Function ExtractHTTP2Frame (end): .NewFramer(nil, frameReader) // Read the frame frame, err := framer.ReadFrame() if err != nil { return nil, 0, fmt.Errorf("failed to read frame: %v", err) } return frame, totalSize, nil }
------------------

--- Chunk 3---
func NewStreamManager(logger *zap.Logger) *DefaultStreamManager { return &DefaultStreamManager{ streams: make(map[uint32]*HTTP2StreamState), buffer: make([]byte, 0, DefaultMaxFrameSize), logger: logger, decoder: hpack.NewDecoder(MaxDynamicTableSize, nil), // Initialize separate header tables requestHeaders: make(map[string]string), responseHeaders: make(map[string]string), trailerHeaders: make(map[string]string), } }
------------------

--- Chunk 4---
func (sm *DefaultStreamManager) storeHeaders(headers *models.GrpcHeaders, isRequest bool, isTrailer bool) { if headers == nil { return } // Select the appropriate header table var headerTable map[string]string if isTrailer { headerTable = sm.trailerHeaders } else if isRequest { headerTable = sm.requestHeaders } else { headerTable = sm.responseHeaders } // Store pseudo headers for k, v := range headers.PseudoHeaders { headerTable[k] = v } // Store ordinary headers for k, v := range headers.OrdinaryHeaders { headerTable[k] = v } }
------------------

--- Chunk 5---
Function rehydrateHeaders (start): func (sm *DefaultStreamManager) rehydrateHeaders(headers *models.GrpcHeaders, isRequest bool, isTrailer bool) { if headers == nil { return } // Select the appropriate header table var headerTable map[string]string if isTrailer { headerTable = sm.trailerHeaders } else if isRequest { headerTable = sm.requestHeaders } else { headerTable = sm.responseHeaders } // Initialize maps if nil if headers.PseudoHeaders == nil { headers.PseudoHeaders = make(map[string]string) } if headers.OrdinaryHeaders == nil { headers.OrdinaryHeaders = make(map[string]string) } // Add missing headers from the connection's header table for k, v := range headerTable { if strings.HasPrefix(k, ":") { // This is a pseudo-header if _, exists := headers.PseudoHeaders[k]; !exists { headers.PseudoHeaders[k] = v } } else { // This is an ordinary header if _, exists := headers.OrdinaryHeaders[k]; !exists { headers.OrdinaryHeaders[k] = v }
------------------

--- Chunk 6---
Function rehydrateHeaders (end): } } }
------------------

--- Chunk 7---
Function HandleFrame (start): func (sm *DefaultStreamManager) HandleFrame(frame http2.Frame, isOutgoing bool, frameTime time.Time) error { sm.mutex.Lock() defer sm.mutex.Unlock() streamID := frame.Header().StreamID // Initialize stream if it doesn't exist if _, exists := sm.streams[streamID]; !exists { prefix := "Incoming_" if isOutgoing { prefix = "Outgoing_" } requestID := fmt.Sprintf(prefix+"%d", streamID) sm.streams[streamID] = &HTTP2StreamState{ ID: streamID, RequestID: requestID, isRequest: streamID != 0, // Stream 0 is for connection control startTime: frameTime, } } stream := sm.streams[streamID] switch f := frame.(type) { case *http2.HeadersFrame: // Store header block fragments for later processing stream.headerBlockFragments = append(stream.headerBlockFragments, f.HeaderBlockFragment()) if f.HeadersEnded() { // Process complete headers headerBlock := bytes.Join(stream.headerBlockFragments, nil) stream.headerBlockF
------------------

--- Chunk 8---
Function HandleFrame (part 2): ragments = nil fields, err := sm.decoder.DecodeFull(headerBlock) if err != nil { return fmt.Errorf("failed to decode headers: %v", err) } for _, field := range fields { if field.Name == ":status" { stream.isRequest = false } } headers := ProcessHeaders(fields) if !stream.headersReceived { // These are initial headers if stream.isRequest { // Rehydrate from request headers sm.rehydrateHeaders(headers, true, false) stream.grpcReq = &models.GrpcReq{ Headers: *headers, } // Store headers for future requests sm.storeHeaders(headers, true, false) } else { // Rehydrate from response headers sm.rehydrateHeaders(headers, false, false) stream.grpcResp = &models.GrpcResp{ Headers: *headers, } // Store headers for future responses sm.storeHeaders(headers, false, false) } stream.headersReceived = true } else if !stream.trailersReceived && !stream.isRequest { // These are trailers
------------------

--- Chunk 9---
Function HandleFrame (part 3): (only for responses) // Rehydrate from trailer headers sm.rehydrateHeaders(headers, false, true) if stream.grpcResp != nil { stream.grpcResp.Trailers = *headers // Store headers for future trailers sm.storeHeaders(headers, false, true) } stream.trailersReceived = true } } if f.StreamEnded() { stream.endStreamReceived = true // Process the complete message if err := sm.processCompleteMessage(stream); err != nil { return err } sm.checkStreamCompletion(streamID) // Clear header fragments and data frames after processing request part if stream.isRequest { stream.headerBlockFragments = nil stream.endStreamReceived = false stream.headersReceived = false stream.trailersReceived = false } else { stream.endTime = frameTime } } case *http2.DataFrame: // Store data frames for later processing stream.dataFrames = append(stream.dataFrames, f.Data()) if f.StreamEnded() { stream.endStreamReceived = true // Process the complete message
------------------

--- Chunk 10---
Function HandleFrame (end): if err := sm.processCompleteMessage(stream); err != nil { return err } sm.checkStreamCompletion(streamID) // Clear header fragments and data frames after processing request part if stream.isRequest { stream.headerBlockFragments = nil stream.endStreamReceived = false stream.headersReceived = false stream.trailersReceived = false } else { stream.endTime = frameTime } } } return nil }
------------------

--- Chunk 11---
func (sm *DefaultStreamManager) GetCompleteStreams() []*HTTP2Stream { sm.mutex.Lock() defer sm.mutex.Unlock() var completed []*HTTP2Stream for id, stream := range sm.streams { if stream.isComplete { stream.grpcReq.Timestamp = stream.startTime stream.grpcResp.Timestamp = stream.endTime http2Stream := &HTTP2Stream{ ID: id, GRPCReq: stream.grpcReq, GRPCResp: stream.grpcResp, } completed = append(completed, http2Stream) } } return completed }
------------------

--- Chunk 12---
func (sm *DefaultStreamManager) CleanupStream(streamID uint32) { sm.mutex.Lock() defer sm.mutex.Unlock() delete(sm.streams, streamID) }
------------------

--- Chunk 13---
func (sm *DefaultStreamManager) processCompleteMessage(stream *HTTP2StreamState) error { if stream == nil { return fmt.Errorf("nil stream") } if len(stream.dataFrames) == 0 { return nil } // Combine all data frame fragments data := bytes.Join(stream.dataFrames, nil) // Process the complete gRPC message msg := CreateLengthPrefixedMessageFromPayload(data) if stream.isRequest { if stream.grpcReq == nil { stream.grpcReq = &models.GrpcReq{} } stream.grpcReq.Body = msg } else { if stream.grpcResp == nil { stream.grpcResp = &models.GrpcResp{} } stream.grpcResp.Body = msg } // Clear the data frames after processing stream.dataFrames = nil return nil }
------------------

--- Chunk 14---
func (sm *DefaultStreamManager) checkStreamCompletion(streamID uint32) { stream := sm.streams[streamID] // For requests: mark the message part as complete but don't complete the stream if stream.isRequest { if stream.endStreamReceived && stream.headersReceived { // Mark request part as complete but keep stream open for response stream.requestComplete = true } return // Don't mark stream as complete yet } // For responses: check if both request and response are complete if !stream.isRequest && stream.requestComplete { if stream.endStreamReceived && stream.headersReceived && stream.trailersReceived { // For gRPC, ensure trailers are received sm.logger.Debug("Stream completed", zap.Any("stream", stream)) stream.isComplete = true } } }
------------------

--- Chunk 15---
func ProcessHeaders(fields []hpack.HeaderField) *models.GrpcHeaders { headers := &models.GrpcHeaders{ PseudoHeaders: make(map[string]string), OrdinaryHeaders: make(map[string]string), } for _, field := range fields { if len(field.Name) > 0 && field.Name[0] == ':' { headers.PseudoHeaders[field.Name] = field.Value } else { headers.OrdinaryHeaders[field.Name] = field.Value } } return headers }
------------------

--- Chunk 16---
func IsGRPCGatewayRequest(stream *HTTP2Stream) bool { if stream == nil || stream.GRPCReq == nil { return false } // Check for HTTP gateway specific headers headers := stream.GRPCReq.Headers.OrdinaryHeaders gatewayHeaders := []string{ "grpc-gateway-user-agent", } for _, header := range gatewayHeaders { if _, exists := headers[header]; exists { return true } } return false }
------------------

--- Chunk 17---
Function SimulateGRPC (start): func SimulateGRPC(_ context.Context, tc *models.TestCase, testSetID string, logger *zap.Logger) (*models.GrpcResp, error) { grpcReq := tc.GrpcReq logger.Info("starting test for of", zap.Any("test case", models.HighlightString(tc.Name)), zap.Any("test set", models.HighlightString(testSetID))) // Create a TCP connection conn, err := net.Dial("tcp", grpcReq.Headers.PseudoHeaders[":authority"]) if err != nil { return nil, fmt.Errorf("failed to dial: %w", err) } defer func() { if cerr := conn.Close(); cerr != nil { logger.Error("failed to close connection", zap.Error(cerr)) } }() // Write HTTP/2 connection preface if _, err := conn.Write([]byte(http2.ClientPreface)); err != nil { return nil, fmt.Errorf("failed to write client preface: %w", err) } // Create HTTP/2 client connection framer := http2.NewFramer(conn, conn) framer.AllowIllegalWrites = true // Allow HTTP/2 without TLS // Initial sequence of frames that gRPC sends: //
------------------

--- Chunk 18---
Function SimulateGRPC (part 2): 1. Empty SETTINGS frame // 2. Wait for server SETTINGS and ACK // 3. Send SETTINGS ACK // 4. HEADERS frame // 5. DATA frame // 6. WINDOW_UPDATE frame (connection-level) // 7. PING frame // Send initial empty SETTINGS frame err = framer.WriteSettings() if err != nil { return nil, fmt.Errorf("failed to write settings: %w", err) } // Wait for server's SETTINGS and SETTINGS ACK settingsReceived := false settingsAckReceived := false for !settingsReceived || !settingsAckReceived { frame, err := framer.ReadFrame() if err != nil { return nil, fmt.Errorf("failed to read server settings: %w", err) } switch f := frame.(type) { case *http2.SettingsFrame: if f.IsAck() { settingsAckReceived = true } else { settingsReceived = true // Send ACK for server SETTINGS if err := framer.WriteSettingsAck(); err != nil { return nil, fmt.Errorf("failed to write settings ack: %w", err
------------------

--- Chunk 19---
Function SimulateGRPC (part 3): ) } } } } // Create stream ID (client streams are odd-numbered) streamID := uint32(1) // Prepare HEADERS frame headerBuf := new(bytes.Buffer) encoder := hpack.NewEncoder(headerBuf) // Write pseudo-headers first (order matters in HTTP/2) pseudoHeaders := []struct { name, value string }{ {":method", grpcReq.Headers.PseudoHeaders[":method"]}, {":scheme", grpcReq.Headers.PseudoHeaders[":scheme"]}, {":authority", grpcReq.Headers.PseudoHeaders[":authority"]}, {":path", grpcReq.Headers.PseudoHeaders[":path"]}, } for _, ph := range pseudoHeaders { if err := encoder.WriteField(hpack.HeaderField{Name: ph.name, Value: ph.value}); err != nil { return nil, fmt.Errorf("failed to encode pseudo-header %s: %w", ph.name, err) } } // Write regular headers in a specific order orderedHeaders := []struct { name, value string }{} // Add any remaining headers from the request for k
------------------

--- Chunk 20---
Function SimulateGRPC (part 4): , v := range grpcReq.Headers.OrdinaryHeaders { orderedHeaders = append(orderedHeaders, struct{ name, value string }{k, v}) } for _, h := range orderedHeaders { if err := encoder.WriteField(hpack.HeaderField{Name: h.name, Value: h.value}); err != nil { return nil, fmt.Errorf("failed to encode header %s: %w", h.name, err) } } // Send HEADERS frame if err := framer.WriteHeaders(http2.HeadersFrameParam{ StreamID: streamID, BlockFragment: headerBuf.Bytes(), EndHeaders: true, EndStream: false, }); err != nil { return nil, fmt.Errorf("failed to write headers: %w", err) } // Create and send DATA frame payload, err := CreatePayloadFromLengthPrefixedMessage(grpcReq.Body) if err != nil { return nil, fmt.Errorf("failed to create payload: %w", err) } if err := framer.WriteData(streamID, true, payload); err != nil { return nil, fmt.Errorf("failed to write data: %w", err)
------------------

--- Chunk 21---
Function SimulateGRPC (part 5): } // Send WINDOW_UPDATE frame for connection (stream 0) if err := framer.WriteWindowUpdate(0, 983041); err != nil { return nil, fmt.Errorf("failed to write window update: %w", err) } // Send PING frame pingData := [8]byte{1, 2, 3, 4, 5, 6, 7, 8} // Example ping data if err := framer.WritePing(false, pingData); err != nil { return nil, fmt.Errorf("failed to write ping: %w", err) } // Read response frames grpcResp := &models.GrpcResp{ Headers: models.GrpcHeaders{ PseudoHeaders: make(map[string]string), OrdinaryHeaders: make(map[string]string), }, Body: models.GrpcLengthPrefixedMessage{}, Trailers: models.GrpcHeaders{ PseudoHeaders: make(map[string]string), OrdinaryHeaders: make(map[string]string), }, } // Read frames until we get the end of stream streamEnded := false for !streamEnded { frame, err
------------------

--- Chunk 22---
Function SimulateGRPC (part 6): := framer.ReadFrame() if err != nil { if err == io.EOF { break } return nil, fmt.Errorf("failed to read frame: %w", err) } switch f := frame.(type) { case *http2.HeadersFrame: // If we already have headers, this must be trailers if len(grpcResp.Headers.OrdinaryHeaders) > 0 || len(grpcResp.Headers.PseudoHeaders) > 0 { decoder := hpack.NewDecoder(MaxDynamicTableSize, func(f hpack.HeaderField) { if strings.HasPrefix(f.Name, ":") { grpcResp.Trailers.PseudoHeaders[f.Name] = f.Value } else { grpcResp.Trailers.OrdinaryHeaders[f.Name] = f.Value } }) if _, err := decoder.Write(f.HeaderBlockFragment()); err != nil { return nil, fmt.Errorf("failed to decode trailers: %w", err) } } else { // These are headers decoder := hpack.NewDecoder(MaxDynamicTableSize, func(f hpack.HeaderField) { if strings.HasPrefix(f
------------------

--- Chunk 23---
Function SimulateGRPC (end): .Name, ":") { grpcResp.Headers.PseudoHeaders[f.Name] = f.Value } else { grpcResp.Headers.OrdinaryHeaders[f.Name] = f.Value } }) if _, err := decoder.Write(f.HeaderBlockFragment()); err != nil { return nil, fmt.Errorf("failed to decode headers: %w", err) } } if f.StreamEnded() { streamEnded = true } case *http2.DataFrame: frame, err := ReadGRPCFrame(bytes.NewReader(f.Data())) if err != nil { return nil, fmt.Errorf("failed to read gRPC frame: %w", err) } grpcResp.Body = CreateLengthPrefixedMessageFromPayload(frame) if f.StreamEnded() { streamEnded = true } case *http2.RSTStreamFrame: // Stream was reset by peer streamEnded = true case *http2.GoAwayFrame: // Connection is being closed streamEnded = true } } return grpcResp, nil }
------------------

--- Chunk 24---
func CreateLengthPrefixedMessageFromPayload(data []byte) models.GrpcLengthPrefixedMessage { msg := models.GrpcLengthPrefixedMessage{} // If the body is not length prefixed, we return the default value. if len(data) < 5 { return msg } // The first byte is the compression flag. msg.CompressionFlag = uint(data[0]) // The next 4 bytes are message length. msg.MessageLength = binary.BigEndian.Uint32(data[1:5]) // The payload could be empty. We only parse it if it is present. if len(data) > 5 { // Use protoscope to decode the message. msg.DecodedData = protoscope.Write(data[5:], protoscope.WriterOptions{}) } return msg }
------------------

--- Chunk 25---
func CreatePayloadFromLengthPrefixedMessage(msg models.GrpcLengthPrefixedMessage) ([]byte, error) { scanner := protoscope.NewScanner(msg.DecodedData) encodedData, err := scanner.Exec() if err != nil { return nil, fmt.Errorf("could not encode grpc msg using protoscope: %v", err) } // Note that the encoded length is present in the msg, but it is also equal to the len of encodedData. // We should give the preference to the length of encodedData, since the mocks might have been altered. // Reserve 1 byte for compression flag, 4 bytes for length capture. payload := make([]byte, 1+4) payload[0] = uint8(msg.CompressionFlag) binary.BigEndian.PutUint32(payload[1:5], uint32(len(encodedData))) payload = append(payload, encodedData...) return payload, nil }
------------------

--- Chunk 26---
func ReadGRPCFrame(r io.Reader) ([]byte, error) { // Read compression flag (1 byte) compFlag := make([]byte, 1) if _, err := io.ReadFull(r, compFlag); err != nil { if err == io.EOF { return nil, err } return nil, fmt.Errorf("failed to read compression flag: %w", err) } // Read message length (4 bytes) lenBuf := make([]byte, 4) if _, err := io.ReadFull(r, lenBuf); err != nil { return nil, fmt.Errorf("failed to read message length: %w", err) } msgLen := binary.BigEndian.Uint32(lenBuf) // Read message data msgBuf := make([]byte, msgLen) if _, err := io.ReadFull(r, msgBuf); err != nil { return nil, fmt.Errorf("failed to read message: %w", err) } // Combine all parts frame := make([]byte, 5+msgLen) frame[0] = compFlag[0] copy(frame[1:5], lenBuf) copy(frame[5:], msgBuf) return frame, nil }
------------------

--- File: pkg/matcher/grpc/match.go---

--- Chunk 1---
Function Match (start): func Match(tc *models.TestCase, actualResp *models.GrpcResp, noiseConfig map[string]map[string][]string, logger *zap.Logger) (bool, *models.Result) { expectedResp := tc.GrpcResp result := &models.Result{ HeadersResult: make([]models.HeaderResult, 0), BodyResult: make([]models.BodyResult, 0), TrailerResult: make([]models.HeaderResult, 0), } // Local variables to track overall match status differences := make(map[string]struct { Expected string Actual string Message string }) // Only compare :status in pseudo headers if expectedStatus, ok := expectedResp.Headers.PseudoHeaders[":status"]; ok { actualStatus, exists := actualResp.Headers.PseudoHeaders[":status"] headerResult := models.HeaderResult{ Expected: models.Header{ Key: ":status", Value: []string{expectedStatus}, }, Actual: models.Header{ Key: ":status", Value: []string{}, }, } if !exists { differences["headers.pseudo_headers.:status"] =
------------------

--- Chunk 2---
Function Match (part 2): struct { Expected string Actual string Message string }{ Expected: expectedStatus, Actual: "", Message: "missing status header in response", } headerResult.Normal = false } else { headerResult.Actual.Value = []string{actualStatus} headerResult.Normal = expectedStatus == actualStatus if !headerResult.Normal { differences["headers.pseudo_headers.:status"] = struct { Expected string Actual string Message string }{ Expected: expectedStatus, Actual: actualStatus, Message: "status header value mismatch", } } } result.HeadersResult = append(result.HeadersResult, headerResult) } // Compare Body - using specialized body types for gRPC // Compare compression flag compressionFlagNormal := expectedResp.Body.CompressionFlag == actualResp.Body.CompressionFlag if !compressionFlagNormal { differences["body.compression_flag"] = struct { Expected string Actual string Message string }{ Expected: fmt.Sprintf("%d
------------------

--- Chunk 3---
Function Match (part 3): ", expectedResp.Body.CompressionFlag), Actual: fmt.Sprintf("%d", actualResp.Body.CompressionFlag), Message: "compression flag mismatch", } } result.BodyResult = append(result.BodyResult, models.BodyResult{ Normal: compressionFlagNormal, Type: models.GrpcCompression, Expected: fmt.Sprintf("%d", expectedResp.Body.CompressionFlag), Actual: fmt.Sprintf("%d", actualResp.Body.CompressionFlag), }) // Compare message length messageLengthNormal := expectedResp.Body.MessageLength == actualResp.Body.MessageLength if !messageLengthNormal { differences["body.message_length"] = struct { Expected string Actual string Message string }{ Expected: fmt.Sprintf("%d", expectedResp.Body.MessageLength), Actual: fmt.Sprintf("%d", actualResp.Body.MessageLength), Message: "message length mismatch", } } result.BodyResult = append(result.BodyResult, models.BodyResult{ Normal: messageLengthNormal, Type: models.GrpcLength, Expected: fmt.Sprintf("%d", expectedResp.Body.MessageLength),
------------------

--- Chunk 4---
Function Match (part 4): Actual: fmt.Sprintf("%d", actualResp.Body.MessageLength), }) // Compare decoded data decodedDataNormal := expectedResp.Body.DecodedData == actualResp.Body.DecodedData if !decodedDataNormal { differences["body.decoded_data"] = struct { Expected string Actual string Message string }{ Expected: expectedResp.Body.DecodedData, Actual: actualResp.Body.DecodedData, Message: "decoded data mismatch", } } result.BodyResult = append(result.BodyResult, models.BodyResult{ Normal: decodedDataNormal, Type: models.GrpcData, Expected: expectedResp.Body.DecodedData, Actual: actualResp.Body.DecodedData, }) // Handle noise configuration var ( bodyNoise = noiseConfig["body"] headerNoise = noiseConfig["header"] ) if bodyNoise == nil { bodyNoise = map[string][]string{} } if headerNoise == nil { headerNoise = map[string][]string{} } // Apply noise configuration to ignore specified differences for path := range differences { pathParts := strings.Split
------------------

--- Chunk 5---
Function Match (part 5): (path, ".") if len(pathParts) > 1 { if pathParts[0] == "body" && len(bodyNoise) > 0 { if _, found := bodyNoise[strings.Join(pathParts[1:], ".")]; found { delete(differences, path) } } else if pathParts[0] == "headers" && len(headerNoise) > 0 { if _, found := headerNoise[pathParts[len(pathParts)-1]]; found { delete(differences, path) } } } } // Calculate final match status based on remaining differences matched := len(differences) == 0 if !matched { // Display differences to the user, similar to HTTP matcher logDiffs := matcher.NewDiffsPrinter(tc.Name) newLogger := pp.New() newLogger.WithLineInfo = false newLogger.SetColorScheme(models.GetFailingColorScheme()) var logs = "" logs = logs + newLogger.Sprintf("Testrun failed for testcase with id: %s\n\n--------------------------------------------------------------------\n\n", tc.Name) // Display gRPC differences if len(differences) >
------------------

--- Chunk 6---
Function Match (part 6): 0 { for path, diff := range differences { if strings.HasPrefix(path, "headers.") { // Header differences header := strings.TrimPrefix(path, "headers.") logDiffs.PushHeaderDiff(diff.Expected, diff.Actual, header, headerNoise) } else if strings.HasPrefix(path, "body.") { bodyPart := strings.TrimPrefix(path, "body.") switch bodyPart { case "message_length": // Message length is a good indicator of difference for gRPC logDiffs.PushHeaderDiff(diff.Expected, diff.Actual, "message_length (body)", bodyNoise) case "compression_flag": // Compression flag logDiffs.PushHeaderDiff(diff.Expected, diff.Actual, "compression_flag (body)", bodyNoise) default: // Any other body differences logDiffs.PushBodyDiff(diff.Expected, diff.Actual, bodyNoise) } } } } else { // If there are no specific differences but match still failed, show a generic message logDiffs.PushHeaderDiff("See logs for details", "Matching failed", "gRPC", nil)
------------------

--- Chunk 7---
Function Match (end): } // Print the differences _, err := newLogger.Printf(logs) if err != nil { utils.LogError(logger, err, "failed to print the logs") } err = logDiffs.Render() if err != nil { utils.LogError(logger, err, "failed to render the diffs") } } else { // Display success message newLogger := pp.New() newLogger.WithLineInfo = false newLogger.SetColorScheme(models.GetPassingColorScheme()) var log2 = "" log2 += newLogger.Sprintf("Testrun passed for testcase with id: %s\n\n--------------------------------------------------------------------\n\n", tc.Name) _, err := newLogger.Printf(log2) if err != nil { utils.LogError(logger, err, "failed to print the logs") } } return matched, result }
------------------

--- File: pkg/matcher/http/absmatch.go---

--- Chunk 1---
Function AbsMatch (start): func AbsMatch(tcs1, tcs2 *models.TestCase, noiseConfig map[string]map[string][]string, ignoreOrdering bool, logger *zap.Logger) (bool, bool, bool, *models.AbsResult) { if tcs1 == nil || tcs2 == nil { logger.Error("test case is nil", zap.Any("tcs1", tcs1), zap.Any("tcs2", tcs2)) return false, false, false, nil } pass := true absResult := &models.AbsResult{} kindResult := models.StringResult{ Normal: true, Expected: string(tcs1.Kind), Actual: string(tcs2.Kind), } nameResult := models.StringResult{ Normal: true, Expected: tcs1.Name, Actual: tcs2.Name, } // curlResult := models.StringResult{ // Normal: true, // Expected: tcs1.Curl, // Actual: tcs2.Curl, // } //compare kind if tcs1.Kind != tcs2.Kind { kindResult.Normal
------------------

--- Chunk 2---
Function AbsMatch (part 2): = false logger.Info("test case kind is not equal", zap.Any("tcs1Kind", tcs1.Kind), zap.Any("tcs2Kind", tcs2.Kind)) pass = false } //compare name (just for debugging) if tcs1.Name != tcs2.Name { nameResult.Normal = false logger.Debug("test case name is not equal", zap.Any("tcs1Name", tcs1.Name), zap.Any("tcs2Name", tcs2.Name)) } //compare curl // ok := CompareCurl(tcs1.Curl, tcs2.Curl, logger) // if !ok { // curlResult.Normal = false // logger.Info("test case curl is not equal", zap.Any("tcs1Curl", tcs1.Curl), zap.Any("tcs2Curl", tcs2.Curl)) // pass = false // } //compare http req reqPass, reqCompare := CompareHTTPReq(tcs1, tcs2, noiseConfig, ignoreOrdering, logger) if !reqPass { logger.Info("test case http req is not equal",
------------------

--- Chunk 3---
Function AbsMatch (end): zap.Any("tcs1HttpReq", tcs1.HTTPReq), zap.Any("tcs2HttpReq", tcs2.HTTPReq)) pass = false } //compare http resp respPass, respCompare := CompareHTTPResp(tcs1, tcs2, noiseConfig, ignoreOrdering, logger) if !respPass { logger.Info("test case http resp is not equal", zap.Any("tcs1HttpResp", tcs1.HTTPResp), zap.Any("tcs2HttpResp", tcs2.HTTPResp)) pass = false } absResult.Name = nameResult absResult.Kind = kindResult absResult.Req = reqCompare absResult.Resp = respCompare // absResult.CurlResult = curlResult return pass, reqPass, respPass, absResult }
------------------

--- Chunk 4---
Function CompareHTTPReq (start): func CompareHTTPReq(tcs1, tcs2 *models.TestCase, _ models.GlobalNoise, ignoreOrdering bool, logger *zap.Logger) (bool, models.ReqCompare) { pass := true //compare http req reqCompare := models.ReqCompare{ MethodResult: models.StringResult{ Normal: true, Expected: string(tcs1.HTTPReq.Method), Actual: string(tcs2.HTTPReq.Method), }, URLResult: models.StringResult{ Normal: true, Expected: tcs1.HTTPReq.URL, Actual: tcs2.HTTPReq.URL, }, URLParamsResult: []models.URLParamsResult{}, ProtoMajor: models.IntResult{ Normal: true, Expected: tcs1.HTTPReq.ProtoMajor, Actual: tcs2.HTTPReq.ProtoMajor, }, ProtoMinor: models.IntResult{ Normal: true, Expected: tcs1.HTTPReq.ProtoMinor, Actual: tcs2.HTTPReq.ProtoMinor, }, HeaderResult: []models.HeaderResult{},
------------------

--- Chunk 5---
Function CompareHTTPReq (part 2): BodyResult: models.BodyResult{ Normal: true, Expected: tcs1.HTTPReq.Body, Actual: tcs2.HTTPReq.Body, }, } if tcs1.HTTPReq.Method != tcs2.HTTPReq.Method { reqCompare.MethodResult.Normal = false logger.Debug("test case http req method is not equal", zap.Any("tcs1HttpReqMethod", tcs1.HTTPReq.Method), zap.Any("tcs2HttpReqMethod", tcs2.HTTPReq.Method)) pass = false } if tcs1.HTTPReq.URL != tcs2.HTTPReq.URL { reqCompare.URLResult.Normal = false logger.Debug("test case http req url is not equal", zap.Any("tcs1HttpReqURL", tcs1.HTTPReq.URL), zap.Any("tcs2HttpReqURL", tcs2.HTTPReq.URL)) pass = false } if tcs1.HTTPReq.ProtoMajor != tcs2.HTTPReq.ProtoMajor { reqCompare.ProtoMajor.Normal = false logger.Debug("test case http req proto major is not equal", zap.Any("tcs1HttpReqProtoMajor", tcs1.HTTP
------------------

--- Chunk 6---
Function CompareHTTPReq (part 3): Req.ProtoMajor), zap.Any("tcs2HttpReqProtoMajor", tcs2.HTTPReq.ProtoMajor)) pass = false } if tcs1.HTTPReq.ProtoMinor != tcs2.HTTPReq.ProtoMinor { reqCompare.ProtoMinor.Normal = false logger.Debug("test case http req proto minor is not equal", zap.Any("tcs1HttpReqProtoMinor", tcs1.HTTPReq.ProtoMinor), zap.Any("tcs2HttpReqProtoMinor", tcs2.HTTPReq.ProtoMinor)) pass = false } //compare url params urlParams1 := tcs1.HTTPReq.URLParams urlParams2 := tcs2.HTTPReq.URLParams if len(urlParams1) == len(urlParams2) { ok := CompareURLParams(urlParams1, urlParams2, &reqCompare.URLParamsResult) if !ok { logger.Debug("test case http req url params are not equal", zap.Any("tcs1HttpReqURLParams", tcs1.HTTPReq.URLParams), zap.Any("tcs2HttpReqURLParams", tcs2.HTTPReq.URLParams)) pass = false } } else {
------------------

--- Chunk 7---
Function CompareHTTPReq (part 4): logger.Debug("test case http req url params are not equal", zap.Any("tcs1HttpReqURLParams", tcs1.HTTPReq.URLParams), zap.Any("tcs2HttpReqURLParams", tcs2.HTTPReq.URLParams)) pass = false } reqHeaderNoise := map[string][]string{} reqHeaderNoise["keploy-test-id"] = []string{} reqHeaderNoise["keploy-test-set-id"] = []string{} tcs1.HTTPReq.Header["Keploy-Test-Id"] = "dummyTest" tcs1.HTTPReq.Header["Keploy-Test-Set-Id"] = "dummyTestSet" // compare http req headers ok := matcher.CompareHeaders(pkg.ToHTTPHeader(tcs1.HTTPReq.Header), pkg.ToHTTPHeader(tcs2.HTTPReq.Header), &reqCompare.HeaderResult, reqHeaderNoise) if !ok { logger.Debug("test case http req headers are not equal", zap.Any("tcs1HttpReqHeaders", tcs1.HTTPReq.Header), zap.Any("tcs2HttpReqHeaders", tcs2.HTTPReq.Header)) pass = false } reqBodyNoise := map[string][]string{} // compare http req body bodyType1
------------------

--- Chunk 8---
Function CompareHTTPReq (part 5): := models.Plain if json.Valid([]byte(tcs1.HTTPReq.Body)) { bodyType1 = models.JSON } bodyType2 := models.Plain if json.Valid([]byte(tcs2.HTTPReq.Body)) { bodyType2 = models.JSON } if bodyType1 != bodyType2 { logger.Debug("test case http req body type is not equal", zap.Any("tcs1HttpReqBodyType", bodyType1), zap.Any("tcs2HttpReqBodyType", bodyType2)) pass = false reqCompare.BodyResult.Normal = false return pass, reqCompare } bodyRes := true // stores the json body after removing the noise cleanExp, cleanAct := tcs1.HTTPReq.Body, tcs2.HTTPReq.Body var jsonComparisonResult matcher.JSONComparisonResult if !matcher.Contains(matcher.MapToArray(reqBodyNoise), "body") && bodyType1 == models.JSON { //validate the stored json validatedJSON, err := matcher.ValidateAndMarshalJSON(logger, &cleanExp, &cleanAct) if err != nil { logger.Error("failed to validate and marshal json", zap.Error(err))
------------------

--- Chunk 9---
Function CompareHTTPReq (end): reqCompare.BodyResult.Normal = false return false, reqCompare } if validatedJSON.IsIdentical() { jsonComparisonResult, err = matcher.JSONDiffWithNoiseControl(validatedJSON, reqBodyNoise, ignoreOrdering) exact := jsonComparisonResult.IsExact() if err != nil { logger.Error("failed to compare json", zap.Error(err)) reqCompare.BodyResult.Normal = false return false, reqCompare } if !exact { pass = false bodyRes = false } } else { pass = false bodyRes = false } // debug log for cleanExp and cleanAct logger.Debug("cleanExp", zap.Any("", cleanExp)) logger.Debug("cleanAct", zap.Any("", cleanAct)) } else { if !matcher.Contains(matcher.MapToArray(reqBodyNoise), "body") && tcs1.HTTPReq.Body != tcs2.HTTPReq.Body { pass = false bodyRes = false } } if !bodyRes { reqCompare.BodyResult.Normal = false } return pass, reqCompare }
------------------

--- Chunk 10---
Function CompareHTTPResp (start): func CompareHTTPResp(tcs1, tcs2 *models.TestCase, noiseConfig models.GlobalNoise, ignoreOrdering bool, logger *zap.Logger) (bool, models.RespCompare) { pass := true //compare http resp respCompare := models.RespCompare{ StatusCode: models.IntResult{ Normal: true, Expected: tcs1.HTTPResp.StatusCode, Actual: tcs2.HTTPResp.StatusCode, }, HeadersResult: []models.HeaderResult{}, BodyResult: models.BodyResult{ Normal: true, Expected: tcs1.HTTPResp.Body, Actual: tcs2.HTTPResp.Body, }, } if tcs1.HTTPResp.StatusCode != tcs2.HTTPResp.StatusCode { respCompare.StatusCode.Normal = false logger.Debug("test case http resp status code is not equal", zap.Any("tcs1HttpRespStatusCode", tcs1.HTTPResp.StatusCode), zap.Any("tcs2HttpRespStatusCode", tcs2.HTTPResp.StatusCode)) pass = false } //compare the auto added noise in test case noise1 := tcs1.Noise noise2 :=
------------------

--- Chunk 11---
Function CompareHTTPResp (part 2): tcs2.Noise ok := CompareNoise(noise1, noise2) if !ok { logger.Debug("test case noise is not equal", zap.Any("tcs1Noise", tcs1.Noise), zap.Any("tcs2Noise", tcs2.Noise)) logger.Debug("response body and headers can not be compared because noise is not equal") pass = false respCompare.BodyResult.Normal = false return pass, respCompare } noise := noise1 var ( bodyNoise = noiseConfig["body"] headerNoise = noiseConfig["header"] ) if bodyNoise == nil { bodyNoise = map[string][]string{} } if headerNoise == nil { headerNoise = map[string][]string{} } for field, regexArr := range noise { a := strings.Split(field, ".") if len(a) > 1 && a[0] == "body" { x := strings.Join(a[1:], ".") bodyNoise[strings.ToLower(x)] = regexArr } else if a[0] == "header" { headerNoise[strings.ToLower(a[len(a)-1])] = regexArr }
------------------

--- Chunk 12---
Function CompareHTTPResp (part 3): } // compare http resp headers ok = matcher.CompareHeaders(pkg.ToHTTPHeader(tcs1.HTTPResp.Header), pkg.ToHTTPHeader(tcs2.HTTPResp.Header), &respCompare.HeadersResult, headerNoise) if !ok { logger.Debug("test case http resp headers are not equal", zap.Any("tcs1HttpRespHeaders", tcs1.HTTPResp.Header), zap.Any("tcs2HttpRespHeaders", tcs2.HTTPResp.Header)) pass = false } // compare http resp body bodyType1 := models.Plain if json.Valid([]byte(tcs1.HTTPResp.Body)) { bodyType1 = models.JSON } bodyType2 := models.Plain if json.Valid([]byte(tcs2.HTTPResp.Body)) { bodyType2 = models.JSON } if bodyType1 != bodyType2 { logger.Debug("test case http resp body type is not equal", zap.Any("tcs1HttpRespBodyType", bodyType1), zap.Any("tcs2HttpRespBodyType", bodyType2)) pass = false respCompare.BodyResult.Normal = false return pass, respCompare } bodyRes := true // stores the json
------------------

--- Chunk 13---
Function CompareHTTPResp (part 4): body after removing the noise cleanExp, cleanAct := tcs1.HTTPResp.Body, tcs2.HTTPResp.Body var jsonComparisonResult matcher.JSONComparisonResult if !matcher.Contains(matcher.MapToArray(noise), "body") && bodyType1 == models.JSON { //validate the stored json validatedJSON, err := matcher.ValidateAndMarshalJSON(logger, &cleanExp, &cleanAct) if err != nil { logger.Error("failed to validate and marshal json", zap.Error(err)) respCompare.BodyResult.Normal = false return false, respCompare } if validatedJSON.IsIdentical() { jsonComparisonResult, err = matcher.JSONDiffWithNoiseControl(validatedJSON, bodyNoise, ignoreOrdering) exact := jsonComparisonResult.IsExact() if err != nil { logger.Error("failed to compare json", zap.Error(err)) respCompare.BodyResult.Normal = false return false, respCompare } if !exact { pass = false bodyRes = false } } else { pass = false bodyRes = false } // debug log for cleanExp and
------------------

--- Chunk 14---
Function CompareHTTPResp (end): cleanAct logger.Debug("cleanExp", zap.Any("", cleanExp)) logger.Debug("cleanAct", zap.Any("", cleanAct)) } else { if !matcher.Contains(matcher.MapToArray(noise), "body") && tcs1.HTTPResp.Body != tcs2.HTTPResp.Body { pass = false bodyRes = false } } if !bodyRes { respCompare.BodyResult.Normal = false } return pass, respCompare }
------------------

--- Chunk 15---
func CompareURLParams(urlParams1, urlParams2 map[string]string, urlParamsResult *[]models.URLParamsResult) bool { pass := true for k, v := range urlParams1 { if v2, ok := urlParams2[k]; ok { if v != v2 { pass = false } *urlParamsResult = append(*urlParamsResult, models.URLParamsResult{ Normal: v == v2, Expected: models.Params{ Key: k, Value: v, }, Actual: models.Params{ Key: k, Value: v2, }, }) } else { pass = false } } return pass }
------------------

--- Chunk 16---
func CompareNoise(noise1, noise2 map[string][]string) bool { pass := true for k, v := range noise1 { if v2, ok := noise2[k]; ok { if len(v) != len(v2) { pass = false } else { for i := 0; i < len(v); i++ { if v[i] != v2[i] { pass = false } } } } else { pass = false } } return pass }
------------------

--- Chunk 17---
Function CompareCurl (start): func CompareCurl(curl1, curl2 string, logger *zap.Logger) bool { // Parse the values into method, URL, headers, and data method1, url1, headers1, data1 := parseCurlString(curl1) method2, url2, headers2, data2 := parseCurlString(curl2) // Compare method, URL, and data if method1 != method2 || url1 != url2 || data1 != data2 { return false } // remove any quotes from the header keys (if any due to parsing issues) for k, v := range headers1 { delete(headers1, k) headers1[strings.Trim(k, "'")] = v } for k, v := range headers2 { delete(headers2, k) headers2[strings.Trim(k, "'")] = v } curlHeaderNoise := map[string][]string{} curlHeaderNoise["keploy-test-id"] = []string{} curlHeaderNoise["keploy-test-set-id"] = []string{} headers1["Keploy-Test-Id"] = "dummyTest" headers1["Keploy-Test-Set-Id"] = "dummyTestSet"
------------------

--- Chunk 18---
Function CompareCurl (end): hres := []models.HeaderResult{} ok := matcher.CompareHeaders(pkg.ToHTTPHeader(headers1), pkg.ToHTTPHeader(headers2), &hres, curlHeaderNoise) if !ok { logger.Debug("test case curl headers are not equal", zap.Any("curlHeaderResult", hres)) return false } return true }
------------------

--- Chunk 19---
func parseCurlString(curlString string) (method, url string, headers map[string]string, data string) { lines := strings.Split(curlString, "\\") headers = make(map[string]string) for _, line := range lines { line = strings.TrimSpace(line) if strings.HasPrefix(line, "--request") { method = strings.TrimSpace(strings.Split(line, " ")[1]) } else if strings.HasPrefix(line, "--url") { url = strings.TrimSpace(strings.Split(line, " ")[1]) } else if strings.HasPrefix(line, "--header") { headerParts := strings.SplitN(strings.TrimSpace(strings.TrimPrefix(line, "--header")), ":", 2) if len(headerParts) == 2 { headers[strings.TrimSpace(headerParts[0])] = strings.TrimSpace(headerParts[1]) } } else if strings.HasPrefix(line, "--data") { data = strings.TrimSpace(strings.TrimPrefix(line, "--data")) } } return }
------------------

--- File: pkg/matcher/http/match.go---

--- Chunk 1---
Function Match (start): func Match(tc *models.TestCase, actualResponse *models.HTTPResp, noiseConfig map[string]map[string][]string, ignoreOrdering bool, logger *zap.Logger) (bool, *models.Result) { bodyType := models.Plain if json.Valid([]byte(actualResponse.Body)) { bodyType = models.JSON } pass := true hRes := &[]models.HeaderResult{} res := &models.Result{ StatusCode: models.IntResult{ Normal: false, Expected: tc.HTTPResp.StatusCode, Actual: actualResponse.StatusCode, }, BodyResult: []models.BodyResult{{ Normal: false, Type: bodyType, Expected: tc.HTTPResp.Body, Actual: actualResponse.Body, }}, } noise := tc.Noise var ( bodyNoise = noiseConfig["body"] headerNoise = noiseConfig["header"] ) if bodyNoise != nil { if ignoreFields, ok := bodyNoise["*"]; ok && len(ignoreFields) > 0 && ignoreFields[0] == "*" { if noise["body"] == nil { noise["body"] = make([]string
------------------

--- Chunk 2---
Function Match (part 2): , 0) } } } else { bodyNoise = map[string][]string{} } if headerNoise == nil { headerNoise = map[string][]string{} } for field, regexArr := range noise { a := strings.Split(field, ".") if len(a) > 1 && a[0] == "body" { x := strings.Join(a[1:], ".") bodyNoise[strings.ToLower(x)] = regexArr } else if a[0] == "header" { headerNoise[strings.ToLower(a[len(a)-1])] = regexArr } } // stores the json body after removing the noise cleanExp, cleanAct := tc.HTTPResp.Body, actualResponse.Body var jsonComparisonResult matcherUtils.JSONComparisonResult if !matcherUtils.Contains(matcherUtils.MapToArray(noise), "body") && bodyType == models.JSON { //validate the stored json validatedJSON, err := matcherUtils.ValidateAndMarshalJSON(logger, &cleanExp, &cleanAct) if err != nil { return false, res } if validatedJSON.IsIdentical() { jsonComparisonResult,
------------------

--- Chunk 3---
Function Match (part 3): err = matcherUtils.JSONDiffWithNoiseControl(validatedJSON, bodyNoise, ignoreOrdering) pass = jsonComparisonResult.IsExact() if err != nil { return false, res } } else { pass = false } // debug log for cleanExp and cleanAct logger.Debug("cleanExp", zap.Any("", cleanExp)) logger.Debug("cleanAct", zap.Any("", cleanAct)) } else { if !matcherUtils.Contains(matcherUtils.MapToArray(noise), "body") && tc.HTTPResp.Body != actualResponse.Body { pass = false } } res.BodyResult[0].Normal = pass if !matcherUtils.CompareHeaders(pkg.ToHTTPHeader(tc.HTTPResp.Header), pkg.ToHTTPHeader(actualResponse.Header), hRes, headerNoise) { pass = false } res.HeadersResult = *hRes if tc.HTTPResp.StatusCode == actualResponse.StatusCode { res.StatusCode.Normal = true } else { pass = false } skipSuccessMsg := false if !pass { isStatusMismatch := false isHeaderMismatch := false isBodyMismatch := false logDiffs := matcherUtils
------------------

--- Chunk 4---
Function Match (part 4): .NewDiffsPrinter(tc.Name) newLogger := pp.New() newLogger.WithLineInfo = false newLogger.SetColorScheme(models.GetFailingColorScheme()) var logs = "" logs = logs + newLogger.Sprintf("Testrun failed for testcase with id: %s\n\n--------------------------------------------------------------------\n\n", tc.Name) // ------------ DIFFS RELATED CODE ----------- if !res.StatusCode.Normal { logDiffs.PushStatusDiff(fmt.Sprint(res.StatusCode.Expected), fmt.Sprint(res.StatusCode.Actual)) isStatusMismatch = true } else { isStatusMismatch = false } var ( actualHeader = map[string][]string{} expectedHeader = map[string][]string{} ) for _, j := range res.HeadersResult { var actualValue []string var expectedValue []string if !j.Normal { for _, v := range j.Actual.Value { _, temp, err := tools.RenderIfTemplatized(v) if err != nil { utils.LogError(logger, err, "failed to render the actual header") return false, nil } val, ok := temp.(string) if
------------------

--- Chunk 5---
Function Match (part 5): !ok { utils.LogError(logger, fmt.Errorf("failed to convert the actual header value to string while templatizing"), "") return false, nil } actualValue = append(actualValue, val) } for _, v := range j.Expected.Value { _, temp, err := tools.RenderIfTemplatized(v) if err != nil { utils.LogError(logger, err, "failed to render the expected header") return false, nil } val, ok := temp.(string) if !ok { utils.LogError(logger, fmt.Errorf("failed to convert the expected header value to string while templatizing"), "") return false, nil } expectedValue = append(expectedValue, val) } } if len(actualValue) != len(expectedValue) { isHeaderMismatch = true actualHeader[j.Actual.Key] = actualValue expectedHeader[j.Expected.Key] = expectedValue } else { for i, v := range actualValue { if v != expectedValue[i] { isHeaderMismatch = true actualHeader[j.Actual.Key] = actualValue expectedHeader[j
------------------

--- Chunk 6---
Function Match (part 6): .Expected.Key] = expectedValue break } } } } if isHeaderMismatch { for i, j := range expectedHeader { logDiffs.PushHeaderDiff(fmt.Sprint(j), fmt.Sprint(actualHeader[i]), i, headerNoise) } } actRespBodyType := pkg.GuessContentType([]byte(actualResponse.Body)) expRespBodyType := pkg.GuessContentType([]byte(tc.HTTPResp.Body)) if !res.BodyResult[0].Normal { if actRespBodyType != expRespBodyType { actRespBodyType = models.UnknownType } switch actRespBodyType { case models.JSON: patch, err := jsondiff.Compare(tc.HTTPResp.Body, actualResponse.Body) if err != nil { logger.Warn("failed to compute json diff", zap.Error(err)) } // Checking for templatized values. for _, val := range patch { // Parse the value in map. expStringVal, ok := val.OldValue.(string) if !ok { continue } // Parse the body into json. expResponse,
------------------

--- Chunk 7---
Function Match (part 7): err := matcherUtils.ParseIntoJSON(expStringVal) if err != nil { utils.LogError(logger, err, "failed to parse the exp response into json") break } actStringVal, ok := val.Value.(string) if !ok { continue } actResponse, err := matcherUtils.ParseIntoJSON(actStringVal) if err != nil { utils.LogError(logger, err, "failed to parse the act response into json") break } matcherUtils.CompareResponses(&expResponse, &actResponse, "") jsonBytes, err := json.Marshal(expResponse) if err != nil { return false, nil } actJSONBytes, err := json.Marshal(actResponse) if err != nil { return false, nil } tc.HTTPResp.Body = string(jsonBytes) actualResponse.Body = string(actJSONBytes) } validatedJSON, err := matcherUtils.ValidateAndMarshalJSON(logger, &tc.HTTPResp.Body, &actualResponse.Body) if err != nil { return false, res } isBodyMismatch = false if validatedJSON.IsIdentical() {
------------------

--- Chunk 8---
Function Match (part 8): jsonComparisonResult, err = matcherUtils.JSONDiffWithNoiseControl(validatedJSON, bodyNoise, ignoreOrdering) if err != nil { return false, res } if !pass { isBodyMismatch = true } else { isBodyMismatch = false } } // Comparing the body again after updating the expected patch, err = jsondiff.Compare(tc.HTTPResp.Body, actualResponse.Body) if err != nil { logger.Warn("failed to compute json diff", zap.Error(err)) } for _, op := range patch { if jsonComparisonResult.Matches() { logDiffs.SetHasarrayIndexMismatch(true) logDiffs.PushFooterDiff(strings.Join(jsonComparisonResult.Differences(), ", ")) } logDiffs.PushBodyDiff(fmt.Sprint(op.OldValue), fmt.Sprint(op.Value), bodyNoise) } default: // right now for every other type we would do a simple comparison, till we don't have dedicated logic for other types. if tc.HTTPResp.Body != actualResponse.Body { isBodyMismatch = true } logDiffs.PushBodyDiff(fmt.S
------------------

--- Chunk 9---
Function Match (part 9): print(tc.HTTPResp.Body), fmt.Sprint(actualResponse.Body), bodyNoise) } } if isStatusMismatch || isHeaderMismatch || isBodyMismatch { skipSuccessMsg = true _, err := newLogger.Printf(logs) if err != nil { utils.LogError(logger, err, "failed to print the logs") } err = logDiffs.Render() if err != nil { utils.LogError(logger, err, "failed to render the diffs") } } else { pass = true } } if !skipSuccessMsg { newLogger := pp.New() newLogger.WithLineInfo = false newLogger.SetColorScheme(models.GetPassingColorScheme()) var log2 = "" log2 += newLogger.Sprintf("Testrun passed for testcase with id: %s\n\n--------------------------------------------------------------------\n\n", tc.Name) _, err := newLogger.Printf(log2) if err != nil { utils.LogError(logger, err, "failed to print the logs") } } if len(tc.Assertions) > 1 || (len(tc.Assertions) == 1 && tc.Assertions[models.NoiseAssertion]
------------------

--- Chunk 10---
Function Match (end): == nil) { return AssertionMatch(tc, actualResponse, logger) } return pass, res }
------------------

--- Chunk 11---
Function AssertionMatch (start): func AssertionMatch(tc *models.TestCase, actualResponse *models.HTTPResp, logger *zap.Logger) (bool, *models.Result) { pass := true res := &models.Result{ StatusCode: models.IntResult{ Normal: false, Expected: tc.HTTPResp.StatusCode, Actual: actualResponse.StatusCode, }, BodyResult: []models.BodyResult{{ Normal: false, Expected: tc.HTTPResp.Body, Actual: actualResponse.Body, }}, } for assertionName, value := range tc.Assertions { switch assertionName { case models.StatusCode: expected, err := toInt(value) if err != nil || expected != actualResponse.StatusCode { pass = false logger.Error("status_code assertion failed", zap.Int("expected", expected), zap.Int("actual", actualResponse.StatusCode)) } else { res.StatusCode.Normal = true } case models.StatusCodeClass: class := toString(value) actualClass := fmt.Sprintf("%dxx", actualResponse.StatusCode/100) if class != actualClass { pass = false logger.Error("status_code_class assertion failed", zap.String("expected",
------------------

--- Chunk 12---
Function AssertionMatch (part 2): class), zap.String("actual", actualClass)) } case models.StatusCodeIn: codes := toStringSlice(value) var ints []int for _, s := range codes { if i, err := strconv.Atoi(s); err == nil { ints = append(ints, i) } } found := false for _, c := range ints { if c == actualResponse.StatusCode { found = true break } } if !found { pass = false logger.Error("status_code_in assertion failed", zap.Any("expectedCodes", ints), zap.Int("actual", actualResponse.StatusCode)) } case models.HeaderEqual: // value should be a map[string]interface{} â†’ we convert to map[string]string hm := toStringMap(value) for header, exp := range hm { act, ok := actualResponse.Header[header] if !ok || act != exp { pass = false logger.Error("header_equal assertion failed", zap.String("header", header), zap.String("expected", exp), zap.String("actual", act), ) }
------------------

--- Chunk 13---
Function AssertionMatch (part 3): logger.Info("header_equal assertion failed", zap.String("header", header), zap.String("expected", exp), zap.String("actual", act), ) } case models.HeaderContains: hm := toStringMap(value) for header, exp := range hm { act, ok := actualResponse.Header[header] if !ok || !strings.Contains(act, exp) { pass = false logger.Error("header_contains assertion failed", zap.String("header", header), zap.String("expected_substr", exp), zap.String("actual", act), ) } } case models.HeaderExists: switch v := value.(type) { // a flat slice of header names case []interface{}: for _, item := range v { hdr := fmt.Sprint(item) if _, ok := actualResponse.Header[hdr]; !ok { pass = false logger.Error("header_exists assertion failed", zap.String("header", hdr)) } } // a map[string]â€¦ where the keys are header names case map[string]interface{}: for hdr := range v
------------------

--- Chunk 14---
Function AssertionMatch (part 4): { if _, ok := actualResponse.Header[hdr]; !ok { pass = false logger.Error("header_exists assertion failed", zap.String("header", hdr)) } } case map[models.AssertionType]interface{}: for kt := range v { hdr := string(kt) if _, ok := actualResponse.Header[hdr]; !ok { pass = false logger.Error("header_exists assertion failed", zap.String("header", hdr)) } } default: pass = false logger.Error("header_exists: unsupported format, expected slice or map", zap.Any("value", value)) } case models.HeaderMatches: // value should be a map[string]interface{} â†’ convert to map[string]string hm := toStringMap(value) for header, pattern := range hm { act, ok := actualResponse.Header[header] if !ok { pass = false logger.Error("header_matches: header not found", zap.String("header", header)) continue } if matched, err := regexp.MatchString(pattern, act); err != nil || !matched { pass = false logger.Error
------------------

--- Chunk 15---
Function AssertionMatch (part 5): ("header_matches assertion failed", zap.String("header", header), zap.String("pattern", pattern), zap.String("actual", act), zap.Error(err), ) } } case models.JsonEqual: expJSON := tc.HTTPResp.Body actJSON := actualResponse.Body if expJSON != actJSON { pass = false logger.Error("json_equal assertion failed", zap.String("expected", expJSON), zap.String("actual", actJSON)) } case models.JsonContains: var expectedMap map[string]interface{} switch v := value.(type) { case map[string]interface{}: expectedMap = v case string: _ = json.Unmarshal([]byte(v), &expectedMap) default: pass = false logger.Error("json_contains: unexpected format", zap.Any("value", value)) continue } if ok, _ := matcherUtils.JsonContains(actualResponse.Body, expectedMap); !ok { pass = false logger.Error("json_contains assertion failed", zap.Any("expected", expectedMap)) } default: if assertionName != models.NoiseAssertion {
------------------

--- Chunk 16---
Function AssertionMatch (end): logger.Warn("unhandled assertion type", zap.String("name", string(assertionName))) } } } if pass { res.StatusCode.Normal = true res.BodyResult[0].Normal = true } return pass, res }
------------------

--- Chunk 17---
func FlattenHTTPResponse(h http.Header, body string) (map[string][]string, error) { m := map[string][]string{} for k, v := range h { m["header."+k] = []string{strings.Join(v, "")} } err := matcherUtils.AddHTTPBodyToMap(body, m) if err != nil { return m, err } return m, nil }
------------------

--- File: pkg/matcher/http/utils.go---

--- Chunk 1---
func toInt(v interface{}) (int, error) { switch x := v.(type) { case int: return x, nil case float64: return int(x), nil case json.Number: i64, err := x.Int64() return int(i64), err case string: i64, err := strconv.ParseInt(x, 10, 64) if err != nil { return 0, err } const maxInt = int64(^uint(0) >> 1) // Maximum value for int const minInt = -maxInt - 1 // Minimum value for int if i64 > maxInt || i64 < minInt { return 0, fmt.Errorf("value out of range for int: %d", i64) } return int(i64), nil default: return 0, fmt.Errorf("cannot convert %T to int", v) } }
------------------

--- Chunk 2---
func toString(v interface{}) string { switch x := v.(type) { case string: return x case json.Number: return x.String() case float64: return strconv.FormatFloat(x, 'f', -1, 64) case int: return strconv.Itoa(x) default: return fmt.Sprintf("%v", v) } }
------------------

--- Chunk 3---
func toStringSlice(v interface{}) []string { var out []string switch x := v.(type) { case []interface{}: for _, e := range x { out = append(out, toString(e)) } case string: for _, part := range strings.Split(x, ",") { out = append(out, strings.TrimSpace(part)) } } return out }
------------------

--- Chunk 4---
func toStringMap(val interface{}) map[string]string { out := make(map[string]string) switch m := val.(type) { case map[string]interface{}: for k, v := range m { out[k] = fmt.Sprint(v) } case map[string]string: // already the right shape for k, v := range m { out[k] = v } case map[models.AssertionType]interface{}: for kType, v := range m { out[string(kType)] = fmt.Sprint(v) } case map[models.AssertionType]string: for kType, v := range m { out[string(kType)] = v } case map[interface{}]interface{}: // sometimes YAML v3 gives you this for ki, vi := range m { key := fmt.Sprint(ki) out[key] = fmt.Sprint(vi) } default: // not a map we knowâ€”return empty } return out }
------------------

--- File: pkg/matcher/schema/match.go---

--- Chunk 1---
func compareOperationTypes(mockOperationType, testOperationType string) (bool, error) { pass := true if mockOperationType != testOperationType { pass = false return pass, nil } return pass, nil }
------------------

--- Chunk 2---
func compareRequestBodies(mockOperation, testOperation *models.Operation, logDiffs matcher.DiffsPrinter, newLogger *pp.PrettyPrinter, logger *zap.Logger, testName, mockName, testSetID, mockSetID string) (bool, error) { pass := false var score float64 mockRequestBodyStr, testRequestBodyStr, err := matcher.MarshalRequestBodies(mockOperation, testOperation) if err != nil { return false, err } validatedJSON, err := matcher.ValidateAndMarshalJSON(logger, &mockRequestBodyStr, &testRequestBodyStr) if err != nil { return false, err } if validatedJSON.IsIdentical() { if score, pass, err = handleJSONDiff(validatedJSON, logDiffs, newLogger, logger, testName, mockName, testSetID, mockSetID, mockRequestBodyStr, testRequestBodyStr, "request", 0); err != nil { return false, err } if score == NOTCANDIDATE { return false, nil } } else { pass = false return pass, nil } return pass, nil }
------------------

--- Chunk 3---
func compareParameters(mockParameters, testParameters []models.Parameter) (bool, error) { pass := true for _, mockParam := range mockParameters { if mockParam.In == "header" { continue } found := false for _, testParam := range testParameters { if mockParam.Name == testParam.Name && mockParam.In == testParam.In { found = true if mockParam.Schema.Type != testParam.Schema.Type { pass = false return pass, nil } } } if !found { pass = false return pass, nil } } return pass, nil }
------------------

--- Chunk 4---
Function compareResponseBodies (start): func compareResponseBodies(status string, mockOperation, testOperation *models.Operation, logDiffs matcher.DiffsPrinter, newLogger *pp.PrettyPrinter, logger *zap.Logger, testName, mockName, testSetID, mockSetID string, mode models.SchemaMatchMode) (float64, bool, bool, error) { pass := true overallScore := 0.0 matched := false differencesCount := 0.0 if _, ok := testOperation.Responses[status]; ok { mockResponseBodyStr, testResponseBodyStr, err := matcher.MarshalResponseBodies(status, mockOperation, testOperation) if err != nil { return differencesCount, false, false, err } overallScore = float64(len(mockOperation.Responses[status].Content["application/json"].Schema.Properties)) validatedJSON, err := matcher.ValidateAndMarshalJSON(logger, &mockResponseBodyStr, &testResponseBodyStr) if err != nil { return differencesCount, false, false, err } if validatedJSON.IsIdentical() { switch mode { case models.CompareMode: if _, matched, err = handleJSONDiff(validatedJSON, logDiffs
------------------

--- Chunk 5---
Function compareResponseBodies (part 2): , newLogger, logger, testName, mockName, testSetID, mockSetID, mockResponseBodyStr, testResponseBodyStr, "response", mode); err != nil { return differencesCount, false, false, err } case models.IdentifyMode: differencesCount, err = calculateSimilarityScore(mockOperation, testOperation, status) if err != nil { return differencesCount, false, false, err } } } else { differencesCount = overallScore if mode == models.CompareMode { logDiffs.PushTypeDiff(fmt.Sprint(reflect.TypeOf(validatedJSON.Expected())), fmt.Sprint(reflect.TypeOf(validatedJSON.Actual()))) logs := newLogger.Sprintf("Contract Check failed for test: %s (%s) / mock: %s (%s) \n\n--------------------------------------------------------------------\n\n", testName, testSetID, mockName, mockSetID) if err := printAndRenderLogs(logs, newLogger, logDiffs, logger); err != nil { return differencesCount, false, false, err } } } } else { pass = false d
------------------

--- Chunk 6---
Function compareResponseBodies (end): ifferencesCount = -1 } return differencesCount / overallScore, pass, matched, nil }
------------------

--- Chunk 7---
Function Match (start): func Match(mock, test models.OpenAPI, testSetID string, mockSetID string, logger *zap.Logger, mode models.SchemaMatchMode) (float64, bool, error) { pass := false candidateScore := -1.0 newLogger := pp.New() newLogger.WithLineInfo = false newLogger.SetColorScheme(models.GetFailingColorScheme()) for path, mockItem := range mock.Paths { logDiffs := matcher.NewDiffsPrinter(test.Info.Title + "/" + mock.Info.Title) var err error if testItem, found := test.Paths[path]; found { mockOperation, mockOperationType := matcher.FindOperation(mockItem) testOperation, testOperationType := matcher.FindOperation(testItem) if mode == models.IdentifyMode { if pass, err = compareOperationTypes(mockOperationType, testOperationType); err != nil { return candidateScore, false, err } if !pass { continue } if pass, err = compareParameters(mockOperation.Parameters, testOperation.Parameters); err != nil { return candidateScore, false, err } if !pass { continue } if pass, err
------------------

--- Chunk 8---
Function Match (end): = compareRequestBodies(mockOperation, testOperation, logDiffs, newLogger, logger, test.Info.Title, mock.Info.Title, testSetID, mockSetID); err != nil { return candidateScore, false, err } if !pass { continue } } var statusCode string for status := range mockOperation.Responses { statusCode = status break } if candidateScore, pass, _, err = compareResponseBodies(statusCode, mockOperation, testOperation, logDiffs, newLogger, logger, test.Info.Title, mock.Info.Title, testSetID, mockSetID, mode); err != nil { return candidateScore, false, err } } else { pass = false } } return candidateScore, pass, nil }
------------------

--- Chunk 9---
func calculateSimilarityScore(mockOperation, testOperation *models.Operation, status string) (float64, error) { testParameters := testOperation.Responses[status].Content["application/json"].Schema.Properties mockParameters := mockOperation.Responses[status].Content["application/json"].Schema.Properties score := 0.0 for key, testParam := range testParameters { if _, ok := mockParameters[key]; ok { if testParam["type"] == mockParameters[key]["type"] { score++ } } } return score, nil }
------------------

--- Chunk 10---
Function handleJSONDiff (start): func handleJSONDiff(validatedJSON matcher.ValidatedJSON, logDiffs matcher.DiffsPrinter, newLogger *pp.PrettyPrinter, logger *zap.Logger, _ string, _ string, _ string, _ string, mockBodyStr string, testBodyStr string, diffType string, mode models.SchemaMatchMode) (float64, bool, error) { pass := true differencesCount := 0.0 jsonComparisonResult, err := matcher.JSONDiffWithNoiseControl(validatedJSON, nil, false) if err != nil { return differencesCount, false, err } if !jsonComparisonResult.IsExact() { pass = false // logs := newLogger.Sprintf("Contract Check failed for test: %s (%s) / mock: %s (%s) \n\n--------------------------------------------------------------------\n\n", testName, testSetID, mockName, mockSetID) if json.Valid([]byte(mockBodyStr)) { patch, err := jsondiff.Compare(testBodyStr, mockBodyStr) if err != nil { logger.Warn("failed to compute json diff", zap.Error(err)) return differencesCount, false, err } differencesCount = float64(len(patch
------------------

--- Chunk 11---
Function handleJSONDiff (end): )) if diffType == "request" && differencesCount > 1 { return -1.0, false, nil } if diffType == "response" { for _, op := range patch { if jsonComparisonResult.Matches() { logDiffs.SetHasarrayIndexMismatch(true) logDiffs.PushFooterDiff(strings.Join(jsonComparisonResult.Differences(), ", ")) } logDiffs.PushBodyDiff(fmt.Sprint(op.OldValue), fmt.Sprint(op.Value), nil) } } } if diffType == "response" && mode == models.CompareMode { if err := printAndRenderLogs("", newLogger, logDiffs, logger); err != nil { return differencesCount, false, err } } } return differencesCount, pass, nil }
------------------

--- Chunk 12---
func printAndRenderLogs(logs string, newLogger *pp.PrettyPrinter, logDiffs matcher.DiffsPrinter, logger *zap.Logger) error { if _, err := newLogger.Printf(logs); err != nil { utils.LogError(logger, err, "failed to print the logs") return err } if err := logDiffs.RenderAppender(); err != nil { utils.LogError(logger, err, "failed to render the diffs") return err } return nil }
------------------

--- File: pkg/matcher/utils.go---

--- Chunk 1---
func (v *ValidatedJSON) IsIdentical() bool { return v.isIdentical }
------------------

--- Chunk 2---
func (v *ValidatedJSON) Expected() interface{} { return v.expected }
------------------

--- Chunk 3---
func (v *ValidatedJSON) Actual() interface{} { return v.actual }
------------------

--- Chunk 4---
func (v *JSONComparisonResult) IsExact() bool { return v.isExact }
------------------

--- Chunk 5---
func (v *JSONComparisonResult) Matches() bool { return v.matches }
------------------

--- Chunk 6---
func (v *JSONComparisonResult) Differences() []string { return v.differences }
------------------

--- Chunk 7---
func MarshalRequestBodies(mockOperation, testOperation *models.Operation) (string, string, error) { var mockRequestBody []byte var testRequestBody []byte var err error if mockOperation.RequestBody != nil { mockRequestBody, err = json.Marshal(mockOperation.RequestBody.Content["application/json"].Schema.Properties) if err != nil { return "", "", fmt.Errorf("error marshalling mock RequestBody: %v", err) } } if testOperation.RequestBody != nil { testRequestBody, err = json.Marshal(testOperation.RequestBody.Content["application/json"].Schema.Properties) if err != nil { return "", "", fmt.Errorf("error marshalling test RequestBody: %v", err) } } return string(mockRequestBody), string(testRequestBody), nil }
------------------

--- Chunk 8---
func MarshalResponseBodies(status string, mockOperation, testOperation *models.Operation) (string, string, error) { var mockResponseBody []byte var testResponseBody []byte var err error if mockOperation.Responses[status].Content != nil { mockResponseBody, err = json.Marshal(mockOperation.Responses[status].Content["application/json"].Schema.Properties) if err != nil { return "", "", fmt.Errorf("error marshalling mock ResponseBody: %v", err) } } if testOperation.Responses[status].Content != nil { testResponseBody, err = json.Marshal(testOperation.Responses[status].Content["application/json"].Schema.Properties) if err != nil { return "", "", fmt.Errorf("error marshalling test ResponseBody: %v", err) } } return string(mockResponseBody), string(testResponseBody), nil }
------------------

--- Chunk 9---
func FindOperation(item models.PathItem) (*models.Operation, string) { operations := map[string]*models.Operation{ "GET": item.Get, "POST": item.Post, "PUT": item.Put, "DELETE": item.Delete, "PATCH": item.Patch, } for method, operation := range operations { if operation != nil { return operation, method } } return nil, "" }
------------------

--- Chunk 10---
func ParseIntoJSON(response string) (interface{}, error) { // Parse the response into a json object. if response == "" { return nil, nil } result, err := geko.JSONUnmarshal([]byte(response)) if err != nil { return nil, fmt.Errorf("failed to unmarshal the response: %v", err) } return result, nil }
------------------

--- Chunk 11---
Function CompareResponses (start): func CompareResponses(response1, response2 *interface{}, key string) { switch v1 := (*response1).(type) { case geko.Array: for _, val1 := range v1.List { CompareResponses(&val1, response2, "") } case geko.ObjectItems: keys := v1.Keys() vals := v1.Values() for i := range keys { CompareResponses(&vals[i], response2, keys[i]) v1.SetValueByIndex(i, vals[i]) // in order to change the expected value if required } case map[string]interface{}: for key, val := range v1 { CompareResponses(&val, response2, key) v1[key] = val // in order to change the expected value if required } case string: compareSecondResponse(&v1, response2, key, "") *response1 = v1 case float64, int64, int, float32: v1String := utils.ToString(v1) compareSecondResponse(&(v1String), response2, key, "") // Retain the original type switch (*response1).(type) {
------------------

--- Chunk 12---
Function CompareResponses (end): case float64: *response1 = utils.ToFloat(v1String) case int: *response1 = utils.ToInt(v1String) case int64: *response1 = utils.ToInt(v1String) case float32: f := utils.ToFloat(v1String) *response1 = float32(f) default: *response1 = v1 // Keep it unchanged if itâ€™s an unexpected type } } }
------------------

--- Chunk 13---
Function compareSecondResponse (start): func compareSecondResponse(val1 *string, response2 *interface{}, key1 string, key2 string) { switch v2 := (*response2).(type) { case geko.Array: for _, val2 := range v2.List { compareSecondResponse(val1, &val2, key1, "") } case geko.ObjectItems: keys := v2.Keys() vals := v2.Values() for i := range keys { compareSecondResponse(val1, &vals[i], key1, keys[i]) } case map[string]interface{}: for key, val := range v2 { compareSecondResponse(val1, &val, key1, key) } case string: if *val1 != v2 { // Reverse the templatized values map. revMap := reverseMap(utils.TemplatizedValues) if _, ok := revMap[*val1]; ok && key1 == key2 { key := revMap[*val1] utils.TemplatizedValues[key] = v2 *val1 = v2 } } case float64, int64, int, float
------------------

--- Chunk 14---
Function compareSecondResponse (part 2): 32: if *val1 != v2 { // Reverse the templatized values map. revMap := reverseMap(utils.TemplatizedValues) if _, ok := revMap[*val1]; ok && key1 == key2 { key := revMap[*val1] utils.TemplatizedValues[key] = v2 *val1 = utils.ToString(v2) return } // 1) try integer parse if i, err := strconv.Atoi(*val1); err == nil { if _, ok := revMap[i]; ok && key1 == key2 { key := revMap[i] utils.TemplatizedValues[key] = v2 *val1 = utils.ToString(v2) } } if f, err := strconv.ParseFloat(*val1, 32); err == nil { if _, ok := revMap[f]; ok && key1 == key2 { key := revMap[f] utils.TemplatizedValues[key] = v2 *val1 = utils.ToString(v2) } } if f, err := strconv.Parse
------------------

--- Chunk 15---
Function compareSecondResponse (end): Float(*val1, 64); err == nil { if _, ok := revMap[f]; ok && key1 == key2 { key := revMap[*val1] utils.TemplatizedValues[key] = v2 *val1 = utils.ToString(v2) } } } } }
------------------

--- Chunk 16---
func reverseMap(m map[string]interface{}) map[interface{}]string { var reverseMap = make(map[interface{}]string) for key, val := range m { reverseMap[val] = key } return reverseMap }
------------------

--- Chunk 17---
func ValidateAndMarshalJSON(log *zap.Logger, exp, act *string) (ValidatedJSON, error) { var validatedJSON ValidatedJSON var expected interface{} var actual interface{} var err error if *exp != "" { expected, err = UnmarshallJSON(*exp, log) if err != nil { return validatedJSON, err } } if *act != "" { actual, err = UnmarshallJSON(*act, log) if err != nil { return validatedJSON, err } } validatedJSON.expected = expected validatedJSON.actual = actual if reflect.TypeOf(expected) != reflect.TypeOf(actual) { validatedJSON.isIdentical = false return validatedJSON, nil } cleanExp, err := json.Marshal(expected) if err != nil { return validatedJSON, err } cleanAct, err := json.Marshal(actual) if err != nil { return validatedJSON, err } *exp = string(cleanExp) *act = string(cleanAct) validatedJSON.isIdentical = true return validatedJSON, nil }
------------------

--- Chunk 18---
func UnmarshallJSON(s string, log *zap.Logger) (interface{}, error) { var result interface{} if s == "" { return nil, nil } if err := json.Unmarshal([]byte(s), &result); err != nil { utils.LogError(log, err, "cannot convert json string into json object", zap.String("json", s)) return nil, err } return result, nil }
------------------

--- Chunk 19---
func (d *DiffsPrinter) SetHasarrayIndexMismatch(has bool) { d.hasarrayIndexMismatch = has }
------------------

--- Chunk 20---
func NewDiffsPrinter(testCase string) DiffsPrinter { return DiffsPrinter{testCase, "", "", map[string]string{}, map[string]string{}, "", "", map[string][]string{}, map[string][]string{}, false, "", "", ""} }
------------------

--- Chunk 21---
func (d *DiffsPrinter) PushTypeDiff(exp, act string) { d.typeExp, d.typeAct = exp, act }
------------------

--- Chunk 22---
func (d *DiffsPrinter) PushStatusDiff(exp, act string) { d.statusExp, d.statusAct = exp, act }
------------------

--- Chunk 23---
func (d *DiffsPrinter) PushFooterDiff(key string) { d.hasarrayIndexMismatch = true d.text = key }
------------------

--- Chunk 24---
func (d *DiffsPrinter) PushHeaderDiff(exp, act, key string, noise map[string][]string) { d.headerExp[key], d.headerAct[key], d.headNoise = exp, act, noise }
------------------

--- Chunk 25---
func (d *DiffsPrinter) PushBodyDiff(exp, act string, noise map[string][]string) { d.bodyExp, d.bodyAct, d.bodyNoise = exp, act, noise }
------------------

--- Chunk 26---
Function Render (start): func (d *DiffsPrinter) Render() error { diffs := []string{} if d.statusExp != d.statusAct { diffs = append(diffs, sprintDiff(d.statusExp, d.statusAct, "status")) } diffs = append(diffs, sprintDiffHeader(d.headerExp, d.headerAct)) if len(d.bodyExp) != 0 || len(d.bodyAct) != 0 { bE, bA := []byte(d.bodyExp), []byte(d.bodyAct) if json.Valid(bE) && json.Valid(bA) { difference, err := sprintJSONDiff(bE, bA, "body", d.bodyNoise) if err != nil { difference = sprintDiff(d.bodyExp, d.bodyAct, "body") } diffs = append(diffs, difference) } else { diffs = append(diffs, sprintDiff(d.bodyExp, d.bodyAct, "body")) } } table := tablewriter.NewWriter(os.Stdout) table.SetAutoWrapText(false) table.SetHeader([]string{fmt.Sprintf("Diffs %v", d.testCase)}) table.SetHeaderColor(tablewriter.Colors{tablewriter.Fg
------------------

--- Chunk 27---
Function Render (end): HiRedColor}) table.SetAlignment(tablewriter.ALIGN_CENTER) for _, e := range diffs { table.Append([]string{e}) } if d.hasarrayIndexMismatch { yellowPaint := color.New(color.FgYellow).SprintFunc() redPaint := color.New(color.FgRed).SprintFunc() startPart := " Expected and actual value" var midPartpaint string if len(d.text) > 0 { midPartpaint = redPaint(d.text) startPart += " of " } initalPart := yellowPaint(utils.WarningSign + startPart) endPaint := yellowPaint(" are in different order but have the same objects") table.SetHeader([]string{initalPart + midPartpaint + endPaint}) table.SetAlignment(tablewriter.ALIGN_CENTER) table.Append([]string{initalPart + midPartpaint + endPaint}) } table.Render() return nil }
------------------

--- Chunk 28---
Function TableWriter (start): func (d *DiffsPrinter) TableWriter(diffs []string) error { table := tablewriter.NewWriter(os.Stdout) table.SetAutoWrapText(false) table.SetHeader([]string{fmt.Sprintf("Diffs %v", d.testCase)}) table.SetHeaderColor(tablewriter.Colors{tablewriter.FgHiRedColor}) table.SetAlignment(tablewriter.ALIGN_CENTER) for _, e := range diffs { table.Append([]string{e}) } if d.hasarrayIndexMismatch { yellowPaint := color.New(color.FgYellow).SprintFunc() redPaint := color.New(color.FgRed).SprintFunc() startPart := " Expected and actual value" var midPartpaint string if len(d.text) > 0 { midPartpaint = redPaint(d.text) startPart += " of " } initalPart := yellowPaint(utils.WarningSign + startPart) endPaint := yellowPaint(" are in different order but have the same objects") table.SetHeader([]string{initalPart + midPartpaint + endPaint}) table.SetAlignment(tablewriter.ALIGN_CENTER) table.Append([]string{initalPart + midPartpaint + endPaint})
------------------

--- Chunk 29---
Function TableWriter (end): } table.Render() return nil }
------------------

--- Chunk 30---
Function RenderAppender (start): func (d *DiffsPrinter) RenderAppender() error { //Only show difference for the response body diffs := []string{} pass := true if d.typeExp != d.typeAct { diffs = append(diffs, sprintDiff(d.typeExp, d.typeAct, "request body type")) pass = false } if !pass { err := d.TableWriter(diffs) if err != nil { return err } return nil } if len(d.bodyExp) != 0 || len(d.bodyAct) != 0 { pass = false bE, bA := []byte(d.bodyExp), []byte(d.bodyAct) if json.Valid(bE) && json.Valid(bA) { difference, err := sprintJSONDiff(bE, bA, "response", d.bodyNoise) if err != nil { difference = sprintDiff(d.bodyExp, d.bodyAct, "response") } diffs = append(diffs, difference) } else { diffs = append(diffs, sprintDiff(d.bodyExp, d.bodyAct, "response")) } } if !pass {
------------------

--- Chunk 31---
Function RenderAppender (end): err := d.TableWriter(diffs) if err != nil { return err } } return nil }
------------------

--- Chunk 32---
func sprintDiffHeader(expect, actual map[string]string) string { diff := jsonDiff.CompareHeaders(expect, actual) if len(expect) > maxLineLength || len(actual) > maxLineLength { return expectActualTable(diff.Expected, diff.Actual, "header", false) // Don't centerize } return expectActualTable(diff.Expected, diff.Actual, "header", true) }
------------------

--- Chunk 33---
func sprintDiff(expect, actual, field string) string { diff := jsonDiff.Compare(expect, actual) if len(expect) > maxLineLength || len(actual) > maxLineLength { return expectActualTable(diff.Expected, diff.Actual, field, false) } return expectActualTable(diff.Expected, diff.Actual, field, true) }
------------------

--- Chunk 34---
func sprintJSONDiff(json1 []byte, json2 []byte, field string, noise map[string][]string) (string, error) { diff, err := jsonDiff.CompareJSON(json1, json2, noise, false) if err != nil { return "", err } result := expectActualTable(diff.Expected, diff.Actual, field, false) return result, nil }
------------------

--- Chunk 35---
Function wrapTextWithAnsi (start): func wrapTextWithAnsi(input string) string { scanner := bufio.NewScanner(strings.NewReader(input)) // Create a scanner to read the input string line by line. var wrappedBuilder strings.Builder // Builder for the resulting wrapped text. currentAnsiCode := "" // Variable to hold the current ANSI escape sequence. lastAnsiCode := "" // Variable to hold the last ANSI escape sequence. // Iterate over each line in the input string. for scanner.Scan() { line := scanner.Text() // Get the current line. // If there is a current ANSI code, append it to the builder. if currentAnsiCode != "" { wrappedBuilder.WriteString(currentAnsiCode) } // Find all ANSI escape sequences in the current line. startAnsiCodes := ansiRegex.FindAllString(line, -1) if len(startAnsiCodes) > 0 { // Update the last ANSI escape sequence to the last one found in the line. lastAnsiCode = startAnsiCodes[len(startAnsiCodes)-1] } // Append the current line to the builder. wrappedBuilder.WriteString(line) // Check if the current ANSI
------------------

--- Chunk 36---
Function wrapTextWithAnsi (end): code needs to be reset or updated. if (currentAnsiCode != "" && !strings.HasSuffix(line, ansiResetCode)) || len(startAnsiCodes) > 0 { // If the current line does not end with a reset code or if there are ANSI codes, append a reset code. wrappedBuilder.WriteString(ansiResetCode) // Update the current ANSI code to the last one found in the line. currentAnsiCode = lastAnsiCode } else { // If no ANSI codes need to be maintained, reset the current ANSI code. currentAnsiCode = "" } // Append a newline character to the builder. wrappedBuilder.WriteString("\n") } // Return the processed string with properly wrapped ANSI escape sequences. return wrappedBuilder.String() }
------------------

--- Chunk 37---
func expectActualTable(exp string, act string, field string, centerize bool) string { buf := &bytes.Buffer{} table := tablewriter.NewWriter(buf) if centerize { table.SetAlignment(tablewriter.ALIGN_CENTER) } else { table.SetAlignment(tablewriter.ALIGN_LEFT) } // jsonDiff.JsonDiff() exp = wrapTextWithAnsi(exp) act = wrapTextWithAnsi(act) table.SetHeader([]string{fmt.Sprintf("Expect %v", field), fmt.Sprintf("Actual %v", field)}) table.SetAutoWrapText(false) table.SetBorder(false) table.SetColMinWidth(0, maxLineLength) table.SetColMinWidth(1, maxLineLength) table.Append([]string{exp, act}) table.Render() return buf.String() }
------------------

--- Chunk 38---
func Contains(elems []string, v string) bool { for _, s := range elems { if v == s { return true } } return false }
------------------

--- Chunk 39---
func checkKey(res *[]models.HeaderResult, key string) bool { for _, v := range *res { if key == v.Expected.Key { return false } } return true }
------------------

--- Chunk 40---
Function CompareHeaders (start): func CompareHeaders(h1 http.Header, h2 http.Header, res *[]models.HeaderResult, noise map[string][]string) bool { if res == nil { return false } match := true _, isHeaderNoisy := noise["header"] for k, v := range h1 { regexArr, isNoisy := CheckStringExist(strings.ToLower(k), noise) if isNoisy && len(regexArr) != 0 { isNoisy, _ = MatchesAnyRegex(v[0], regexArr) } isNoisy = isNoisy || isHeaderNoisy val, ok := h2[k] if !isNoisy { if !ok { if checkKey(res, k) { *res = append(*res, models.HeaderResult{ Normal: false, Expected: models.Header{ Key: k, Value: v, }, Actual: models.Header{ Key: k, Value: nil, }, }) } match = false continue } if len(v) != len(val) { if checkKey(res, k) {
------------------

--- Chunk 41---
Function CompareHeaders (part 2): *res = append(*res, models.HeaderResult{ Normal: false, Expected: models.Header{ Key: k, Value: v, }, Actual: models.Header{ Key: k, Value: val, }, }) } match = false continue } for i, e := range v { if val[i] != e { if checkKey(res, k) { *res = append(*res, models.HeaderResult{ Normal: false, Expected: models.Header{ Key: k, Value: v, }, Actual: models.Header{ Key: k, Value: val, }, }) } match = false continue } } } if checkKey(res, k) { *res = append(*res, models.HeaderResult{ Normal: true, Expected: models.Header{ Key: k, Value: v, }, Actual: models.Header{ Key: k, Value: val,
------------------

--- Chunk 42---
Function CompareHeaders (part 3): }, }) } } for k, v := range h2 { regexArr, isNoisy := CheckStringExist(strings.ToLower(k), noise) if isNoisy && len(regexArr) != 0 { isNoisy, _ = MatchesAnyRegex(v[0], regexArr) } isNoisy = isNoisy || isHeaderNoisy val, ok := h1[k] if isNoisy && checkKey(res, k) { *res = append(*res, models.HeaderResult{ Normal: true, Expected: models.Header{ Key: k, Value: val, }, Actual: models.Header{ Key: k, Value: v, }, }) continue } if !ok { if checkKey(res, k) { *res = append(*res, models.HeaderResult{ Normal: false, Expected: models.Header{ Key: k, Value: nil, }, Actual: models.Header{ Key: k, Value: v, }, })
------------------

--- Chunk 43---
Function CompareHeaders (end): } match = false } } return match }
------------------

--- Chunk 44---
func MapToArray(mp map[string][]string) []string { var result []string for k := range mp { result = append(result, k) } return result }
------------------

--- Chunk 45---
func CheckStringExist(s string, mp map[string][]string) ([]string, bool) { if val, ok := mp[s]; ok { return val, ok } return []string{}, false }
------------------

--- Chunk 46---
func MatchesAnyRegex(str string, regexArray []string) (bool, string) { for _, pattern := range regexArray { re := regexp.MustCompile(pattern) if re.MatchString(str) { return true, pattern } } return false, "" }
------------------

--- Chunk 47---
func AddHTTPBodyToMap(body string, m map[string][]string) error { // add body if json.Valid([]byte(body)) { var result interface{} err := json.Unmarshal([]byte(body), &result) if err != nil { return err } j := Flatten(result) for k, v := range j { nk := "body" if k != "" { nk = nk + "." + k } m[nk] = v } } else { // add it as raw text m["body"] = []string{body} } return nil }
------------------

--- Chunk 48---
Function Flatten (start): func Flatten(j interface{}) map[string][]string { if j == nil { return map[string][]string{"": {""}} } o := make(map[string][]string) x := reflect.ValueOf(j) switch x.Kind() { case reflect.Map: m, ok := j.(map[string]interface{}) if !ok { return map[string][]string{} } for k, v := range m { nm := Flatten(v) for nk, nv := range nm { fk := k if nk != "" { fk = fk + "." + nk } o[fk] = nv } } case reflect.Bool: o[""] = []string{strconv.FormatBool(x.Bool())} case reflect.Float64: o[""] = []string{strconv.FormatFloat(x.Float(), 'E', -1, 64)} case reflect.String: o[""] = []string{x.String()} case reflect.Slice: child, ok := j.([]interface{}) if !ok { return map[string][]string{} } for _, av := range child { nm := Flatten(av) for nk, nv := range nm {
------------------

--- Chunk 49---
Function Flatten (end): if ov, exists := o[nk]; exists { o[nk] = append(ov, nv...) } else { o[nk] = nv } } } } return o }
------------------

--- Chunk 50---
func JSONDiffWithNoiseControl(validatedJSON ValidatedJSON, noise map[string][]string, ignoreOrdering bool) (JSONComparisonResult, error) { var matchJSONComparisonResult JSONComparisonResult matchJSONComparisonResult, err := matchJSONWithNoiseHandling("", validatedJSON.expected, validatedJSON.actual, noise, ignoreOrdering) if err != nil { return matchJSONComparisonResult, err } return matchJSONComparisonResult, nil }
------------------

--- Chunk 51---
Function matchJSONWithNoiseHandling (start): func matchJSONWithNoiseHandling(key string, expected, actual interface{}, noiseMap map[string][]string, ignoreOrdering bool) (JSONComparisonResult, error) { var matchJSONComparisonResult JSONComparisonResult if reflect.TypeOf(expected) != reflect.TypeOf(actual) { return matchJSONComparisonResult, errors.New("type not matched") } if expected == nil && actual == nil { matchJSONComparisonResult.isExact = true matchJSONComparisonResult.matches = true return matchJSONComparisonResult, nil } x := reflect.ValueOf(expected) prefix := "" if key != "" { prefix = key + "." } switch x.Kind() { case reflect.Float64, reflect.String, reflect.Bool: regexArr, isNoisy := CheckStringExist(key, noiseMap) if isNoisy && len(regexArr) != 0 { isNoisy, _ = MatchesAnyRegex(InterfaceToString(expected), regexArr) } if expected != actual && !isNoisy { return matchJSONComparisonResult, nil } case reflect.Map: expMap := expected.(map[string]interface{}) actMap := actual.(map[string]interface{}) copiedExpMap
------------------

--- Chunk 52---
Function matchJSONWithNoiseHandling (part 2): := make(map[string]interface{}) copiedActMap := make(map[string]interface{}) if regexArr, isNoisy := CheckStringExist(key, noiseMap); isNoisy && len(regexArr) == 0 { break } // Copy each key-value pair from expMap to copiedExpMap for key, value := range expMap { copiedExpMap[key] = value } // Repeat the same process for actual map for key, value := range actMap { copiedActMap[key] = value } isExact := true differences := []string{} for k, v := range expMap { val, ok := actMap[k] if !ok { return matchJSONComparisonResult, nil } if valueMatchJSONComparisonResult, er := matchJSONWithNoiseHandling(strings.ToLower(prefix+k), v, val, noiseMap, ignoreOrdering); !valueMatchJSONComparisonResult.matches || er != nil { return valueMatchJSONComparisonResult, nil } else if !valueMatchJSONComparisonResult.isExact { isExact = false differences = append
------------------

--- Chunk 53---
Function matchJSONWithNoiseHandling (part 3): (differences, k) differences = append(differences, valueMatchJSONComparisonResult.differences...) } // remove the noisy key from both expected and actual JSON. // Viper bindings are case insensitive, so we need convert the key to lowercase. if _, ok := CheckStringExist(strings.ToLower(prefix+k), noiseMap); ok { delete(copiedExpMap, prefix+k) delete(copiedActMap, k) continue } } // checks if there is a key which is not present in expMap but present in actMap. for k := range actMap { _, ok := expMap[k] if !ok { return matchJSONComparisonResult, nil } } matchJSONComparisonResult.matches = true matchJSONComparisonResult.isExact = isExact matchJSONComparisonResult.differences = append(matchJSONComparisonResult.differences, differences...) return matchJSONComparisonResult, nil case reflect.Slice: if regexArr, isNoisy := CheckStringExist(key, noiseMap); isNoisy && len(regexArr) == 0 { break } expSlice := reflect.Value
------------------

--- Chunk 54---
Function matchJSONWithNoiseHandling (part 4): Of(expected) actSlice := reflect.ValueOf(actual) if expSlice.Len() != actSlice.Len() { return matchJSONComparisonResult, nil } isMatched := true isExact := true for i := 0; i < expSlice.Len(); i++ { matched := false for j := 0; j < actSlice.Len(); j++ { // Â­Special rule: we're at the root of the slice (key == "") // and every element is a map or slice (i.e. a JSON object or array) â†’ donâ€™t add â€œ[i]â€ prefixes. dropPrefix := key == "" && expSlice.Len() > 0 && (reflect.TypeOf(expSlice.Index(i).Interface()).Kind() == reflect.Map || reflect.TypeOf(expSlice.Index(i).Interface()).Kind() == reflect.Slice) childKey := "" if !dropPrefix { childKey = fmt.Sprintf("%s[%d]", key, j) } if valMatchJSONComparisonResult, err := matchJSONWithNoiseHandling(childKey, expSlice.Index(i).Interface(), actSlice.Index(j).Interface(), noiseMap, ignoreOrdering); err ==
------------------

--- Chunk 55---
Function matchJSONWithNoiseHandling (part 5): nil && valMatchJSONComparisonResult.matches { if !valMatchJSONComparisonResult.isExact { for _, val := range valMatchJSONComparisonResult.differences { if childKey != "" { val = childKey + "." + val } matchJSONComparisonResult.differences = append(matchJSONComparisonResult.differences, val) } } matched = true break } } if !matched { isMatched = false isExact = false break } } if !isMatched { matchJSONComparisonResult.matches = isMatched matchJSONComparisonResult.isExact = isExact return matchJSONComparisonResult, nil } if !ignoreOrdering { for i := 0; i < expSlice.Len(); i++ { if valMatchJSONComparisonResult, er := matchJSONWithNoiseHandling(key, expSlice.Index(i).Interface(), actSlice.Index(i).Interface(), noiseMap, ignoreOrdering); er != nil || !valMatchJSONComparisonResult.isExact { isExact = false break } } } matchJSON
------------------

--- Chunk 56---
Function matchJSONWithNoiseHandling (end): ComparisonResult.matches = isMatched matchJSONComparisonResult.isExact = isExact return matchJSONComparisonResult, nil default: return matchJSONComparisonResult, errors.New("type not registered for json") } matchJSONComparisonResult.matches = true matchJSONComparisonResult.isExact = true return matchJSONComparisonResult, nil }
------------------

--- Chunk 57---
func ArrayToMap(arr []string) map[string]bool { res := map[string]bool{} for i := range arr { res[arr[i]] = true } return res }
------------------

--- Chunk 58---
func InterfaceToString(val interface{}) string { switch v := val.(type) { case int: return fmt.Sprintf("%d", v) case float64: return fmt.Sprintf("%f", v) case bool: return fmt.Sprintf("%t", v) case string: return v default: return fmt.Sprintf("%v", v) } }
------------------

--- Chunk 59---
func JsonContains(actualJSON string, expectedJSON map[string]interface{}) (bool, error) { var actual interface{} err := json.Unmarshal([]byte(actualJSON), &actual) if err != nil { return false, fmt.Errorf("failed to unmarshal actual JSON: %v", err) } return containsRecursive(actual, expectedJSON), nil }
------------------

--- Chunk 60---
func containsRecursive(actual interface{}, expected map[string]interface{}) bool { actualMap, ok := actual.(map[string]interface{}) if !ok { return false } for key, expectedValue := range expected { actualValue, exists := actualMap[key] if !exists { return false } switch v := expectedValue.(type) { case map[string]interface{}: if actualMapVal, ok := actualValue.(map[string]interface{}); ok { if !containsRecursive(actualMapVal, v) { return false } } else { return false } default: if !reflect.DeepEqual(actualValue, expectedValue) { return false } } } return true }
------------------

--- File: pkg/models/config.go---

--- Chunk 1---
func (ts *TestSet) SetSecrets(secrets map[string]interface{}) { ts.Secret = secrets }
------------------

--- File: pkg/models/errors.go---

--- Chunk 1---
func (e AppError) Error() string { if e.Err != nil { return fmt.Sprintf("%s: %v", e.AppErrorType, e.Err) } return string(e.AppErrorType) }
------------------

--- File: pkg/models/grpc.go---

--- Chunk 1---
func NewGrpcStream(streamID uint32) GrpcStream { return GrpcStream{ StreamID: streamID, GrpcReq: GrpcReq{ Headers: GrpcHeaders{ PseudoHeaders: make(map[string]string), OrdinaryHeaders: make(map[string]string), }, }, GrpcResp: GrpcResp{ Headers: GrpcHeaders{ PseudoHeaders: make(map[string]string), OrdinaryHeaders: make(map[string]string), }, Trailers: GrpcHeaders{ PseudoHeaders: make(map[string]string), OrdinaryHeaders: make(map[string]string), }, }, } }
------------------

--- File: pkg/models/mock.go---

--- Chunk 1---
func (m *Mock) GetKind() string { return string(m.Kind) }
------------------

--- File: pkg/models/mode.go---

--- Chunk 1---
func (m Mode) Valid() bool { if m == MODE_RECORD || m == MODE_TEST || m == MODE_OFF { return true } return false }
------------------

--- Chunk 2---
func GetMode() Mode { return mode }
------------------

--- Chunk 3---
func SetTestMode() { _ = SetMode(MODE_TEST) }
------------------

--- Chunk 4---
func SetMode(m Mode) error { if !m.Valid() { return errors.New("invalid mode: " + string(m)) } mode = m return nil }
------------------

--- File: pkg/models/mongo.go---

--- Chunk 1---
func (mr *MongoRequest) UnmarshalBSON(data []byte) error { // duplicate struct to avoid infinite recursion type MongoRequestAlias struct { Header *MongoHeader `bson:"header,omitempty"` Message bson.Raw `bson:"message,omitempty"` ReadDelay int64 `bson:"read_delay,omitempty"` } var aux MongoRequestAlias if err := bson.Unmarshal(data, &aux); err != nil { return err } // assign the unmarshalled data to the original data mr.Header = aux.Header mr.ReadDelay = aux.ReadDelay // unmarshal the message into the correct type switch mr.Header.Opcode { case wiremessage.OpMsg: var msg MongoOpMessage if err := bson.Unmarshal(aux.Message, &msg); err != nil { return err } mr.Message = &msg case wiremessage.OpQuery: var msg MongoOpQuery if err := bson.Unmarshal(aux.Message, &msg); err != nil { return err } mr.Message = &msg default: return errors.New("failed to unmarshal unknown opcode") } return nil }
------------------

--- Chunk 2---
func (mr *MongoRequest) UnmarshalJSON(data []byte) error { // duplicate struct to avoid infinite recursion type MongoRequestAlias struct { Header *MongoHeader `json:"header"` Message json.RawMessage `json:"message"` ReadDelay int64 `json:"read_delay"` } var aux MongoRequestAlias if err := json.Unmarshal(data, &aux); err != nil { return err } // assign the unmarshalled data to the original data mr.Header = aux.Header mr.ReadDelay = aux.ReadDelay // unmarshal the message into the correct type switch mr.Header.Opcode { case wiremessage.OpMsg: var msg MongoOpMessage if err := json.Unmarshal(aux.Message, &msg); err != nil { return err } mr.Message = &msg case wiremessage.OpQuery: var msg MongoOpQuery if err := json.Unmarshal(aux.Message, &msg); err != nil { return err } mr.Message = &msg default: return errors.New("failed to unmarshal unknown opcode") } return nil }
------------------

--- Chunk 3---
func (mr *MongoRequest) MarshalJSON() ([]byte, error) { // duplicate struct to avoid infinite recursion type MongoRequestAlias struct { Header *MongoHeader `json:"header"` Message json.RawMessage `json:"message"` ReadDelay int64 `json:"read_delay"` } aux := MongoRequestAlias{ Header: mr.Header, Message: json.RawMessage(nil), ReadDelay: mr.ReadDelay, } if mr.Message != nil { // Marshal the message interface{} into JSON msgJSON, err := json.Marshal(mr.Message) if err != nil { return nil, err } aux.Message = msgJSON } return json.Marshal(aux) }
------------------

--- Chunk 4---
func (mr *MongoResponse) UnmarshalBSON(data []byte) error { // duplicate struct to avoid infinite recursion type MongoResponseAlias struct { Header *MongoHeader `bson:"header,omitempty"` Message bson.Raw `bson:"message,omitempty"` ReadDelay int64 `bson:"read_delay,omitempty"` } var aux MongoResponseAlias if err := bson.Unmarshal(data, &aux); err != nil { return err } // assign the unmarshalled data to the original data mr.Header = aux.Header mr.ReadDelay = aux.ReadDelay // unmarshal the message into the correct type switch mr.Header.Opcode { case wiremessage.OpMsg: var msg MongoOpMessage if err := bson.Unmarshal(aux.Message, &msg); err != nil { return err } mr.Message = &msg case wiremessage.OpReply: var msg MongoOpReply if err := bson.Unmarshal(aux.Message, &msg); err != nil { return err } mr.Message = &msg default: return errors.New("failed to unmarshal unknown opcode") } return nil }
------------------

--- Chunk 5---
func (mr *MongoResponse) UnmarshalJSON(data []byte) error { // duplicate struct to avoid infinite recursion type MongoResponseAlias struct { Header *MongoHeader `json:"header"` Message json.RawMessage `json:"message"` ReadDelay int64 `json:"read_delay"` } var aux MongoResponseAlias if err := json.Unmarshal(data, &aux); err != nil { return err } // assign the unmarshalled data to the original data mr.Header = aux.Header mr.ReadDelay = aux.ReadDelay // unmarshal the message into the correct type switch mr.Header.Opcode { case wiremessage.OpMsg: var msg MongoOpMessage if err := json.Unmarshal(aux.Message, &msg); err != nil { return err } mr.Message = &msg case wiremessage.OpReply: var msg MongoOpReply if err := json.Unmarshal(aux.Message, &msg); err != nil { return err } mr.Message = &msg default: return errors.New("failed to unmarshal unknown opcode") } return nil }
------------------

--- Chunk 6---
func (mr *MongoResponse) MarshalJSON() ([]byte, error) { // duplicate struct to avoid infinite recursion type MongoResponseAlias struct { Header *MongoHeader `json:"header"` Message json.RawMessage `json:"message"` ReadDelay int64 `json:"read_delay"` } aux := MongoResponseAlias{ Header: mr.Header, Message: json.RawMessage(nil), ReadDelay: mr.ReadDelay, } if mr.Message != nil { // Marshal the message interface{} into JSON msgJSON, err := json.Marshal(mr.Message) if err != nil { return nil, err } aux.Message = msgJSON } return json.Marshal(aux) }
------------------

--- File: pkg/models/mysql/const.go---

--- Chunk 1---
func StatusToString(status byte) string { if str, ok := statusToString[status]; ok { return str } return "UNKNOWN" }
------------------

--- Chunk 2---
func AuthStatusToString(status byte) string { if str, ok := authStatusToString[status]; ok { return str } return "UNKNOWN" }
------------------

--- Chunk 3---
func CommandStatusToString(status byte) string { if str, ok := commandStatusToString[status]; ok { return str } return "UNKNOWN" }
------------------

--- Chunk 4---
func CachingSha2PasswordToString(status CachingSha2Password) string { if str, ok := cachingSha2PasswordToString[status]; ok { return str } return "UNKNOWN" }
------------------

--- File: pkg/models/openapi.go---

--- Chunk 1---
func (s SchemaMatchMode) String() string { schemaModes := []string{"IDENTIFYMODE", "COMPAREMODE"} if int(s) < 0 || int(s) >= len(schemaModes) { return "UNKNOWN" } return schemaModes[s] }
------------------

--- Chunk 2---
func (d DrivenMode) String() string { drivenModes := []string{"consumer", "provider"} if int(d) < 0 || int(d) >= len(drivenModes) { return "UNKNOWN" } return drivenModes[d] }
------------------

--- File: pkg/models/testcase.go---

--- Chunk 1---
func SetVersion(V1 string) { currentVersion = Version(V1) }
------------------

--- Chunk 2---
func GetVersion() (V1 Version) { return currentVersion }
------------------

--- Chunk 3---
func (tc *TestCase) GetKind() string { return string(tc.Kind) }
------------------

--- File: pkg/models/testrun.go---

--- Chunk 1---
func (tr *TestReport) GetKind() string { return "TestReport" }
------------------

--- Chunk 2---
func (tr *TestResult) GetKind() string { return string(tr.Kind) }
------------------

--- Chunk 3---
func StringToTestSetStatus(s string) (TestSetStatus, error) { switch s { case "RUNNING": return TestSetStatusRunning, nil case "FAILED": return TestSetStatusFailed, nil case "PASSED": return TestSetStatusPassed, nil case "APP_HALTED": return TestSetStatusAppHalted, nil case "USER_ABORT": return TestSetStatusUserAbort, nil case "APP_FAULT": return TestSetStatusFaultUserApp, nil case "INTERNAL_ERR": return TestSetStatusInternalErr, nil case "NO_TESTS_TO_RUN": return TestSetStatusNoTestsToRun, nil default: return "", errors.New("invalid TestSetStatus value") } }
------------------

--- File: pkg/platform/auth/auth.go---

--- Chunk 1---
func New(serverURL string, installationID string, logger *zap.Logger, gitHubClientID string) service.Auth { return &Auth{ serverURL: serverURL, installationID: installationID, logger: logger, GitHubClientID: gitHubClientID, } }
------------------

--- Chunk 2---
func (a *Auth) Login(ctx context.Context) bool { deviceCodeResp, err := requestDeviceCode(a.logger, a.GitHubClientID) if err != nil { a.logger.Error("Error requesting device code", zap.Error(err)) return false } promptUser(deviceCodeResp) tokenResp, err := pollForAccessToken(ctx, a.logger, deviceCodeResp.DeviceCode, a.GitHubClientID, deviceCodeResp.Interval) if err != nil { if ctx.Err() == context.Canceled { return false } utils.LogError(a.logger, err, "failed to poll for access token") return false } userEmail, isValid, authErr, err := a.Validate(ctx, tokenResp.AccessToken) if err != nil { if ctx.Err() == context.Canceled { return false } a.logger.Error("Error checking auth", zap.Error(err)) return false } if !isValid { a.logger.Error("Invalid token", zap.Any("error", authErr)) return false } a.logger.Info("Successfully logged in to Keploy using GitHub as " + userEmail) return true }
------------------

--- Chunk 3---
Function Validate (start): func (a *Auth) Validate(ctx context.Context, token string) (string, bool, string, error) { url := fmt.Sprintf("%s/auth/github", a.serverURL) // this i can directly call the vs code extension requestBody := &models.AuthReq{ GitHubToken: token, InstallationID: a.installationID, } requestJSON, err := json.Marshal(requestBody) if err != nil { utils.LogError(a.logger, err, "failed to marshal request body for authentication") return "", false, "", fmt.Errorf("error marshaling request body for authentication: %s", err.Error()) } req, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewBuffer(requestJSON)) if err != nil { utils.LogError(a.logger, err, "failed to create request for authentication") return "", false, "", fmt.Errorf("error creating request for authentication: %s", err.Error()) } req.Header.Set("Content-Type", "application/json") client := &http.Client{} res, err := client.Do(req) if err != nil { return "", false, "", fmt.Errorf("failed to authenticate: %s", err.Error()) } defer func() { err
------------------

--- Chunk 4---
Function Validate (end): := res.Body.Close() if err != nil { utils.LogError(a.logger, err, "failed to close response body for authentication") } }() var respBody models.AuthResp err = json.NewDecoder(res.Body).Decode(&respBody) if err != nil { return "", false, "", fmt.Errorf("error unmarshalling the authentication response: %s", err.Error()) } if res.StatusCode != 200 || res.StatusCode >= 300 { return "", false, "", fmt.Errorf("failed to authenticate: %s", respBody.Error) } a.jwtToken = respBody.JwtToken return respBody.EmailID, respBody.IsValid, respBody.Error, nil }
------------------

--- Chunk 5---
func (a *Auth) GetToken(ctx context.Context) (string, error) { if a.jwtToken == "" { _, _, _, err := a.Validate(ctx, "") if err != nil { return "", err } } if a.jwtToken == "" { a.logger.Warn("Looks like you are not logged in.") a.logger.Warn("Please follow the instructions to login.") isSuccessful := a.Login(ctx) if !isSuccessful { return "", fmt.Errorf("failed to login") } } return a.jwtToken, nil }
------------------

--- Chunk 6---
func requestDeviceCode(logger *zap.Logger, gitHubClientID string) (*models.DeviceCodeResponse, error) { data := url.Values{} data.Set("client_id", gitHubClientID) data.Set("scope", "read:user") resp, err := http.PostForm(models.DeviceCodeURL, data) if err != nil { return nil, err } defer func() { err := resp.Body.Close() if err != nil { utils.LogError(logger, err, "failed to close response body") } }() body, err := io.ReadAll(resp.Body) if err != nil { return nil, err } // Parse the URL-encoded response parsed, err := url.ParseQuery(string(body)) if err != nil { return nil, err } // Populate the DeviceCodeResponse struct deviceCodeResp := &models.DeviceCodeResponse{ DeviceCode: parsed.Get("device_code"), UserCode: parsed.Get("user_code"), VerificationURI: parsed.Get("verification_uri"), Interval: 5, // Default value; you can parse this from the response if needed } return deviceCodeResp, nil }
------------------

--- Chunk 7---
func promptUser(deviceCodeResp *models.DeviceCodeResponse) { fmt.Printf("Please go to %s and enter the code: %s\n", deviceCodeResp.VerificationURI, deviceCodeResp.UserCode) }
------------------

--- Chunk 8---
Function pollForAccessToken (start): func pollForAccessToken(ctx context.Context, logger *zap.Logger, deviceCode, gitHubClientID string, interval int) (*models.AccessTokenResponse, error) { data := url.Values{} data.Set("client_id", gitHubClientID) data.Set("device_code", deviceCode) data.Set("grant_type", "urn:ietf:params:oauth:grant-type:device_code") fmt.Println("waiting for approval (this might take 4-5 sec for approval)...") for { resp, err := http.PostForm(models.TokenURL, data) if err != nil { return nil, err } defer func() { err := resp.Body.Close() if err != nil { utils.LogError(logger, err, "failed to close response body") } }() body, err := io.ReadAll(resp.Body) if err != nil { return nil, err } if resp.StatusCode != http.StatusOK { return nil, fmt.Errorf("unexpected status code: %d", resp.StatusCode) } var tokenResp models.AccessTokenResponse parsed, err := url.ParseQuery(string(body)) if err != nil { return nil, err }
------------------

--- Chunk 9---
Function pollForAccessToken (end): if parsed.Get("error") == "authorization_pending" { select { case <-time.After(time.Duration(interval) * time.Second): case <-ctx.Done(): return nil, ctx.Err() } continue } else if parsed.Get("error") != "" { return nil, fmt.Errorf("error: %s", parsed.Get("error_description")) } if accessToken := parsed.Get("access_token"); accessToken != "" { return &models.AccessTokenResponse{ AccessToken: accessToken, TokenType: parsed.Get("token_type"), Scope: parsed.Get("scope"), }, nil } return &tokenResp, nil } }
------------------

--- File: pkg/platform/docker/docker.go---

--- Chunk 1---
func New(logger *zap.Logger) (Client, error) { dockerClient, err := nativeDockerClient.NewClientWithOpts(nativeDockerClient.FromEnv, nativeDockerClient.WithAPIVersionNegotiation()) if err != nil { return nil, err } return &Impl{ APIClient: dockerClient, timeoutForDockerQuery: defaultTimeoutForDockerQuery, logger: logger, }, nil }
------------------

--- Chunk 2---
func (idc *Impl) GetContainerID() string { return idc.containerID }
------------------

--- Chunk 3---
func (idc *Impl) SetContainerID(containerID string) { idc.containerID = containerID }
------------------

--- Chunk 4---
func (idc *Impl) ExtractNetworksForContainer(containerName string) (map[string]*network.EndpointSettings, error) { ctx, cancel := context.WithTimeout(context.Background(), idc.timeoutForDockerQuery) defer cancel() containerJSON, err := idc.ContainerInspect(ctx, containerName) if err != nil { utils.LogError(idc.logger, err, "couldn't inspect container via the Docker API", zap.String("containerName", containerName)) return nil, err } if settings := containerJSON.NetworkSettings; settings != nil { return settings.Networks, nil } // Docker attaches the container to "bridge" network by default. // If the network list is empty, the docker daemon is possibly misbehaving, // or the container is in a bad state. utils.LogError(idc.logger, nil, "The network list for the given container is empty. This is unexpected.", zap.String("containerName", containerName)) return nil, fmt.Errorf("the container is not attached to any network") }
------------------

--- Chunk 5---
func (idc *Impl) ConnectContainerToNetworks(containerName string, settings map[string]*network.EndpointSettings) error { if settings == nil { return fmt.Errorf("provided network settings is empty") } existingNetworks, err := idc.ExtractNetworksForContainer(containerName) if err != nil { return fmt.Errorf("could not get existing networks for container %s", containerName) } ctx, cancel := context.WithTimeout(context.Background(), idc.timeoutForDockerQuery) defer cancel() for networkName, setting := range settings { // If the container is already part of this network, skip it. _, ok := existingNetworks[networkName] if ok { continue } err := idc.NetworkConnect(ctx, networkName, containerName, setting) if err != nil { return err } } return nil }
------------------

--- Chunk 6---
func (idc *Impl) AttachNetwork(containerName string, networkNames []string) error { if len(networkNames) == 0 { return fmt.Errorf("provided network names list is empty") } existingNetworks, err := idc.ExtractNetworksForContainer(containerName) if err != nil { return fmt.Errorf("could not get existing networks for container %s", containerName) } ctx, cancel := context.WithTimeout(context.Background(), idc.timeoutForDockerQuery) defer cancel() for _, networkName := range networkNames { // If the container is already part of this network, skip it. _, ok := existingNetworks[networkName] if ok { continue } // As there are no specific settings, use nil for the settings parameter. err := idc.NetworkConnect(ctx, networkName, containerName, nil) if err != nil { return err } } return nil }
------------------

--- Chunk 7---
func (idc *Impl) StopAndRemoveDockerContainer() error { dockerClient := idc containerID := idc.containerID container, err := dockerClient.ContainerInspect(context.Background(), containerID) if err != nil { return fmt.Errorf("failed to inspect the docker container: %w", err) } if container.State.Status == "running" { err = dockerClient.ContainerStop(context.Background(), containerID, dockerContainerPkg.StopOptions{}) if err != nil { return fmt.Errorf("failed to stop the docker container: %w", err) } } removeOptions := types.ContainerRemoveOptions{ RemoveVolumes: true, Force: true, } err = dockerClient.ContainerRemove(context.Background(), containerID, removeOptions) if err != nil { return fmt.Errorf("failed to remove the docker container: %w", err) } idc.logger.Debug("Docker Container stopped and removed successfully.") return nil }
------------------

--- Chunk 8---
func (idc *Impl) NetworkExists(networkName string) (bool, error) { ctx, cancel := context.WithTimeout(context.Background(), idc.timeoutForDockerQuery) defer cancel() // Retrieve all networks. networks, err := idc.NetworkList(ctx, types.NetworkListOptions{}) if err != nil { return false, fmt.Errorf("error retrieving networks: %v", err) } // Check if the specified network is in the list. for _, net := range networks { if net.Name == networkName { return true, nil } } return false, nil }
------------------

--- Chunk 9---
func (idc *Impl) CreateNetwork(networkName string) error { ctx, cancel := context.WithTimeout(context.Background(), idc.timeoutForDockerQuery) defer cancel() _, err := idc.NetworkCreate(ctx, networkName, types.NetworkCreate{ Driver: "bridge", }) return err }
------------------

--- Chunk 10---
func (idc *Impl) ReadComposeFile(filePath string) (*Compose, error) { data, err := os.ReadFile(filePath) if err != nil { return nil, err } var compose Compose err = yaml.Unmarshal(data, &compose) if err != nil { return nil, err } return &compose, nil }
------------------

--- Chunk 11---
func (idc *Impl) WriteComposeFile(compose *Compose, path string) error { data, err := yaml.Marshal(compose) if err != nil { return err } // write data to file err = os.WriteFile(path, data, 0644) if err != nil { return err } return nil }
------------------

--- Chunk 12---
func (idc *Impl) HasRelativePath(compose *Compose) bool { if compose.Services.Content == nil { return false } for _, service := range compose.Services.Content { for i, item := range service.Content { if i+1 >= len(service.Content) { break } if item.Value == "volumes" { // volumeKeyNode := service.Content[i] or item volumeValueNode := service.Content[i+1] // Loop over all the volume mounts for _, volumeMount := range volumeValueNode.Content { // If volume mount starts with ./ or ../ then it as a relative path so return true if volumeMount.Kind == yaml.ScalarNode && (volumeMount.Value[:2] == "./" || volumeMount.Value[:3] == "../") { return true } } } } } return false }
------------------

--- Chunk 13---
Function GetNetworkInfo (start): func (idc *Impl) GetNetworkInfo(compose *Compose) *NetworkInfo { if compose.Networks.Content == nil { return nil } var defaultNetwork string for i := 0; i < len(compose.Networks.Content); i += 2 { if i+1 >= len(compose.Networks.Content) { break } networkKeyNode := compose.Networks.Content[i] networkValueNode := compose.Networks.Content[i+1] if defaultNetwork == "" { defaultNetwork = networkKeyNode.Value } isExternal := false var externalName string for j := 0; j < len(networkValueNode.Content); j += 2 { if j+1 >= len(networkValueNode.Content) { break } propertyNode := networkValueNode.Content[j] valueNode := networkValueNode.Content[j+1] if propertyNode.Value == "external" { if valueNode.Kind == yaml.ScalarNode && valueNode.Value == "true" { isExternal = true break } else if valueNode.Kind == yaml.MappingNode { for k := 0; k <
------------------

--- Chunk 14---
Function GetNetworkInfo (end): len(valueNode.Content); k += 2 { if k+1 >= len(valueNode.Content) { break } subPropertyNode := valueNode.Content[k] subValueNode := valueNode.Content[k+1] if subPropertyNode.Value == "name" { isExternal = true externalName = subValueNode.Value break } } } break } } if isExternal { n := &NetworkInfo{External: true, Name: networkKeyNode.Value} if externalName != "" { n.Name = externalName } return n } } if defaultNetwork != "" { return &NetworkInfo{External: false, Name: defaultNetwork} } return nil }
------------------

--- Chunk 15---
func (idc *Impl) GetHostWorkingDirectory() (string, error) { ctx, cancel := context.WithTimeout(context.Background(), idc.timeoutForDockerQuery) defer cancel() curDir, err := os.Getwd() if err != nil { utils.LogError(idc.logger, err, "failed to get current working directory") return "", err } container, err := idc.ContainerInspect(ctx, "keploy-v2") if err != nil { utils.LogError(idc.logger, err, "error inspecting keploy-v2 container") return "", err } containerMounts := container.Mounts // Loop through container mounts and find the mount for current directory in the container for _, mount := range containerMounts { if mount.Destination == curDir { idc.logger.Debug(fmt.Sprintf("found mount for %s in keploy-v2 container", curDir), zap.Any("mount", mount)) return mount.Source, nil } } return "", fmt.Errorf("%s", fmt.Sprintf("could not find mount for %s in keploy-v2 container", curDir)) }
------------------

--- Chunk 16---
Function ForceAbsolutePath (start): func (idc *Impl) ForceAbsolutePath(c *Compose, basePath string) error { hostWorkingDirectory, err := idc.GetHostWorkingDirectory() if err != nil { return err } dockerComposeContext, err := filepath.Abs(filepath.Join(hostWorkingDirectory, basePath)) if err != nil { utils.LogError(idc.logger, err, "error getting absolute path for docker compose file") return err } dockerComposeContext = filepath.Dir(dockerComposeContext) idc.logger.Debug("docker compose file location in host filesystem", zap.Any("dockerComposeContext", dockerComposeContext)) // Loop through all services in compose file for _, service := range c.Services.Content { for i, item := range service.Content { if i+1 >= len(service.Content) { break } if item.Value == "volumes" { // volumeKeyNode := service.Content[i] or item volumeValueNode := service.Content[i+1] // Loop over all the volume mounts for _, volumeMount := range volumeValueNode.Content { // If volume mount starts with ./ or ../ then it is a relative path if volumeMount.Kind == yaml.Scalar
------------------

--- Chunk 17---
Function ForceAbsolutePath (end): Node && (volumeMount.Value[:2] == "./" || volumeMount.Value[:3] == "../") { // Replace the relative path with absolute path absPath, err := filepath.Abs(filepath.Join(dockerComposeContext, volumeMount.Value)) if err != nil { return err } volumeMount.Value = absPath } } } } } return nil }
------------------

--- Chunk 18---
Function MakeNetworkExternal (start): func (idc *Impl) MakeNetworkExternal(c *Compose) error { // Iterate over all networks and check the 'external' flag. if c.Networks.Content != nil { for i := 0; i < len(c.Networks.Content); i += 2 { if i+1 >= len(c.Networks.Content) { break } // networkKeyNode := compose.Networks.Content[i] networkValueNode := c.Networks.Content[i+1] // If it's a shorthand notation or null value, initialize it as an empty mapping node if (networkValueNode.Kind == yaml.ScalarNode && networkValueNode.Value == "") || networkValueNode.Tag == "!!null" { networkValueNode.Kind = yaml.MappingNode networkValueNode.Tag = "" networkValueNode.Content = make([]*yaml.Node, 0) } externalFound := false for index, propertyNode := range networkValueNode.Content { if index+1 >= len(networkValueNode.Content) { break } if propertyNode.Value == "external" { externalFound = true valueNode := networkValueNode.Content
------------------

--- Chunk 19---
Function MakeNetworkExternal (end): [index+1] if valueNode.Kind == yaml.ScalarNode && (valueNode.Value == "false" || valueNode.Value == "") { valueNode.Value = "true" } break } } if !externalFound { networkValueNode.Content = append(networkValueNode.Content, &yaml.Node{Kind: yaml.ScalarNode, Value: "external"}, &yaml.Node{Kind: yaml.ScalarNode, Value: "true"}, ) } } } return nil }
------------------

--- Chunk 20---
Function SetKeployNetwork (start): func (idc *Impl) SetKeployNetwork(c *Compose) (*NetworkInfo, error) { // Ensure that the top-level networks mapping exists. if c.Networks.Content == nil { c.Networks.Kind = yaml.MappingNode c.Networks.Content = make([]*yaml.Node, 0) } networkInfo := &NetworkInfo{ Name: "keploy-network", External: true, } // Check if "keploy-network" already exists exists := false for i := 0; i < len(c.Networks.Content); i += 2 { if c.Networks.Content[i].Value == "keploy-network" { exists = true break } } if !exists { // Add the keploy-network with external: true c.Networks.Content = append(c.Networks.Content, &yaml.Node{Kind: yaml.ScalarNode, Value: "keploy-network"}, &yaml.Node{Kind: yaml.MappingNode, Content: []*yaml.Node{ {Kind: yaml.ScalarNode, Value: "external"}, {Kind: yaml.ScalarNode, Value: "true"},
------------------

--- Chunk 21---
Function SetKeployNetwork (end): }}, ) } // Add or modify network for each service for _, service := range c.Services.Content { networksFound := false for _, item := range service.Content { if item.Value == "networks" { networksFound = true break } } if !networksFound { service.Content = append(service.Content, &yaml.Node{Kind: yaml.ScalarNode, Value: "networks"}, &yaml.Node{ Kind: yaml.SequenceNode, Content: []*yaml.Node{ {Kind: yaml.ScalarNode, Value: "keploy-network"}, }, }, ) } else { for _, item := range service.Content { if item.Value == "networks" { item.Content = append(item.Content, &yaml.Node{Kind: yaml.ScalarNode, Value: "keploy-network"}) } } } } return networkInfo, nil }
------------------

--- Chunk 22---
func (idc *Impl) IsContainerRunning(containerName string) (bool, error) { ctx, cancel := context.WithTimeout(context.Background(), idc.timeoutForDockerQuery) defer cancel() containerJSON, err := idc.ContainerInspect(ctx, containerName) if err != nil { return false, err } if containerJSON.State.Running { return true, nil } return false, nil }
------------------

--- Chunk 23---
Function CreateVolume (start): func (idc *Impl) CreateVolume(ctx context.Context, volumeName string, recreate bool) error { // Set a timeout for the context ctx, cancel := context.WithTimeout(ctx, idc.timeoutForDockerQuery) defer cancel() // Check if the 'debugfs' volume exists filter := filters.NewArgs() filter.Add("name", volumeName) volumeList, err := idc.VolumeList(ctx, volume.ListOptions{Filters: filter}) if err != nil { idc.logger.Error("failed to list docker volumes", zap.Error(err)) return err } if len(volumeList.Volumes) > 0 { if !recreate { idc.logger.Info("volume already exists", zap.Any("volume", volumeName)) return err } err := idc.VolumeRemove(ctx, volumeName, false) if err != nil { idc.logger.Error("failed to delete volume "+volumeName, zap.Error(err)) return err } } // Create the 'debugfs' volume if it doesn't exist _, err = idc.VolumeCreate(ctx, volume.CreateOptions{ Name: volumeName, Driver: "local",
------------------

--- Chunk 24---
Function CreateVolume (end): DriverOpts: map[string]string{ "type": volumeName, // Use "none" for local driver "device": volumeName, }, }) if err != nil { idc.logger.Error("failed to create volume", zap.Any("volume", volumeName), zap.Error(err)) return err } idc.logger.Debug("volume created", zap.Any("volume", volumeName)) return nil }
------------------

--- File: pkg/platform/docker/util.go---

--- Chunk 1---
Function ParseDockerCmd (start): func ParseDockerCmd(cmd string, kind utils.CmdType, idc Client) (string, string, error) { // Regular expression patterns var containerNamePattern string switch kind { case utils.DockerStart: containerNamePattern = `start\s+(?:-[^\s]+\s+)*([^\s]*)` default: containerNamePattern = `--name\s+([^\s]+)` } networkNamePattern := `(--network|--net)\s+([^\s]+)` // Extract container name containerNameRegex := regexp.MustCompile(containerNamePattern) containerNameMatches := containerNameRegex.FindStringSubmatch(cmd) if len(containerNameMatches) < 2 { return "", "", fmt.Errorf("failed to parse container name") } containerName := containerNameMatches[1] if kind == utils.DockerStart { networks, err := idc.ExtractNetworksForContainer(containerName) if err != nil { return containerName, "", err } for i := range networks { return containerName, i, nil } return containerName, "", fmt.Errorf("failed to parse network name") } // Extract network name network
------------------

--- Chunk 2---
Function ParseDockerCmd (end): NameRegex := regexp.MustCompile(networkNamePattern) networkNameMatches := networkNameRegex.FindStringSubmatch(cmd) if len(networkNameMatches) < 3 { return containerName, "", fmt.Errorf("failed to parse network name") } networkName := networkNameMatches[2] return containerName, networkName, nil }
------------------

--- File: pkg/platform/storage/storage.go---

--- Chunk 1---
func New(serverURL string, logger *zap.Logger) *Storage { return &Storage{ serverURL: serverURL, logger: logger, } }
------------------

--- Chunk 2---
Function Upload (start): func (s *Storage) Upload(ctx context.Context, file io.Reader, mockName string, appName string, token string) error { done := make(chan struct{}) var once sync.Once closeDone := func() { once.Do(func() { close(done) }) } // Spinner goroutine go func() { spinnerChars := []rune{'|', '/', '-', '\\'} i := 0 for { select { case <-done: fmt.Print("\r") // Clear spinner line after done return default: fmt.Printf("\rUploading... %c", spinnerChars[i%len(spinnerChars)]) i++ time.Sleep(100 * time.Millisecond) } } }() defer closeDone() // Ensure we close the channel when the function exits // Create a multipart buffer and writer body := &bytes.Buffer{} writer := multipart.NewWriter(body) // Create a custom part header for the file field partHeader := textproto.MIMEHeader{} partHeader.Set("Content-Disposition", fmt.Sprintf(`form-data; name="%s"; filename="%s"`, "mock", filepath.Base("mocks.yaml"))) partHeader.Set("Content
------------------

--- Chunk 3---
Function Upload (part 2): -Type", "application/octet-stream") partHeader.Set("Content-Encoding", "gzip") // Explicitly declare compression part, err := writer.CreatePart(partHeader) if err != nil { return err } // Compress file data with gzip and write into multipart part gzipWriter := gzip.NewWriter(part) if _, err := io.Copy(gzipWriter, file); err != nil { return err } if err := gzipWriter.Close(); err != nil { return err } // Add other form fields if err := writer.WriteField("appName", appName); err != nil { s.logger.Error("Error writing appName field", zap.Error(err)) return err } if err := writer.WriteField("mockName", mockName); err != nil { s.logger.Error("Error writing mockName field", zap.Error(err)) return err } if err := writer.Close(); err != nil { s.logger.Error("Error closing writer", zap.Error(err)) return err } // Prepare the HTTP request req, err := http.NewRequestWithContext(ctx, "POST", s.serverURL+"/mock/upload", body) if err != nil { return err } req.Header
------------------

--- Chunk 4---
Function Upload (part 3): .Set("Content-Type", writer.FormDataContentType()) req.Header.Set("Authorization", "Bearer "+token) // Execute the HTTP request resp, err := http.DefaultClient.Do(req) if err != nil { return err } defer func() { if err := resp.Body.Close(); err != nil { utils.LogError(s.logger, err, "failed to close the http response body") } }() // Read the raw body bodyBytes, err := io.ReadAll(resp.Body) if err != nil { utils.LogError(s.logger, err, "failed to read the response body") return err } // Decode into struct from the raw bytes var mockUploadResponse MockUploadResponse if err := json.NewDecoder(bytes.NewReader(bodyBytes)).Decode(&mockUploadResponse); err != nil { utils.LogError(s.logger, err, "failed to decode the response body", zap.Any("Response", resp), zap.String("body", string(bodyBytes))) return err } closeDone() if resp.StatusCode != http.StatusOK { return fmt.Errorf("upload failed with status code: %d and error %s", resp.StatusCode, mockUploadResponse.Error) } if !mockUploadResponse.IsSuccess { utils.LogError
------------------

--- Chunk 5---
Function Upload (end): (s.logger, fmt.Errorf("upload failed: %s", mockUploadResponse.Error), "failed to upload the mock") return fmt.Errorf("upload failed: %s", mockUploadResponse.Error) } s.logger.Info("Mock uploaded successfully") return nil }
------------------

--- Chunk 6---
Function Download (start): func (s *Storage) Download(ctx context.Context, mockName string, appName string, userName string, jwtToken string) (io.Reader, error) { // Create the HTTP request req, err := http.NewRequestWithContext(ctx, "GET", fmt.Sprintf("%s/mock/download?appName=%s&mockName=%s&userName=%s", s.serverURL, appName, mockName, userName), nil) if err != nil { return nil, err } req.Header.Set("Authorization", "Bearer "+jwtToken) req.Header.Set("Accept-Encoding", "gzip") // Request gzip encoding // Execute the request resp, err := http.DefaultClient.Do(req) if err != nil { return nil, err } if resp.StatusCode != http.StatusOK { defer func() { err := resp.Body.Close() if err != nil { utils.LogError(s.logger, err, "failed to close the http response body") } }() // Read the response body to get the error message body, err := io.ReadAll(resp.Body) if err != nil { return nil, fmt.Errorf("failed to read response body and the resp code is: %d", resp.StatusCode)
------------------

--- Chunk 7---
Function Download (end): } return nil, fmt.Errorf("download failed with status code: %d, message: %s", resp.StatusCode, strings.TrimSpace(string(body))) } // Check if the response is gzipped if strings.EqualFold(resp.Header.Get("Content-Encoding"), "gzip") { s.logger.Debug("mock response is gzipped") gr, err := gzip.NewReader(resp.Body) if err != nil { defer func() { err := resp.Body.Close() if err != nil { utils.LogError(s.logger, err, "failed to close the http response body") } }() return nil, fmt.Errorf("failed to create gzip reader: %w", err) } return gr, nil // gr is an io.Reader, decompressing transparently } return resp.Body, nil }
------------------

--- File: pkg/platform/telemetry/telemetry.go---

--- Chunk 1---
func NewTelemetry(logger *zap.Logger, opt Options) *Telemetry { return &Telemetry{ Enabled: opt.Enabled, logger: logger, KeployVersion: opt.Version, GlobalMap: opt.GlobalMap, InstallationID: opt.InstallationID, client: &http.Client{Timeout: 10 * time.Second}, } }
------------------

--- Chunk 2---
func (tel *Telemetry) Ping() { if !tel.Enabled { return } go func() { for { tel.SendTelemetry("Ping") time.Sleep(5 * time.Minute) } }() }
------------------

--- Chunk 3---
func (tel *Telemetry) TestSetRun(success int, failure int, testSet string, runStatus string) { dataMap := &sync.Map{} dataMap.Store("Passed-Tests", success) dataMap.Store("Failed-Tests", failure) dataMap.Store("Test-Set", testSet) dataMap.Store("Run-Status", runStatus) go tel.SendTelemetry("TestSetRun", dataMap) }
------------------

--- Chunk 4---
func (tel *Telemetry) TestRun(success int, failure int, testSets int, runStatus string) { dataMap := &sync.Map{} dataMap.Store("Passed-Tests", success) dataMap.Store("Failed-Tests", failure) dataMap.Store("Test-Sets", testSets) dataMap.Store("Run-Status", runStatus) go tel.SendTelemetry("TestRun", dataMap) }
------------------

--- Chunk 5---
func (tel *Telemetry) MockTestRun(utilizedMocks int) { dataMap := &sync.Map{} dataMap.Store("Utilized-Mocks", utilizedMocks) go tel.SendTelemetry("MockTestRun", dataMap) }
------------------

--- Chunk 6---
func (tel *Telemetry) RecordedTestSuite(testSet string, testsTotal int, mockTotal map[string]int) { dataMap := &sync.Map{} dataMap.Store("test-set", testSet) dataMap.Store("tests", testsTotal) mockMap := &sync.Map{} for k, v := range mockTotal { mockMap.Store(k, v) } dataMap.Store("mocks", mockMap) go tel.SendTelemetry("RecordedTestSuite", dataMap) }
------------------

--- Chunk 7---
func (tel *Telemetry) RecordedTestAndMocks() { dataMap := &sync.Map{} mapcheck := make(map[string]int) dataMap.Store("mocks", mapcheck) go tel.SendTelemetry("RecordedTestAndMocks", dataMap) }
------------------

--- Chunk 8---
func (tel *Telemetry) GenerateUT() { dataMap := &sync.Map{} go tel.SendTelemetry("GenerateUT", dataMap) }
------------------

--- Chunk 9---
func (tel *Telemetry) GenerateEmbedding() { dataMap := &sync.Map{} go tel.SendTelemetry("GenerateEmbedding", dataMap) }
------------------

--- Chunk 10---
func (tel *Telemetry) RecordedMocks(mockTotal map[string]int) { mockMap := &sync.Map{} for k, v := range mockTotal { mockMap.Store(k, v) } dataMap := &sync.Map{} dataMap.Store("mocks", mockMap) go tel.SendTelemetry("RecordedMocks", dataMap) }
------------------

--- Chunk 11---
func (tel *Telemetry) RecordedTestCaseMock(mockType string) { dataMap := &sync.Map{} dataMap.Store("mock", mockType) go tel.SendTelemetry("RecordedTestCaseMock", dataMap) }
------------------

--- Chunk 12---
Function SendTelemetry (start): func (tel *Telemetry) SendTelemetry(eventType string, output ...*sync.Map) { if tel.Enabled { event := models.TeleEvent{ EventType: eventType, CreatedAt: time.Now().Unix(), } if len(output) > 0 { event.Meta = output[0] } else { event.Meta = &sync.Map{} } hasGlobalMap := false tel.GlobalMap.Range(func(key, value interface{}) bool { hasGlobalMap = true return false // Stop iteration after finding the first element }) if hasGlobalMap { // event.Meta["global-map"] = syncMapToMap(tel.GlobalMap) // If you want to nest the global map, you can do this (but the telemetry // endpoint needs to support nested sync.Maps): // event.Meta.Store("global-map", tel.GlobalMap) // Otherwise, merge the global map into the event's meta map tel.GlobalMap.Range(func(key, value interface{}) bool { event.Meta.Store(key, value) return true }) } event.InstallationID = tel.Install
------------------

--- Chunk 13---
Function SendTelemetry (end): ationID event.OS = runtime.GOOS event.KeployVersion = tel.KeployVersion event.Arch = runtime.GOARCH bin, err := marshalEvent(event, tel.logger) if err != nil { tel.logger.Debug("failed to marshal event", zap.Error(err)) return } req, err := http.NewRequest(http.MethodPost, teleURL, bytes.NewBuffer(bin)) if err != nil { tel.logger.Debug("failed to create request for analytics", zap.Error(err)) return } req.Header.Set("Content-Type", "application/json; charset=utf-8") resp, err := tel.client.Do(req) if err != nil { tel.logger.Debug("failed to send request for analytics", zap.Error(err)) return } _, err = unmarshalResp(resp, tel.logger) if err != nil { tel.logger.Debug("failed to unmarshal response", zap.Error(err)) return } } }
------------------

--- File: pkg/platform/telemetry/utils.go---

--- Chunk 1---
func marshalEvent(event models.TeleEvent, log *zap.Logger) (bin []byte, err error) { bin, err = json.Marshal(event) if err != nil { log.Fatal("failed to marshal event struct into json", zap.Error(err)) } return }
------------------

--- Chunk 2---
func unmarshalResp(resp *http.Response, log *zap.Logger) (id string, err error) { defer func(Body io.ReadCloser) { err = Body.Close() if err != nil { log.Debug("failed to close connecton reader", zap.String("url", "https://telemetry.keploy.io/analytics"), zap.Error(err)) return } }(resp.Body) var res map[string]string body, err := io.ReadAll(resp.Body) if err != nil { log.Debug("failed to read response from telemetry server", zap.String("url", "https://telemetry.keploy.io/analytics"), zap.Error(err)) return } err = json.Unmarshal(body, &res) if err != nil { log.Debug("failed to read testcases from telemetry server", zap.Error(err)) return } id, ok := res["InstallationID"] if !ok { log.Debug("InstallationID not present") err = errors.New("InstallationID not present") return } return }
------------------

--- File: pkg/platform/yaml/configdb/testset/db.go---

--- Chunk 1---
func New[T any](logger *zap.Logger, path string) *Db[T] { return &Db[T]{ logger: logger, path: path, } }
------------------

--- Chunk 2---
func (db *Db[T]) Read(ctx context.Context, testSetID string) (T, error) { filePath := filepath.Join(db.path, testSetID) var config T data, err := yaml.ReadFile(ctx, db.logger, filePath, "config") if err != nil { return config, err } if err := yamlLib.Unmarshal(data, &config); err != nil { utils.LogError(db.logger, err, "failed to unmarshal test-set config file", zap.String("testSet", testSetID)) return config, err } secretConfig, ok := any(config).(models.Secret) if !ok { return config, nil } secretValues, err := db.ReadSecret(ctx, testSetID) if err != nil { db.logger.Warn("Failed to read secret values, continuing without secrets", zap.String("testSet", testSetID), zap.Error(err)) return config, err } secretConfig.SetSecrets(secretValues) return config, nil }
------------------

--- Chunk 3---
func (db *Db[T]) Write(ctx context.Context, testSetID string, config T) error { filePath := filepath.Join(db.path, testSetID) data, err := yamlLib.Marshal(config) if err != nil { utils.LogError(db.logger, err, "failed to marshal test-set config file", zap.String("testSet", testSetID)) return err } err = yaml.WriteFile(ctx, db.logger, filePath, "config", data, false) if err != nil { utils.LogError(db.logger, err, "failed to write test-set configuration in yaml file", zap.String("testSet", testSetID)) return err } return nil }
------------------

--- Chunk 4---
func (db *Db[T]) ReadSecret(ctx context.Context, testSetID string) (map[string]interface{}, error) { filePath := filepath.Join(db.path, testSetID) secretPath := filepath.Join(filePath, "secret.yaml") if _, err := os.Stat(secretPath); os.IsNotExist(err) { return make(map[string]interface{}), nil } data, err := yaml.ReadFile(ctx, db.logger, filePath, "secret") if err != nil { return nil, err } var secretConfig map[string]interface{} if err := yamlLib.Unmarshal(data, &secretConfig); err != nil { utils.LogError(db.logger, err, "failed to unmarshal test-set secret file", zap.String("testSet", testSetID)) return nil, err } return secretConfig, nil }
------------------

--- File: pkg/platform/yaml/configdb/user/db.go---

--- Chunk 1---
func HomeDir() string { configFolder := "/.keploy" if runtime.GOOS == "windows" { home := os.Getenv("HOMEDRIVE") + os.Getenv("HOMEPATH") if home == "" { home = os.Getenv("USERPROFILE") } return home + configFolder } return os.Getenv("HOME") + configFolder }
------------------

--- Chunk 2---
func (db *Db) ReadKeployConfig() (*KeployConfig, error) { path := HomeDir() + "/keploy.yaml" content, err := os.ReadFile(path) if err != nil { return nil, err } // Decode the yaml file var data KeployConfig err = yaml.Unmarshal(content, &data) if err != nil { utils.LogError(db.logger, err, "failed to unmarshal keploy.yaml") return nil, err } return &data, nil }
------------------

--- Chunk 3---
func (db *Db) WriteKeployConfig(data *KeployConfig) error { // Open the keploy.yaml file path := HomeDir() + "/keploy.yaml" file, err := os.OpenFile(path, os.O_RDWR|os.O_CREATE, 0644) if err != nil { return err } defer func() { if err := file.Close(); err != nil { db.logger.Error("failed to close file", zap.Error(err)) } }() updatedData, err := yamlLib.Marshal(data) if err != nil { return err } // Truncate the file before writing to it. err = file.Truncate(0) if err != nil { return err } _, err = file.Write(updatedData) if err != nil { return err } return nil }
------------------

--- Chunk 4---
func New(logger *zap.Logger, cfg *config.Config) *Db { return &Db{ logger: logger, cfg: cfg, } }
------------------

--- Chunk 5---
func (db *Db) GetInstallationID(_ context.Context) (string, error) { var id string var err error inDocker := os.Getenv("KEPLOY_INDOCKER") if inDocker == "true" { id = os.Getenv("INSTALLATION_ID") } else { id, err = machineid.ID() if err != nil { db.logger.Debug("failed to get machine id", zap.Error(err)) return "", nil } } if id == "" { db.logger.Debug("got empty machine id") return "", nil } return id, nil }
------------------

--- File: pkg/platform/yaml/mockdb/db.go---

--- Chunk 1---
func New(Logger *zap.Logger, mockPath string, mockName string) *MockYaml { return &MockYaml{ MockPath: mockPath, MockName: mockName, Logger: Logger, idCounter: -1, } }
------------------

--- Chunk 2---
Function UpdateMocks (start): func (ys *MockYaml) UpdateMocks(ctx context.Context, testSetID string, mockNames map[string]models.MockState) error { mockFileName := "mocks" if ys.MockName != "" { mockFileName = ys.MockName } path := filepath.Join(ys.MockPath, testSetID) ys.Logger.Debug("logging the names of the unused mocks to be removed", zap.Any("mockNames", mockNames), zap.Any("for testset", testSetID), zap.Any("at path", filepath.Join(path, mockFileName+".yaml"))) // Read the mocks from the yaml file mockPath, err := yaml.ValidatePath(filepath.Join(path, mockFileName+".yaml")) if err != nil { utils.LogError(ys.Logger, err, "failed to read mocks due to inaccessible path", zap.Any("at path", filepath.Join(path, mockFileName+".yaml"))) return err } if _, err := os.Stat(mockPath); err != nil { utils.LogError(ys.Logger, err, "failed to find the mocks yaml file") return err } data, err := yaml.ReadFile(ctx, ys.Logger, path, mockFileName) if err != nil { utils.LogError(ys.Logger,
------------------

--- Chunk 3---
Function UpdateMocks (part 2): err, "failed to read the mocks from yaml file", zap.Any("at path", filepath.Join(path, mockFileName+".yaml"))) return err } // decode the mocks read from the yaml file dec := yamlLib.NewDecoder(bytes.NewReader(data)) var mockYamls []*yaml.NetworkTrafficDoc for { var doc *yaml.NetworkTrafficDoc err := dec.Decode(&doc) if errors.Is(err, io.EOF) { break } if err != nil { utils.LogError(ys.Logger, err, "failed to decode the yaml file documents", zap.Any("at path", filepath.Join(path, mockFileName+".yaml"))) return fmt.Errorf("failed to decode the yaml file documents. error: %v", err.Error()) } mockYamls = append(mockYamls, doc) } mocks, err := decodeMocks(mockYamls, ys.Logger) if err != nil { return err } var newMocks []*models.Mock for _, mock := range mocks { if _, ok := mockNames[mock.Name]; ok { newMocks = append(newMocks, mock) continue } } ys.Logger.Debug("
------------------

--- Chunk 4---
Function UpdateMocks (part 3): logging the names of the used mocks", zap.Any("mockNames", newMocks), zap.Any("for testset", testSetID)) // remove the old mock yaml file err = os.Remove(filepath.Join(path, mockFileName+".yaml")) if err != nil { return err } // write the new mocks to the new yaml file for _, newMock := range newMocks { mockYaml, err := EncodeMock(newMock, ys.Logger) if err != nil { utils.LogError(ys.Logger, err, "failed to encode the mock to yaml", zap.Any("mock", newMock.Name), zap.Any("for testset", testSetID)) return err } data, err = yamlLib.Marshal(&mockYaml) if err != nil { utils.LogError(ys.Logger, err, "failed to marshal the mock to yaml", zap.Any("mock", newMock.Name), zap.Any("for testset", testSetID)) return err } err = yaml.WriteFile(ctx, ys.Logger, path, mockFileName, data, true) if err != nil { utils.LogError(ys.Logger, err, "failed to write the mock to yaml",
------------------

--- Chunk 5---
Function UpdateMocks (end): zap.Any("mock", newMock.Name), zap.Any("for testset", testSetID)) return err } } return nil }
------------------

--- Chunk 6---
func (ys *MockYaml) InsertMock(ctx context.Context, mock *models.Mock, testSetID string) error { mock.Name = fmt.Sprint("mock-", ys.getNextID()) mockYaml, err := EncodeMock(mock, ys.Logger) if err != nil { return err } mockPath := filepath.Join(ys.MockPath, testSetID) mockFileName := ys.MockName if mockFileName == "" { mockFileName = "mocks" } data, err := yamlLib.Marshal(&mockYaml) if err != nil { return err } exists, err := yaml.FileExists(ctx, ys.Logger, mockPath, mockFileName) if err != nil { utils.LogError(ys.Logger, err, "failed to find yaml file", zap.String("path directory", mockPath), zap.String("yaml", mockFileName)) return err } if !exists { data = append([]byte(utils.GetVersionAsComment()), data...) } err = yaml.WriteFile(ctx, ys.Logger, mockPath, mockFileName, data, true) if err != nil { return err } return nil }
------------------

--- Chunk 7---
Function GetFilteredMocks (start): func (ys *MockYaml) GetFilteredMocks(ctx context.Context, testSetID string, afterTime time.Time, beforeTime time.Time) ([]*models.Mock, error) { var tcsMocks = make([]*models.Mock, 0) mockFileName := "mocks" if ys.MockName != "" { mockFileName = ys.MockName } path := filepath.Join(ys.MockPath, testSetID) mockPath, err := yaml.ValidatePath(path + "/" + mockFileName + ".yaml") if err != nil { return nil, err } if _, err := os.Stat(mockPath); err == nil { var mockYamls []*yaml.NetworkTrafficDoc data, err := yaml.ReadFile(ctx, ys.Logger, path, mockFileName) if err != nil { utils.LogError(ys.Logger, err, "failed to read the mocks from yaml file", zap.Any("session", filepath.Base(path)), zap.String("path", mockPath)) return nil, err } if len(data) == 0 { utils.LogError(ys.Logger, err, "failed to read the mocks from yaml file", zap.Any("session", filepath.Base(path)), zap.String("path", mockPath
------------------

--- Chunk 8---
Function GetFilteredMocks (part 2): )) return nil, fmt.Errorf("failed to get mocks, empty file") } dec := yamlLib.NewDecoder(bytes.NewReader(data)) for { var doc *yaml.NetworkTrafficDoc err := dec.Decode(&doc) if errors.Is(err, io.EOF) { break } if err != nil { return nil, fmt.Errorf("failed to decode the yaml file documents. error: %v", err.Error()) } mockYamls = append(mockYamls, doc) } mocks, err := decodeMocks(mockYamls, ys.Logger) if err != nil { utils.LogError(ys.Logger, err, "failed to decode the config mocks from yaml docs", zap.Any("session", filepath.Base(path))) return nil, err } for _, mock := range mocks { isFilteredMock := true switch mock.Kind { case "Generic": isFilteredMock = false case "Postgres": isFilteredMock = false case "Http": isFilteredMock = false case "Redis": isFilteredMock = false case "MySQL": isFilteredMock = false
------------------

--- Chunk 9---
Function GetFilteredMocks (end): } if mock.Spec.Metadata["type"] != "config" && isFilteredMock { tcsMocks = append(tcsMocks, mock) } } } filtered := pkg.FilterTcsMocks(ctx, ys.Logger, tcsMocks, afterTime, beforeTime) return filtered, nil }
------------------

--- Chunk 10---
Function GetUnFilteredMocks (start): func (ys *MockYaml) GetUnFilteredMocks(ctx context.Context, testSetID string, afterTime time.Time, beforeTime time.Time) ([]*models.Mock, error) { var configMocks = make([]*models.Mock, 0) mockName := "mocks" if ys.MockName != "" { mockName = ys.MockName } path := filepath.Join(ys.MockPath, testSetID) mockPath, err := yaml.ValidatePath(path + "/" + mockName + ".yaml") if err != nil { return nil, err } if _, err := os.Stat(mockPath); err == nil { var mockYamls []*yaml.NetworkTrafficDoc data, err := yaml.ReadFile(ctx, ys.Logger, path, mockName) if err != nil { utils.LogError(ys.Logger, err, "failed to read the mocks from config yaml", zap.Any("session", filepath.Base(path))) return nil, err } dec := yamlLib.NewDecoder(bytes.NewReader(data)) for { var doc *yaml.NetworkTrafficDoc err := dec.Decode(&doc) if errors.Is(err, io.EOF) { break } if err !=
------------------

--- Chunk 11---
Function GetUnFilteredMocks (part 2): nil { return nil, fmt.Errorf("failed to decode the yaml file documents. error: %v", err.Error()) } mockYamls = append(mockYamls, doc) } mocks, err := decodeMocks(mockYamls, ys.Logger) if err != nil { utils.LogError(ys.Logger, err, "failed to decode the config mocks from yaml docs", zap.Any("session", filepath.Base(path))) return nil, err } for _, mock := range mocks { isUnFilteredMock := false switch mock.Kind { case "Generic": isUnFilteredMock = true case "Postgres": isUnFilteredMock = true case "Http": isUnFilteredMock = true case "Redis": isUnFilteredMock = true case "MySQL": isUnFilteredMock = true } if mock.Spec.Metadata["type"] == "config" || isUnFilteredMock { configMocks = append(configMocks, mock) } } } unfiltered := pkg.FilterConfigMocks(ctx, ys.Logger, configMocks, afterTime, beforeTime) return unfiltered,
------------------

--- Chunk 12---
Function GetUnFilteredMocks (end): nil }
------------------

--- Chunk 13---
func (ys *MockYaml) getNextID() int64 { return atomic.AddInt64(&ys.idCounter, 1) }
------------------

--- Chunk 14---
func (ys *MockYaml) GetHTTPMocks(ctx context.Context, testSetID string, mockPath string, mockFileName string) ([]*models.HTTPDoc, error) { if ys.MockName != "" { ys.MockName = mockFileName } ys.MockPath = mockPath tcsMocks, err := ys.GetUnFilteredMocks(ctx, testSetID, time.Time{}, time.Time{}) if err != nil { return nil, err } var httpMocks []*models.HTTPDoc for _, mock := range tcsMocks { if mock.Kind != "Http" { continue } var httpMock models.HTTPDoc httpMock.Kind = mock.GetKind() httpMock.Name = mock.Name httpMock.Spec.Request = *mock.Spec.HTTPReq httpMock.Spec.Response = *mock.Spec.HTTPResp httpMock.Spec.Metadata = mock.Spec.Metadata httpMock.Version = string(mock.Version) httpMocks = append(httpMocks, &httpMock) } return httpMocks, nil }
------------------

--- File: pkg/platform/yaml/mockdb/util.go---

--- Chunk 1---
Function EncodeMock (start): func EncodeMock(mock *models.Mock, logger *zap.Logger) (*yaml.NetworkTrafficDoc, error) { yamlDoc := yaml.NetworkTrafficDoc{ Version: mock.Version, Kind: mock.Kind, Name: mock.Name, ConnectionID: mock.ConnectionID, } switch mock.Kind { case models.Mongo: requests := []models.RequestYaml{} for _, v := range mock.Spec.MongoRequests { req := models.RequestYaml{ Header: v.Header, ReadDelay: v.ReadDelay, } err := req.Message.Encode(v.Message) if err != nil { utils.LogError(logger, err, "failed to encode mongo request wiremessage into yaml") return nil, err } requests = append(requests, req) } responses := []models.ResponseYaml{} for _, v := range mock.Spec.MongoResponses { resp := models.ResponseYaml{ Header: v.Header, ReadDelay: v.ReadDelay, } err := resp.Message.Encode(v.Message) if err != nil { utils.LogError(logger, err, "failed to encode mongo response wiremessage into yaml")
------------------

--- Chunk 2---
Function EncodeMock (part 2): return nil, err } responses = append(responses, resp) } mongoSpec := models.MongoSpec{ Metadata: mock.Spec.Metadata, Requests: requests, Response: responses, CreatedAt: mock.Spec.Created, ReqTimestampMock: mock.Spec.ReqTimestampMock, ResTimestampMock: mock.Spec.ResTimestampMock, } err := yamlDoc.Spec.Encode(mongoSpec) if err != nil { utils.LogError(logger, err, "failed to marshal the mongo input-output as yaml") return nil, err } case models.HTTP: httpSpec := models.HTTPSchema{ Metadata: mock.Spec.Metadata, Request: *mock.Spec.HTTPReq, Response: *mock.Spec.HTTPResp, Created: mock.Spec.Created, ReqTimestampMock: mock.Spec.ReqTimestampMock, ResTimestampMock: mock.Spec.ResTimestampMock, } err := yamlDoc.Spec.Encode(httpSpec) if err != nil { utils.LogError(logger, err, "failed to marshal the http input-output as yaml") return nil, err } case models.G
------------------

--- Chunk 3---
Function EncodeMock (part 3): ENERIC: genericSpec := models.GenericSchema{ Metadata: mock.Spec.Metadata, GenericRequests: mock.Spec.GenericRequests, GenericResponses: mock.Spec.GenericResponses, ReqTimestampMock: mock.Spec.ReqTimestampMock, ResTimestampMock: mock.Spec.ResTimestampMock, } err := yamlDoc.Spec.Encode(genericSpec) if err != nil { utils.LogError(logger, err, "failed to marshal the generic input-output as yaml") return nil, err } case models.REDIS: redisSpec := models.RedisSchema{ Metadata: mock.Spec.Metadata, RedisRequests: mock.Spec.RedisRequests, RedisResponses: mock.Spec.RedisResponses, ReqTimestampMock: mock.Spec.ReqTimestampMock, ResTimestampMock: mock.Spec.ResTimestampMock, } err := yamlDoc.Spec.Encode(redisSpec) if err != nil { utils.LogError(logger, err, "failed to marshal the redis input-output as yaml") return nil, err } case models.Postgres: // case models.PostgresV2: postgresSpec := models.PostgresSpec{
------------------

--- Chunk 4---
Function EncodeMock (part 4): Metadata: mock.Spec.Metadata, PostgresRequests: mock.Spec.PostgresRequests, PostgresResponses: mock.Spec.PostgresResponses, ReqTimestampMock: mock.Spec.ReqTimestampMock, ResTimestampMock: mock.Spec.ResTimestampMock, } err := yamlDoc.Spec.Encode(postgresSpec) if err != nil { utils.LogError(logger, err, "failed to marshal the postgres input-output as yaml") return nil, err } case models.GRPC_EXPORT: gRPCSpec := models.GrpcSpec{ Metadata: mock.Spec.Metadata, GrpcReq: *mock.Spec.GRPCReq, GrpcResp: *mock.Spec.GRPCResp, ReqTimestampMock: mock.Spec.ReqTimestampMock, ResTimestampMock: mock.Spec.ResTimestampMock, } err := yamlDoc.Spec.Encode(gRPCSpec) if err != nil { utils.LogError(logger, err, "failed to marshal gRPC of external call into yaml") return nil, err } case models.MySQL: requests := []mysql.RequestYaml{} for _, v := range mock.Spec
------------------

--- Chunk 5---
Function EncodeMock (part 5): .MySQLRequests { req := mysql.RequestYaml{ Header: v.Header, Meta: v.Meta, } err := req.Message.Encode(v.Message) if err != nil { utils.LogError(logger, err, "failed to encode mongo request wiremessage into yaml") return nil, err } requests = append(requests, req) } responses := []mysql.ResponseYaml{} for _, v := range mock.Spec.MySQLResponses { resp := mysql.ResponseYaml{ Header: v.Header, Meta: v.Meta, } err := resp.Message.Encode(v.Message) if err != nil { utils.LogError(logger, err, "failed to encode mongo response wiremessage into yaml") return nil, err } responses = append(responses, resp) } sqlSpec := mysql.Spec{ Metadata: mock.Spec.Metadata, Requests: requests, Response: responses, CreatedAt: mock.Spec.Created, ReqTimestampMock: mock.Spec.ReqTimestampMock, ResTimestampMock: mock.Spec.ResTimestampMock, } err
------------------

--- Chunk 6---
Function EncodeMock (end): := yamlDoc.Spec.Encode(sqlSpec) if err != nil { utils.LogError(logger, err, "failed to marshal the MySQL input-output as yaml") return nil, err } default: utils.LogError(logger, nil, "failed to marshal the recorded mock into yaml due to invalid kind of mock") return nil, errors.New("type of mock is invalid") } return &yamlDoc, nil }
------------------

--- Chunk 7---
Function decodeMocks (start): func decodeMocks(yamlMocks []*yaml.NetworkTrafficDoc, logger *zap.Logger) ([]*models.Mock, error) { mocks := []*models.Mock{} for _, m := range yamlMocks { mock := models.Mock{ Version: m.Version, Name: m.Name, Kind: m.Kind, ConnectionID: m.ConnectionID, } mockCheck := strings.Split(string(m.Kind), "-") if len(mockCheck) > 1 { logger.Debug("This dependency does not belong to open source version, will be skipped", zap.String("mock kind:", string(m.Kind))) continue } switch m.Kind { case models.HTTP: httpSpec := models.HTTPSchema{} err := m.Spec.Decode(&httpSpec) if err != nil { utils.LogError(logger, err, "failed to unmarshal a yaml doc into http mock", zap.Any("mock name", m.Name)) return nil, err } mock.Spec = models.MockSpec{ Metadata: httpSpec.Metadata, HTTPReq: &httpSpec.Request, HTTPResp: &httpSpec.Response, Created: httpSpec.Created, Req
------------------

--- Chunk 8---
Function decodeMocks (part 2): TimestampMock: httpSpec.ReqTimestampMock, ResTimestampMock: httpSpec.ResTimestampMock, } case models.Mongo: mongoSpec := models.MongoSpec{} err := m.Spec.Decode(&mongoSpec) if err != nil { utils.LogError(logger, err, "failed to unmarshal a yaml doc into mongo mock", zap.Any("mock name", m.Name)) return nil, err } mockSpec, err := decodeMongoMessage(&mongoSpec, logger) if err != nil { return nil, err } mock.Spec = *mockSpec case models.GRPC_EXPORT: grpcSpec := models.GrpcSpec{} err := m.Spec.Decode(&grpcSpec) if err != nil { utils.LogError(logger, err, "failed to unmarshal a yaml doc into http mock", zap.Any("mock name", m.Name)) return nil, err } mock.Spec = models.MockSpec{ Metadata: grpcSpec.Metadata, GRPCResp: &grpcSpec.GrpcResp, GRPCReq: &grpcSpec.GrpcReq, ReqTimestampMock: grpcSpec.ReqTimestamp
------------------

--- Chunk 9---
Function decodeMocks (part 3): Mock, ResTimestampMock: grpcSpec.ResTimestampMock, } case models.GENERIC: genericSpec := models.GenericSchema{} err := m.Spec.Decode(&genericSpec) if err != nil { utils.LogError(logger, err, "failed to unmarshal a yaml doc into generic mock", zap.Any("mock name", m.Name)) return nil, err } mock.Spec = models.MockSpec{ Metadata: genericSpec.Metadata, GenericRequests: genericSpec.GenericRequests, GenericResponses: genericSpec.GenericResponses, ReqTimestampMock: genericSpec.ReqTimestampMock, ResTimestampMock: genericSpec.ResTimestampMock, } case models.REDIS: redisSpec := models.RedisSchema{} err := m.Spec.Decode(&redisSpec) if err != nil { utils.LogError(logger, err, "failed to unmarshal a yaml doc into redis mock", zap.Any("mock name", m.Name)) return nil, err } mock.Spec = models.MockSpec{ Metadata: redisSpec.Metadata, RedisRequests: redisSpec.RedisRequests, RedisResponses: redisSpec
------------------

--- Chunk 10---
Function decodeMocks (part 4): .RedisResponses, ReqTimestampMock: redisSpec.ReqTimestampMock, ResTimestampMock: redisSpec.ResTimestampMock, } case models.Postgres: // case models.PostgresV2: PostSpec := models.PostgresSpec{} err := m.Spec.Decode(&PostSpec) if err != nil { utils.LogError(logger, err, "failed to unmarshal a yaml doc into generic mock", zap.Any("mock name", m.Name)) return nil, err } mock.Spec = models.MockSpec{ Metadata: PostSpec.Metadata, // OutputBinary: genericSpec.Objects, PostgresRequests: PostSpec.PostgresRequests, PostgresResponses: PostSpec.PostgresResponses, ReqTimestampMock: PostSpec.ReqTimestampMock, ResTimestampMock: PostSpec.ResTimestampMock, } case models.MySQL: mySQLSpec := mysql.Spec{} err := m.Spec.Decode(&mySQLSpec) if err != nil { utils.LogError(logger, err, "failed to unmarshal a yaml doc into mysql mock", zap.Any("mock name", m.Name)) return nil, err
------------------

--- Chunk 11---
Function decodeMocks (end): } mockSpec, err := decodeMySQLMessage(context.Background(), logger, &mySQLSpec) if err != nil { return nil, err } mock.Spec = *mockSpec default: utils.LogError(logger, nil, "failed to unmarshal a mock yaml doc of unknown type", zap.Any("type", m.Kind)) continue } mocks = append(mocks, &mock) } return mocks, nil }
------------------

--- Chunk 12---
Function decodeMySQLMessage (start): func decodeMySQLMessage(_ context.Context, logger *zap.Logger, yamlSpec *mysql.Spec) (*models.MockSpec, error) { mockSpec := models.MockSpec{ Metadata: yamlSpec.Metadata, Created: yamlSpec.CreatedAt, ReqTimestampMock: yamlSpec.ReqTimestampMock, ResTimestampMock: yamlSpec.ResTimestampMock, } // Decode the requests requests := []mysql.Request{} for _, v := range yamlSpec.Requests { req := mysql.Request{ PacketBundle: mysql.PacketBundle{ Header: v.Header, Meta: v.Meta, }, } switch v.Header.Type { // connection phase case mysql.SSLRequest: msg := &mysql.SSLRequestPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql SSLRequestPacket") return nil, err } req.Message = msg case mysql.HandshakeResponse41: msg := &mysql.HandshakeResponse41Packet{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err,
------------------

--- Chunk 13---
Function decodeMySQLMessage (part 2): "failed to unmarshal yaml document into mysql HandshakeResponse41Packet") return nil, err } req.Message = msg case mysql.CachingSha2PasswordToString(mysql.RequestPublicKey): var msg string err := v.Message.Decode(&msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql (string) RequestPublicKey") return nil, err } req.Message = msg case mysql.EncryptedPassword: var msg string err := v.Message.Decode(&msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql (string) encrypted_password") return nil, err } req.Message = msg case mysql.PlainPassword: var msg string err := v.Message.Decode(&msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql (string) plain_password") return nil, err } req.Message = msg // command phase // utility packets case mysql.CommandStatusToString(mysql.COM_QUIT): msg := &mysql
------------------

--- Chunk 14---
Function decodeMySQLMessage (part 3): .QuitPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql QuitPacket") return nil, err } req.Message = msg case mysql.CommandStatusToString(mysql.COM_INIT_DB): msg := &mysql.InitDBPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql InitDBPacket") return nil, err } req.Message = msg case mysql.CommandStatusToString(mysql.COM_STATISTICS): msg := &mysql.StatisticsPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql StatisticsPacket") return nil, err } req.Message = msg case mysql.CommandStatusToString(mysql.COM_DEBUG): msg := &mysql.DebugPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql DebugPacket") return nil, err } req.Message = msg case
------------------

--- Chunk 15---
Function decodeMySQLMessage (part 4): mysql.CommandStatusToString(mysql.COM_PING): msg := &mysql.PingPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql PingPacket") return nil, err } req.Message = msg case mysql.CommandStatusToString(mysql.COM_CHANGE_USER): msg := &mysql.ChangeUserPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql ChangeUserPacket") return nil, err } req.Message = msg case mysql.CommandStatusToString(mysql.COM_RESET_CONNECTION): msg := &mysql.ResetConnectionPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql ResetConnectionPacket") return nil, err } req.Message = msg // case mysql.CommandStatusToString(mysql.COM_SET_OPTION): // not supported yet // query packets case mysql.CommandStatusToString(mysql.COM_QUERY): msg := &mysql.QueryPacket{} err := v.Message.Decode(msg)
------------------

--- Chunk 16---
Function decodeMySQLMessage (part 5): if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql QueryPacket") return nil, err } req.Message = msg case mysql.CommandStatusToString(mysql.COM_STMT_PREPARE): msg := &mysql.StmtPreparePacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql StmtPreparePacket") return nil, err } req.Message = msg case mysql.CommandStatusToString(mysql.COM_STMT_EXECUTE): msg := &mysql.StmtExecutePacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql StmtExecutePacket") return nil, err } req.Message = msg // case mysql.CommandStatusToString(mysql.COM_FETCH): // not supported yet case mysql.CommandStatusToString(mysql.COM_STMT_CLOSE): msg := &mysql.StmtClosePacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql StmtClosePacket") return nil
------------------

--- Chunk 17---
Function decodeMySQLMessage (part 6): , err } req.Message = msg case mysql.CommandStatusToString(mysql.COM_STMT_RESET): msg := &mysql.StmtResetPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql StmtResetPacket") return nil, err } req.Message = msg case mysql.CommandStatusToString(mysql.COM_STMT_SEND_LONG_DATA): msg := &mysql.StmtSendLongDataPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yaml document into mysql StmtSendLongDataPacket") return nil, err } req.Message = msg } requests = append(requests, req) } mockSpec.MySQLRequests = requests // Decode the responses responses := []mysql.Response{} for _, v := range yamlSpec.Response { resp := mysql.Response{ PacketBundle: mysql.PacketBundle{ Header: v.Header, Meta: v.Meta, }, } switch v.Header.Type { // generic response case mysql.StatusToString
------------------

--- Chunk 18---
Function decodeMySQLMessage (part 7): (mysql.EOF): msg := &mysql.EOFPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mysql EOFPacket") return nil, err } resp.Message = msg case mysql.StatusToString(mysql.ERR): msg := &mysql.ERRPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mysql ERRPacket") return nil, err } resp.Message = msg case mysql.StatusToString(mysql.OK): msg := &mysql.OKPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mysql OKPacket") return nil, err } resp.Message = msg // connection phase case mysql.AuthStatusToString(mysql.HandshakeV10): msg := &mysql.HandshakeV10Packet{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mysql HandshakeV
------------------

--- Chunk 19---
Function decodeMySQLMessage (part 8): 10Packet") return nil, err } resp.Message = msg case mysql.AuthStatusToString(mysql.AuthSwitchRequest): msg := &mysql.AuthSwitchRequestPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mysql AuthSwitchRequestPacket") return nil, err } resp.Message = msg case mysql.AuthStatusToString(mysql.AuthMoreData): msg := &mysql.AuthMoreDataPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mysql AuthMoreDataPacket") return nil, err } resp.Message = msg case mysql.AuthStatusToString(mysql.AuthNextFactor): // not supported yet msg := &mysql.AuthNextFactorPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mysql AuthNextFactorPacket") return nil, err } resp.Message = msg // command phase case mysql.COM_STMT_PREPARE_OK:
------------------

--- Chunk 20---
Function decodeMySQLMessage (end): msg := &mysql.StmtPrepareOkPacket{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mysql StmtPrepareOkPacket") return nil, err } resp.Message = msg case string(mysql.Text): msg := &mysql.TextResultSet{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mysql TextResultSet") return nil, err } resp.Message = msg case string(mysql.Binary): msg := &mysql.BinaryProtocolResultSet{} err := v.Message.Decode(msg) if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mysql BinaryProtocolResultSet") return nil, err } resp.Message = msg } responses = append(responses, resp) } mockSpec.MySQLResponses = responses return &mockSpec, nil }
------------------

--- Chunk 21---
Function decodeMongoMessage (start): func decodeMongoMessage(yamlSpec *models.MongoSpec, logger *zap.Logger) (*models.MockSpec, error) { mockSpec := models.MockSpec{ Metadata: yamlSpec.Metadata, Created: yamlSpec.CreatedAt, ReqTimestampMock: yamlSpec.ReqTimestampMock, ResTimestampMock: yamlSpec.ResTimestampMock, } // mongo request requests := []models.MongoRequest{} for _, v := range yamlSpec.Requests { req := models.MongoRequest{ Header: v.Header, ReadDelay: v.ReadDelay, } // decode the yaml document to mongo request wiremessage switch v.Header.Opcode { case wiremessage.OpMsg: requestMessage := &models.MongoOpMessage{} err := v.Message.Decode(requestMessage) if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mongo OpMsg request wiremessage") return nil, err } req.Message = requestMessage case wiremessage.OpReply: requestMessage := &models.MongoOpReply{} err := v.Message.Decode(requestMessage) if err != nil { utils.LogError(logger, err,
------------------

--- Chunk 22---
Function decodeMongoMessage (part 2): "failed to unmarshal yml document into mongo OpReply request wiremessage") return nil, err } req.Message = requestMessage case wiremessage.OpQuery: requestMessage := &models.MongoOpQuery{} err := v.Message.Decode(requestMessage) if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mongo OpQuery request wiremessage") // return fmt.Errorf("failed to decode the mongo OpReply of mock with name: %s. error: %s", doc.Name, err.Error()) return nil, err } req.Message = requestMessage default: } requests = append(requests, req) } mockSpec.MongoRequests = requests // mongo response responses := []models.MongoResponse{} for _, v := range yamlSpec.Response { resp := models.MongoResponse{ Header: v.Header, ReadDelay: v.ReadDelay, } // decode the yaml document to mongo response wiremessage switch v.Header.Opcode { case wiremessage.OpMsg: responseMessage := &models.MongoOpMessage{} err := v.Message.Decode(responseMessage)
------------------

--- Chunk 23---
Function decodeMongoMessage (part 3): if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mongo OpMsg response wiremessage") // return fmt.Errorf("failed to decode the mongo OpMsg of mock with name: %s. error: %s", doc.Name, err.Error()) return nil, err } resp.Message = responseMessage case wiremessage.OpReply: responseMessage := &models.MongoOpReply{} err := v.Message.Decode(responseMessage) if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mongo OpMsg response wiremessage") return nil, err } resp.Message = responseMessage case wiremessage.OpQuery: responseMessage := &models.MongoOpQuery{} err := v.Message.Decode(responseMessage) if err != nil { utils.LogError(logger, err, "failed to unmarshal yml document into mongo OpMsg response wiremessage") // return fmt.Errorf("failed to decode the mongo OpMsg of mock with name: %s. error: %s", doc.Name, err.Error()) return nil, err } resp.Message = responseMessage
------------------

--- Chunk 24---
Function decodeMongoMessage (end): default: } responses = append(responses, resp) } mockSpec.MongoResponses = responses return &mockSpec, nil }
------------------

--- File: pkg/platform/yaml/openapidb/db.go---

--- Chunk 1---
func New(logger *zap.Logger, openAPIPath string) *OpenAPIYaml { return &OpenAPIYaml{ OpenAPIPath: openAPIPath, logger: logger, } }
------------------

--- Chunk 2---
Function GetTestCasesSchema (start): func (ts *OpenAPIYaml) GetTestCasesSchema(ctx context.Context, testSetID string, testPath string) ([]*models.OpenAPI, error) { var path string if testPath == "" { path = filepath.Join(ts.OpenAPIPath, testSetID) } else { path = filepath.Join(testPath, testSetID) } tcs := []*models.OpenAPI{} TestPath, err := yaml.ValidatePath(path) if err != nil { return nil, err } _, err = os.Stat(TestPath) if err != nil { ts.logger.Debug("no tests are recorded for the session", zap.String("index", testSetID)) return nil, nil } dir, err := yaml.ReadDir(TestPath, fs.ModePerm) if err != nil { utils.LogError(ts.logger, err, "failed to open the directory containing yaml testcases", zap.Any("path", TestPath)) return nil, err } files, err := dir.ReadDir(0) if err != nil { utils.LogError(ts.logger, err, "failed to read the file names of yaml testcases", zap.Any("path", TestPath)) return nil, err
------------------

--- Chunk 3---
Function GetTestCasesSchema (end): } for _, j := range files { name := strings.TrimSuffix(j.Name(), filepath.Ext(j.Name())) data, err := yaml.ReadFile(ctx, ts.logger, TestPath, name) if err != nil { utils.LogError(ts.logger, err, "failed to read the testcase from yaml") return nil, err } var testCase *models.OpenAPI err = yamlLib.Unmarshal(data, &testCase) if err != nil { utils.LogError(ts.logger, err, "failed to unmarshall YAML data") return nil, err } tcs = append(tcs, testCase) } return tcs, nil }
------------------

--- Chunk 4---
Function GetMocksSchemas (start): func (ts *OpenAPIYaml) GetMocksSchemas(ctx context.Context, testSetID string, mockPath string, mockFileName string) ([]*models.OpenAPI, error) { var tcsMocks = make([]*models.OpenAPI, 0) path := filepath.Join(mockPath, testSetID) mockPath, err := yaml.ValidatePath(path + "/" + mockFileName + ".yaml") if err != nil { return nil, err } if _, err := os.Stat(mockPath); err == nil { var mockYamls []*models.OpenAPI data, err := yaml.ReadFile(ctx, ts.logger, path, mockFileName) if err != nil { utils.LogError(ts.logger, err, "failed to read the mocks from config yaml", zap.Any("session", filepath.Base(path))) return nil, err } dec := yamlLib.NewDecoder(bytes.NewReader(data)) for { var doc *models.OpenAPI err := dec.Decode(&doc) if errors.Is(err, io.EOF) { break } if err != nil { return nil, fmt.Errorf("failed to decode the yaml file documents. error: %v", err.Error())
------------------

--- Chunk 5---
Function GetMocksSchemas (end): } mockYamls = append(mockYamls, doc) } if err != nil { utils.LogError(ts.logger, err, "failed to decode the config mocks from yaml docs", zap.Any("session", filepath.Base(path))) return nil, err } tcsMocks = mockYamls } return tcsMocks, nil }
------------------

--- Chunk 6---
func (ts *OpenAPIYaml) ChangePath(path string) { // ts.OpenAPIPath = "./keploy/" ts.OpenAPIPath = path }
------------------

--- Chunk 7---
func (ts *OpenAPIYaml) WriteSchema(ctx context.Context, logger *zap.Logger, outputPath, name string, openapi models.OpenAPI, isAppend bool) error { openapiYAML, err := yamlLib.Marshal(openapi) if err != nil { return err } _, err = os.Stat(outputPath) if os.IsNotExist(err) { err = os.MkdirAll(outputPath, os.ModePerm) if err != nil { utils.LogError(logger, err, "failed to create directory", zap.String("directory", outputPath)) return err } logger.Info("Directory created", zap.String("directory", outputPath)) } err = yaml.WriteFile(ctx, logger, outputPath, name, openapiYAML, isAppend) if err != nil { utils.LogError(logger, err, "failed to write OpenAPI YAML to a file", zap.String("outputPath", outputPath), zap.String("name", name)) return err } outputFilePath := outputPath + "/" + name + ".yaml" logger.Info("OpenAPI YAML has been saved to ", zap.String("path", outputFilePath)) return nil }
------------------

--- File: pkg/platform/yaml/reportdb/db.go---

--- Chunk 1---
func New(logger *zap.Logger, reportPath string) *TestReport { return &TestReport{ tests: make(map[string]map[string][]models.TestResult), m: sync.Mutex{}, Logger: logger, Path: reportPath, } }
------------------

--- Chunk 2---
func (fe *TestReport) ClearTestCaseResults(_ context.Context, testRunID string, testSetID string) { fe.m.Lock() defer fe.m.Unlock() fe.tests[testRunID] = make(map[string][]models.TestResult) }
------------------

--- Chunk 3---
func (fe *TestReport) GetAllTestRunIDs(ctx context.Context) ([]string, error) { return yaml.ReadSessionIndices(ctx, fe.Path, fe.Logger) }
------------------

--- Chunk 4---
func (fe *TestReport) InsertTestCaseResult(_ context.Context, testRunID string, testSetID string, result *models.TestResult) error { fe.m.Lock() defer fe.m.Unlock() testSet := fe.tests[testRunID] if testSet == nil { testSet = make(map[string][]models.TestResult) testSet[testSetID] = []models.TestResult{*result} } else { testSet[testSetID] = append(testSet[testSetID], *result) } fe.tests[testRunID] = testSet return nil }
------------------

--- Chunk 5---
func (fe *TestReport) GetTestCaseResults(_ context.Context, testRunID string, testSetID string) ([]models.TestResult, error) { testRun, ok := fe.tests[testRunID] if !ok { return []models.TestResult{}, fmt.Errorf("%s found no test results for test report with id: %s", utils.Emoji, testRunID) } testSetResults, ok := testRun[testSetID] if !ok { return []models.TestResult{}, fmt.Errorf("%s found no test results for test set with id: %s", utils.Emoji, testSetID) } return testSetResults, nil }
------------------

--- Chunk 6---
func (fe *TestReport) GetReport(ctx context.Context, testRunID string, testSetID string) (*models.TestReport, error) { path := filepath.Join(fe.Path, testRunID) reportName := testSetID + "-report" _, err := yaml.ValidatePath(filepath.Join(path, reportName+".yaml")) if err != nil { return nil, err } data, err := yaml.ReadFile(ctx, fe.Logger, path, reportName) if err != nil { utils.LogError(fe.Logger, err, "failed to read the test-set report", zap.Any("reportName", reportName), zap.Any("session", filepath.Base(path))) return nil, err } decoder := yamlLib.NewDecoder(bytes.NewReader(data)) var doc models.TestReport err = decoder.Decode(&doc) if err != nil { return &models.TestReport{}, fmt.Errorf("%s failed to decode the yaml file documents. error: %v", utils.Emoji, err.Error()) } return &doc, nil }
------------------

--- Chunk 7---
func (fe *TestReport) InsertReport(ctx context.Context, testRunID string, testSetID string, testReport *models.TestReport) error { reportPath := filepath.Join(fe.Path, testRunID) if testReport.Name == "" { testReport.Name = testSetID + "-report" } testReport.CreatedAt = time.Now().Unix() data := []byte{} d, err := yamlLib.Marshal(&testReport) if err != nil { return fmt.Errorf("%s failed to marshal document to yaml. error: %s", utils.Emoji, err.Error()) } data = append(data, d...) data = append([]byte(utils.GetVersionAsComment()), data...) err = yaml.WriteFile(ctx, fe.Logger, reportPath, testReport.Name, data, false) if err != nil { utils.LogError(fe.Logger, err, "failed to write the report to yaml", zap.Any("session", filepath.Base(reportPath))) return err } return nil }
------------------

--- Chunk 8---
func (fe *TestReport) UpdateReport(ctx context.Context, testRunID string, coverageReport any) error { reportPath := filepath.Join(fe.Path, testRunID) data := []byte{} d, err := yamlLib.Marshal(&coverageReport) if err != nil { return fmt.Errorf("%s failed to marshal document to yaml. error: %s", utils.Emoji, err.Error()) } data = append(data, d...) err = yaml.WriteFile(ctx, fe.Logger, reportPath, "coverage", data, false) if err != nil { utils.LogError(fe.Logger, err, "failed to write the coverage report to yaml", zap.Any("session", filepath.Base(reportPath))) return err } return nil }
------------------

--- File: pkg/platform/yaml/testdb/db.go---

--- Chunk 1---
func New(logger *zap.Logger, tcsPath string) *TestYaml { return &TestYaml{ TcsPath: tcsPath, logger: logger, } }
------------------

--- Chunk 2---
func (ts *TestYaml) InsertTestCase(ctx context.Context, tc *models.TestCase, testSetID string, enableLog bool) error { tcsInfo, err := ts.upsert(ctx, testSetID, tc) if err != nil { return err } if enableLog { ts.logger.Info("ðŸŸ  Keploy has captured test cases for the user's application.", zap.String("path", tcsInfo.path), zap.String("testcase name", tcsInfo.name)) } return nil }
------------------

--- Chunk 3---
func (ts *TestYaml) GetAllTestSetIDs(ctx context.Context) ([]string, error) { return yaml.ReadSessionIndices(ctx, ts.TcsPath, ts.logger) }
------------------

--- Chunk 4---
Function GetTestCases (start): func (ts *TestYaml) GetTestCases(ctx context.Context, testSetID string) ([]*models.TestCase, error) { path := filepath.Join(ts.TcsPath, testSetID, "tests") tcs := []*models.TestCase{} TestPath, err := yaml.ValidatePath(path) if err != nil { return nil, err } _, err = os.Stat(TestPath) if err != nil { ts.logger.Debug("no tests are recorded for the session", zap.String("index", testSetID)) return nil, nil } dir, err := yaml.ReadDir(TestPath, fs.ModePerm) if err != nil { utils.LogError(ts.logger, err, "failed to open the directory containing yaml testcases", zap.Any("path", TestPath)) return nil, err } files, err := dir.ReadDir(0) if err != nil { utils.LogError(ts.logger, err, "failed to read the file names of yaml testcases", zap.Any("path", TestPath)) return nil, err } for _, j := range files { if filepath.Ext(j.Name()) != ".yaml" || strings.Contains(j.Name(), "mocks") { continue
------------------

--- Chunk 5---
Function GetTestCases (part 2): } name := strings.TrimSuffix(j.Name(), filepath.Ext(j.Name())) data, err := yaml.ReadFile(ctx, ts.logger, TestPath, name) if err != nil { utils.LogError(ts.logger, err, "failed to read the testcase from yaml") return nil, err } if len(data) == 0 { ts.logger.Warn("skipping empty testcase", zap.String("testcase name", name)) continue } var testCase *yaml.NetworkTrafficDoc err = yamlLib.Unmarshal(data, &testCase) if err != nil { utils.LogError(ts.logger, err, "failed to unmarshall YAML data") return nil, err } if testCase == nil { ts.logger.Warn("skipping invalid testCase yaml", zap.String("testcase name", name)) continue } tc, err := Decode(testCase, ts.logger) if err != nil { utils.LogError(ts.logger, err, "failed to decode the testcase") return nil, err } tcs = append(tcs, tc) } sort.SliceStable(tcs, func(i, j int) bool { return tcs[i
------------------

--- Chunk 6---
Function GetTestCases (end): ].HTTPReq.Timestamp.Before(tcs[j].HTTPReq.Timestamp) }) return tcs, nil }
------------------

--- Chunk 7---
func (ts *TestYaml) UpdateTestCase(ctx context.Context, tc *models.TestCase, testSetID string, enableLog bool) error { tcsInfo, err := ts.upsert(ctx, testSetID, tc) if err != nil { return err } if enableLog { ts.logger.Info("ðŸ”„ Keploy has updated the test cases for the user's application.", zap.String("path", tcsInfo.path), zap.String("testcase name", tcsInfo.name)) } return nil }
------------------

--- Chunk 8---
Function upsert (start): func (ts *TestYaml) upsert(ctx context.Context, testSetID string, tc *models.TestCase) (tcsInfo, error) { tcsPath := filepath.Join(ts.TcsPath, testSetID, "tests") var tcsName string if tc.Name == "" { lastIndx, err := yaml.FindLastIndex(tcsPath, ts.logger) if err != nil { return tcsInfo{name: "", path: tcsPath}, err } tcsName = fmt.Sprintf("test-%v", lastIndx) } else { tcsName = tc.Name } yamlTc, err := EncodeTestcase(*tc, ts.logger) if err != nil { return tcsInfo{name: tcsName, path: tcsPath}, err } yamlTc.Name = tcsName data, err := yamlLib.Marshal(&yamlTc) if err != nil { return tcsInfo{name: tcsName, path: tcsPath}, err } exists, err := yaml.FileExists(ctx, ts.logger, tcsPath, tcsName) if err != nil { utils.LogError(ts.logger
------------------

--- Chunk 9---
Function upsert (end): , err, "failed to find yaml file", zap.String("path directory", tcsPath), zap.String("yaml", tcsName)) return tcsInfo{name: tcsName, path: tcsPath}, err } if !exists { data = append([]byte(utils.GetVersionAsComment()), data...) } err = yaml.WriteFile(ctx, ts.logger, tcsPath, tcsName, data, false) if err != nil { utils.LogError(ts.logger, err, "failed to write testcase yaml file") return tcsInfo{name: tcsName, path: tcsPath}, err } return tcsInfo{name: tcsName, path: tcsPath}, nil }
------------------

--- Chunk 10---
func (ts *TestYaml) DeleteTests(ctx context.Context, testSetID string, testCaseIDs []string) error { path := filepath.Join(ts.TcsPath, testSetID, "tests") for _, testCaseID := range testCaseIDs { err := yaml.DeleteFile(ctx, ts.logger, path, testCaseID) if err != nil { ts.logger.Error("failed to delete the testcase", zap.String("testcase id", testCaseID), zap.String("testset id", testSetID)) return err } } return nil }
------------------

--- Chunk 11---
func (ts *TestYaml) DeleteTestSet(ctx context.Context, testSetID string) error { path := filepath.Join(ts.TcsPath, testSetID) err := yaml.DeleteDir(ctx, ts.logger, path) if err != nil { ts.logger.Error("failed to delete the testset", zap.String("testset id", testSetID)) return err } return nil }
------------------

--- Chunk 12---
func (ts *TestYaml) ChangePath(path string) { ts.TcsPath = path }
------------------

--- Chunk 13---
Function UpdateAssertions (start): func (ts *TestYaml) UpdateAssertions(ctx context.Context, testCaseID string, testSetID string, assertions map[models.AssertionType]interface{}) error { // get the test case and fill the assertion and update the test case tcsPath := filepath.Join(ts.TcsPath, testSetID, "tests") data, err := yaml.ReadFile(ctx, ts.logger, tcsPath, testCaseID) if err != nil { utils.LogError(ts.logger, err, "failed to read the testcase from yaml") return err } if len(data) == 0 { ts.logger.Warn("skipping empty testcase", zap.String("testcase name", testCaseID)) return nil } var testCase *yaml.NetworkTrafficDoc err = yamlLib.Unmarshal(data, &testCase) if err != nil { utils.LogError(ts.logger, err, "failed to unmarshall YAML data") return err } if testCase == nil { ts.logger.Warn("skipping invalid testCase yaml", zap.String("testcase name", testCaseID)) return nil } tc, err := Decode(testCase, ts.logger) if err != nil { utils.LogError(ts.logger, err, "failed to decode the testcase")
------------------

--- Chunk 14---
Function UpdateAssertions (end): return err } tc.Assertions = assertions yamlTc, err := EncodeTestcase(*tc, ts.logger) if err != nil { utils.LogError(ts.logger, err, "failed to encode the testcase") return err } yamlTc.Name = testCaseID data, err = yamlLib.Marshal(&yamlTc) if err != nil { utils.LogError(ts.logger, err, "failed to marshall the testcase") return err } err = yaml.WriteFile(ctx, ts.logger, tcsPath, testCaseID, data, false) if err != nil { utils.LogError(ts.logger, err, "failed to write testcase yaml file") return err } return nil }
------------------

--- File: pkg/platform/yaml/testdb/util.go---

--- Chunk 1---
Function EncodeTestcase (start): func EncodeTestcase(tc models.TestCase, logger *zap.Logger) (*yaml.NetworkTrafficDoc, error) { logger.Debug("Starting test case encoding", zap.String("kind", string(tc.Kind)), zap.String("name", tc.Name)) doc := &yaml.NetworkTrafficDoc{ Version: tc.Version, Kind: tc.Kind, Name: tc.Name, } var noise map[string][]string switch tc.Kind { case models.HTTP: logger.Debug("Encoding HTTP test case") doc.Curl = pkg.MakeCurlCommand(tc.HTTPReq) // find noisy fields only for HTTP responses m, err := FlattenHTTPResponse(pkg.ToHTTPHeader(tc.HTTPResp.Header), tc.HTTPResp.Body) if err != nil { msg := "error in flattening http response" utils.LogError(logger, err, msg) } noise = tc.Noise if tc.Name == "" { noiseFieldsFound := FindNoisyFields(m, func(_ string, vals []string) bool { // check if k is date for _, v := range vals { if pkg.IsTime(v) { return true } } //
------------------

--- Chunk 2---
Function EncodeTestcase (part 2): maybe we need to concatenate the values return pkg.IsTime(strings.Join(vals, ", ")) }) for _, v := range noiseFieldsFound { noise[v] = []string{} } } httpSchema := models.HTTPSchema{ Request: tc.HTTPReq, Response: tc.HTTPResp, Created: tc.Created, // need to check here for type here as well as push in other custom assertions Assertions: func() map[models.AssertionType]interface{} { a := map[models.AssertionType]interface{}{} if len(noise) > 0 { a[models.NoiseAssertion] = noise } for k, v := range tc.Assertions { a[k] = v } // Optionally add other custom assertions if needed here // Example: // a[models.StatusCode] = tc.HTTPResp.StatusCode return a }(), } if tc.Description != "" { httpSchema.Metadata = map[string]string{ "description": tc.Description, } } err = doc.Spec.Encode(httpSchema) if err != nil { utils.LogError
------------------

--- Chunk 3---
Function EncodeTestcase (part 3): (logger, err, "failed to encode testcase into a yaml doc") return nil, err } case models.GRPC_EXPORT: logger.Debug("Encoding gRPC test case") // For gRPC, use the noise directly from the test case noise = tc.Noise // Create a YAML node for the gRPC schema grpcSpec := models.GrpcSpec{ GrpcReq: tc.GrpcReq, GrpcResp: tc.GrpcResp, Created: tc.Created, // need to check here for type here as well as push in other custom assertions Assertions: func() map[models.AssertionType]interface{} { a := map[models.AssertionType]interface{}{} if len(noise) > 0 { a[models.NoiseAssertion] = noise } // Optionally add other custom assertions if needed here // Example: // a[models.StatusCode] = tc.HTTPResp.StatusCode return a }(), } logger.Debug("gRPC schema created", zap.Any("request_headers", grpcSpec.GrpcReq.Headers), zap.Any
------------------

--- Chunk 4---
Function EncodeTestcase (end): ("response_headers", grpcSpec.GrpcResp.Headers), zap.Int("request_body_length", len(grpcSpec.GrpcReq.Body.DecodedData)), zap.Int("response_body_length", len(grpcSpec.GrpcResp.Body.DecodedData))) // Create a new YAML node and encode the gRPC schema var node yamlLib.Node err := node.Encode(grpcSpec) if err != nil { utils.LogError(logger, err, "failed to encode gRPC schema to YAML node") return nil, err } // Set the node as the spec doc.Spec = node logger.Debug("Successfully encoded gRPC test case") default: utils.LogError(logger, nil, "failed to marshal the testcase into yaml due to invalid kind of testcase") return nil, errors.New("type of testcases is invalid") } return doc, nil }
------------------

--- Chunk 5---
func FindNoisyFields(m map[string][]string, comparator func(string, []string) bool) []string { var noise []string for k, v := range m { if comparator(k, v) { noise = append(noise, k) } } return noise }
------------------

--- Chunk 6---
func FlattenHTTPResponse(h http.Header, body string) (map[string][]string, error) { m := map[string][]string{} for k, v := range h { m["header."+k] = []string{strings.Join(v, "")} } err := AddHTTPBodyToMap(body, m) if err != nil { return m, err } return m, nil }
------------------

--- Chunk 7---
func AddHTTPBodyToMap(body string, m map[string][]string) error { // add body if json.Valid([]byte(body)) { var result interface{} err := json.Unmarshal([]byte(body), &result) if err != nil { return err } j := Flatten(result) for k, v := range j { nk := "body" if k != "" { nk = nk + "." + k } m[nk] = v } } else { // add it as raw text m["body"] = []string{body} } return nil }
------------------

--- Chunk 8---
Function Flatten (start): func Flatten(j interface{}) map[string][]string { if j == nil { return map[string][]string{"": {""}} } o := make(map[string][]string) x := reflect.ValueOf(j) switch x.Kind() { case reflect.Map: m, ok := j.(map[string]interface{}) if !ok { return map[string][]string{} } for k, v := range m { nm := Flatten(v) for nk, nv := range nm { fk := k if nk != "" { fk = fk + "." + nk } o[fk] = nv } } case reflect.Bool: o[""] = []string{strconv.FormatBool(x.Bool())} case reflect.Float64: o[""] = []string{strconv.FormatFloat(x.Float(), 'E', -1, 64)} case reflect.String: o[""] = []string{x.String()} case reflect.Slice: child, ok := j.([]interface{}) if !ok { return map[string][]string{} } for _, av := range child { nm := Flatten(av) for nk, nv := range nm {
------------------

--- Chunk 9---
Function Flatten (end): if ov, exists := o[nk]; exists { o[nk] = append(ov, nv...) } else { o[nk] = nv } } } default: fmt.Println(utils.Emoji, "found invalid value in json", j, x.Kind()) } return o }
------------------

--- Chunk 10---
func ContainsMatchingURL(urlMethods []string, urlStr string, requestURL string, requestMethod models.Method) (bool, error) { urlMatched := false parsedURL, err := url.Parse(requestURL) if err != nil { return false, err } // Check for URL path and method regex, err := regexp.Compile(urlStr) if err != nil { return false, err } urlMatch := regex.MatchString(parsedURL.Path) if urlMatch && len(urlStr) != 0 { urlMatched = true } if len(urlMethods) != 0 && urlMatched { urlMatched = false for _, method := range urlMethods { if string(method) == string(requestMethod) { urlMatched = true } } } return urlMatched, nil }
------------------

--- Chunk 11---
func HasBannedHeaders(object map[string]string, bannedHeaders map[string]string) (bool, error) { for headerName, headerNameValue := range object { for bannedHeaderName, bannedHeaderValue := range bannedHeaders { regex, err := regexp.Compile(headerName) if err != nil { return false, err } headerNameMatch := regex.MatchString(bannedHeaderName) regex, err = regexp.Compile(bannedHeaderValue) if err != nil { return false, err } headerValueMatch := regex.MatchString(headerNameValue) if headerNameMatch && headerValueMatch { return true, nil } } } return false, nil }
------------------

--- Chunk 12---
Function Decode (start): func Decode(yamlTestcase *yaml.NetworkTrafficDoc, logger *zap.Logger) (*models.TestCase, error) { tc := &models.TestCase{ Version: yamlTestcase.Version, Kind: yamlTestcase.Kind, Name: yamlTestcase.Name, Curl: yamlTestcase.Curl, Noise: make(map[string][]string), Assertions: make(map[models.AssertionType]interface{}), } switch tc.Kind { case models.HTTP: var httpSpec models.HTTPSchema if err := yamlTestcase.Spec.Decode(&httpSpec); err != nil { utils.LogError(logger, err, "failed to decode HTTP JSON spec") return nil, err } tc.Created = httpSpec.Created tc.HTTPReq = httpSpec.Request tc.HTTPResp = httpSpec.Response tc.Description = httpSpec.Metadata["description"] // single map-based loop for all assertions for key, raw := range httpSpec.Assertions { tc.Assertions[key] = raw if key == models.NoiseAssertion { noiseMap, ok := raw.(map[models.AssertionType]interface{}) if !ok { logger.Warn("noise assertion
------------------

--- Chunk 13---
Function Decode (part 2): not in expected map[AssertionType]interface{}", zap.Any("raw", raw)) continue } for kt, inner := range noiseMap { field := string(kt) // initialize slice tc.Noise[field] = []string{} arr, ok := inner.([]interface{}) if !ok { continue } for _, item := range arr { if s, ok2 := item.(string); ok2 && s != "" { tc.Noise[field] = append(tc.Noise[field], s) } } } } } case models.GRPC_EXPORT: var grpcSpec models.GrpcSpec if err := yamlTestcase.Spec.Decode(&grpcSpec); err != nil { utils.LogError(logger, err, "failed to decode gRPC spec") return nil, err } tc.Created = grpcSpec.Created tc.GrpcReq = grpcSpec.GrpcReq tc.GrpcResp = grpcSpec.GrpcResp for key, raw := range grpcSpec.Assertions { tc.Assertions[key] = raw if key == models.NoiseAssertion { noiseMap, ok := raw
------------------

--- Chunk 14---
Function Decode (end): .(map[models.AssertionType]interface{}) if !ok { logger.Warn("noise assertion not in expected map[AssertionType]interface{}", zap.Any("raw", raw)) continue } for kt, inner := range noiseMap { field := string(kt) tc.Noise[field] = []string{} arr, ok := inner.([]interface{}) if !ok { continue } for _, item := range arr { if s, ok2 := item.(string); ok2 && s != "" { tc.Noise[field] = append(tc.Noise[field], s) } } } } } default: utils.LogError(logger, nil, "invalid testcase kind", zap.String("kind", string(tc.Kind))) return nil, errors.New("invalid testcase kind") } return tc, nil }
------------------

--- File: pkg/platform/yaml/utils.go---

--- Chunk 1---
Function CompareHeaders (start): func CompareHeaders(h1 http.Header, h2 http.Header, res *[]models.HeaderResult, noise map[string]string) bool { if res == nil { return false } match := true _, isHeaderNoisy := noise["header"] for k, v := range h1 { _, isNoisy := noise[k] isNoisy = isNoisy || isHeaderNoisy val, ok := h2[k] if !isNoisy { if !ok { if checkKey(res, k) { *res = append(*res, models.HeaderResult{ Normal: false, Expected: models.Header{ Key: k, Value: v, }, Actual: models.Header{ Key: k, Value: nil, }, }) } match = false continue } if len(v) != len(val) { if checkKey(res, k) { *res = append(*res, models.HeaderResult{ Normal: false, Expected: models.Header{ Key: k, Value: v, }, Actual
------------------

--- Chunk 2---
Function CompareHeaders (part 2): : models.Header{ Key: k, Value: val, }, }) } match = false continue } for i, e := range v { if val[i] != e { if checkKey(res, k) { *res = append(*res, models.HeaderResult{ Normal: false, Expected: models.Header{ Key: k, Value: v, }, Actual: models.Header{ Key: k, Value: val, }, }) } match = false continue } } } if checkKey(res, k) { *res = append(*res, models.HeaderResult{ Normal: true, Expected: models.Header{ Key: k, Value: v, }, Actual: models.Header{ Key: k, Value: val, }, }) } } for k, v := range h2 { _, isNoisy := noise[k] isNoisy = isNoisy || isHeaderNoisy
------------------

--- Chunk 3---
Function CompareHeaders (end): val, ok := h1[k] if isNoisy && checkKey(res, k) { *res = append(*res, models.HeaderResult{ Normal: true, Expected: models.Header{ Key: k, Value: val, }, Actual: models.Header{ Key: k, Value: v, }, }) continue } if !ok { if checkKey(res, k) { *res = append(*res, models.HeaderResult{ Normal: false, Expected: models.Header{ Key: k, Value: nil, }, Actual: models.Header{ Key: k, Value: v, }, }) } match = false } } return match }
------------------

--- Chunk 4---
func checkKey(res *[]models.HeaderResult, key string) bool { for _, v := range *res { if key == v.Expected.Key { return false } } return true }
------------------

--- Chunk 5---
func Contains(elems []string, v string) bool { for _, s := range elems { if v == s { return true } } return false }
------------------

--- Chunk 6---
func NewSessionIndex(path string, Logger *zap.Logger) (string, error) { indx := 0 dir, err := ReadDir(path, fs.FileMode(os.O_RDONLY)) if err != nil { Logger.Debug("creating a folder for the keploy generated testcases", zap.Error(err)) return fmt.Sprintf("%s%v", models.TestSetPattern, indx), nil } files, err := dir.ReadDir(0) if err != nil { return "", err } for _, v := range files { // fmt.Println("name for the file", v.Name()) fileName := filepath.Base(v.Name()) fileNamePackets := strings.Split(fileName, "-") if len(fileNamePackets) == 3 { fileIndx, err := strconv.Atoi(fileNamePackets[2]) if err != nil { Logger.Debug("failed to convert the index string to integer", zap.Error(err)) continue } if indx < fileIndx+1 { indx = fileIndx + 1 } } } return fmt.Sprintf("%s%v", models.TestSetPattern, indx), nil }
------------------

--- Chunk 7---
func ValidatePath(path string) (string, error) { // Validate the input to prevent directory traversal attack if strings.Contains(path, "..") { return "", errors.New("invalid path: contains '..' indicating directory traversal") } return path, nil }
------------------

--- Chunk 8---
func FindLastIndex(path string, _ *zap.Logger) (int, error) { dir, err := ReadDir(path, fs.FileMode(os.O_RDONLY)) if err != nil { return 1, nil } files, err := dir.ReadDir(0) if err != nil { return 1, nil } lastIndex := 0 for _, v := range files { if v.Name() == "mocks.yaml" || v.Name() == "config.yaml" { continue } fileName := filepath.Base(v.Name()) fileNameWithoutExt := fileName[:len(fileName)-len(filepath.Ext(fileName))] fileNameParts := strings.Split(fileNameWithoutExt, "-") if len(fileNameParts) != 2 || (fileNameParts[0] != "test" && fileNameParts[0] != "report") { continue } indxStr := fileNameParts[1] indx, err := strconv.Atoi(indxStr) if err != nil { continue } if indx > lastIndex { lastIndex = indx } } lastIndex++ return lastIndex, nil }
------------------

--- Chunk 9---
func ReadDir(path string, fileMode fs.FileMode) (*os.File, error) { dir, err := os.OpenFile(path, os.O_RDONLY, fileMode) if err != nil { return nil, err } return dir, nil }
------------------

--- Chunk 10---
func CreateDir(path string, logger *zap.Logger) error { if _, err := os.Stat(path); os.IsNotExist(err) { err := os.MkdirAll(path, os.ModePerm) if err != nil { utils.LogError(logger, err, "failed to create directory", zap.String("directory", path)) return err } } return nil }
------------------

--- Chunk 11---
func ReadYAMLFile(ctx context.Context, logger *zap.Logger, filePath string, fileName string, v interface{}, extType bool) error { if !extType { filePath = filepath.Join(filePath, fileName+".yml") } else { filePath = filepath.Join(filePath, fileName+".yaml") } file, err := os.Open(filePath) if err != nil { return fmt.Errorf("failed to read the file: %v", err) } defer func() { if err := file.Close(); err != nil { utils.LogError(logger, err, "failed to close file", zap.String("file", filePath)) } }() cr := &ctxReader{ ctx: ctx, r: file, } configData, err := io.ReadAll(cr) if err != nil { if err == ctx.Err() { return err // Ignore context cancellation error } return fmt.Errorf("failed to read the file: %v", err) } err = yaml.Unmarshal(configData, v) if err != nil { utils.LogError(logger, err, "failed to unmarshal YAML", zap.String("file", filePath)) return err } return nil }
------------------

--- Chunk 12---
Function CopyFile (start): func CopyFile(src, dst string, rename bool, logger *zap.Logger) error { srcFile, err := os.Open(src) if err != nil { return err } defer func() { if err := srcFile.Close(); err != nil { utils.LogError(logger, err, "failed to close file", zap.String("file", srcFile.Name())) } }() // If rename is true, generate a new name for the destination file if rename { dst = generateSchemaName(dst) } dstFile, err := os.Create(dst) if err != nil { return err } defer func() { if err := dstFile.Close(); err != nil { utils.LogError(logger, err, "failed to close file", zap.String("file", dstFile.Name())) } }() _, err = io.Copy(dstFile, srcFile) if err != nil { return err } // Ensure the copied file has the same permissions as the original file srcInfo, err := os.Stat(src) if err != nil { return err } err = os.Chmod(dst, srcInfo.Mode()) if err != nil { return err } return nil
------------------

--- Chunk 13---
Function CopyFile (end): }
------------------

--- Chunk 14---
func CopyDir(srcDir, destDir string, rename bool, logger *zap.Logger) error { // Ensure the destination directory exists if _, err := os.Stat(destDir); os.IsNotExist(err) { err := os.MkdirAll(destDir, os.ModePerm) if err != nil { return err } } entries, err := os.ReadDir(srcDir) if err != nil { return err } for _, entry := range entries { srcPath := filepath.Join(srcDir, entry.Name()) destPath := filepath.Join(destDir, entry.Name()) info, err := entry.Info() if err != nil { return err } if info.IsDir() { err = os.MkdirAll(destPath, info.Mode()) if err != nil { return err } err = CopyDir(srcPath, destPath, rename, logger) if err != nil { return err } } else { err = CopyFile(srcPath, destPath, rename, logger) if err != nil { return err } } } return nil }
------------------

--- Chunk 15---
func generateSchemaName(src string) string { dir := filepath.Dir(src) newName := "schema" + filepath.Ext(src) return filepath.Join(dir, newName) }
------------------

--- Chunk 16---
func FileExists(_ context.Context, logger *zap.Logger, path string, fileName string) (bool, error) { yamlPath, err := ValidatePath(filepath.Join(path, fileName+".yaml")) if err != nil { utils.LogError(logger, err, "failed to validate the yaml file path", zap.String("path directory", path), zap.String("yaml", fileName)) return false, err } if _, err := os.Stat(yamlPath); err != nil { if os.IsNotExist(err) { return false, nil } utils.LogError(logger, err, "failed to check if the yaml file exists", zap.String("path directory", path), zap.String("yaml", fileName)) return false, err } return true, nil }
------------------

--- File: pkg/platform/yaml/yaml.go---

--- Chunk 1---
func (cr *ctxReader) Read(p []byte) (n int, err error) { select { case <-cr.ctx.Done(): return 0, cr.ctx.Err() default: return cr.r.Read(p) } }
------------------

--- Chunk 2---
func (cw *ctxWriter) Write(p []byte) (n int, err error) { for len(p) > 0 { var written int written, err = cw.writer.Write(p) n += written if err != nil { return n, err } p = p[written:] } return n, nil }
------------------

--- Chunk 3---
Function WriteFile (start): func WriteFile(ctx context.Context, logger *zap.Logger, path, fileName string, docData []byte, isAppend bool) error { isFileEmpty, err := CreateYamlFile(ctx, logger, path, fileName) if err != nil { utils.LogError(logger, err, "failed to create a yaml file", zap.String("path directory", path), zap.String("yaml", fileName)) return err } flag := os.O_WRONLY | os.O_TRUNC if isAppend { data := []byte("---\n") if isFileEmpty { data = []byte{} } docData = append(data, docData...) flag = os.O_WRONLY | os.O_APPEND } yamlPath := filepath.Join(path, fileName+".yaml") file, err := os.OpenFile(yamlPath, flag, fs.ModePerm) if err != nil { utils.LogError(logger, err, "failed to open file for writing", zap.String("file", yamlPath)) return err } defer func() { if err := file.Close(); err != nil { utils.LogError(logger, err, "failed to close file", zap.String("file", yamlPath)) } }() cw := &
------------------

--- Chunk 4---
Function WriteFile (end): ctxWriter{ ctx: ctx, writer: file, } _, err = cw.Write(docData) if err != nil { if err == ctx.Err() { return nil // Ignore context cancellation error } utils.LogError(logger, err, "failed to write the yaml document", zap.String("yaml file name", fileName)) return err } return nil }
------------------

--- Chunk 5---
func ReadFile(ctx context.Context, logger *zap.Logger, path, name string) ([]byte, error) { filePath := filepath.Join(path, name+".yaml") file, err := os.Open(filePath) if err != nil { return nil, fmt.Errorf("failed to read the file: %v", err) } defer func() { if err := file.Close(); err != nil { utils.LogError(logger, err, "failed to close file", zap.String("file", filePath)) } }() cr := &ctxReader{ ctx: ctx, r: file, } data, err := io.ReadAll(cr) if err != nil { if err == ctx.Err() { return nil, err // Ignore context cancellation error } return nil, fmt.Errorf("failed to read the file: %v", err) } return data, nil }
------------------

--- Chunk 6---
Function CreateYamlFile (start): func CreateYamlFile(ctx context.Context, Logger *zap.Logger, path string, fileName string) (bool, error) { yamlPath, err := ValidatePath(filepath.Join(path, fileName+".yaml")) if err != nil { utils.LogError(Logger, err, "failed to validate the yaml file path", zap.String("path directory", path), zap.String("yaml", fileName)) return false, err } if _, err := os.Stat(yamlPath); err != nil { if ctx.Err() == nil || ctx.Err() == context.Canceled { err = os.MkdirAll(filepath.Join(path), 0777) if err != nil { utils.LogError(Logger, err, "failed to create a directory for the yaml file", zap.String("path directory", path), zap.String("yaml", fileName)) return false, err } file, err := os.OpenFile(yamlPath, os.O_CREATE, 0777) // Set file permissions to 777 if err != nil { utils.LogError(Logger, err, "failed to create a yaml file", zap.String("path directory", path), zap.String("yaml", fileName)) return false, err } err = file
------------------

--- Chunk 7---
Function CreateYamlFile (end): .Close() if err != nil { utils.LogError(Logger, err, "failed to close the yaml file", zap.String("path directory", path), zap.String("yaml", fileName)) return false, err } return true, nil } return false, err } return false, nil }
------------------

--- Chunk 8---
func ReadSessionIndices(_ context.Context, path string, Logger *zap.Logger) ([]string, error) { var indices []string dir, err := ReadDir(path, fs.FileMode(os.O_RDONLY)) if err != nil { Logger.Debug("creating a folder for the keploy generated testcases", zap.Error(err)) return indices, nil } files, err := dir.ReadDir(0) if err != nil { return indices, err } for _, v := range files { if v.Name() != "reports" && v.Name() != "testReports" && v.Name() != "schema" && v.IsDir() { indices = append(indices, v.Name()) } } return indices, nil }
------------------

--- Chunk 9---
func DeleteFile(_ context.Context, logger *zap.Logger, path, name string) error { filePath := filepath.Join(path, name+".yaml") err := os.Remove(filePath) if err != nil { utils.LogError(logger, err, "failed to delete the file", zap.String("file", filePath)) return fmt.Errorf("failed to delete the file: %v", err) } return nil }
------------------

--- Chunk 10---
func DeleteDir(_ context.Context, logger *zap.Logger, path string) error { err := os.RemoveAll(path) if err != nil { utils.LogError(logger, err, "failed to delete the directory", zap.String("path", path)) return fmt.Errorf("failed to delete the directory: %v", err) } return nil }
------------------

--- File: pkg/service/contract/consumer/consumer.go---

--- Chunk 1---
func New(logger *zap.Logger, config *config.Config) Service { return &consumer{ logger: logger, config: config, } }
------------------

--- Chunk 2---
func (s *consumer) ValidateSchema(testsMapping map[string]map[string]*models.OpenAPI, mocksMapping []models.MockMapping) error { // Retrieve mocks and calculate scores for each service scores, err := s.getMockScores(testsMapping, mocksMapping) if err != nil { return err } // Compare the scores and generate a summary summary, err := s.ValidateMockAgainstTests(scores, testsMapping) if err != nil { return err } // Print the summary generateSummaryTable(summary) return nil }
------------------

--- Chunk 3---
Function getMockScores (start): func (s *consumer) getMockScores(testsMapping map[string]map[string]*models.OpenAPI, mocksMapping []models.MockMapping) (map[string]map[string]map[string]models.SchemaInfo, error) { // Initialize a map to store the scores for each service, mock set, and mock. scores := make(map[string]map[string]map[string]models.SchemaInfo) for _, mapping := range mocksMapping { // Initialize the service entry in the scores map if it doesn't already exist. if scores[mapping.Service] == nil { scores[mapping.Service] = make(map[string]map[string]models.SchemaInfo) } // Initialize the mock set entry if it hasn't been initialized yet. if scores[mapping.Service][mapping.TestSetID] == nil { scores[mapping.Service][mapping.TestSetID] = make(map[string]models.SchemaInfo) } // Compare the mocks with test cases and calculate scores. // The result is stored in the scores map under the respective service and mock set ID. s.scoresForMocks(mapping.Mocks, scores[mapping.Service][mapping.TestSetID], testsMapping, mapping.TestSetID)
------------------

--- Chunk 4---
Function getMockScores (end): } // Return the calculated scores. return scores, nil }
------------------

--- Chunk 5---
Function scoresForMocks (start): func (s *consumer) scoresForMocks(mocks []*models.OpenAPI, mockSet map[string]models.SchemaInfo, testsMapping map[string]map[string]*models.OpenAPI, mockSetID string) { // Ensure mockSet is initialized before assigning if mockSet == nil { mockSet = make(map[string]models.SchemaInfo) } // Loop through each mock in the provided list of mocks. for _, mock := range mocks { // Initialize the mock's score to 0.0 and store the mock's data in the mockSet map. // 'mockSet' is a map where the key is the mock title and the value is the SchemaInfo structure containing score and data. mockSet[mock.Info.Title] = models.SchemaInfo{ Score: 0.0, Data: *mock, // Store the mock data here. } // Loop through each test set (testSetID) in the testsMapping. // testsMapping maps test set IDs to test case titles. for testSetID, tests := range testsMapping { // Loop through each test in the current test set. for _, test := range tests { // Call
------------------

--- Chunk 6---
Function scoresForMocks (part 2): 'match2' to compare the mock with the current test. // This function returns a candidateScore (how well the mock matches the test) and a pass boolean. candidateScore, pass, err := schemaMatcher.Match(*mock, *test, testSetID, mockSetID, s.logger, models.IdentifyMode) // Handle any errors encountered during the comparison process. if err != nil { // Log the error and continue with the next iteration, skipping the current comparison. utils.LogError(s.logger, err, "Error in matching the two models") continue } // If the mock passed the comparison and the candidate score is greater than the current score: if pass && candidateScore > mockSet[mock.Info.Title].Score { // Update the mock's score and store the test case information in the mockSet. // This keeps track of the best matching test case for the current mock. mockSet[mock.Info.Title] = models.SchemaInfo{ Service: "", // Optional: could store service info if needed. TestSetID: testSetID, // Store the test set ID that provided the highest score. Name:
------------------

--- Chunk 7---
Function scoresForMocks (end): test.Info.Title, // Store the test case name (title). Score: candidateScore, // Update the score with the highest candidate score. Data: *mock, // Store the mock data. } } } } } }
------------------

--- Chunk 8---
Function ValidateMockAgainstTests (start): func (s *consumer) ValidateMockAgainstTests(scores map[string]map[string]map[string]models.SchemaInfo, testsMapping map[string]map[string]*models.OpenAPI) (models.Summary, error) { var summary models.Summary // Defining color schemes for success, failure, and other statuses notMatchedColor := color.New(color.FgHiRed).SprintFunc() missedColor := color.New(color.FgHiYellow).SprintFunc() successColor := color.New(color.FgHiGreen).SprintFunc() serviceColor := color.New(color.FgHiBlue).SprintFunc() // Loop through the services in the scores map // Each "service" represents a consumer service being validated for service, mockSetIDs := range scores { // Create a new service summary for each service var serviceSummary models.ServiceSummary serviceSummary.TestSets = make(map[string]models.Status) serviceSummary.Service = service // Store the service name // Output the beginning of the validation for the current service fmt.Println("==========================================") fmt.Print("Starting Validation for Consumer Service: ") fmt.Print(serviceColor(service)) // Print service name in blue fmt.Println("
------------------

--- Chunk 9---
Function ValidateMockAgainstTests (part 2): ....") fmt.Println("==========================================") // Iterate over the mockSetIDs for each service (mock set contains multiple mocks) for mockSetID, mockTest := range mockSetIDs { if _, ok := serviceSummary.TestSets[mockSetID]; !ok { // Initialize the Status struct if it doesn't already exist for the mockSetID serviceSummary.TestSets[mockSetID] = models.Status{} } // Iterate over each mock in the mockTest map for _, mockInfo := range mockTest { // Print validation information only if the score is not zero if mockInfo.Score != 0.0 { fmt.Print("Validating '") fmt.Print(serviceColor(service)) // Print the service name in blue fmt.Printf("': (%s)/%s for (%s)/%s\n", mockSetID, mockInfo.Data.Info.Title, mockInfo.TestSetID, mockInfo.Name) } // Case 1: If the score is 1.0, the mock passed the validation if mockInfo.Score == 1.0 { // Retrieve the Status struct for the given mockSetID status
------------------

--- Chunk 10---
Function ValidateMockAgainstTests (part 3): := serviceSummary.TestSets[mockSetID] // Append the passed mock title status.Passed = append(status.Passed, mockInfo.Data.Info.Title) // Reassign the updated status back to the map serviceSummary.TestSets[mockSetID] = status serviceSummary.PassedCount++ // Increment the passed count // Print a success message in green fmt.Print("Contract check ") fmt.Print(successColor("passed")) // Print "passed" in green fmt.Printf(" for the test '%s' / mock '%s'\n", mockInfo.Name, mockInfo.Data.Info.Title) fmt.Println("--------------------------------------------------------------------") // Case 2: If the score is between 0 and 1.0, the mock failed the validation } else if mockInfo.Score > 0.0 { // Retrieve the Status struct for the given mockSetID status := serviceSummary.TestSets[mockSetID] // Append the failed mock title status.Failed = append(status.Failed, mockInfo.Data.Info.Title) // Reassign the updated status back to the map serviceSummary.TestSets[mockSetID] =
------------------

--- Chunk 11---
Function ValidateMockAgainstTests (part 4): status serviceSummary.FailedCount++ // Increment the failed count // Print a failure message in red fmt.Print("Contract check") fmt.Print(notMatchedColor(" failed")) // Print "failed" in red fmt.Printf(" for the test '%s' / mock '%s'\n", mockInfo.Name, mockInfo.Data.Info.Title) fmt.Println() // Additional information: Print consumer and current service comparison fmt.Printf(" Current %s || Consumer %s\n", serviceColor(s.config.Contract.Mappings.Self), serviceColor(service)) // Perform comparison between the mock and test case again _, _, err := schemaMatcher.Match(mockInfo.Data, *testsMapping[mockInfo.TestSetID][mockInfo.Name], mockInfo.TestSetID, mockSetID, s.logger, models.CompareMode) if err != nil { // If an error occurs during comparison, return it utils.LogError(s.logger, err, "Error in matching the two models") return models.Summary{}, err } // Case 3: If the score is 0.0, there was no matching test case found } else if mock
------------------

--- Chunk 12---
Function ValidateMockAgainstTests (end): Info.Score == 0.0 { // Retrieve the Status struct for the given mockSetID status := serviceSummary.TestSets[mockSetID] // Append the missed mock title status.Missed = append(status.Missed, mockInfo.Data.Info.Title) // Reassign the updated status back to the map serviceSummary.TestSets[mockSetID] = status serviceSummary.MissedCount++ // Increment the missed count // Print a "missed" message in yellow fmt.Println(missedColor(fmt.Sprintf("No ideal test case found for the (%s)/'%s'", mockSetID, mockInfo.Data.Info.Title))) fmt.Println("--------------------------------------------------------------------") } } } // Append the completed service summary to the overall summary summary.ServicesSummary = append(summary.ServicesSummary, serviceSummary) } // Return the overall summary containing details of all services validated return summary, nil }
------------------

--- Chunk 13---
Function generateSummaryTable (start): func generateSummaryTable(summary models.Summary) { notMatchedColor := color.New(color.FgHiRed).SprintFunc() missedColor := color.New(color.FgHiYellow).SprintFunc() successColor := color.New(color.FgHiGreen).SprintFunc() serviceColor := color.New(color.FgHiBlue).SprintFunc() // Create a new tablewriter to format the output as a table table := tablewriter.NewWriter(os.Stdout) // Set table headers table.SetHeader([]string{"Consumer Service", "Consumer Service Test-set", "Mock-name", "Failed", "Passed", "Missed"}) table.SetAlignment(tablewriter.ALIGN_CENTER) table.SetAutoMergeCells(true) // Loop through each service summary to populate the table for idx, serviceSummary := range summary.ServicesSummary { failedCount := serviceSummary.FailedCount passedCount := serviceSummary.PassedCount missedCount := serviceSummary.MissedCount table.Append([]string{ serviceColor(serviceSummary.Service), "", "", notMatchedColor(failedCount), successColor(passedCount), missedColor(missedCount), }) for test
------------------

--- Chunk 14---
Function generateSummaryTable (end): Set, status := range serviceSummary.TestSets { for _, mock := range status.Failed { // Add rows for failed mocks table.Append([]string{ "", testSet, notMatchedColor(mock), "", "", "", }) } for _, mock := range status.Missed { table.Append([]string{ "", testSet, missedColor(mock), "", "", "", }) } table.Append([]string{ "", "", "", "", "", "", }) } // Add a blank line (or border) after each service if idx < len(summary.ServicesSummary)-1 { table.Append([]string{"----------------", "----------------", "----------------", "----------------", "----------------", "----------------"}) } } // Render the table to stdout table.Render() }
------------------

--- File: pkg/service/contract/contract.go---

--- Chunk 1---
func New(logger *zap.Logger, testDB TestDB, mockDB MockDB, openAPIDB OpenAPIDB, config *config.Config) Service { return &contract{ logger: logger, testDB: testDB, mockDB: mockDB, openAPIDB: openAPIDB, config: config, consumer: consumer.New(logger, config), provider: provider.New(logger, config), } }
------------------

--- Chunk 2---
Function HTTPDocToOpenAPI (start): func (s *contract) HTTPDocToOpenAPI(logger *zap.Logger, custom models.HTTPDoc) (models.OpenAPI, error) { var err error // Convert response body to an object var responseBodyObject map[string]interface{} if custom.Spec.Response.Body != "" { err := json.Unmarshal([]byte(custom.Spec.Response.Body), &responseBodyObject) if err != nil { return models.OpenAPI{}, err } } // Get the type of each value in the response body object responseTypes := ExtractVariableTypes(responseBodyObject) // Convert request body to an object var requestBodyObject map[string]interface{} if custom.Spec.Request.Body != "" { err := json.Unmarshal([]byte(custom.Spec.Request.Body), &requestBodyObject) if err != nil { return models.OpenAPI{}, err } } // Get the type of each value in the request body object requestTypes := ExtractVariableTypes(requestBodyObject) // Generate response by status code byCode := GenerateResponse(Response{ Code: custom.Spec.Response.StatusCode, Message: custom.Spec.Response.StatusMessage, Types: responseTypes, Body: responseBodyObject, }) // Add
------------------

--- Chunk 3---
Function HTTPDocToOpenAPI (part 2): parameters to the request parameters := GenerateHeader(custom.Spec.Request.Header) // Extract In Path parameters identifiers := ExtractIdentifiers(custom.Spec.Request.URL) // Generate Dummy Names for the identifiers dummyNames := GenerateDummyNamesForIdentifiers(identifiers) // Add In Path parameters to the parameters if len(identifiers) > 0 { parameters = AppendInParameters(parameters, dummyNames, "path") } // Extract Query parameters queryParams, err := ExtractQueryParams(custom.Spec.Request.URL) if err != nil { utils.LogError(logger, err, "failed to extract query parameters") return models.OpenAPI{}, err } // Add Query parameters to the parameters if len(queryParams) > 0 { parameters = AppendInParameters(parameters, queryParams, "query") } // Generate Operation ID operationID := generateUniqueID() if operationID == "" { err := fmt.Errorf("failed to generate unique ID") utils.LogError(logger, err, "failed to generate unique ID") return models.OpenAPI{}, err } // Determine if the request method is GET or POST var pathItem models.PathItem switch custom.Spec.Request.Method { case "GET":
------------------

--- Chunk 4---
Function HTTPDocToOpenAPI (part 3): pathItem = models.PathItem{ Get: &models.Operation{ Summary: "Auto-generated operation", Description: "Auto-generated from custom format", OperationID: operationID, Parameters: parameters, Responses: byCode, }, } case "POST": pathItem = models.PathItem{ Post: &models.Operation{ Summary: "Auto-generated operation", Description: "Auto-generated from custom format", Parameters: parameters, OperationID: operationID, RequestBody: &models.RequestBody{ Content: map[string]models.MediaType{ "application/json": { Schema: models.Schema{ Type: "object", Properties: requestTypes, }, Example: requestBodyObject, }, }, }, Responses: byCode, }, } case "PUT": pathItem.Put = &models.Operation{ Summary: "Update an employee by ID", Description: "Update an employee by ID", Parameters: parameters, OperationID: operationID, RequestBody: &models.RequestBody
------------------

--- Chunk 5---
Function HTTPDocToOpenAPI (part 4): { Content: map[string]models.MediaType{ "application/json": { Schema: models.Schema{ Type: "object", Properties: requestTypes, }, Example: (requestBodyObject), }, }, }, Responses: byCode, } case "PATCH": pathItem.Patch = &models.Operation{ Summary: "Auto-generated operation", Description: "Auto-generated from custom format", Parameters: parameters, OperationID: operationID, RequestBody: &models.RequestBody{ Content: map[string]models.MediaType{ "application/json": { Schema: models.Schema{ Type: "object", Properties: requestTypes, }, Example: (requestBodyObject), }, }, }, Responses: byCode, } case "DELETE": pathItem.Delete = &models.Operation{ Summary: "Delete an employee by ID", Description: "Delete an employee by ID", OperationID: operationID, Parameters: parameters, Responses: byCode,
------------------

--- Chunk 6---
Function HTTPDocToOpenAPI (part 5): } default: utils.LogError(logger, err, "Unsupported Method") return models.OpenAPI{}, err } // Extract the URL path parsedURL, hostName := ExtractURLPath(custom.Spec.Request.URL) if parsedURL == "" { utils.LogError(logger, err, "failed to extract URL path") return models.OpenAPI{}, err } // Replace numeric identifiers in the path with dummy names (if exists) parsedURL = ReplacePathIdentifiers(parsedURL, dummyNames) //If it's mock so there is no hostname so put it temp if hostName == "" { hostName = "temp" } // Convert to OpenAPI format openapi := models.OpenAPI{ OpenAPI: "3.0.0", Info: models.Info{ Title: custom.Name, Version: custom.Version, Description: custom.Kind, }, Servers: []map[string]string{ { "url": hostName, }, }, Paths: map[string]models.PathItem{ parsedURL: pathItem, }, Components: map[string]interface{}{}, } return openapi, nil
------------------

--- Chunk 7---
Function HTTPDocToOpenAPI (end): }
------------------

--- Chunk 8---
Function GenerateMocksSchemas (start): func (s *contract) GenerateMocksSchemas(ctx context.Context, services []string, mappings map[string][]string) error { // Retrieve all test set IDs from the test database. testSetsIDs, err := s.testDB.GetAllTestSetIDs(ctx) if err != nil { // Log and return error if test set IDs retrieval fails. utils.LogError(s.logger, err, "failed to get test set IDs") return err } // If specific services are provided, ensure they exist in the mappings. if len(services) != 0 { for _, service := range services { if _, exists := mappings[service]; !exists { // Warn if the service is not found in the services mapping. s.logger.Warn("Service not found in services mapping, no contract generation", zap.String("service", service)) } } } // Loop through each test set ID to process the HTTP mocks. for _, testSetID := range testSetsIDs { // Retrieve HTTP mocks for the test set from the mock database. httpMocks, err := s.mockDB.GetHTTPMocks(ctx, testSetID, s.config.Path, "mocks") if err != nil {
------------------

--- Chunk 9---
Function GenerateMocksSchemas (part 2): // Log and return error if HTTP mock retrieval fails. utils.LogError(s.logger, err, "failed to get HTTP mocks", zap.String("testSetID", testSetID)) return err } // Track duplicate mocks to avoid generating the same schema multiple times. var duplicateServices []string // Loop through each HTTP mock to generate OpenAPI documentation. for _, mock := range httpMocks { var isAppend bool // Flag to indicate whether to append to existing mocks. // Loop through services and their mappings to find the relevant mock. for service, serviceMappings := range mappings { // If a specific service list is provided, skip services not in the list. if !yaml.Contains(services, service) && len(services) != 0 { continue } var mappingFound bool // Flag to track if the mapping for the service is found. // Check if the mock's URL matches any service mapping. for _, mapping := range serviceMappings { if mapping == mock.Spec.Request.URL { // Check for duplicate services to append the mock to the existing mocks.yaml before. if yaml.Contains(duplicateServices, service) { is
------------------

--- Chunk 10---
Function GenerateMocksSchemas (part 3): Append = true } else { duplicateServices = append(duplicateServices, service) } // Convert the HTTP mock to OpenAPI documentation. openapi, err := s.HTTPDocToOpenAPI(s.logger, *mock) if err != nil { utils.LogError(s.logger, err, "failed to convert the yaml file to openapi") return fmt.Errorf("failed to convert the yaml file to openapi") } // Validate the generated OpenAPI schema. err = validateSchema(openapi) if err != nil { utils.LogError(s.logger, err, "failed to validate the OpenAPI schema") return err } // Write the OpenAPI document to the specified directory. err = s.openAPIDB.WriteSchema(ctx, s.logger, filepath.Join(s.config.Path, "schema", "mocks", service, testSetID), "mocks", openapi, isAppend) if err != nil { utils.LogError(s.logger, err, "failed to write the OpenAPI schema") return err } mappingFound = true // Mark the mapping as found. break } }
------------------

--- Chunk 11---
Function GenerateMocksSchemas (end): // Break the outer loop if the relevant mapping is found. if mappingFound { break } } } } return nil // Return nil if the function completes successfully. }
------------------

--- Chunk 12---
Function GenerateTestsSchemas (start): func (s *contract) GenerateTestsSchemas(ctx context.Context, selectedTests []string) error { testSetsIDs, err := s.testDB.GetAllTestSetIDs(ctx) if err != nil { utils.LogError(s.logger, err, "failed to get test set IDs") return err } for _, testSetID := range testSetsIDs { if !yaml.Contains(selectedTests, testSetID) && len(selectedTests) != 0 { continue } testCases, err := s.testDB.GetTestCases(ctx, testSetID) if err != nil { utils.LogError(s.logger, err, "failed to get test cases", zap.String("testSetID", testSetID)) return err } for _, tc := range testCases { var httpSpec models.HTTPDoc httpSpec.Kind = string(tc.Kind) httpSpec.Name = tc.Name httpSpec.Spec.Request = tc.HTTPReq httpSpec.Spec.Response = tc.HTTPResp httpSpec.Version = string(tc.Version) openapi, err := s.HTTPDocToOpenAPI(s.logger, httpSpec) if err != nil { utils.LogError(s.logger, err, "failed to
------------------

--- Chunk 13---
Function GenerateTestsSchemas (end): convert the yaml file to openapi") return fmt.Errorf("failed to convert the yaml file to openapi") } // Validate the OpenAPI document err = validateSchema(openapi) if err != nil { utils.LogError(s.logger, err, "failed to validate the OpenAPI schema") return err } // Save it using the OpenAPIDB err = s.openAPIDB.WriteSchema(ctx, s.logger, filepath.Join(s.config.Path, "schema", "tests", testSetID), tc.Name, openapi, false) if err != nil { utils.LogError(s.logger, err, "failed to write the OpenAPI schema") return err } } } return nil }
------------------

--- Chunk 14---
Function Generate (start): func (s *contract) Generate(ctx context.Context, checkConfig bool) error { if checkConfig && checkConfigFile(s.config.Contract.Mappings.ServicesMapping) != nil { utils.LogError(s.logger, fmt.Errorf("unable to find services mappings in the config file"), "Unable to find services mappings in the config file") return fmt.Errorf("unable to find services mappings in the config file") } mappings := s.config.Contract.Mappings.ServicesMapping serviceColor := color.New(color.FgYellow).SprintFunc() fmt.Println(serviceColor("==========================================")) fmt.Println(serviceColor(fmt.Sprintf("Starting Generating OpenAPI Schemas for Current Service: %s ....", s.config.Contract.Mappings.Self))) fmt.Println(serviceColor("==========================================")) err := s.GenerateTestsSchemas(ctx, s.config.Contract.Tests) if err != nil { utils.LogError(s.logger, err, "failed to generate tests schemas") return err } err = s.GenerateMocksSchemas(ctx, s.config.Contract.Services, mappings) if err != nil { utils.LogError(s.logger, err, "failed to generate mocks schemas") return err } if err := saveServiceMappings(s.config.Contract.Mappings, filepath.Join(s.config.Path, "schema")); err
------------------

--- Chunk 15---
Function Generate (end): != nil { utils.LogError(s.logger, err, "failed to save service mappings") return err } return nil }
------------------

--- Chunk 16---
Function DownloadTests (start): func (s *contract) DownloadTests(_ string) error { targetPath := "./Download/Tests" if err := yaml.CreateDir(targetPath, s.logger); err != nil { utils.LogError(s.logger, err, "failed to create directory", zap.String("directory", targetPath)) return err } cprFolder, err := filepath.Abs("../VirtualCPR") if err != nil { utils.LogError(s.logger, err, "failed to get absolute path", zap.String("path", "../VirtualCPR")) return err } // Loop through the services in the mappings in the config file for service := range s.config.Contract.Mappings.ServicesMapping { // Fetch the tests of those services from virtual cpr testsPath := filepath.Join(cprFolder, service, "keploy", "schema", "tests") // Copy this dir to the target path serviceFolder := filepath.Join(targetPath, service) if err := yaml.CopyDir(testsPath, serviceFolder, false, s.logger); err != nil { utils.LogError(s.logger, err, "failed to copy directory", zap.String("directory", testsPath)) return err } s.logger.Info("Service
------------------

--- Chunk 17---
Function DownloadTests (part 2): 's tests (contracts) downloaded", zap.String("service", service)) // Copy the Keploy version (HTTP) tests keployTestsPath := filepath.Join(cprFolder, service, "keploy") testEntries, err := os.ReadDir(keployTestsPath) if err != nil { utils.LogError(s.logger, err, "failed to read directory", zap.String("directory", keployTestsPath)) return err } for _, testSetID := range testEntries { if !testSetID.IsDir() || !strings.Contains(testSetID.Name(), "test") { continue } // Copy the directory to the target path if err := yaml.CopyDir(filepath.Join(keployTestsPath, testSetID.Name(), "tests"), filepath.Join(serviceFolder, "schema", testSetID.Name()), false, s.logger); err != nil { utils.LogError(s.logger, err, "failed to copy directory", zap.String("directory", filepath.Join(keployTestsPath, testSetID.Name(), "tests"))) return err } s.logger.Info("Service's HTTP tests downloaded", zap.String("service", service), zap.String
------------------

--- Chunk 18---
Function DownloadTests (end): ("tests", testSetID.Name())) } } return nil }
------------------

--- Chunk 19---
Function DownloadMocks (start): func (s *contract) DownloadMocks(ctx context.Context, _ string) error { // Set the target path where the downloaded mocks will be stored targetPath := "./Download/Mocks" // Create the target directory if it doesn't already exist if err := yaml.CreateDir(targetPath, s.logger); err != nil { utils.LogError(s.logger, err, "failed to create directory", zap.String("directory", targetPath)) return err } // Get the absolute path to the VirtualCPR folder cprFolder, err := filepath.Abs("../VirtualCPR") if err != nil { utils.LogError(s.logger, err, "failed to get absolute path", zap.String("path", "../VirtualCPR")) return err } // Read all entries (files and directories) in the VirtualCPR folder entries, err := os.ReadDir(cprFolder) if err != nil { utils.LogError(s.logger, err, "failed to read directory", zap.String("directory", cprFolder)) return err } // Loop through each entry in the VirtualCPR folder for _, entry := range entries { // If the entry is not a directory, skip it
------------------

--- Chunk 20---
Function DownloadMocks (part 2): if !entry.IsDir() { continue } // Extract the name of the current service (the one being processed) var self = s.config.Contract.Mappings.Self var schemaConfigMappings config.Mappings // Construct the path to the schema configuration file for the current service configFilePath := filepath.Join(cprFolder, entry.Name(), "keploy", "schema") // Read the schema configuration YAML schemaConfigMappings if err := yaml.ReadYAMLFile(ctx, s.logger, configFilePath, "serviceMappings", &schemaConfigMappings, true); err != nil { utils.LogError(s.logger, err, "failed to read the schema configuration file", zap.String("file", "serviceMappings")) return err } // Check if the current service exists in the service mapping from the schema configuration serviceFound := false if _, exists := schemaConfigMappings.ServicesMapping[self]; exists { serviceFound = true } // If the service is not found in the mapping, skip to the next service if !serviceFound { continue } // Create a directory for the current service inside the target path
------------------

--- Chunk 21---
Function DownloadMocks (part 3): serviceFolder := filepath.Join(targetPath, schemaConfigMappings.Self) if err := yaml.CreateDir(serviceFolder, s.logger); err != nil { utils.LogError(s.logger, err, "failed to create directory", zap.String("directory", serviceFolder)) return err } // Construct the path to the mock files for the current service mocksSourcePath := filepath.Join(cprFolder, entry.Name(), "keploy", "schema", "mocks", self) // Log and display the start of the mock download process for the service serviceColor := color.New(color.FgYellow).SprintFunc() fmt.Println(serviceColor("==========================================")) fmt.Println(serviceColor(fmt.Sprintf("Starting Downloading Mocks for Service: %s ....", entry.Name()))) fmt.Println(serviceColor("==========================================")) // Copy the mock files from the source directory to the target directory if err := yaml.CopyDir(mocksSourcePath, serviceFolder, true, s.logger); err != nil { utils.LogError(s.logger, err, "failed to copy directory", zap.String("directory", mocksSourcePath)) return err } // Log that the mocks for the
------------------

--- Chunk 22---
Function DownloadMocks (part 4): service have been downloaded s.logger.Info("Service's schema mocks contracts downloaded", zap.String("service", entry.Name()), zap.String("mocks", mocksSourcePath)) // Move the Keploy version-specific mocks // Read the contents of the "keploy" folder to find the mock folders mocksFolders, err := os.ReadDir(filepath.Join(cprFolder, entry.Name(), "keploy")) if err != nil { utils.LogError(s.logger, err, "failed to read directory", zap.String("directory", cprFolder), zap.Error(err)) return err } // Loop through each folder inside the "keploy" folder for _, mockFolder := range mocksFolders { // If the folder is not a directory or does not contain "test" in its name, skip it if !mockFolder.IsDir() || !strings.Contains(mockFolder.Name(), "test") { continue } // Retrieve the HTTP mocks from the mock database for the current test set httpMocks, err := s.mockDB.GetHTTPMocks(ctx, mockFolder.Name(), filepath.Join(cprFolder, entry.Name(), "keploy"), "mocks")
------------------

--- Chunk 23---
Function DownloadMocks (part 5): if err != nil { utils.LogError(s.logger, err, "failed to get HTTP mocks", zap.String("testSetID", mockFolder.Name()), zap.Error(err)) return err } // Filter the HTTP mocks based on the service URL mappings var filteredMocks []*models.HTTPDoc for _, mock := range httpMocks { for _, service := range schemaConfigMappings.ServicesMapping[self] { // Add the mock to the filtered list if the service URL matches if service == mock.Spec.Request.URL { filteredMocks = append(filteredMocks, mock) break } } } // Write the filtered mocks to the appropriate folder var initialMock = true for _, mock := range filteredMocks { // Marshal the mock data to YAML format mockYAML, err := yamlLib.Marshal(mock) if err != nil { utils.LogError(s.logger, err, "failed to marshal mock data", zap.Any("mock", mock)) return err } // Write the mock YAML file to the target service folder err = yaml.WriteFile(ctx, s.logger, filepath.Join(serviceFolder, mockFolder.Name
------------------

--- Chunk 24---
Function DownloadMocks (end): ()), "mocks", mockYAML, !initialMock) if err != nil { utils.LogError(s.logger, err, "failed to write mock file", zap.String("service", entry.Name()), zap.String("testSetID", mockFolder.Name())) return err } // Ensure only the first file is marked as the initial mock if initialMock { initialMock = false } } // Log that the HTTP mocks for the service have been downloaded s.logger.Info("Service's HTTP mocks contracts downloaded", zap.String("service", entry.Name()), zap.String("mocks", mockFolder.Name())) } } // Return nil to indicate success return nil }
------------------

--- Chunk 25---
func (s *contract) Download(ctx context.Context, checkConfig bool) error { if checkConfig && checkConfigFile(s.config.Contract.Mappings.ServicesMapping) != nil { utils.LogError(s.logger, fmt.Errorf("unable to find services mappings in the config file"), "Unable to find services mappings in the config file") return fmt.Errorf("unable to find services mappings in the config file") } path := s.config.Contract.Path // Validate the path path, err := yaml.ValidatePath(path) if err != nil { utils.LogError(s.logger, err, "failed to validate path") return fmt.Errorf("error in validating path") } driven := s.config.Contract.Driven if driven == models.ProviderMode.String() { err = s.DownloadTests(path) if err != nil { utils.LogError(s.logger, err, "failed to download tests") return err } } else if driven == models.ConsumerMode.String() { err = s.DownloadMocks(ctx, path) if err != nil { utils.LogError(s.logger, err, "failed to download mocks") return err } } return nil }
------------------

--- Chunk 26---
Function Validate (start): func (s *contract) Validate(ctx context.Context) error { if s.config.Contract.Mappings.Self == "" { utils.LogError(s.logger, fmt.Errorf("self service is not defined in the config file"), "Self service is not defined in the config file") return fmt.Errorf("self service is not defined in the config file") } if s.config.Contract.Generate { err := s.Generate(ctx, false) if err != nil { utils.LogError(s.logger, err, "failed to generate contract") return err } } if s.config.Contract.Download { err := s.Download(ctx, false) if err != nil { utils.LogError(s.logger, err, "failed to download contract") return err } } if s.config.Contract.Driven == models.ConsumerMode.String() { // Retrieve tests from the schema folder testsMapping, err := s.GetAllTestsSchema(ctx) if err != nil { utils.LogError(s.logger, err, "failed to get tests from schema") return err } // Retrieve mocks of each service from the download folder mocksSchemasDownloaded, err := s.GetAllDownloadedMocksSchemas(ctx)
------------------

--- Chunk 27---
Function Validate (end): if err != nil { utils.LogError(s.logger, err, "failed to get downloaded mocks schemas") return err } err = s.consumer.ValidateSchema(testsMapping, mocksSchemasDownloaded) if err != nil { utils.LogError(s.logger, err, "failed to validate schema") return err } } else if s.config.Contract.Driven == models.ProviderMode.String() { err := s.provider.ValidateSchema(ctx) if err != nil { utils.LogError(s.logger, err, "failed to validate schema") return err } fmt.Println("Provider driven validation is not implemented yet") } return nil }
------------------

--- File: pkg/service/contract/provider/provider.go---

--- Chunk 1---
func New(logger *zap.Logger, config *config.Config) Service { return &provider{ logger: logger, config: config, } }
------------------

--- Chunk 2---
Function ValidateSchema (start): func (s *provider) ValidateSchema(_ context.Context) error { // downloadTestsFolder := filepath.Join("./Download", "Tests") // entries, err := os.ReadDir(downloadTestsFolder) // if err != nil { // s.logger.Error("Failed to read directory", zap.String("directory", downloadTestsFolder), zap.Error(err)) // return err // } // mocksFolder := filepath.Join("./keploy", "schema", "mocks") // s.openAPIDB.ChangeTcPath(mocksFolder) // services, err := os.ReadDir(mocksFolder) // if err != nil { // s.logger.Error("Failed to read directory", zap.String("directory", mocksFolder), zap.Error(err)) // return err // } // var mocksMapping map[string]map[string]map[string]*models.OpenAPI = make(map[string]map[string]map[string]*models.OpenAPI) // var mocks []*models.OpenAPI // for _, service := range services { // if !service.IsDir() { // continue // }
------------------

--- Chunk 3---
Function ValidateSchema (part 2): // testSetIDs, err := os.ReadDir(filepath.Join(mocksFolder, service.Name())) // if err != nil { // s.logger.Error("Failed to read directory", zap.String("directory", service.Name()), zap.Error(err)) // return err // } // mocksMapping[service.Name()] = make(map[string]map[string]*models.OpenAPI) // for _, testSetID := range testSetIDs { // if !testSetID.IsDir() { // continue // } // mocks, err = s.openAPIDB.GetMocksSchemas(ctx, filepath.Join(service.Name(), testSetID.Name()), mocksFolder, "mocks") // if err != nil { // s.logger.Error("Failed to get HTTP mocks", zap.String("testSetID", testSetID.Name()), zap.Error(err)) // return err // } // mocksMapping[service.Name()][testSetID.Name()] = make(map[string]*models.OpenAPI) // for _, mock := range mocks { // mocksMapping[service.Name()][testSetID.Name()][mock
------------------

--- Chunk 4---
Function ValidateSchema (part 3): .Info.Title] = mock // } // } // } // var scores map[string]map[string]map[string]models.SchemaInfo = make(map[string]map[string]map[string]models.SchemaInfo) // for _, entry := range entries { // if entry.IsDir() { // serviceFolder := filepath.Join(downloadTestsFolder, entry.Name()) // testSetIDs, err := os.ReadDir(filepath.Join(serviceFolder, "schema", "tests")) // if err != nil { // s.logger.Error("Failed to read directory", zap.String("directory", serviceFolder), zap.Error(err)) // return err // } // scores[entry.Name()] = make(map[string]map[string]models.SchemaInfo) // for _, testSetID := range testSetIDs { // if !testSetID.IsDir() { // continue // } // tests, err := s.openAPIDB.GetTestCasesSchema(ctx, testSetID.Name(), filepath.Join(serviceFolder, "schema", "tests")) // if err != nil { // s
------------------

--- Chunk 5---
Function ValidateSchema (part 4): .logger.Error("Failed to get test cases", zap.String("testSetID", testSetID.Name()), zap.Error(err)) // return err // } // scores[entry.Name()][testSetID.Name()] = make(map[string]models.SchemaInfo) // for _, test := range tests { // // Take each test and get the ideal mock for it // scores[entry.Name()][testSetID.Name()][test.Info.Title] = models.SchemaInfo{Score: 0.0, Data: *test} // for providerService, mockSetIDs := range mocksMapping { // for mockSetID, mocks := range mockSetIDs { // for _, mock := range mocks { // candidateScore, pass, err := match2(*test, *mock, mockSetID, testSetID.Name(), s.logger, IDENTIFYMODE) // if err != nil { // s.logger.Error("Error in matching the two models", zap.Error(err)) // fmt.Println("test-set-id: ", testSetID.Name(), ", mock-set-id: ", mockSetID) // return
------------------

--- Chunk 6---
Function ValidateSchema (end): err // } // if pass && candidateScore > 0 { // if candidateScore > scores[entry.Name()][testSetID.Name()][test.Info.Title].Score { // idealMock := models.SchemaInfo{ // Service: providerService, // TestSetID: mockSetID, // Name: mock.Info.Title, // Score: candidateScore, // Data: *test, // } // scores[entry.Name()][testSetID.Name()][test.Info.Title] = idealMock // } // } // } // } // } // } // } // } // } // // TODO: Validate the scores and generate a summary return nil }
------------------

--- File: pkg/service/contract/schema.go---

--- Chunk 1---
func validateSchema(openapi models.OpenAPI) error { openapiYAML, err := yamlLib.Marshal(openapi) if err != nil { return err } // Validate using kin-openapi loader := openapi3.NewLoader() doc, err := loader.LoadFromData(openapiYAML) if err != nil { return err } // Validate the OpenAPI document if err := doc.Validate(context.Background()); err != nil { return err } return nil }
------------------

--- Chunk 2---
func (s *contract) GetAllTestsSchema(ctx context.Context) (map[string]map[string]*models.OpenAPI, error) { testsFolder := filepath.Join("./keploy", "schema", "tests") s.openAPIDB.ChangePath(testsFolder) testSetIDs, err := os.ReadDir(testsFolder) if err != nil { return nil, fmt.Errorf("failed to read tests directory: %w", err) } testsMapping := make(map[string]map[string]*models.OpenAPI) for _, testSetID := range testSetIDs { if !testSetID.IsDir() { continue } tests, err := s.openAPIDB.GetTestCasesSchema(ctx, testSetID.Name(), "") if err != nil { return nil, fmt.Errorf("failed to get test cases for testSetID %s: %w", testSetID.Name(), err) } testsMapping[testSetID.Name()] = make(map[string]*models.OpenAPI) for _, test := range tests { testsMapping[testSetID.Name()][test.Info.Title] = test } } return testsMapping, nil }
------------------

--- Chunk 3---
Function GetAllDownloadedMocksSchemas (start): func (s *contract) GetAllDownloadedMocksSchemas(ctx context.Context) ([]models.MockMapping, error) { // ***** TODO: See what part can be moved to DB layer ***** downloadMocksFolder := filepath.Join("./Download", "Mocks") // Read the contents of the Download Mocks folder to get all service directories. entries, err := os.ReadDir(downloadMocksFolder) if err != nil { // If there's an error reading the directory, return it. return nil, fmt.Errorf("failed to read mocks directory: %w", err) } var mocksSchemasMapping []models.MockMapping // Loop over each entry in the Download Mocks folder. for _, entry := range entries { // Check if the entry is a directory (indicating a service folder). if entry.IsDir() { // Define the path to the service folder (e.g., Download/Mocks/service-name). serviceFolder := filepath.Join(downloadMocksFolder, entry.Name()) // Read the contents of the service folder to get mock set IDs (subdirectories). mockSetIDs, err := os.ReadDir(serviceFolder) if err != nil { // If there's an error reading
------------------

--- Chunk 4---
Function GetAllDownloadedMocksSchemas (end): the service folder, return it. return nil, fmt.Errorf("failed to read service directory %s: %w", serviceFolder, err) } // Loop over each mock set ID in the service folder. for _, mockSetID := range mockSetIDs { // Ensure the mock set ID is a directory. if !mockSetID.IsDir() { continue } // Retrieve the mocks for the given mock set ID (e.g., schema files in the folder). mocks, err := s.openAPIDB.GetMocksSchemas(ctx, mockSetID.Name(), serviceFolder, "schema") if err != nil { // If there's an error retrieving mocks, return it. return nil, fmt.Errorf("failed to get HTTP mocks for mockSetID %s: %w", mockSetID.Name(), err) } mocksSchemasMapping = append(mocksSchemasMapping, models.MockMapping{ Service: entry.Name(), TestSetID: mockSetID.Name(), Mocks: mocks, }) } } } return mocksSchemasMapping, nil }
------------------

--- File: pkg/service/contract/utils.go---

--- Chunk 1---
Function ExtractVariableTypes (start): func ExtractVariableTypes(obj map[string]interface{}) map[string]map[string]interface{} { types := make(map[string]map[string]interface{}, len(obj)) getType := func(value interface{}) string { switch value.(type) { case float64: return "number" case int, int32, int64: return "integer" case string: return "string" case bool: return "boolean" case map[string]interface{}: return "object" case []interface{}: return "array" default: return "string" } } for key, value := range obj { valueType := getType(value) responseType := map[string]interface{}{ "type": valueType, } switch valueType { case "object": responseType["properties"] = ExtractVariableTypes(value.(map[string]interface{})) case "array": arrayItems := value.([]interface{}) arrayType := "string" // Default to string if array is empty if len(arrayItems) > 0 { firstElement := arrayItems[0] arrayType = getType(firstElement) if arrayType == "object" { responseType["items"] =
------------------

--- Chunk 2---
Function ExtractVariableTypes (end): map[string]interface{}{ "type": arrayType, "properties": ExtractVariableTypes(firstElement.(map[string]interface{})), } types[key] = responseType continue } } responseType["items"] = map[string]interface{}{ "type": arrayType, } } types[key] = responseType } return types }
------------------

--- Chunk 3---
func GenerateResponse(response Response) map[string]models.ResponseItem { byCode := map[string]models.ResponseItem{ fmt.Sprintf("%d", response.Code): { Description: response.Message, Content: map[string]models.MediaType{ "application/json": { Schema: models.Schema{ Type: "object", Properties: response.Types, }, Example: (response.Body), }, }, }, } return byCode }
------------------

--- Chunk 4---
func ExtractURLPath(URL string) (string, string) { parsedURL, err := url.Parse(URL) if err != nil { return "", "" } return parsedURL.Path, parsedURL.Host }
------------------

--- Chunk 5---
func GenerateHeader(header map[string]string) []models.Parameter { var parameters []models.Parameter for key, value := range header { parameters = append(parameters, models.Parameter{ Name: key, In: "header", Required: true, Schema: models.ParamSchema{Type: "string"}, Example: value, }) } return parameters }
------------------

--- Chunk 6---
func isNumeric(s string) bool { if _, err := strconv.Atoi(s); err == nil { return true } if _, err := strconv.ParseFloat(s, 64); err == nil { return true } return false }
------------------

--- Chunk 7---
func ExtractIdentifiers(path string) []string { segments := strings.Split(path, "/") segments2 := strings.Split(segments[len(segments)-1], "?") segments = append(segments[:len(segments)-1], segments2[0]) var identifiers []string for _, segment := range segments { if segment != "" { // Check if the segment is numeric (integer or float) if isNumeric(segment) { identifiers = append(identifiers, segment) } } } return identifiers }
------------------

--- Chunk 8---
func ExtractQueryParams(rawURL string) (map[string]string, error) { parsedURL, err := url.Parse(rawURL) if err != nil { return nil, err } queryParams := parsedURL.Query() params := make(map[string]string) for key, values := range queryParams { if len(values) > 0 { // Take the first value if multiple are present params[key] = values[0] } } return params, nil }
------------------

--- Chunk 9---
func GenerateDummyNamesForIdentifiers(identifiers []string) map[string]string { dummyNames := make(map[string]string) for i, id := range identifiers { dummyName := fmt.Sprintf("param%d", i+1) dummyNames[dummyName] = id } return dummyNames }
------------------

--- Chunk 10---
func AppendInParameters(parameters []models.Parameter, inParameters map[string]string, paramType string) []models.Parameter { for key, value := range inParameters { parameters = append(parameters, models.Parameter{ Name: key, In: paramType, Required: true, Schema: models.ParamSchema{Type: "string"}, Example: value, }) } return parameters }
------------------

--- Chunk 11---
func ReplacePathIdentifiers(path string, dummyNames map[string]string) string { segments := strings.Split(path, "/") var replacedPath []string for _, segment := range segments { if segment != "" { // Check if the segment is numeric (integer or float) if isNumeric(segment) { dummyName := "" for key, value := range dummyNames { if value == segment { // i want to put '{' and '}' around the key dummyName = "{" + key + "}" break } } if dummyName != "" { replacedPath = append(replacedPath, dummyName) } else { replacedPath = append(replacedPath, segment) } } else { replacedPath = append(replacedPath, segment) } } } finalPath := strings.Join(replacedPath, "/") // Add slash at the beginning of the path finalPath = "/" + finalPath return finalPath }
------------------

--- Chunk 12---
func generateUniqueID() string { b := make([]byte, 16) _, err := rand.Read(b) if err != nil { // handle error return "" } return hex.EncodeToString(b) + "-" + time.Now().Format("20060102150405") }
------------------

--- Chunk 13---
func checkConfigFile(servicesMapping map[string][]string) error { // Check if the size of servicesMapping is less than 1 if len(servicesMapping) < 1 { return fmt.Errorf("services mapping must contain at least 1 services") } return nil }
------------------

--- Chunk 14---
func saveServiceMappings(servicesMapping config.Mappings, filePath string) error { // Marshal the services mapping to YAML servicesMappingYAML, err := yamlLib.Marshal(servicesMapping) if err != nil { return fmt.Errorf("failed to marshal services mapping: %w", err) } // Write the services mapping to the specified file path err = yaml.WriteFile(context.Background(), zap.NewNop(), filePath, "serviceMappings", servicesMappingYAML, false) if err != nil { return fmt.Errorf("failed to write services mapping to file: %w", err) } return nil }
------------------

--- File: pkg/service/embed/ai_client.go---

--- Chunk 1---
func NewAIClient(cfg *config.Config, logger *zap.Logger, auth service.Auth) (*AIClient, error) { apiKey := os.Getenv("API_KEY") if apiKey == "" { return nil, fmt.Errorf("API key not found. Please set API_KEY environment variable") } return &AIClient{ cfg: cfg, logger: logger, apiKey: apiKey, Auth: auth, }, nil }
------------------

--- Chunk 2---
Function GenerateResponse (start): func (ac *AIClient) GenerateResponse(ctx context.Context, prompt *Prompt) (string, error) { apiBaseURL := "https://api.openai.com/v1" if ac.cfg.Embed.LLMBaseURL != "" { apiBaseURL = ac.cfg.Embed.LLMBaseURL } if strings.Contains(apiBaseURL, "keploy.io") { token, err := ac.getKeployToken(ctx) if err != nil { return "", fmt.Errorf("error getting Keploy token: %v", err) } ac.logger.Debug("Making AI request to Keploy API server", zap.String("api_server_url", apiBaseURL)) aiRequest := KeployAIRequest{ Prompt: *prompt, SessionID: uuid.NewString(), } aiRequestBytes, err := json.Marshal(aiRequest) if err != nil { return "", fmt.Errorf("error marshalling Keploy AI request: %v", err) } req, err := http.NewRequestWithContext(ctx, "POST", apiBaseURL+"/ai/call", bytes.NewBuffer(aiRequestBytes)) if err != nil { return "", fmt.Errorf("error creating
------------------

--- Chunk 3---
Function GenerateResponse (part 2): request for Keploy AI: %v", err) } req.Header.Set("Content-Type", "application/json") req.Header.Set("Authorization", "Bearer "+token) client := &http.Client{} resp, err := client.Do(req) if err != nil { return "", fmt.Errorf("error making request to Keploy AI: %v", err) } defer resp.Body.Close() bodyBytes, _ := io.ReadAll(resp.Body) if resp.StatusCode != http.StatusOK { return "", fmt.Errorf("unexpected status code from Keploy AI: %v, response body: %s", resp.StatusCode, string(bodyBytes)) } var aiResponse KeployAIResponse err = json.Unmarshal(bodyBytes, &aiResponse) if err != nil { return "", fmt.Errorf("error unmarshalling Keploy AI response body: %v", err) } if !aiResponse.IsSuccess { return "", fmt.Errorf("Keploy AI service returned an error: %s", aiResponse.Error) } return ac.unmarshalYAML(aiResponse.FinalContent) } model := ac.cfg.Embed.Model if model == "" {
------------------

--- Chunk 4---
Function GenerateResponse (part 3): model = "gpt-4o" } messages := []Message{ {Role: "system", Content: prompt.System}, {Role: "user", Content: prompt.User}, } requestBody, err := json.Marshal(map[string]interface{}{ "model": model, "messages": messages, "temperature": 0.7, }) if err != nil { return "", fmt.Errorf("error marshalling request body: %v", err) } queryParams := "" if ac.cfg.Embed.LLMApiVersion != "" { queryParams = "?api-version=" + ac.cfg.Embed.LLMApiVersion } req, err := http.NewRequestWithContext(ctx, "POST", apiBaseURL+"/chat/completions"+queryParams, bytes.NewBuffer(requestBody)) if err != nil { return "", fmt.Errorf("error creating request: %v", err) } req.Header.Set("Content-Type", "application/json") req.Header.Set("Authorization", "Bearer "+ac.apiKey) req.Header.Set("api-key", ac.apiKey) client := &http.Client{} resp, err := client.Do(req) if err != nil { return "", fmt.Errorf("error
------------------

--- Chunk 5---
Function GenerateResponse (end): making request: %v", err) } defer resp.Body.Close() if resp.StatusCode != http.StatusOK { bodyBytes, _ := io.ReadAll(resp.Body) bodyString := string(bodyBytes) return "", fmt.Errorf("unexpected status code: %v, response body: %s", resp.StatusCode, bodyString) } responseData, err := io.ReadAll(resp.Body) if err != nil { return "", fmt.Errorf("error reading response: %v", err) } var completionResponse CompletionResponse err = json.Unmarshal(responseData, &completionResponse) if err != nil { return "", fmt.Errorf("error unmarshalling response: %v", err) } if len(completionResponse.Choices) == 0 { return "", fmt.Errorf("no choices returned from AI") } response := completionResponse.Choices[0].Message.Content return ac.unmarshalYAML(response) }
------------------

--- Chunk 6---
func (ac *AIClient) getKeployToken(ctx context.Context) (string, error) { if ac.Auth == nil { return "", fmt.Errorf("Auth is not configured for Keploy token retrieval") } return ac.Auth.GetToken(ctx) }
------------------

--- Chunk 7---
func (ac *AIClient) unmarshalYAML(response string) (string, error) { var data map[string]interface{} err := yaml.Unmarshal([]byte(response), &data) if err != nil { ac.logger.Debug("Response is not a YAML, returning as is.", zap.String("response", response)) return response, nil } return response, nil }
------------------

--- File: pkg/service/embed/assets/settings.go---

--- Chunk 1---
func GetSettings() *toml.Tree { settingsOnce.Do(func() { data, err := assets.ReadFile("ai_chat.toml") if err != nil { panic("failed to read embedded toml file: " + err.Error()) } settings, err = toml.Load(string(data)) if err != nil { panic("failed to parse embedded toml file: " + err.Error()) } }) return settings }
------------------

--- File: pkg/service/embed/chunker.go---

--- Chunk 1---
func PrintChunks(chunks map[int]string) { keys := make([]int, 0, len(chunks)) for k := range chunks { keys = append(keys, k) } sort.Ints(keys) for _, k := range keys { chunkCode := chunks[k] fmt.Printf("Chunk %d:\n", k) fmt.Println("=" + strings.Repeat("=", 39)) fmt.Println(chunkCode) fmt.Println("=" + strings.Repeat("=", 39)) } }
------------------

--- Chunk 2---
func ConsolidateChunksIntoFile(chunks map[int]string) string { keys := make([]int, 0, len(chunks)) for k := range chunks { keys = append(keys, k) } sort.Ints(keys) var builder strings.Builder for i, k := range keys { if i > 0 { builder.WriteString("\n") } builder.WriteString(chunks[k]) } return builder.String() }
------------------

--- Chunk 3---
func CountLinesInConsolidated(consolidatedChunks string) int { if consolidatedChunks == "" { return 0 } return strings.Count(consolidatedChunks, "\n") + 1 }
------------------

--- Chunk 4---
func NewCodeChunker(fileExtension string, encodingName string) *CodeChunker { if encodingName == "" { encodingName = "cl100k_base" } return &CodeChunker{ fileExtension: fileExtension, encodingName: encodingName, } }
------------------

--- Chunk 5---
Function Chunk (start): func (cc *CodeChunker) Chunk(parser *CodeParser, rootNode *sitter.Node, code string, tokenLimit int) (map[int]string, error) { if parser == nil { return nil, fmt.Errorf("code parser is nil") } if rootNode == nil { return nil, fmt.Errorf("root AST node is nil") } if code == "" { return map[int]string{}, nil } pointsOfInterest, err := parser.ExtractPointsOfInterest(rootNode, cc.fileExtension) if err != nil { return nil, fmt.Errorf("failed to get points of interest (ext: %s): %w", cc.fileExtension, err) } // Sort POIs by their start line to process the file in order. sort.Slice(pointsOfInterest, func(i, j int) bool { return pointsOfInterest[i].Node.StartPoint().Row < pointsOfInterest[j].Node.StartPoint().Row }) chunks := make(map[int]string) chunkNumber := 1 // Process each function/method as a block. for _, poi := range pointsOfInterest { // Process the POI block itself. blockContent := poi.Node.Content([]byte(code)) token
------------------

--- Chunk 6---
Function Chunk (end): Count, err := CountTokens(blockContent, cc.encodingName) if err != nil { return nil, fmt.Errorf("error counting tokens for a block: %w", err) } if tokenCount <= tokenLimit { // The entire block fits into a single chunk. if strings.TrimSpace(blockContent) != "" { chunks[chunkNumber] = blockContent chunkNumber++ } } else { // The block is too large; split it by token count. functionName := parser.ExtractSymbolName(poi.Node, []byte(code)) splitOversizedBlock(blockContent, tokenLimit, cc.encodingName, &chunks, &chunkNumber, functionName) } } return chunks, nil }
------------------

--- Chunk 7---
Function splitOversizedBlock (start): func splitOversizedBlock(blockContent string, tokenLimit int, encodingName string, chunks *map[int]string, chunkNumber *int, functionName string) { tke, err := tiktoken.EncodingForModel(encodingName) if err != nil { tke, _ = tiktoken.GetEncoding("cl100k_base") } allTokens := tke.Encode(blockContent, nil, nil) partNumber := 1 for start := 0; start < len(allTokens); { end := start + tokenLimit if end > len(allTokens) { end = len(allTokens) } chunkTokens := allTokens[start:end] chunkContentBytes := tke.Decode(chunkTokens) chunkContent := string(chunkContentBytes) isLast := end == len(allTokens) var header string if partNumber == 1 { header = fmt.Sprintf("Function %s (start):\n", functionName) } else if isLast { header = fmt.Sprintf("Function %s (end):\n", functionName) } else { header = fmt.Sprintf("Function %s (part %d):\n", functionName, partNumber) } (*chunks
------------------

--- Chunk 8---
Function splitOversizedBlock (end): )[*chunkNumber] = header + chunkContent *chunkNumber++ partNumber++ start = end } }
------------------

--- Chunk 9---
func (cc *CodeChunker) GetChunk(chunkedCodebase map[int]string, chunkNumber int) (string, bool) { chunk, ok := chunkedCodebase[chunkNumber] return chunk, ok }
------------------

--- File: pkg/service/embed/codeparser.go---

--- Chunk 1---
func NewCodeParser() (*CodeParser, error) { cp := &CodeParser{ languages: make(map[string]*sitter.Language), } cp.languages["go"] = golang.GetLanguage() return cp, nil }
------------------

--- Chunk 2---
func (cp *CodeParser) ParseCode(code string, fileExtension string) (*sitter.Node, error) { languageName, ok := languageExtensionMap[fileExtension] if !ok { return nil, fmt.Errorf("unsupported file type: %s. Supported extensions: go", fileExtension) } lang, ok := cp.languages[languageName] if !ok || lang == nil { return nil, fmt.Errorf("language parser for %s (extension: %s) not loaded", languageName, fileExtension) } parser := sitter.NewParser() parser.SetLanguage(lang) tree, err := parser.ParseCtx(context.Background(), nil, []byte(code)) if err != nil { return nil, fmt.Errorf("failed to parse code (ext: %s): %w", fileExtension, err) } if tree == nil { return nil, fmt.Errorf("failed to parse the code (ext: %s), tree is nil", fileExtension) } return tree.RootNode(), nil }
------------------

--- Chunk 3---
func (cp *CodeParser) getNodeTypesOfInterest(fileExtension string) (map[string]string, error) { types, ok := nodeTypesOfInterestData[fileExtension] if !ok { return nil, fmt.Errorf("unsupported file type for points of interest: %s. Supported: py, js, go", fileExtension) } return types, nil }
------------------

--- Chunk 4---
func (cp *CodeParser) ExtractPointsOfInterest(rootNode *sitter.Node, fileExtension string) ([]PointOfInterest, error) { lang, ok := cp.languages[languageExtensionMap[fileExtension]] if !ok { return nil, fmt.Errorf("language not supported for query: %s", fileExtension) } // Query for functions and methods queryStr := ` (function_declaration) @func (method_declaration) @func` q, err := sitter.NewQuery([]byte(queryStr), lang) if err != nil { return nil, fmt.Errorf("failed to create query: %w", err) } qc := sitter.NewQueryCursor() qc.Exec(q, rootNode) var points []PointOfInterest for { m, ok := qc.NextMatch() if !ok { break } for _, c := range m.Captures { label := "Function" if c.Node.Type() == "method_declaration" { label = "Method" } points = append(points, PointOfInterest{Node: c.Node, Label: label}) } } return points, nil }
------------------

--- Chunk 5---
func (cp *CodeParser) getNodesForComments(fileExtension string) (map[string]string, error) { types, ok := nodesForCommentsData[fileExtension] if !ok { return nil, fmt.Errorf("unsupported file type for comments: %s. Supported: py, js, go", fileExtension) } return types, nil }
------------------

--- Chunk 6---
func (cp *CodeParser) ExtractComments(node *sitter.Node, fileExtension string) ([]PointOfInterest, error) { commentMap, err := cp.getNodesForComments(fileExtension) if err != nil { return nil, err } var comments []PointOfInterest var recurse func(n *sitter.Node) recurse = func(n *sitter.Node) { if n == nil { return } nodeType := n.Type() if label, ok := commentMap[nodeType]; ok { comments = append(comments, PointOfInterest{Node: n, Label: label}) } for i := 0; i < int(n.ChildCount()); i++ { recurse(n.Child(i)) } } recurse(node) return comments, nil }
------------------

--- Chunk 7---
func (cp *CodeParser) ExtractSymbolName(node *sitter.Node, code []byte) string { var nameNode *sitter.Node nodeType := node.Type() switch nodeType { case "function_definition", "class_definition": // Python nameNode = node.ChildByFieldName("name") case "function_declaration", "class_declaration": // JavaScript nameNode = node.ChildByFieldName("name") case "method_declaration": // Go nameNode = node.ChildByFieldName("name") case "type_declaration": typeSpecNode := node.ChildByFieldName("type") if typeSpecNode != nil { nameNode = node.ChildByFieldName("name") } } if nameNode != nil { return nameNode.Content(code) } // Fallback for Go function declarations where the name is directly a child if nodeType == "function_declaration" { nameNode = node.ChildByFieldName("name") if nameNode != nil { return nameNode.Content(code) } } return "" }
------------------

--- File: pkg/service/embed/embed.go---

--- Chunk 1---
Function NewEmbedService (start): func NewEmbedService( cfg *config.Config, tel Telemetry, auth service.Auth, logger *zap.Logger, ) (*EmbedService, error) { ctx := context.Background() databaseURL := cfg.Embed.DatabaseURL if databaseURL == "" { databaseURL = os.Getenv("KEPLOY_EMBED_DATABASE_URL") } if databaseURL == "" { databaseURL = os.Getenv("DATABASE_URL") } if databaseURL == "" { return nil, fmt.Errorf("database URL not configured. Set KEPLOY_EMBED_DATABASE_URL environment variable or configure in config file") } conn, err := pgx.Connect(ctx, databaseURL) if err != nil { return nil, fmt.Errorf("failed to connect to database: %w", err) } // Enable vector extension _, err = conn.Exec(ctx, "CREATE EXTENSION IF NOT EXISTS vector") if err != nil { logger.Warn("Failed to create vector extension", zap.Error(err)) } // Register pgvector types err = pgxvector.RegisterTypes(ctx, conn) if err != nil { return nil, fmt.Errorf("failed to register pgvector types: %w", err) } // Initialize the shared code parser
------------------

--- Chunk 2---
Function NewEmbedService (end): once. parser, err := NewCodeParser() if err != nil { return nil, fmt.Errorf("failed to initialize shared code parser: %w", err) } return &EmbedService{ cfg: cfg, logger: logger, auth: auth, tel: tel, pgConn: conn, parser: parser, allChunks: make(map[string]map[int]string), }, nil }
------------------

--- Chunk 3---
func (e *EmbedService) Start(ctx context.Context) error { e.tel.GenerateEmbedding() select { case <-ctx.Done(): return fmt.Errorf("process cancelled by user") default: } sourcePath := e.cfg.Embed.SourcePath if sourcePath == "" { sourcePath = "." } e.logger.Info("Starting embedding generation", zap.String("sourcePath", sourcePath)) // Check if source path is a file or directory fileInfo, err := os.Stat(sourcePath) if err != nil { return fmt.Errorf("failed to stat source path: %w", err) } if fileInfo.IsDir() { // Process directory using streaming approach err = e.processDirectoryStreaming(ctx, sourcePath) } else { // Process single file err = e.processSingleFile(ctx, sourcePath) } if err != nil { return err } if err := e.writeChunksToFile(); err != nil { e.logger.Error("Failed to write chunks to file", zap.Error(err)) } return nil }
------------------

--- Chunk 4---
Function writeChunksToFile (start): func (e *EmbedService) writeChunksToFile() error { cwd, err := os.Getwd() if err != nil { return fmt.Errorf("failed to get current working directory: %w", err) } outputFile, err := os.Create(filepath.Join(cwd, "chunks.txt")) if err != nil { return fmt.Errorf("failed to create chunks.txt: %w", err) } defer outputFile.Close() e.mu.Lock() defer e.mu.Unlock() // Sort file paths for consistent output filePaths := make([]string, 0, len(e.allChunks)) for path := range e.allChunks { filePaths = append(filePaths, path) } sort.Strings(filePaths) for _, path := range filePaths { chunks := e.allChunks[path] if _, err := outputFile.WriteString(fmt.Sprintf("--- File: %s---\n\n", path)); err != nil { return err } // Sort chunk IDs for consistent output chunkIDs := make([]int, 0, len(chunks)) for id := range chunks { chunkIDs = append(chunkIDs, id) } sort.Ints(chunkIDs) for _, id := range
------------------

--- Chunk 5---
Function writeChunksToFile (end): chunkIDs { content := chunks[id] header := fmt.Sprintf("--- Chunk %d---\n", id) separator := "------------------\n\n" if _, err := outputFile.WriteString(header + content + "\n" + separator); err != nil { return err } } } e.logger.Info("Successfully wrote generated chunks to chunks.txt") return nil }
------------------

--- Chunk 6---
func (e *EmbedService) ProcessCodeWithAST(rootNode *sitter.Node, code string, fileExtension string, tokenLimit int, filePath string) (map[int]string, error) { // Create a code chunker for the specific file extension chunker := NewCodeChunker(fileExtension, "cl100k_base") // Chunk the code chunks, err := chunker.Chunk(e.parser, rootNode, code, tokenLimit) if err != nil { e.logger.Error("Failed to chunk code", zap.Error(err)) return nil, fmt.Errorf("failed to chunk code: %w", err) } logFields := []zap.Field{zap.Int("numChunks", len(chunks))} if filePath != "" { logFields = append(logFields, zap.String("filePath", filePath)) } e.logger.Info("Code chunking completed", logFields...) // Clean chunks by removing \n and \t characters cleanedChunks := e.cleanChunks(chunks) return cleanedChunks, nil }
------------------

--- Chunk 7---
func (e *EmbedService) ProcessCode(code string, fileExtension string, tokenLimit int) (map[int]string, error) { rootNode, err := e.parser.ParseCode(code, fileExtension) if err != nil { e.logger.Warn("Failed to parse code in ProcessCode", zap.Error(err)) return nil, fmt.Errorf("failed to parse code: %w", err) } return e.ProcessCodeWithAST(rootNode, code, fileExtension, tokenLimit, "") }
------------------

--- Chunk 8---
func (e *EmbedService) cleanChunks(chunks map[int]string) map[int]string { cleanedChunks := make(map[int]string) for chunkID, content := range chunks { // Normalize all Unicode whitespace (including newlines and tabs) into single spaces. // This is a more robust and efficient approach than multiple replacements. cleanedContent := strings.Join(strings.Fields(content), " ") cleanedChunks[chunkID] = cleanedContent e.logger.Debug("Cleaned chunk", zap.Int("chunkID", chunkID), zap.Int("originalLength", len(content)), zap.Int("cleanedLength", len(cleanedContent))) } return cleanedChunks }
------------------

--- Chunk 9---
Function GenerateEmbeddings (start): func (e *EmbedService) GenerateEmbeddings(chunks map[int]string, filePath string) error { e.logger.Info("Generating and storing embeddings for chunks", zap.Int("numChunks", len(chunks)), zap.String("filePath", filePath)) ctx := context.Background() if err := e.initializeDatabase(ctx); err != nil { return fmt.Errorf("failed to initialize database: %w", err) } if len(chunks) == 0 { return nil } var results []EmbeddingResult // To keep order, since maps are unordered. sortedChunkIDs := make([]int, 0, len(chunks)) for chunkID := range chunks { sortedChunkIDs = append(sortedChunkIDs, chunkID) } sort.Ints(sortedChunkIDs) const batchSize = 32 // Process chunks in batches to manage memory for i := 0; i < len(sortedChunkIDs); i += batchSize { end := i + batchSize if end > len(sortedChunkIDs) { end = len(sortedChunkIDs) } batchIDs := sortedChunkIDs[i:end] batchContents := make([]string, 0, len(batchIDs)) validChunkIDs
------------------

--- Chunk 10---
Function GenerateEmbeddings (part 2): := make([]int, 0, len(batchIDs)) for _, chunkID := range batchIDs { chunkContent := chunks[chunkID] if strings.TrimSpace(chunkContent) == "" { e.logger.Warn("Skipping empty chunk", zap.Int("chunkID", chunkID), zap.String("filePath", filePath)) continue } batchContents = append(batchContents, chunkContent) validChunkIDs = append(validChunkIDs, chunkID) } if len(batchContents) == 0 { continue } embeddings, err := e.callAIService(batchContents) if err != nil { e.logger.Error("Failed to generate embeddings for batch", zap.String("filePath", filePath), zap.Error(err)) continue // Continue with the next batch } if len(embeddings) != len(batchContents) { e.logger.Error("Mismatch in number of embeddings returned for batch", zap.Int("expected", len(batchContents)), zap.Int("received", len(embeddings)), zap.String("filePath", filePath)) continue // Continue with the next batch } for j, embedding := range embeddings { results
------------------

--- Chunk 11---
Function GenerateEmbeddings (end): = append(results, EmbeddingResult{ FilePath: filePath, ChunkID: validChunkIDs[j], Content: batchContents[j], Embedding: embedding, }) } } if err := e.storeEmbeddingsBatch(ctx, results); err != nil { e.logger.Error("Failed to store embeddings batch for file", zap.String("filePath", filePath), zap.Error(err)) return err } e.logger.Info("Embedding generation and storage completed successfully for file", zap.String("filePath", filePath)) return nil }
------------------

--- Chunk 12---
func (e *EmbedService) readSourceFile(sourcePath string) (string, error) { content, err := os.ReadFile(sourcePath) if err != nil { return "", fmt.Errorf("failed to read file %s: %w", sourcePath, err) } return string(content), nil }
------------------

--- Chunk 13---
func (e *EmbedService) getFileExtension(filePath string) string { ext := strings.ToLower(strings.TrimPrefix(filepath.Ext(filePath), ".")) switch ext { case "py", "python": return "py" case "js", "javascript", "ts", "typescript": return "js" case "go": return "go" default: e.logger.Warn("Unsupported file extension, defaulting to 'go'", zap.String("extension", ext)) return "go" } }
------------------

--- Chunk 14---
func (e *EmbedService) getTokenLimit() int { return 256 }
------------------

--- Chunk 15---
Function shouldSkipDirectory (start): func (e *EmbedService) shouldSkipDirectory(dirPath string) bool { dirName := filepath.Base(dirPath) // List of directories to skip skipDirs := map[string]bool{ "node_modules": true, ".git": true, ".svn": true, ".hg": true, "vendor": true, "target": true, "build": true, "dist": true, "out": true, ".vscode": true, ".idea": true, ".gradle": true, ".mvn": true, "__pycache__": true, ".pytest_cache": true, ".tox": true, "coverage": true, "test-results": true, "bin": true, "obj": true, ".next": true, ".nuxt": true, ".output": true, "tmp": true, "temp": true, } return skipDirs[dir
------------------

--- Chunk 16---
Function shouldSkipDirectory (end): Name] }
------------------

--- Chunk 17---
Function processDirectoryStreaming (start): func (e *EmbedService) processDirectoryStreaming(ctx context.Context, dirPath string) error { e.logger.Info("Processing directory for embeddings (streaming)", zap.String("directory", dirPath)) if err := e.initializeDatabase(ctx); err != nil { return fmt.Errorf("failed to initialize database: %w", err) } // 1. Collect all file paths to process. var filePaths []string walkErr := filepath.Walk(dirPath, func(path string, info os.FileInfo, err error) error { if err != nil { e.logger.Warn("Error accessing path, skipping", zap.String("path", path), zap.Error(err)) return nil // Continue walking even if one path fails. } if ctx.Err() != nil { return ctx.Err() } if info.IsDir() { if e.shouldSkipDirectory(path) { e.logger.Debug("Skipping directory", zap.String("dir", path)) return filepath.SkipDir } return nil } if e.isCodeFile(path) { filePaths = append(filePaths, path) } return nil }) if walkErr != nil { return fmt.Errorf("
------------------

--- Chunk 18---
Function processDirectoryStreaming (part 2): error walking directory to collect files: %w", walkErr) } // Pipeline setup numChunkWorkers := runtime.NumCPU() numEmbeddingWorkers := 4 // Configurable, mindful of API rate limits chunkingJobs := make(chan string, len(filePaths)) chunkChan := make(chan ChunkJob, 100) embeddingJobsChan := make(chan []ChunkJob, numEmbeddingWorkers) dbWriteChan := make(chan EmbeddingResult, 100) var chunkingWg, embeddingWg sync.WaitGroup var totalChunks, totalEmbeddings, totalStored int64 // Stage 1: Chunking Workers for i := 0; i < numChunkWorkers; i++ { chunkingWg.Add(1) go func() { defer chunkingWg.Done() for path := range chunkingJobs { e.processFileForChunking(path, chunkChan, ctx) } }() } // Stage 2: Chunk Batcher go func() { const batchSize = 32 var batch []ChunkJob for chunk := range chunkChan { atomic.AddInt64(&totalChunks, 1) batch =
------------------

--- Chunk 19---
Function processDirectoryStreaming (part 3): append(batch, chunk) if len(batch) >= batchSize { embeddingJobsChan <- batch batch = nil } } if len(batch) > 0 { embeddingJobsChan <- batch } close(embeddingJobsChan) }() // Stage 3: Embedding Workers for i := 0; i < numEmbeddingWorkers; i++ { embeddingWg.Add(1) go func() { defer embeddingWg.Done() for batch := range embeddingJobsChan { results, err := e.processChunkBatchForEmbeddings(batch) if err != nil { e.logger.Error("Failed to process chunk batch for embeddings", zap.Error(err)) continue } atomic.AddInt64(&totalEmbeddings, int64(len(results))) for _, res := range results { dbWriteChan <- res } } }() } // Stage 4: Database Writer var dbWg sync.WaitGroup dbWg.Add(1) go func() { defer dbWg.Done() const dbBatchSize = 128 var dbBatch []EmbeddingResult
------------------

--- Chunk 20---
Function processDirectoryStreaming (part 4): for res := range dbWriteChan { dbBatch = append(dbBatch, res) if len(dbBatch) >= dbBatchSize { if err := e.storeEmbeddingsBatch(ctx, dbBatch); err != nil { e.logger.Error("Failed to store embeddings batch", zap.Error(err)) } atomic.AddInt64(&totalStored, int64(len(dbBatch))) dbBatch = nil } } if len(dbBatch) > 0 { if err := e.storeEmbeddingsBatch(ctx, dbBatch); err != nil { e.logger.Error("Failed to store remaining embeddings batch", zap.Error(err)) } atomic.AddInt64(&totalStored, int64(len(dbBatch))) } }() // Start the pipeline for _, path := range filePaths { chunkingJobs <- path } close(chunkingJobs) // Wait for pipeline to finish chunkingWg.Wait() close(chunkChan) embeddingWg.Wait() close(dbWriteChan) dbWg.Wait() e.logger.Info("Embedding generation completed (streaming)", zap.Int("totalFiles", len(filePaths)), zap.Int64("totalChunksGenerated
------------------

--- Chunk 21---
Function processDirectoryStreaming (end): ", totalChunks), zap.Int64("totalEmbeddingsGenerated", totalEmbeddings), zap.Int64("totalEmbeddingsStored", totalStored)) return nil }
------------------

--- Chunk 22---
Function processFileForChunking (start): func (e *EmbedService) processFileForChunking(path string, chunkChan chan<- ChunkJob, ctx context.Context) { select { case <-ctx.Done(): return default: } e.logger.Debug("Processing file for symbols and chunks", zap.String("file", path)) code, err := e.readSourceFile(path) if err != nil { e.logger.Warn("Failed to read file, skipping", zap.String("file", path), zap.Error(err)) return } fileExt := e.getFileExtension(path) rootNode, err := e.parser.ParseCode(code, fileExt) if err != nil { e.logger.Warn("Failed to parse code, skipping", zap.String("file", path), zap.Error(err)) return } chunks, err := e.ProcessCodeWithAST(rootNode, code, fileExt, e.getTokenLimit(), path) if err != nil { e.logger.Warn("Failed to process and chunk file", zap.String("file", path), zap.Error(err)) return } if len(chunks) > 0 { e.mu.Lock() e.allChunks[path] = chunks e.mu.Unlock() } for chunkID, content := range chunks { select {
------------------

--- Chunk 23---
Function processFileForChunking (end): case chunkChan <- ChunkJob{FilePath: path, ChunkID: chunkID, Content: content}: case <-ctx.Done(): return } } }
------------------

--- Chunk 24---
Function processChunkBatchForEmbeddings (start): func (e *EmbedService) processChunkBatchForEmbeddings(batch []ChunkJob) ([]EmbeddingResult, error) { e.logger.Debug("Processing chunk batch for embedding", zap.Int("batchSize", len(batch))) contents := make([]string, 0, len(batch)) validJobs := make([]ChunkJob, 0, len(batch)) for _, job := range batch { if strings.TrimSpace(job.Content) == "" { e.logger.Warn("Skipping empty chunk in batch", zap.Int("chunkID", job.ChunkID), zap.String("filePath", job.FilePath)) continue } contents = append(contents, job.Content) validJobs = append(validJobs, job) } if len(contents) == 0 { return nil, nil } embeddings, err := e.callAIService(contents) if err != nil { return nil, fmt.Errorf("failed to generate embeddings for batch: %w", err) } if len(embeddings) != len(validJobs) { return nil, fmt.Errorf("mismatch in number of embeddings returned for batch (expected %d, got %d)", len(validJobs), len(embeddings)) } results := make([]EmbeddingResult,
------------------

--- Chunk 25---
Function processChunkBatchForEmbeddings (end): len(validJobs)) for i, embedding := range embeddings { job := validJobs[i] results[i] = EmbeddingResult{ FilePath: job.FilePath, ChunkID: job.ChunkID, Content: job.Content, Embedding: embedding, } } return results, nil }
------------------

--- Chunk 26---
func (e *EmbedService) processSingleFile(_ context.Context, filePath string) error { chunks, err := e.processSingleFileForChunks(filePath) if err != nil { return err } if len(chunks) > 0 { e.mu.Lock() e.allChunks[filePath] = chunks e.mu.Unlock() } return e.GenerateEmbeddings(chunks, filePath) }
------------------

--- Chunk 27---
func (e *EmbedService) processSingleFileForChunks(filePath string) (map[int]string, error) { // Read the file code, err := e.readSourceFile(filePath) if err != nil { return nil, fmt.Errorf("failed to read source file: %w", err) } // Determine file extension fileExt := e.getFileExtension(filePath) // Parse the code once to get the AST rootNode, err := e.parser.ParseCode(code, fileExt) if err != nil { return nil, fmt.Errorf("failed to parse code: %w", err) } // Process the code using chunker chunks, err := e.ProcessCodeWithAST(rootNode, code, fileExt, e.getTokenLimit(), filePath) if err != nil { return nil, fmt.Errorf("failed to process code: %w", err) } return chunks, nil }
------------------

--- Chunk 28---
func (e *EmbedService) isCodeFile(filePath string) bool { ext := strings.ToLower(filepath.Ext(filePath)) codeExtensions := map[string]bool{ ".go": true, ".py": true, ".js": true, } return codeExtensions[ext] }
------------------

--- Chunk 29---
Function initializeDatabase (start): func (e *EmbedService) initializeDatabase(ctx context.Context) error { dropCleanup := ` DROP INDEX IF EXISTS code_embeddings_embedding_idx; DROP TABLE IF EXISTS code_embeddings; ` if _, err := e.pgConn.Exec(ctx, dropCleanup); err != nil { e.logger.Warn("Failed to drop existing index/table", zap.Error(err)) } // Create the vector extension if it doesn't exist. _, err := e.pgConn.Exec(ctx, "CREATE EXTENSION IF NOT EXISTS vector") if err != nil { e.logger.Warn("Failed to create vector extension, it might already exist.", zap.Error(err)) } // Create the table if it doesn't exist. createTableQuery := ` CREATE TABLE IF NOT EXISTS code_embeddings ( id BIGSERIAL PRIMARY KEY, file_path TEXT NOT NULL, chunk_id INTEGER NOT NULL, content TEXT NOT NULL, embedding VECTOR(1536), created_at TIMESTAMP DEFAULT NOW(), UNIQUE(file_path, chunk_id) ) ` _, err = e.pgConn.Exec(ctx, createTableQuery) if err != nil { return fmt.Errorf("failed to create embeddings table: %w", err) } // Create the index if it
------------------

--- Chunk 30---
Function initializeDatabase (end): doesn't exist. indexQuery := ` CREATE INDEX IF NOT EXISTS code_embeddings_embedding_idx ON code_embeddings USING hnsw (embedding vector_cosine_ops) ` _, err = e.pgConn.Exec(ctx, indexQuery) if err != nil { e.logger.Warn("Failed to create vector index, it might already exist.", zap.Error(err)) } return nil }
------------------

--- Chunk 31---
func (e *EmbedService) storeEmbeddingsBatch(ctx context.Context, batch []EmbeddingResult) error { if len(batch) == 0 { return nil } e.logger.Debug("Storing embeddings batch", zap.Int("size", len(batch))) source := pgx.CopyFromRows(func() [][]any { rows := make([][]any, len(batch)) for i, res := range batch { rows[i] = []any{res.FilePath, res.ChunkID, res.Content, pgvector.NewVector(res.Embedding)} } return rows }()) columns := []string{"file_path", "chunk_id", "content", "embedding"} tableName := pgx.Identifier{"code_embeddings"} _, err := e.pgConn.CopyFrom(ctx, tableName, columns, source) if err != nil { return fmt.Errorf("failed to perform bulk insert of embeddings: %w", err) } return nil }
------------------

--- Chunk 32---
Function callAIService (start): func (e *EmbedService) callAIService(contents []string) ([][]float32, error) { modelID := "sentence-transformers/all-MiniLM-L6-v2" if e.cfg.Embed.ModelName != "" { modelID = e.cfg.Embed.ModelName } url := "https://57b1bf57c566.ngrok-free.app/generate_embeddings/" type requestBody struct { Sentences []string `json:"sentences"` } if len(contents) == 0 { return [][]float32{}, nil } reqBody := requestBody{ Sentences: contents, } payload, err := json.Marshal(reqBody) if err != nil { e.logger.Error("Failed to marshal request body", zap.Error(err)) return nil, fmt.Errorf("failed to marshal request: %w", err) } ctx, cancel := context.WithTimeout(context.Background(), 180*time.Second) defer cancel() req, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewBuffer(payload)) if err != nil { e.logger.Error("Failed to create HTTP request", zap.Error(err)) return nil, fmt.Errorf("failed to create request: %w", err) } req.Header.Set
------------------

--- Chunk 33---
Function callAIService (part 2): ("Content-Type", "application/json") client := &http.Client{ Timeout: 180 * time.Second, } e.logger.Debug("Calling local embedding service", zap.String("model", modelID), zap.String("url", url), zap.Int("contentCount", len(contents))) resp, err := client.Do(req) if err != nil { e.logger.Error("HTTP request failed", zap.Error(err)) return nil, fmt.Errorf("HTTP request failed: %w", err) } defer resp.Body.Close() body, err := io.ReadAll(resp.Body) if err != nil { e.logger.Error("Failed to read response body", zap.Error(err)) return nil, fmt.Errorf("failed to read response: %w", err) } e.logger.Debug("Local embedding service response", zap.Int("statusCode", resp.StatusCode)) if resp.StatusCode != http.StatusOK { e.logger.Error("Local embedding service error", zap.Int("statusCode", resp.StatusCode), zap.String("response", string(body))) return nil, fmt.Errorf("API error %d: %s", resp.StatusCode, string(body)) } var response struct { Embeddings [][]float64 `json:"embed
------------------

--- Chunk 34---
Function callAIService (end): dings"` } if err := json.Unmarshal(body, &response); err != nil { e.logger.Error("Failed to decode JSON response", zap.Error(err), zap.String("rawResponse", string(body))) return nil, fmt.Errorf("failed to decode embeddings: %w", err) } if len(response.Embeddings) != len(contents) { return nil, fmt.Errorf("mismatch between number of sentences sent (%d) and embeddings received (%d)", len(contents), len(response.Embeddings)) } finalEmbeddings := make([][]float32, len(contents)) for i := 0; i < len(contents); i++ { finalEmbeddings[i] = convertToFloat32(response.Embeddings[i], e.logger, i) } e.logger.Debug("Successfully generated embeddings", zap.Int("count", len(finalEmbeddings))) return finalEmbeddings, nil }
------------------

--- Chunk 35---
func (e *EmbedService) GenerateEmbeddingsForQ(contents []string) ([][]float32, error) { if len(contents) == 0 { return [][]float32{}, nil } return e.callAIService(contents) }
------------------

--- Chunk 36---
func (e *EmbedService) SearchSimilarCode(ctx context.Context, queryEmbedding []float32, limit int) ([]SearchResult, error) { query := ` SELECT file_path, chunk_id, content, embedding <-> $1 as distance FROM code_embeddings ORDER BY embedding <-> $1 LIMIT $2 ` vector := pgvector.NewVector(queryEmbedding) rows, err := e.pgConn.Query(ctx, query, vector, limit) if err != nil { return nil, fmt.Errorf("failed to search similar code: %w", err) } defer rows.Close() var results []SearchResult for rows.Next() { var result SearchResult err := rows.Scan(&result.FilePath, &result.ChunkID, &result.Content, &result.Distance) if err != nil { return nil, fmt.Errorf("failed to scan result: %w", err) } results = append(results, result) } e.logger.Info("found similar code snippets", zap.Any("results", results)) return results, nil }
------------------

--- Chunk 37---
func (e *EmbedService) Close() error { if e.pgConn != nil { return e.pgConn.Close(context.Background()) } return nil }
------------------

--- Chunk 38---
func convertToFloat32(embedding []float64, logger *zap.Logger, indexInBatch int) []float32 { result := make([]float32, len(embedding)) for i, val := range embedding { if math.IsNaN(val) || math.IsInf(val, 0) { if logger != nil { logger.Warn("Invalid float value in embedding, replacing with 0.0", zap.Int("originalIndexInBatch", indexInBatch), zap.Int("valueIndex", i), zap.Float64("value", val)) } val = 0.0 } result[i] = float32(val) } return result }
------------------

--- Chunk 39---
Function Converse (start): func (e *EmbedService) Converse(ctx context.Context, query string) error { // 1. Generate an embedding for the user's query e.logger.Info("Generating embedding for query", zap.String("query", query)) queryEmbeddings, err := e.GenerateEmbeddingsForQ([]string{query}) if err != nil { return fmt.Errorf("failed to generate embedding for query: %w", err) } if len(queryEmbeddings) == 0 { return fmt.Errorf("received no embedding for the query") } queryEmbedding := queryEmbeddings[0] // 2. Find similar code chunks from vector DB e.logger.Info("Searching for similar code chunks in the database") searchResults, err := e.SearchSimilarCode(ctx, queryEmbedding, 10) if err != nil { return fmt.Errorf("failed to search for similar code: %w", err) } // 3. Build context from vector search results var contextBuilder strings.Builder if len(searchResults) == 0 { e.logger.Warn("No relevant code snippets or symbols found for the query.") fmt.Println("I couldn't find any code snippets relevant to your question. Please try rephrasing or
------------------

--- Chunk 40---
Function Converse (end): be more specific.") return nil } for _, res := range searchResults { contextBuilder.WriteString(fmt.Sprintf("--- Code Snippet from file: %s ---\n", res.FilePath)) contextBuilder.WriteString(res.Content) contextBuilder.WriteString("\n---\n\n") } // 4. Construct the final prompt using the new prompt builder promptBuilder := NewPromptBuilder(query, contextBuilder.String(), e.logger) prompt, err := promptBuilder.BuildPrompt("ai_conversation") if err != nil { return fmt.Errorf("failed to build prompt: %w", err) } // 5. Call the LLM and stream the response e.logger.Info("Sending request to LLM for answer generation") aiClient, err := NewAIClient(e.cfg, e.logger, e.auth) if err != nil { return fmt.Errorf("failed to create AI client: %w", err) } response, err := aiClient.GenerateResponse(ctx, prompt) if err != nil { return fmt.Errorf("failed to get response from AI: %w", err) } fmt.Println("\nAI Assistant:") fmt.Println("----------------") fmt.Println(response) fmt.Println("----------------") return nil }
------------------

--- File: pkg/service/embed/prompt_builder.go---

--- Chunk 1---
func NewPromptBuilder(question, codeContext string, logger *zap.Logger) *PromptBuilder { return &PromptBuilder{ Question: question, CodeContext: codeContext, Logger: logger, } }
------------------

--- Chunk 2---
Function BuildPrompt (start): func (pb *PromptBuilder) BuildPrompt(file string) (*Prompt, error) { pb.Logger.Debug("Building prompt for conversation", zap.String("file", file)) variables := map[string]interface{}{ "Question": pb.Question, "CodeContext": pb.CodeContext, } settings := assets.GetSettings() prompt := &Prompt{} val := settings.Get(file + ".system") systemPromptTemplate, _ := val.(string) if systemPromptTemplate == "" { pb.Logger.Error("System prompt template not found", zap.String("templateKey", file+".system")) return nil, fmt.Errorf("system prompt template not found for: %s.system", file) } systemPrompt, err := renderTemplate(systemPromptTemplate, variables) if err != nil { pb.Logger.Error("Error rendering system prompt", zap.Error(err), zap.String("templateKey", file+".system")) return nil, fmt.Errorf("error rendering system prompt: %v", err) } prompt.System = systemPrompt val = settings.Get(file + ".user") userPromptTemplate, _ := val.(string) if userPromptTemplate == "" { pb.Logger.Error("User prompt template not found", zap.String("
------------------

--- Chunk 3---
Function BuildPrompt (end): templateKey", file+".user")) return nil, fmt.Errorf("user prompt template not found for: %s.user", file) } userPrompt, err := renderTemplate(userPromptTemplate, variables) if err != nil { pb.Logger.Error("Error rendering user prompt", zap.Error(err), zap.String("templateKey", file+".user")) return nil, fmt.Errorf("error rendering user prompt: %v", err) } prompt.User = html.UnescapeString(userPrompt) fmt.Print(prompt.User) return prompt, nil }
------------------

--- Chunk 4---
func renderTemplate(templateText string, variables map[string]interface{}) (string, error) { if templateText == "" { return "", fmt.Errorf("template text is empty") } funcMap := template.FuncMap{ "trim": strings.TrimSpace, } tmpl, err := template.New("prompt").Funcs(funcMap).Parse(templateText) if err != nil { return "", fmt.Errorf("error parsing template: %w", err) } var buffer bytes.Buffer err = tmpl.Execute(&buffer, variables) if err != nil { return "", fmt.Errorf("error executing template: %w", err) } return buffer.String(), nil }
------------------

--- File: pkg/service/embed/repo_map.go---

--- Chunk 1---
func NewRepoMap(logger *zap.Logger) *RepoMap { return &RepoMap{ Symbols: make(map[string][]SymbolInfo), logger: logger, } }
------------------

--- Chunk 2---
func (rm *RepoMap) AddSymbol(info SymbolInfo) { rm.mu.Lock() defer rm.mu.Unlock() rm.Symbols[info.Name] = append(rm.Symbols[info.Name], info) }
------------------

--- Chunk 3---
func (rm *RepoMap) AddSymbols(infos []SymbolInfo) { rm.mu.Lock() defer rm.mu.Unlock() for _, info := range infos { rm.Symbols[info.Name] = append(rm.Symbols[info.Name], info) } }
------------------

--- Chunk 4---
func (rm *RepoMap) Save(path string) error { rm.mu.RLock() defer rm.mu.RUnlock() data, err := json.MarshalIndent(rm.Symbols, "", " ") if err != nil { rm.logger.Error("Failed to marshal RepoMap", zap.Error(err)) return err } // Ensure the directory exists dir := filepath.Dir(path) if err := os.MkdirAll(dir, 0755); err != nil { rm.logger.Error("Failed to create directory for RepoMap", zap.String("path", dir), zap.Error(err)) return err } if err := os.WriteFile(path, data, 0644); err != nil { rm.logger.Error("Failed to write RepoMap to file", zap.String("path", path), zap.Error(err)) return err } rm.logger.Info("Successfully saved repository map", zap.String("path", path)) return nil }
------------------

--- Chunk 5---
func (rm *RepoMap) Load(path string) error { rm.mu.Lock() defer rm.mu.Unlock() data, err := os.ReadFile(path) if err != nil { if os.IsNotExist(err) { rm.logger.Info("RepoMap file does not exist, starting with an empty map.", zap.String("path", path)) rm.Symbols = make(map[string][]SymbolInfo) return nil } rm.logger.Error("Failed to read RepoMap file", zap.String("path", path), zap.Error(err)) return err } if err := json.Unmarshal(data, &rm.Symbols); err != nil { rm.logger.Error("Failed to unmarshal RepoMap", zap.String("path", path), zap.Error(err)) return err } rm.logger.Info("Successfully loaded repository map", zap.String("path", path)) return nil }
------------------

--- File: pkg/service/embed/utils.go---

--- Chunk 1---
func CountTokens(text string, encodingName string) (int, error) { tke, err := tiktoken.EncodingForModel(encodingName) if err != nil { tke, err = tiktoken.GetEncoding("cl100k_base") if err != nil { return 0, err } } tokens := tke.Encode(text, nil, nil) return len(tokens), nil }
------------------

--- Chunk 2---
func LoadJSON(jsonFile string, v interface{}) error { data, err := os.ReadFile(jsonFile) if err != nil { return err } return json.Unmarshal(data, v) }
------------------

--- File: pkg/service/export/export.go---

--- Chunk 1---
Function ConvertKeployHTTPToPostmanCollection (start): func ConvertKeployHTTPToPostmanCollection(logger *zap.Logger, http *models.HTTPSchema) map[string]interface{} { var request postmanimport.PostmanRequest var response postmanimport.PostmanResponse // Extract URL from the HTTP schema extractedURL := http.Request.URL parsedURL, err := url.Parse(extractedURL) if err != nil || parsedURL.Hostname() == "" { utils.LogError(logger, err, "error parsing URL") return nil } request.URL = map[string]interface{}{ "raw": parsedURL.String(), "protocol": parsedURL.Scheme, "host": []string{parsedURL.Hostname()}, "port": parsedURL.Port(), "path": []string{strings.TrimLeft(parsedURL.Path, "/")}, "query": http.Request.URLParams, } request.Method = string(http.Request.Method) for key, header := range http.Request.Header { request.Header = append(request.Header, map[string]interface{}{ "key": key, "value": header, }) } if http.Request.Form != nil { formDataArray := []map[string]interface{}{} for _, form :=
------------------

--- Chunk 2---
Function ConvertKeployHTTPToPostmanCollection (part 2): range http.Request.Form { formDataArray = append(formDataArray, map[string]interface{}{ "key": form.Key, "values": form.Values, }) } request.Body.Mode = "formdata" request.Body.Formdata = formDataArray } else { request.Body.Mode = "raw" request.Body.Raw = http.Request.Body } if strings.Contains(http.Request.Header["Content-Type"], "application/json") { request.Body.Options = map[string]interface{}{ "raw": map[string]interface{}{ "headerFamily": "json", "language": "json", }, } } // Extract Response Headers for key, header := range http.Response.Header { response.Header = append(response.Header, map[string]string{ "key": key, "value": header, }) } response.Code = http.Response.StatusCode response.Status = http.Response.StatusMessage response.Body = http.Response.Body response.OriginalRequest = &request response.Name = http.Response.StatusMessage if strings.Contains(http.Response.Header["Content-Type"], "application/json") { request.Body.Options = map[string]interface{}{ "raw": map
------------------

--- Chunk 3---
Function ConvertKeployHTTPToPostmanCollection (end): [string]interface{}{ "headerFamily": "json", "language": "json", }, } } // Extract the last segment of the path as the name pathSegments := strings.Split(strings.Trim(parsedURL.Path, "/"), "/") // Create the name by joining segments with dashes name := strings.Join(pathSegments, "-") return map[string]interface{}{ "name": name, "protocolProfileBehavior": map[string]interface{}{ "disableBodyPruning": true, }, "request": request, "response": []postmanimport.PostmanResponse{response}, } }
------------------

--- Chunk 4---
Function Export (start): func Export(_ context.Context, logger *zap.Logger) error { cwd, err := os.Getwd() if err != nil { utils.LogError(logger, err, "failed to get current working directory") return err } // Correctly format the directory path to include "keploy" keployDir := filepath.Join(cwd, "keploy") // Check if the directory exists if _, err := os.Stat(keployDir); os.IsNotExist(err) { utils.LogError(logger, err, "keploy directory does not exist") return err } dir, err := yaml.ReadDir(keployDir, fs.FileMode(os.O_RDONLY)) if err != nil { utils.LogError(logger, err, "failed to open the directory containing yaml testcases", zap.Any("path", keployDir)) return err } files, err := dir.ReadDir(0) if err != nil { utils.LogError(logger, err, "failed to read the file names of yaml testcases", zap.Any("path", keployDir)) return err } folderName := filepath.Base(cwd) collection := PostmanCollection{ Info: struct { PostmanID string
------------------

--- Chunk 5---
Function Export (part 2): `json:"_postman_id"` Name string `json:"name"` Schema string `json:"schema"` }{ PostmanID: uuid.New().String(), Name: folderName, Schema: "https://schema.getpostman.com/json/collection/v2.0.0/collection.json", }, } for _, v := range files { if v.Name() != "reports" && v.Name() != "testReports" && v.IsDir() { testsDir := filepath.Join(keployDir, v.Name(), "tests") if _, err := os.Stat(testsDir); os.IsNotExist(err) { logger.Info("No tests found. Skipping export.", zap.String("path", testsDir)) continue } // Read the "tests" subfolder testFiles, err := os.ReadDir(testsDir) if err != nil { utils.LogError(logger, err, "failed to read the test files", zap.String("path", testsDir)) continue } keployRequests := make(map[interface{}]int, 0) for _, testFile := range testFiles { if filepath.Ext
------------------

--- Chunk 6---
Function Export (part 3): (testFile.Name()) == ".yaml" { filePath := filepath.Join(testsDir, testFile.Name()) // Read the YAML file data, err := os.ReadFile(filePath) if err != nil { utils.LogError(logger, err, "failed to read the YAML file", zap.String("path", filePath)) continue } if len(data) == 0 { logger.Warn("skippping empty testcase", zap.String("testcase name", testFile.Name())) continue } var testCase *yaml.NetworkTrafficDoc err = yamlLib.Unmarshal(data, &testCase) if err != nil { utils.LogError(logger, err, "failed to unmarshall YAML data") continue } if testCase == nil { logger.Warn("skipping invalid testCase yaml", zap.String("testcase name", testFile.Name())) continue } var httpSchema models.HTTPSchema err = testCase.Spec.Decode(&httpSchema) if err != nil { utils.LogError(logger, err, "failed to decode the HTTP schema") continue } requestJSON := ConvertKeployHTTPToPostmanCollection(logger, &httpSchema) //
------------------

--- Chunk 7---
Function Export (part 4): Convert the requestJSON to a string (assuming it's a map or complex type) requestJSONString, err := json.Marshal(requestJSON) if err != nil { utils.LogError(logger, err, "failed to marshal requestJSON to string") continue } keployRequests[string(requestJSONString)]++ } } var uniqueRequests []interface{} for request := range keployRequests { var curlRequest interface{} err := json.Unmarshal([]byte(request.(string)), &curlRequest) if err != nil { utils.LogError(logger, err, "failed to unmarshal the request JSON") continue } uniqueRequests = append(uniqueRequests, curlRequest) } requestFile := map[string]interface{}{ "name": v.Name(), "item": uniqueRequests, } collection.Items = append(collection.Items, requestFile) } } sort.SliceStable(collection.Items, func(i, j int) bool { return collection.Items[i].(map[string]interface{})["name"].(string) < collection.Items[j].(map[string]interface{})["name"].(string) }) var buf bytes.Buffer encoder := json.NewEncoder
------------------

--- Chunk 8---
Function Export (end): (&buf) encoder.SetEscapeHTML(false) // Disable HTML escaping encoder.SetIndent("", " ") err = encoder.Encode(collection) if err != nil { utils.LogError(logger, err, "failed to encode the Postman collection") return err } outputData := buf.Bytes() if err := os.WriteFile("output.json", outputData, 0644); err != nil { utils.LogError(logger, err, "failed to write the output JSON file") return err } fmt.Println("âœ… Curls successfully exported to output.json ðŸŽ‰") return nil }
------------------

--- File: pkg/service/import/import.go---

--- Chunk 1---
func NewPostmanImporter(ctx context.Context, logger *zap.Logger) *PostmanImporter { return &PostmanImporter{ logger: logger, ctx: ctx, toCapture: true, } }
------------------

--- Chunk 2---
func (pi *PostmanImporter) Import(collectionPath, basePath string) error { if err := pi.validateCollectionPath(collectionPath); err != nil { return err } collectionBytes, err := os.ReadFile(collectionPath) if err != nil { return fmt.Errorf("failed to read Postman collection file: %w", err) } postmanCollection, err := pi.parsePostmanCollection(collectionBytes) if err != nil { return err } pi.validatePostmanSchema(postmanCollection.Info.Schema) globalVariables := pi.extractGlobalVariables(postmanCollection.Variables) // Check for empty responses if basePath is not provided emptyResponsesExist := pi.scanForEmptyResponses(postmanCollection) if emptyResponsesExist { if !pi.promptUserForCapture() { pi.toCapture = false pi.logger.Warn("Few test cases will be skipped as responses are missing from the collection") } } if err := pi.importTestSets(postmanCollection, globalVariables, basePath); err != nil { return err } pi.logger.Info("âœ… Postman Collection Successfully Imported To Keploy Tests ðŸŽ‰") return nil }
------------------

--- Chunk 3---
func (pi *PostmanImporter) validateCollectionPath(path string) error { if path == "" { return fmt.Errorf("path to Postman collection cannot be empty") } if !strings.HasSuffix(path, ".json") { return fmt.Errorf("invalid file type: expected .json Postman collection") } return nil }
------------------

--- Chunk 4---
func (pi *PostmanImporter) parsePostmanCollection(collectionBytes []byte) (*PostmanCollectionStruct, error) { var postmanCollection PostmanCollectionStruct if err := json.Unmarshal(collectionBytes, &postmanCollection); err != nil { return nil, fmt.Errorf("failed to unmarshal Postman collection JSON: %w", err) } return &postmanCollection, nil }
------------------

--- Chunk 5---
func (pi *PostmanImporter) validatePostmanSchema(schema string) { if schema != postmanSchemaVersion { pi.logger.Warn("Postman Collection schema mismatch", zap.String("expected", postmanSchemaVersion), zap.String("actual", schema)) } }
------------------

--- Chunk 6---
func (pi *PostmanImporter) extractGlobalVariables(variables []map[string]interface{}) map[string]string { globalVariables := make(map[string]string) for _, variable := range variables { // Skip disabled variables if variable["disabled"] != nil && variable["disabled"].(bool) { continue } // Extract and validate variable key key, ok := variable["key"].(string) if !ok { pi.logger.Error("Global variable key is not a string", zap.Any("key", variable["key"])) continue } // Extract and validate variable value value, ok := variable["value"].(string) if !ok { pi.logger.Error("Global variable value is not a string", zap.Any("value", variable["value"])) continue } globalVariables[key] = value } // Resolve variable dependencies for key, value := range globalVariables { globalVariables[key] = replaceTemplateVars(value, globalVariables) } return globalVariables }
------------------

--- Chunk 7---
Function sendRequest (start): func (pi *PostmanImporter) sendRequest(req models.HTTPReq, basePath string) (models.HTTPResp, error) { var err error if basePath != "" { req.URL, err = utils.ReplaceBaseURL(req.URL, basePath) if err != nil { pi.logger.Error("failed to replace hostname", zap.Error(err)) return models.HTTPResp{}, err } } httpReq, err := http.NewRequest(string(req.Method), req.URL, strings.NewReader(req.Body)) if err != nil { pi.logger.Error("failed to create HTTP request", zap.Error(err)) return models.HTTPResp{}, err } for key, value := range req.Header { httpReq.Header.Set(key, value) } // add timeout to the request client := &http.Client{ Timeout: 60 * time.Second, } if req.ProtoMajor != 0 || req.ProtoMinor != 0 { httpReq.ProtoMajor = req.ProtoMajor httpReq.ProtoMinor = req.ProtoMinor } resp, err := client.Do(httpReq) if err != nil { pi.logger.Error("failed to send HTTP request", zap.Error(err)) return models
------------------

--- Chunk 8---
Function sendRequest (end): .HTTPResp{}, err } defer func() { if cerr := resp.Body.Close(); cerr != nil { pi.logger.Error("failed to close response body", zap.Error(cerr)) } }() responseBody, err := io.ReadAll(resp.Body) if err != nil { pi.logger.Error("failed to read response body", zap.Error(err)) return models.HTTPResp{}, err } response := models.HTTPResp{ StatusCode: resp.StatusCode, StatusMessage: resp.Status, Header: make(map[string]string), Body: string(responseBody), } for key, value := range resp.Header { response.Header[key] = strings.Join(value, ",") } // Use the response.Body field to avoid unused write error pi.logger.Info("Response Body", zap.String("body", response.Body)) return response, nil }
------------------

--- Chunk 9---
Function importTestSets (start): func (pi *PostmanImporter) importTestSets(collection *PostmanCollectionStruct, globalVariables map[string]string, basePath string) error { cwd, err := os.Getwd() if err != nil { return fmt.Errorf("failed to get current working directory: %w", err) } testCounter := 0 var itemsToProcess []TestData if len(collection.Items.PostmanItems) > 0 { for _, item := range collection.Items.PostmanItems { if len(item.Item) == 0 { continue } testSet := item.Name if item.Name == "" { testSet = pi.generateTestSetName() } testSetPath := filepath.Join(cwd, "keploy", testSet) testsPath := filepath.Join(testSetPath, "tests") for _, testItem := range item.Item { if err := pi.processEmptyResponse(&testItem, globalVariables, basePath); err != nil { return err } if err := pi.writeTestData(testItem, testsPath, globalVariables, &testCounter); err != nil { return fmt.Errorf("failed to write test data: %w", err) } }
------------------

--- Chunk 10---
Function importTestSets (end): testCounter = 0 } } if len(collection.Items.TestDataItems) > 0 { testSetName := pi.generateTestSetName() testSetPath := filepath.Join(cwd, "keploy", testSetName) testsPath := filepath.Join(testSetPath, "tests") itemsToProcess = collection.Items.TestDataItems for _, testItem := range itemsToProcess { if err := pi.processEmptyResponse(&testItem, globalVariables, basePath); err != nil { return err } if err := pi.writeTestData(testItem, testsPath, globalVariables, &testCounter); err != nil { return fmt.Errorf("failed to write test data: %w", err) } } return nil } return nil }
------------------

--- Chunk 11---
func (pi *PostmanImporter) generateTestSetName() string { maxTestSetNumber := 0 files, err := os.ReadDir(filepath.Join("keploy")) if err == nil { for _, file := range files { if file.IsDir() && strings.HasPrefix(file.Name(), testSetNamePrefix) { var testSetNumber int if _, err := fmt.Sscanf(file.Name(), testSetNamePrefix+"%d", &testSetNumber); err == nil && testSetNumber > maxTestSetNumber { maxTestSetNumber = testSetNumber } } } } return fmt.Sprintf("%s%d", testSetNamePrefix, maxTestSetNumber+1) }
------------------

--- Chunk 12---
func (pi *PostmanImporter) scanForEmptyResponses(collection *PostmanCollectionStruct) bool { for _, item := range collection.Items.PostmanItems { for _, testItem := range item.Item { if len(testItem.Response) == 0 { pi.logger.Warn("Empty response found", zap.String("testItem", testItem.Name)) return true } } } for _, testItem := range collection.Items.TestDataItems { if len(testItem.Response) == 0 { pi.logger.Warn("Empty response found", zap.String("testItem", testItem.Name)) return true } } return false }
------------------

--- Chunk 13---
func (pi *PostmanImporter) promptUserForCapture() bool { reader := bufio.NewReader(os.Stdin) fmt.Print("Some responses are empty. We need to hit the server to record these responses. Is your server running? (yes/no): ") response, err := reader.ReadString('\n') if err != nil { pi.logger.Error("Failed to read user input", zap.Error(err)) return false } response = strings.TrimSpace(strings.ToLower(response)) return response == "yes" }
------------------

--- Chunk 14---
Function processEmptyResponse (start): func (pi *PostmanImporter) processEmptyResponse(testItem *TestData, globalVariables map[string]string, basePath string) error { if len(testItem.Response) != 0 { return nil } if !pi.toCapture { pi.logger.Info("Skipping request capture as basePath is not provided") return nil } req := constructRequest(&testItem.Request, globalVariables) if req.URL != "" { resp, err := pi.sendRequest(req, basePath) if err != nil { return fmt.Errorf("failed to send request: %w", err) } var result []map[string]string for key, value := range resp.Header { result = append(result, map[string]string{ "key": key, "value": value, }) } response := PostmanResponse{ Name: "New Request", Body: resp.Body, Status: resp.StatusMessage, Code: resp.StatusCode, OriginalRequest: &testItem.Request, Header: result, } testItem.Response = append(testItem.Response, response) return nil } pi.logger.Error("URL is empty
------------------

--- Chunk 15---
Function processEmptyResponse (end): ", zap.String("testItem", testItem.Name)) return fmt.Errorf("URL is empty") }
------------------

--- Chunk 16---
Function writeTestData (start): func (pi *PostmanImporter) writeTestData(testItem TestData, testsPath string, globalVariables map[string]string, testCounter *int) error { for _, response := range testItem.Response { testName := fmt.Sprintf("test-%d", *testCounter+1) requestSchema := constructRequest(response.OriginalRequest, globalVariables) if response.OriginalRequest == nil { requestSchema = constructRequest(&testItem.Request, globalVariables) } responseSchema := constructResponse(response) testCase := &yaml.NetworkTrafficDoc{ Version: models.GetVersion(), Kind: models.HTTP, Name: testItem.Name, } if err := testCase.Spec.Encode(&models.HTTPSchema{ Request: requestSchema, Response: responseSchema, }); err != nil { return fmt.Errorf("failed to encode test case: %w", err) } testCase.Curl = pkg.MakeCurlCommand(requestSchema) testResultBytes, err := yamlLib.Marshal(testCase) if err != nil { return fmt.Errorf("failed to marshal test result: %w", err) } if err := yaml.WriteFile(pi.ctx, pi.logger
------------------

--- Chunk 17---
Function writeTestData (end): , testsPath, testName, testResultBytes, false); err != nil { return fmt.Errorf("failed to write test result: %w", err) } (*testCounter)++ } return nil }
------------------

--- Chunk 18---
func constructRequest(req *PostmanRequest, variables map[string]string) models.HTTPReq { if req == nil { return models.HTTPReq{} } headers := extractHeaders(req.Header) url := extractURL(req.URL) requestSchema := models.HTTPReq{ URL: replaceTemplateVars(url, variables), Method: models.Method(req.Method), Header: headers, } // Process request body based on mode switch req.Body.Mode { case "raw": requestSchema.Body = req.Body.Raw case "urlencoded": requestSchema.Body = processUrlencodedBody(req.Body.Urlencoded) case "formdata": requestSchema.Form = processFormdataBody(req.Body.Formdata) } return requestSchema }
------------------

--- Chunk 19---
func extractHeaders(headers []map[string]interface{}) map[string]string { headersMap := make(map[string]string) for _, header := range headers { headersMap[header["key"].(string)] = header["value"].(string) } return headersMap }
------------------

--- Chunk 20---
func extractURL(url interface{}) string { switch v := url.(type) { case string: return v case map[string]interface{}: url := v["raw"].(string) return url default: return "" } }
------------------

--- Chunk 21---
func processUrlencodedBody(body []map[string]interface{}) string { keyValues := []string{} for _, item := range body { keyValues = append(keyValues, item["key"].(string)+"="+item["value"].(string)) } return strings.Join(keyValues, "&") }
------------------

--- Chunk 22---
func processFormdataBody(body []map[string]interface{}) []models.FormData { form := []models.FormData{} for _, formData := range body { form = append(form, models.FormData{ Key: formData["key"].(string), Values: []string{formData["value"].(string)}, }) } return form }
------------------

--- Chunk 23---
func constructResponse(res PostmanResponse) models.HTTPResp { headers := make(map[string]string) for _, header := range res.Header { headers[header["key"]] = header["value"] } return models.HTTPResp{ Body: res.Body, StatusMessage: res.Status, StatusCode: res.Code, Header: headers, } }
------------------

--- Chunk 24---
func replaceTemplateVars(input string, variables map[string]string) string { re := regexp.MustCompile(`\{\{\s*(\w+)\s*\}\}`) return re.ReplaceAllStringFunc(input, func(match string) string { submatches := re.FindStringSubmatch(match) if len(submatches) > 1 { if replacement, exists := variables[submatches[1]]; exists { return replacement } } return match }) }
------------------

--- Chunk 25---
func (ic *ItemsContainer) UnmarshalJSON(data []byte) error { var postmanItems []PostmanItem if err := json.Unmarshal(data, &postmanItems); err == nil { ic.PostmanItems = postmanItems } var items []TestData if err := json.Unmarshal(data, &items); err != nil { return err } ic.TestDataItems = items return nil }
------------------

--- Chunk 26---
func (ic ItemsContainer) MarshalJSON() ([]byte, error) { if len(ic.PostmanItems) > 0 { return json.Marshal(ic.PostmanItems) } return json.Marshal(ic.TestDataItems) }
------------------

--- File: pkg/service/orchestrator/orchestrator.go---

--- Chunk 1---
func New(logger *zap.Logger, record record.Service, tools tools.Service, replay replay.Service, config *config.Config) *Orchestrator { return &Orchestrator{ logger: logger, record: record, replay: replay, tools: tools, config: config, } }
------------------

--- File: pkg/service/orchestrator/rerecord.go---

--- Chunk 1---
Function ReRecord (start): func (o *Orchestrator) ReRecord(ctx context.Context) error { // creating error group to manage proper shutdown of all the go routines and to propagate the error to the caller var stopReason string var err error defer func() { select { case <-ctx.Done(): default: err := utils.Stop(o.logger, stopReason) if err != nil { utils.LogError(o.logger, err, "failed to stop recording") } } }() // Get all the testsets testSets, err := o.replay.GetAllTestSetIDs(ctx) if err != nil { errMsg := "Failed to get all testset IDs" utils.LogError(o.logger, err, errMsg) return err } // Check for templates o.checkForTemplates(ctx, testSets) // Sort the testsets to ensure that the testcases are re-recorded in the same order sort.SliceStable(testSets, func(i, j int) bool { return testSets[i] < testSets[j] }) var SelectedTests []string for _, testSet := range testSets { if ctx.Err() != nil { break } if _,
------------------

--- Chunk 2---
Function ReRecord (part 2): ok := o.config.Test.SelectedTests[testSet]; !ok && len(o.config.Test.SelectedTests) != 0 { continue } SelectedTests = append(SelectedTests, testSet) o.logger.Info("Re-recording testcases for the given testset", zap.String("testset", testSet)) // Note: Here we've used child context without cancel to avoid the cancellation of the parent context. // When we use errgroup and get an error from any of the go routines spawned by errgroup, it cancels the parent context. // We don't want to stop the execution if there is an error in any of the test-set recording sessions, it should just skip that test-set and continue with the next one. errGrp, _ := errgroup.WithContext(ctx) recordCtx := context.WithoutCancel(ctx) recordCtx, recordCtxCancel := context.WithCancel(recordCtx) var errCh = make(chan error, 1) var replayErrCh = make(chan error, 1) //Keeping two back-to-back selects is used to not do blocking operation if parent ctx is done select { case <-ctx.Done(): default:
------------------

--- Chunk 3---
Function ReRecord (part 3): errGrp.Go(func() error { defer utils.Recover(o.logger) err := o.record.Start(recordCtx, true) errCh <- err return nil }) } select { case <-ctx.Done(): default: errGrp.Go(func() error { defer utils.Recover(o.logger) allRecorded, err := o.replayTests(recordCtx, testSet) if allRecorded && err == nil { o.logger.Info("Re-recorded testcases successfully for the given testset", zap.String("testset", testSet)) } if !allRecorded { o.logger.Warn("Failed to re-record some testcases", zap.String("testset", testSet)) stopReason = "failed to re-record some testcases" } replayErrCh <- err return nil }) } var err error select { case err = <-errCh: if err != nil { stopReason = "error while starting the recording" utils.LogError(o.logger, err, stopReason, zap.String("testset", testSet)) } case err = <-replayErrCh
------------------

--- Chunk 4---
Function ReRecord (part 4): : if err != nil { stopReason = "error while replaying the testcases" utils.LogError(o.logger, err, stopReason, zap.String("testset", testSet)) } case <-ctx.Done(): } if err == nil || ctx.Err() == nil { // Sleep for 3 seconds to ensure that the recording has completed time.Sleep(3 * time.Second) } recordCtxCancel() // Wait for the recording to stop err = errGrp.Wait() if err != nil { utils.LogError(o.logger, err, "failed to stop re-recording") } // Check if the global context is done after each iteration if ctx.Err() != nil { break } } if stopReason != "" { utils.LogError(o.logger, err, stopReason) return fmt.Errorf("%s", stopReason) } if ctx.Err() != nil { stopReason = "context cancelled" o.logger.Warn("Re-record was cancelled, keploy might have not recorded few test cases") return nil } stopReason = "Re-recorded all the selected testsets successfully" if !
------------------

--- Chunk 5---
Function ReRecord (part 5): o.config.InCi { o.logger.Info("Re-record was successfull. Do you want to remove the older testsets? (y/n)", zap.Any("testsets", SelectedTests)) reader := bufio.NewReader(os.Stdin) input, err := reader.ReadString('\n') if err != nil { o.logger.Warn("Failed to read input. The older testsets will be kept.") return nil } if len(input) == 0 { o.logger.Warn("Empty input. The older testsets will be kept.") return nil } // Trimming the newline character for cleaner switch statement input = input[:len(input)-1] switch input { case "y", "Y": for _, testSet := range SelectedTests { err := o.replay.DeleteTestSet(ctx, testSet) if err != nil { o.logger.Warn("Failed to delete the testset", zap.String("testset", testSet)) } } o.logger.Info("Deleted the older testsets successfully") case "n", "N": o.logger.Info("skipping the deletion of older testsets") default: o.logger.Warn("Invalid
------------------

--- Chunk 6---
Function ReRecord (end): input. The older testsets will be kept.") } } return nil }
------------------

--- Chunk 7---
Function replayTests (start): func (o *Orchestrator) replayTests(ctx context.Context, testSet string) (bool, error) { //replay the recorded testcases tcs, err := o.replay.GetTestCases(ctx, testSet) if err != nil { errMsg := "failed to get all testcases" utils.LogError(o.logger, err, errMsg, zap.String("testset", testSet)) return false, fmt.Errorf("%s", errMsg) } if len(tcs) == 0 { o.logger.Warn("No testcases found for the given testset", zap.String("testset", testSet)) return false, nil } host, port, err := pkg.ExtractHostAndPort(tcs[0].Curl) if err != nil { errMsg := "failed to extract host and port" utils.LogError(o.logger, err, "") o.logger.Debug("", zap.String("curl", tcs[0].Curl)) return false, fmt.Errorf("%s", errMsg) } cmdType := utils.CmdType(o.config.CommandType) var userIP string if utils.IsDockerCmd(cmdType) { host = o.config.ContainerName userIP, err =
------------------

--- Chunk 8---
Function replayTests (part 2): o.record.GetContainerIP(ctx, o.config.AppID) if err != nil { utils.LogError(o.logger, err, "failed to get the app ip") return false, err } } delay := o.config.Test.Delay timeout := time.Duration(120+delay) * time.Second o.logger.Debug("", zap.String("host", host), zap.String("port", port), zap.Any("WaitTimeout", timeout), zap.Any("CommandType", cmdType)) if err := pkg.WaitForPort(ctx, host, port, timeout); err != nil { utils.LogError(o.logger, err, "Waiting for port failed", zap.String("host", host), zap.String("port", port)) return false, err } // Read the template and secret values once per test set testSetConf, err := o.replay.GetTestSetConf(ctx, testSet) if err != nil { o.logger.Debug("failed to read template values") } utils.TemplatizedValues = map[string]interface{}{} utils.SecretValues = map[string]interface{}{} if testSetConf != nil { if testSetConf.Template != nil { utils.TemplatizedValues = testSetConf.Template }
------------------

--- Chunk 9---
Function replayTests (part 3): if testSetConf.Secret != nil { utils.SecretValues = testSetConf.Secret } } allTcRecorded := true var simErr bool for _, tc := range tcs { if ctx.Err() != nil { return false, ctx.Err() } if utils.IsDockerCmd(cmdType) { tc.HTTPReq.URL, err = utils.ReplaceHost(tc.HTTPReq.URL, userIP) if err != nil { utils.LogError(o.logger, err, "failed to replace host to docker container's IP") break } o.logger.Debug("", zap.Any("replaced URL in case of docker env", tc.HTTPReq.URL)) } if o.config.ReRecord.Host != "" { tc.HTTPReq.URL, err = utils.ReplaceHost(tc.HTTPReq.URL, o.config.ReRecord.Host) if err != nil { utils.LogError(o.logger, err, "failed to replace host to provided host by the user") break } } if o.config.ReRecord.Port != 0 { tc.HTTPReq.URL, err = utils.ReplacePort(tc.HTTPReq.URL, strconv.Itoa(int(o.config.ReRecord.Port))) if err !=
------------------

--- Chunk 10---
Function replayTests (end): nil { utils.LogError(o.logger, err, "failed to replace port to provided port by the user") break } } resp, err := pkg.SimulateHTTP(ctx, tc, testSet, o.logger, o.config.Test.APITimeout) if err != nil { utils.LogError(o.logger, err, "failed to simulate HTTP request") if resp == nil { allTcRecorded = false } simErr = true continue // Proceed with the next command } o.logger.Info("Re-recorded the testcase successfully", zap.String("curl", tc.Curl), zap.Any("response", (resp))) } if simErr { return allTcRecorded, fmt.Errorf("got error while simulating HTTP request. Please make sure the related services are up and running") } return allTcRecorded, nil }
------------------

--- Chunk 11---
Function checkForTemplates (start): func (o *Orchestrator) checkForTemplates(ctx context.Context, testSets []string) { // Check if the testcases are already templatized. var nonTemplatized []string for _, testSet := range testSets { if _, ok := o.config.Test.SelectedTests[testSet]; !ok && len(o.config.Test.SelectedTests) != 0 { continue } conf, err := o.replay.GetTestSetConf(ctx, testSet) if err != nil || conf == nil || conf.Template == nil { nonTemplatized = append(nonTemplatized, testSet) } } if len(nonTemplatized) == 0 { return } o.config.Templatize.TestSets = nonTemplatized o.logger.Warn("The following testSets are not templatized. Do you want to templatize them to handle noisy fields?(y/n)", zap.Any("testSets:", nonTemplatized)) reader := bufio.NewReader(os.Stdin) input, err := reader.ReadString('\n') if err != nil { o.logger.Warn("failed to read input. Skipping templatization") } if input == "n\n" ||
------------------

--- Chunk 12---
Function checkForTemplates (end): input == "N\n" { o.logger.Info("skipping templatization") return } if input == "y\n" || input == "Y\n" { if err := o.tools.Templatize(ctx); err != nil { utils.LogError(o.logger, err, "failed to templatize test cases, skipping templatization") } } }
------------------

--- File: pkg/service/record/record.go---

--- Chunk 1---
func New(logger *zap.Logger, testDB TestDB, mockDB MockDB, telemetry Telemetry, instrumentation Instrumentation, testSetConf TestSetConfig, config *config.Config) Service { return &Recorder{ logger: logger, testDB: testDB, mockDB: mockDB, telemetry: telemetry, instrumentation: instrumentation, testSetConf: testSetConf, config: config, } }
------------------

--- Chunk 2---
Function Start (start): func (r *Recorder) Start(ctx context.Context, reRecord bool) error { // creating error group to manage proper shutdown of all the go routines and to propagate the error to the caller errGrp, _ := errgroup.WithContext(ctx) ctx = context.WithValue(ctx, models.ErrGroupKey, errGrp) runAppErrGrp, _ := errgroup.WithContext(ctx) runAppCtx := context.WithoutCancel(ctx) runAppCtx, runAppCtxCancel := context.WithCancel(runAppCtx) hookErrGrp, _ := errgroup.WithContext(ctx) hookCtx := context.WithoutCancel(ctx) hookCtx, hookCtxCancel := context.WithCancel(hookCtx) hookCtx = context.WithValue(hookCtx, models.ErrGroupKey, hookErrGrp) // reRecordCtx, reRecordCancel := context.WithCancel(ctx) // defer reRecordCancel() // Cancel the context when the function returns var stopReason string // defining all the channels and variables required for the record var runAppError models.AppError var appErrChan = make(chan models.AppError, 1) var insertTestErrChan = make(chan error, 10) var insertMockErrChan =
------------------

--- Chunk 3---
Function Start (part 2): make(chan error, 10) var appID uint64 var newTestSetID string var testCount = 0 var mockCountMap = make(map[string]int) // defering the stop function to stop keploy in case of any error in record or in case of context cancellation defer func() { select { case <-ctx.Done(): default: if !reRecord { err := utils.Stop(r.logger, stopReason) if err != nil { utils.LogError(r.logger, err, "failed to stop recording") } } } runAppCtxCancel() err := runAppErrGrp.Wait() if err != nil { utils.LogError(r.logger, err, "failed to stop application") } hookCtxCancel() err = hookErrGrp.Wait() if err != nil { utils.LogError(r.logger, err, "failed to stop hooks") } err = errGrp.Wait() if err != nil { utils.LogError(r.logger, err, "failed to stop recording") } r.telemetry.RecordedTestSuite(newTestSetID, testCount, mockCountMap) }() defer close(app
------------------

--- Chunk 4---
Function Start (part 3): ErrChan) defer close(insertTestErrChan) defer close(insertMockErrChan) newTestSetID, err := r.GetNextTestSetID(ctx) if err != nil { stopReason = "failed to get new test-set id" utils.LogError(r.logger, err, stopReason) return fmt.Errorf("%s", stopReason) } // Create config.yaml if metadata is provided if r.config.Record.Metadata != "" { r.createConfigWithMetadata(ctx, newTestSetID) } //checking for context cancellation as we don't want to start the instrumentation if the context is cancelled select { case <-ctx.Done(): return nil default: } // Instrument will setup the environment and start the hooks and proxy appID, err = r.Instrument(hookCtx) if err != nil { stopReason = "failed to instrument the application" utils.LogError(r.logger, err, stopReason) return fmt.Errorf("%s", stopReason) } r.config.AppID = appID // fetching test cases and mocks from the application and inserting them into the database frames, err := r.GetTestAndMockChans(ctx, appID) if err != nil { stop
------------------

--- Chunk 5---
Function Start (part 4): Reason = "failed to get data frames" utils.LogError(r.logger, err, stopReason) if ctx.Err() == context.Canceled { return err } return fmt.Errorf("%s", stopReason) } errGrp.Go(func() error { for testCase := range frames.Incoming { err := r.testDB.InsertTestCase(ctx, testCase, newTestSetID, true) if err != nil { if ctx.Err() == context.Canceled { continue } insertTestErrChan <- err } else { testCount++ r.telemetry.RecordedTestAndMocks() } } return nil }) errGrp.Go(func() error { for mock := range frames.Outgoing { err := r.mockDB.InsertMock(ctx, mock, newTestSetID) if err != nil { if ctx.Err() == context.Canceled { continue } insertMockErrChan <- err } else { mockCountMap[mock.GetKind()]++ r.telemetry.RecordedTestCaseMock(mock.GetKind()) } } return nil }) if !r.config.E2E
------------------

--- Chunk 6---
Function Start (part 5): { runAppErrGrp.Go(func() error { runAppError = r.instrumentation.Run(runAppCtx, appID, models.RunOptions{}) if runAppError.AppErrorType == models.ErrCtxCanceled { return nil } appErrChan <- runAppError return nil }) } // setting a timer for recording if r.config.Record.RecordTimer != 0 { errGrp.Go(func() error { r.logger.Info("Setting a timer of " + r.config.Record.RecordTimer.String() + " for recording") timer := time.After(r.config.Record.RecordTimer) select { case <-timer: r.logger.Warn("Time up! Stopping keploy") err := utils.Stop(r.logger, "Time up! Stopping keploy") if err != nil { utils.LogError(r.logger, err, "failed to stop recording") return errors.New("failed to stop recording") } case <-ctx.Done(): return nil } return nil }) } // Waiting for the error to occur in any of the go routines select { case appErr := <-appErrChan: switch appErr.AppErrorType
------------------

--- Chunk 7---
Function Start (part 6): { case models.ErrCommandError: stopReason = "error in running the user application, hence stopping keploy" case models.ErrUnExpected: stopReason = "user application terminated unexpectedly hence stopping keploy, please check application logs if this behaviour is not expected" case models.ErrInternal: stopReason = "internal error occured while hooking into the application, hence stopping keploy" case models.ErrAppStopped: stopReason = "user application terminated unexpectedly hence stopping keploy, please check application logs if this behaviour is not expected" r.logger.Warn(stopReason, zap.Error(appErr)) return nil case models.ErrCtxCanceled: return nil case models.ErrTestBinStopped: stopReason = "keploy test mode binary stopped, hence stopping keploy" return nil default: stopReason = "unknown error received from application, hence stopping keploy" } case err = <-insertTestErrChan: stopReason = "error while inserting test case into db, hence stopping keploy" case err = <-insertMockErrChan: stopReason = "error while inserting mock into db, hence stopping keploy" case <-ctx.Done(): return nil
------------------

--- Chunk 8---
Function Start (end): } utils.LogError(r.logger, err, stopReason) return fmt.Errorf("%s", stopReason) }
------------------

--- Chunk 9---
Function Instrument (start): func (r *Recorder) Instrument(ctx context.Context) (uint64, error) { var stopReason string // setting up the environment for recording appID, err := r.instrumentation.Setup(ctx, r.config.Command, models.SetupOptions{Container: r.config.ContainerName, DockerNetwork: r.config.NetworkName, DockerDelay: r.config.BuildDelay}) if err != nil { stopReason = "failed setting up the environment" utils.LogError(r.logger, err, stopReason) return 0, fmt.Errorf("%s", stopReason) } r.config.AppID = appID // checking for context cancellation as we don't want to start the hooks and proxy if the context is cancelled select { case <-ctx.Done(): return appID, nil default: // Starting the hooks and proxy hooks := models.HookOptions{ Mode: models.MODE_RECORD, EnableTesting: r.config.EnableTesting, Rules: r.config.BypassRules, E2E: r.config.E2E, Port: r.config.Port, } err = r.instrumentation.Hook(ctx, appID, hooks) if err != nil {
------------------

--- Chunk 10---
Function Instrument (end): stopReason = "failed to start the hooks and proxy" utils.LogError(r.logger, err, stopReason) if ctx.Err() == context.Canceled { return appID, err } return appID, fmt.Errorf("%s", stopReason) } } return appID, nil }
------------------

--- Chunk 11---
func (r *Recorder) GetTestAndMockChans(ctx context.Context, appID uint64) (FrameChan, error) { incomingOpts := models.IncomingOptions{ Filters: r.config.Record.Filters, BasePath: r.config.Record.BasePath, } incomingChan, err := r.instrumentation.GetIncoming(ctx, appID, incomingOpts) if err != nil { return FrameChan{}, fmt.Errorf("failed to get incoming test cases: %w", err) } outgoingOpts := models.OutgoingOptions{ Rules: r.config.BypassRules, MongoPassword: r.config.Test.MongoPassword, FallBackOnMiss: r.config.Test.FallBackOnMiss, Backdate: time.Now(), } outgoingChan, err := r.instrumentation.GetOutgoing(ctx, appID, outgoingOpts) if err != nil { return FrameChan{}, fmt.Errorf("failed to get outgoing mocks: %w", err) } return FrameChan{ Incoming: incomingChan, Outgoing: outgoingChan, }, nil }
------------------

--- Chunk 12---
func (r *Recorder) RunApplication(ctx context.Context, appID uint64, opts models.RunOptions) models.AppError { return r.instrumentation.Run(ctx, appID, opts) }
------------------

--- Chunk 13---
Function GetNextTestSetID (start): func (r *Recorder) GetNextTestSetID(ctx context.Context) (string, error) { testSetIDs, err := r.testDB.GetAllTestSetIDs(ctx) if err != nil { return "", fmt.Errorf("failed to get test set IDs: %w", err) } if r.config.Record.Metadata == "" { return pkg.NextID(testSetIDs, models.TestSetPattern), nil } r.config.Record.Metadata = utils.TrimSpaces(r.config.Record.Metadata) meta, err := utils.ParseMetadata(r.config.Record.Metadata) if err != nil || meta == nil { return pkg.NextID(testSetIDs, models.TestSetPattern), nil } nameVal, ok := meta["name"] requestedName, isStr := nameVal.(string) if !ok || !isStr || requestedName == "" { return pkg.NextID(testSetIDs, models.TestSetPattern), nil } existingIDs := make(map[string]struct{}, len(testSetIDs)) for _, id := range testSetIDs { existingIDs[id] = struct{}{} } if _, occupied := existingIDs[requestedName]; !occupied { return requestedName, nil } var highestSuffix int namePrefix
------------------

--- Chunk 14---
Function GetNextTestSetID (end): := requestedName + "-" for id := range existingIDs { if !strings.HasPrefix(id, namePrefix) { continue } suffixPart := id[len(namePrefix):] if n, err := strconv.Atoi(suffixPart); err == nil && n > highestSuffix { highestSuffix = n } } newSuffix := highestSuffix + 1 assignedName := fmt.Sprintf("%s-%d", requestedName, newSuffix) r.logger.Warn(fmt.Sprintf( "Test set name '%s' already exists, using '%s' instead. You can change this name if you want.", requestedName, assignedName, )) return assignedName, nil }
------------------

--- Chunk 15---
func (r *Recorder) GetContainerIP(ctx context.Context, id uint64) (string, error) { return r.instrumentation.GetContainerIP(ctx, id) }
------------------

--- Chunk 16---
func (r *Recorder) createConfigWithMetadata(ctx context.Context, testSetID string) { // Parse metadata from the config metadata, err := utils.ParseMetadata(r.config.Record.Metadata) if err != nil { utils.LogError(r.logger, err, "failed to parse metadata", zap.String("metadata", r.config.Record.Metadata)) return } testSet := &models.TestSet{ PreScript: "", PostScript: "", Template: make(map[string]interface{}), Metadata: metadata, } err = r.testSetConf.Write(ctx, testSetID, testSet) if err != nil { utils.LogError(r.logger, err, "Failed to create test-set config file with metadata", zap.String("testSet", testSetID)) return } r.logger.Info("Created test-set config file with metadata") }
------------------

--- File: pkg/service/replay/hooks.go---

--- Chunk 1---
func NewHooks(logger *zap.Logger, cfg *config.Config, tsConfigDB TestSetConfig, storage Storage, auth service.Auth, instrumentation Instrumentation, mock *mock) TestHooks { return &Hooks{ cfg: cfg, logger: logger, tsConfigDB: tsConfigDB, storage: storage, auth: auth, instrumentation: instrumentation, mock: mock, } }
------------------

--- Chunk 2---
func (h *Hooks) SimulateRequest(ctx context.Context, _ uint64, tc *models.TestCase, testSetID string) (interface{}, error) { switch tc.Kind { case models.HTTP: h.logger.Debug("Simulating HTTP request", zap.Any("Test case", tc)) return pkg.SimulateHTTP(ctx, tc, testSetID, h.logger, h.cfg.Test.APITimeout) case models.GRPC_EXPORT: h.logger.Debug("Simulating gRPC request", zap.Any("Test case", tc)) return pkg.SimulateGRPC(ctx, tc, testSetID, h.logger) default: return nil, fmt.Errorf("unsupported test case kind: %s", tc.Kind) } }
------------------

--- Chunk 3---
func (h *Hooks) AfterTestSetRun(ctx context.Context, testSetID string, status bool) error { if h.cfg.Test.DisableMockUpload { return nil } if h.cfg.Test.BasePath != "" { h.logger.Debug("Mocking is disabled when basePath is given", zap.String("testSetID", testSetID), zap.String("basePath", h.cfg.Test.BasePath)) return nil } if !status { return nil } token, err := h.auth.GetToken(ctx) if err != nil || token == "" { h.logger.Error("Failed to Authenticate user, skipping mock upload", zap.Error(err)) return nil } h.mock.setToken(token) err = h.mock.upload(ctx, testSetID) if err != nil { h.logger.Warn("Failed to upload mock, hence skipping", zap.String("testSetID", testSetID), zap.Error(err)) } return nil }
------------------

--- Chunk 4---
Function BeforeTestSetRun (start): func (h *Hooks) BeforeTestSetRun(ctx context.Context, testSetID string) error { if h.cfg.Test.BasePath != "" { h.logger.Debug("Mocking is disabled when basePath is given", zap.String("testSetID", testSetID), zap.String("basePath", h.cfg.Test.BasePath)) return nil } if h.cfg.Test.UseLocalMock { h.logger.Debug("Using local mock file, as UseLocalMock is selected", zap.String("testSetID", testSetID)) return nil } token, err := h.auth.GetToken(ctx) if err != nil { h.logger.Warn("Failed to Authenticate user, continuing with local mock if present", zap.Error(err)) return nil } h.mock.setToken(token) // Check if test-set config is present tsConfig, err := h.tsConfigDB.Read(ctx, testSetID) if err != nil || tsConfig == nil || tsConfig.MockRegistry == nil { h.logger.Debug("test set config for upload mock not found, continuing with local mock", zap.String("testSetID", testSetID), zap.Error(err)) return nil } if tsConfig.MockRegistry.Mock == "" { h
------------------

--- Chunk 5---
Function BeforeTestSetRun (part 2): .logger.Warn("Mock is empty in test-set config, continuing with local mock if present", zap.String("testSetID", testSetID)) return nil } if tsConfig.MockRegistry.App == "" { h.logger.Warn("App name is empty in test-set config, continuing with local mock if present", zap.String("testSetID", testSetID)) return nil } // Check if mock file is already downloaded by previous test runs localMockPath := filepath.Join(h.cfg.Path, testSetID, "mocks.yaml") mockContent, err := os.ReadFile(localMockPath) if err == nil { if tsConfig.MockRegistry.Mock == utils.Hash(mockContent) { h.logger.Debug("Mock file already exists, downloading from cloud is not necessary", zap.String("testSetID", testSetID), zap.String("mockPath", localMockPath)) return nil } } if tsConfig.MockRegistry.App != h.cfg.AppName { h.logger.Warn("App name in the keploy.yml does not match with the app name in the config.yml in the test-set", zap.String("test-set-config-AppName", tsConfig.MockRegistry.App), zap.String("global-config-Appname",
------------------

--- Chunk 6---
Function BeforeTestSetRun (part 3): h.cfg.AppName)) h.logger.Warn("Using app name from the test-set's config.yml for mock retrieval", zap.String("appName", tsConfig.MockRegistry.App)) } h.logger.Info("Downloading mock file from cloud...", zap.String("testSetID", testSetID)) cloudFile, err := h.storage.Download(ctx, tsConfig.MockRegistry.Mock, tsConfig.MockRegistry.App, tsConfig.MockRegistry.User, token) if err != nil { h.logger.Error("Failed to download mock file", zap.Error(err)) return err } // Save the downloaded mock file to local file, err := os.Create(localMockPath) if err != nil { h.logger.Error("Failed to create local file", zap.String("path", localMockPath), zap.Error(err)) return err } defer func() { err := file.Close() if err != nil { utils.LogError(h.logger, err, "failed to close the http response body") } }() done := make(chan struct{}) // Spinner goroutine go func() { spinnerChars := []rune{'|', '/', '-', '\\'} i := 0 for { select { case <-done
------------------

--- Chunk 7---
Function BeforeTestSetRun (end): : fmt.Print("\r") // Clear spinner line after done return default: fmt.Printf("\rDownloading... %c", spinnerChars[i%len(spinnerChars)]) i++ time.Sleep(100 * time.Millisecond) } } }() _, err = io.Copy(file, cloudFile) if err != nil { close(done) return err } close(done) h.logger.Info("Mock file downloaded successfully") err = utils.AddToGitIgnore(h.logger, h.cfg.Path, "/*/mocks.yaml") if err != nil { utils.LogError(h.logger, err, "failed to add /*/mocks.yaml to .gitignore file") } return nil }
------------------

--- Chunk 8---
func (h *Hooks) AfterTestRun(_ context.Context, testRunID string, testSetIDs []string, coverage models.TestCoverage) error { h.logger.Debug("AfterTestRun hook executed", zap.String("testRunID", testRunID), zap.Any("testSetIDs", testSetIDs), zap.Any("coverage", coverage)) return nil }
------------------

--- Chunk 9---
func (h *Hooks) GetConsumedMocks(ctx context.Context, id uint64) ([]models.MockState, error) { consumedMocks, err := h.instrumentation.GetConsumedMocks(ctx, id) if err != nil { h.logger.Error("failed to get consumed mocks", zap.Error(err)) return nil, err } return consumedMocks, nil }
------------------

--- Chunk 10---
func extractClaimsWithoutVerification(tokenString string) (jwt.MapClaims, error) { token, _, err := new(jwt.Parser).ParseUnverified(tokenString, jwt.MapClaims{}) if err != nil { return nil, err } if claims, ok := token.Claims.(jwt.MapClaims); ok { return claims, nil } return nil, fmt.Errorf("unable to parse claims") }
------------------

--- Chunk 11---
Function getLatestPlan (start): func getLatestPlan(ctx context.Context, logger *zap.Logger, serverUrl, token string) (string, error) { logger.Debug("Getting the latest plan", zap.String("serverUrl", serverUrl), zap.String("token", token)) req, err := http.NewRequestWithContext(ctx, "GET", fmt.Sprintf("%s/subscription/plan", serverUrl), nil) if err != nil { logger.Error("failed to create request", zap.Error(err)) return "", fmt.Errorf("failed to get plan") } req.Header.Set("Authorization", "Bearer "+token) req.Header.Set("Content-Type", "application/json") client := &http.Client{} resp, err := client.Do(req) if err != nil { logger.Error("http request failed", zap.Error(err)) return "", fmt.Errorf("failed to get plan") } defer func() { if cerr := resp.Body.Close(); cerr != nil { logger.Error("failed to close response body", zap.Error(cerr)) } }() body, err := io.ReadAll(resp.Body) if err != nil { logger.Error("failed to read response body", zap.Error(err)) return "", fmt.Errorf("failed to get plan") } var res getPlanRes if
------------------

--- Chunk 12---
Function getLatestPlan (end): err := json.Unmarshal(body, &res); err != nil { logger.Error("failed to unmarshal response", zap.Error(err)) return "", fmt.Errorf("failed to get plan") } if resp.StatusCode != http.StatusOK { logger.Error("non-200 response from subscription/plan", zap.Int("status", resp.StatusCode), zap.String("api_error", res.Error)) if res.Error != "" { return "", fmt.Errorf("%s", res.Error) } return "", fmt.Errorf("failed to get plan") } if res.Plan.Type == "" { logger.Error("plan type missing in successful response", zap.Any("plan", res.Plan)) return "", fmt.Errorf("plan not found") } return res.Plan.Type, nil }
------------------

--- File: pkg/service/replay/mock.go---

--- Chunk 1---
func (m *mock) setToken(token string) { m.token = token }
------------------

--- Chunk 2---
Function download (start): func (m *mock) download(ctx context.Context, testSetID string) error { // Check if test-set config is present tsConfig, err := m.tsConfigDB.Read(ctx, testSetID) if err != nil || tsConfig == nil || tsConfig.MockRegistry == nil { m.logger.Error("test set mock config not found", zap.String("testSetID", testSetID), zap.Error(err)) return fmt.Errorf("mock registry config not found") } if tsConfig.MockRegistry.Mock == "" { m.logger.Error("Mock is empty in test-set config", zap.String("testSetID", testSetID)) return fmt.Errorf("mock is empty in test-set config") } if tsConfig.MockRegistry.App == "" { m.logger.Warn("App name is empty in test-set config", zap.String("testSetID", testSetID)) return fmt.Errorf("app name is empty in test-set config") } // Check if mock file is already downloaded by previous test runs localMockPath := filepath.Join(m.cfg.Path, testSetID, "mocks.yaml") mockContent, err := os.ReadFile(localMockPath) if err == nil { if tsConfig.MockRegistry.Mock ==
------------------

--- Chunk 3---
Function download (part 2): utils.Hash(mockContent) { m.logger.Info("Mock file already exists, downloading from cloud is not necessary", zap.String("testSetID", testSetID), zap.String("mockPath", localMockPath)) return nil } var response string if len(mockContent) == 0 { m.logger.Warn("Local mock file is empty, proceeding with download from keploy registry", zap.String("testSetID", testSetID)) response = "y" } else { m.logger.Warn("Local mock file is different from the one in the Keploy registry.") // Prompt user for confirmation to override the local mock file fmt.Print("The mock file present locally is different from the one in the Keploy registry. Do you want to override the local mock file with the version from the registry? (y/n): ") } // Create a channel to listen for context cancellation (Ctrl+C) cancelChan := make(chan struct{}) // Start a goroutine to wait for user input asynchronously go func() { if len(mockContent) == 0 { cancelChan <- struct{}{} return } _, err
------------------

--- Chunk 4---
Function download (part 3): := fmt.Scanln(&response) if err != nil { response = "n" // Default to 'no' if there's an error reading input } cancelChan <- struct{}{} }() select { case <-cancelChan: // Normalize user input response = strings.ToLower(strings.TrimSpace(response)) if response != "y" && response != "yes" { m.logger.Info("Keeping the local mock file", zap.String("testSetID", testSetID)) return nil } m.logger.Info("Overriding the local mock file with the version from the Keploy registry", zap.String("testSetID", testSetID)) case <-ctx.Done(): // context cancellation (Ctrl+C) m.logger.Warn("Download interrupted by user") return ctx.Err() // Return the context cancellation error } } if tsConfig.MockRegistry.App != m.cfg.AppName { m.logger.Warn("App name in the keploy.yml does not match with the app name in the config.yml in the test-set", zap.String("test-set-config-AppName", tsConfig.MockRegistry.App), zap.String("global-config-Appname", m.cfg.AppName))
------------------

--- Chunk 5---
Function download (part 4): m.logger.Warn("Using app name from the test-set's config.yml for mock retrieval", zap.String("appName", tsConfig.MockRegistry.App)) } m.logger.Info("Downloading mock file from cloud...", zap.String("testSetID", testSetID)) cloudFile, err := m.storage.Download(ctx, tsConfig.MockRegistry.Mock, tsConfig.MockRegistry.App, tsConfig.MockRegistry.User, m.token) if err != nil { m.logger.Error("Failed to download mock file", zap.Error(err)) return err } // Save the downloaded mock file to local file, err := os.Create(localMockPath) if err != nil { m.logger.Error("Failed to create local file", zap.String("path", localMockPath), zap.Error(err)) return err } defer func() { err := file.Close() if err != nil { utils.LogError(m.logger, err, "failed to close the http response body") } }() done := make(chan struct{}) // Spinner goroutine go func() { spinnerChars := []rune{'|', '/', '-', '\\'} i := 0 for { select { case <-done: fmt.Print("\
------------------

--- Chunk 6---
Function download (end): r") // Clear spinner line after done return default: fmt.Printf("\rDownloading... %c", spinnerChars[i%len(spinnerChars)]) i++ time.Sleep(100 * time.Millisecond) } } }() _, err = io.Copy(file, cloudFile) if err != nil { close(done) return err } close(done) m.logger.Info("Mock file downloaded successfully") err = utils.AddToGitIgnore(m.logger, m.cfg.Path, "/*/mocks.yaml") if err != nil { utils.LogError(m.logger, err, "failed to add /*/mocks.yaml to .gitignore file") } return nil }
------------------

--- Chunk 7---
Function upload (start): func (m *mock) upload(ctx context.Context, testSetID string) error { claims, err := extractClaimsWithoutVerification(m.token) var role, username string var ok bool if err != nil { m.logger.Error("Failed to extract claim from token for mock upload", zap.Error(err)) return err } if role, ok = claims["role"].(string); !ok || role == "" { m.logger.Error("Role not found in the token, skipping mock upload") return fmt.Errorf("failed to upload mock file: role not found in the token") } if username, ok = claims["username"].(string); !ok { m.logger.Error("Username not found in the token, skipping mock upload") return fmt.Errorf("failed to upload mock file: username not found in the token") } // get the plan of the current user plan, err := getLatestPlan(ctx, m.logger, m.cfg.APIServerURL, m.token) if err != nil { m.logger.Error("Failed to get latest plan of the user", zap.Error(err)) return err } m.logger.Debug("The latest plan", zap.Any("Plan", plan)) // Inspect
------------------

--- Chunk 8---
Function upload (part 2): local mock file localMockPath := filepath.Join(m.cfg.Path, testSetID, "mocks.yaml") mockFileContent, err := os.ReadFile(localMockPath) if err != nil { m.logger.Error("Failed to read mock file for mock upload", zap.String("path", localMockPath), zap.Error(err)) return err } // If mock file is empty, return error if len(mockFileContent) == 0 { m.logger.Warn("Mock file is empty, skipping upload", zap.String("testSetID", testSetID), zap.String("mockPath", localMockPath)) return nil } mockHash := utils.Hash(mockFileContent) mockFileReader := bytes.NewReader(mockFileContent) // Cross verify the local mock file with the test-set config tsConfig, err := m.tsConfigDB.Read(ctx, testSetID) // If test-set config is not found, upload the mock file if err != nil || tsConfig == nil || tsConfig.MockRegistry == nil { // create ts config var prescript, postscript string var template map[string]interface{} if tsConfig != nil { prescript = tsConfig.PreScript
------------------

--- Chunk 9---
Function upload (part 3): postscript = tsConfig.PostScript template = tsConfig.Template } tsConfig = &models.TestSet{ PreScript: prescript, PostScript: postscript, Template: template, MockRegistry: &models.MockRegistry{ Mock: mockHash, App: m.cfg.AppName, }, } if plan == "Free" { if username == "" { m.logger.Error("Username not found in the token for Free plan") return fmt.Errorf("failed to upload mock file: username not found in the token") } tsConfig.MockRegistry.User = username } m.logger.Info("uploading mock file...", zap.Any("testSet", testSetID)) err = m.storage.Upload(ctx, mockFileReader, mockHash, m.cfg.AppName, m.token) if err != nil { m.logger.Error("Failed to upload mock file", zap.Error(err)) return err } err := m.tsConfigDB.Write(ctx, testSetID, tsConfig) if err != nil { m.logger.Error("Failed to write test set config", zap.Error(err))
------------------

--- Chunk 10---
Function upload (end): return err } return nil } // If mock file is already uploaded, skip the upload if tsConfig.MockRegistry.Mock == mockHash { m.logger.Info("Mock file is already uploaded, skipping upload", zap.String("testSetID", testSetID), zap.String("mockPath", localMockPath)) return nil } // If mock file is changed, upload the new mock file m.logger.Debug("Mock file has changed, uploading new mock", zap.String("testSetID", testSetID), zap.String("mockPath", localMockPath)) m.logger.Info("uploading mock file...", zap.Any("testSet", testSetID)) err = m.storage.Upload(ctx, mockFileReader, mockHash, m.cfg.AppName, m.token) if err != nil { m.logger.Error("Failed to upload mock file", zap.Error(err)) return err } err = utils.AddToGitIgnore(m.logger, m.cfg.Path, "/*/mocks.yaml") if err != nil { utils.LogError(m.logger, err, "failed to add /*/mocks.yaml to .gitignore file") } return nil }
------------------

--- File: pkg/service/replay/replay.go---

--- Chunk 1---
func NewReplayer(logger *zap.Logger, testDB TestDB, mockDB MockDB, reportDB ReportDB, testSetConf TestSetConfig, telemetry Telemetry, instrumentation Instrumentation, auth service.Auth, storage Storage, config *config.Config) Service { // TODO: add some comment. mock := &mock{ cfg: config, storage: storage, logger: logger, tsConfigDB: testSetConf, } // set the request emulator for simulating test case requests, if not set if HookImpl == nil { SetTestHooks(NewHooks(logger, config, testSetConf, storage, auth, instrumentation, mock)) } instrument := config.Command != "" return &Replayer{ logger: logger, testDB: testDB, mockDB: mockDB, reportDB: reportDB, testSetConf: testSetConf, telemetry: telemetry, instrumentation: instrumentation, config: config, instrument: instrument, auth: auth, mock: mock, } }
------------------

--- Chunk 2---
Function Start (start): func (r *Replayer) Start(ctx context.Context) error { // creating error group to manage proper shutdown of all the go routines and to propagate the error to the caller g, ctx := errgroup.WithContext(ctx) ctx = context.WithValue(ctx, models.ErrGroupKey, g) var hookCancel context.CancelFunc var stopReason = "replay completed successfully" // defering the stop function to stop keploy in case of any error in record or in case of context cancellation defer func() { select { case <-ctx.Done(): break default: r.logger.Info("stopping Keploy", zap.String("reason", stopReason)) } if hookCancel != nil { hookCancel() } err := g.Wait() if err != nil { utils.LogError(r.logger, err, "failed to stop replaying") } }() testSetIDs, err := r.testDB.GetAllTestSetIDs(ctx) if err != nil { stopReason = fmt.Sprintf("failed to get all test set ids: %v", err) utils.LogError(r.logger, err, stopReason) return fmt.Errorf("%s", stopReason) } if len
------------------

--- Chunk 3---
Function Start (part 2): (testSetIDs) == 0 { recordCmd := models.HighlightGrayString("keploy record") errMsg := fmt.Sprintf("No test sets found in the keploy folder. Please record testcases using %s command", recordCmd) utils.LogError(r.logger, err, errMsg) return fmt.Errorf("%s", errMsg) } testRunID, err := r.GetNextTestRunID(ctx) if err != nil { stopReason = fmt.Sprintf("failed to get next test run id: %v", err) utils.LogError(r.logger, err, stopReason) return fmt.Errorf("%s", stopReason) } var language config.Language var executable string // only find language to calculate coverage if instrument is true if r.instrument { language, executable = utils.DetectLanguage(r.logger, r.config.Command) // if language is not provided and language detected is known // then set the language to detected language if r.config.Test.Language == "" { if language == models.Unknown { r.logger.Warn("failed to detect language, skipping coverage caluclation. please use --language to manually set the language") r.config.Test.SkipCoverage = true }
------------------

--- Chunk 4---
Function Start (part 3): else { r.logger.Warn(fmt.Sprintf("%s language detected. please use --language to manually set the language if needed", language)) } r.config.Test.Language = language } else if language != r.config.Test.Language && language != models.Unknown { utils.LogError(r.logger, nil, "language detected is different from the language provided") r.config.Test.SkipCoverage = true } } var cov coverage.Service switch r.config.Test.Language { case models.Go: cov = golang.New(ctx, r.logger, r.reportDB, r.config.Command, r.config.Test.CoverageReportPath, r.config.CommandType) case models.Python: cov = python.New(ctx, r.logger, r.reportDB, r.config.Command, executable) case models.Javascript: cov = javascript.New(ctx, r.logger, r.reportDB, r.config.Command) case models.Java: cov = java.New(ctx, r.logger, r.reportDB, r.config.Command, r.config.Test.JacocoAgentPath, executable) default: r.config.Test.SkipCoverage = true } if !r.config.Test.SkipCoverage { if utils.CmdType(r.config.CommandType) == utils.Native { r.config
------------------

--- Chunk 5---
Function Start (part 4): .Command, err = cov.PreProcess(r.config.Test.DisableLineCoverage) if err != nil { r.config.Test.SkipCoverage = true } } err = os.Setenv("CLEAN", "true") // related to javascript coverage calculation if err != nil { r.config.Test.SkipCoverage = true r.logger.Warn("failed to set CLEAN env variable, skipping coverage caluclation", zap.Error(err)) } } // Instrument will load the hooks and start the proxy inst, err := r.Instrument(ctx) if err != nil { stopReason = fmt.Sprintf("failed to instrument: %v", err) utils.LogError(r.logger, err, stopReason) if ctx.Err() == context.Canceled { return err } return fmt.Errorf("%s", stopReason) } hookCancel = inst.HookCancel var testSetResult bool testRunResult := true abortTestRun := false var flakyTestSets []string var testSets []string for _, testSetID := range testSetIDs { if _, ok := r.config.Test.SelectedTests[testSetID]; !ok && len(r.config.Test.Selected
------------------

--- Chunk 6---
Function Start (part 5): Tests) != 0 { continue } testSets = append(testSets, testSetID) } if len(testSets) == 0 { testSets = testSetIDs } // Sort the testsets. natsort.Sort(testSets) for i, testSet := range testSets { testSetResult = false err := HookImpl.BeforeTestSetRun(ctx, testSet) if err != nil { stopReason = fmt.Sprintf("failed to run before test hook: %v", err) utils.LogError(r.logger, err, stopReason) if ctx.Err() == context.Canceled { return err } return fmt.Errorf("%s", stopReason) } if !r.config.Test.SkipCoverage { err = os.Setenv("TESTSETID", testSet) // related to java coverage calculation if err != nil { r.config.Test.SkipCoverage = true r.logger.Warn("failed to set TESTSETID env variable, skipping coverage caluclation", zap.Error(err)) } } // check if its the last testset running - if i == len(testSets)-1 { r
------------------

--- Chunk 7---
Function Start (part 6): .isLastTestSet = true } var ( initTotal, initPassed, initFailed, initIgnored int initTimeTaken time.Duration ) initTotal = totalTests initPassed = totalTestPassed initFailed = totalTestFailed initIgnored = totalTestIgnored initTimeTaken = totalTestTimeTaken var initialFailedTCs map[string]bool flaky := false // only be changed during replay with --must-pass flag set for attempt := 1; attempt <= int(r.config.Test.MaxFlakyChecks); attempt++ { // clearing testcase from map is required for 2 reasons: // 1st: in next attempt, we need to append results in a fresh array, // rather than appending in the old array which would contain outdated tc results. // 2nd: in must-pass mode, we delete the failed testcases from the map // if the array has some failed testcases, which has already been removed, then not cleaning // the array would mean deleting the already deleted failed testcases again (error). r.reportDB.ClearTestCaseResults(ctx, test
------------------

--- Chunk 8---
Function Start (part 7): RunID, testSet) // overwrite with values before testset run, so after all reruns we don't get a cummulative value // gathered from rerunning, instead only metrics from the last rerun would get added to the variables. totalTests = initTotal totalTestPassed = initPassed totalTestFailed = initFailed totalTestIgnored = initIgnored totalTestTimeTaken = initTimeTaken r.logger.Info("running", zap.String("test-set", models.HighlightString(testSet)), zap.Int("attempt", attempt)) testSetStatus, err := r.RunTestSet(ctx, testSet, testRunID, inst.AppID, false) if err != nil { stopReason = fmt.Sprintf("failed to run test set: %v", err) utils.LogError(r.logger, err, stopReason) if ctx.Err() == context.Canceled { return err } return fmt.Errorf("%s", stopReason) } switch testSetStatus { case models.TestSetStatusAppHalted: testSetResult = false abortTestRun = true case models.TestSetStatusInternalErr:
------------------

--- Chunk 9---
Function Start (part 8): testSetResult = false abortTestRun = true case models.TestSetStatusFaultUserApp: testSetResult = false abortTestRun = true case models.TestSetStatusUserAbort: return nil case models.TestSetStatusFailed: testSetResult = false case models.TestSetStatusPassed: testSetResult = true case models.TestSetStatusIgnored: testSetResult = false case models.TestSetStatusNoTestsToRun: testSetResult = false } if testSetStatus != models.TestSetStatusIgnored { testRunResult = testRunResult && testSetResult if abortTestRun { break } } tcResults, err := r.reportDB.GetTestCaseResults(ctx, testRunID, testSet) if err != nil { if testSetStatus != models.TestSetStatusNoTestsToRun { utils.LogError(r.logger, err, "failed to get testcase results") } break } failedTcIDs := getFailedTCs(tcResults) failedTCsBySetID[testSet] = failedTcIDs
------------------

--- Chunk 10---
Function Start (part 9): // checking for flakiness when --must-pass flag is not set // else if --must-pass is set, delete the failed testcases and rerun if !r.config.Test.MustPass { // populate the map only once at first iteration for flakiness test if attempt == 1 { initialFailedTCs = make(map[string]bool) for _, id := range failedTcIDs { initialFailedTCs[id] = true } continue } // checking if there is no mismatch in failed testcases across max retries // check both length and value if len(failedTcIDs) != len(initialFailedTCs) { utils.LogError(r.logger, nil, "the testset is flaky, rerun the testset with --must-pass flag to remove flaky testcases", zap.String("testSet", testSet)) // don't run more attempts if the testset is flaky flakyTestSets = append(flakyTestSets, testSet) break } for _, id := range failedTcIDs { if _, ok := initialFailedTCs[id
------------------

--- Chunk 11---
Function Start (part 10): ]; !ok { flaky = true utils.LogError(r.logger, nil, "the testset is flaky, rerun the testset with --must-pass flag to remove flaky testcases", zap.String("testSet", testSet)) break } } if flaky { // don't run more attempts if the testset is flaky flakyTestSets = append(flakyTestSets, testSet) break } continue } // this would be executed only when --must-pass flag is set // we would be removing failed testcases if r.config.Test.MaxFailAttempts == 0 { utils.LogError(r.logger, nil, "no. of testset failure occured during rerun reached maximum limit, testset still failing, increase count of maxFailureAttempts", zap.String("testSet", testSet)) break } if len(failedTcIDs) == 0 { // if no testcase failed in this attempt move to next attempt continue } r.logger.Info("deleting failing testcases", zap.String("testSet", testSet), zap.Any
------------------

--- Chunk 12---
Function Start (part 11): ("testCaseIDs", failedTcIDs)) if err := r.testDB.DeleteTests(ctx, testSet, failedTcIDs); err != nil { utils.LogError(r.logger, err, "failed to delete failing testcases", zap.String("testSet", testSet), zap.Any("testCaseIDs", failedTcIDs)) break } // after deleting rerun it maxFlakyChecks times to be sure that no further testcase fails // and if it does then delete those failing testcases and rerun it again maxFlakyChecks times r.config.Test.MaxFailAttempts-- attempt = 0 } if abortTestRun { break } err = HookImpl.AfterTestSetRun(ctx, testSet, testSetResult) if err != nil { utils.LogError(r.logger, err, "failed to execute after test set run hook", zap.Any("testSet", testSet)) } if i == 0 && !r.config.Test.SkipCoverage { err = os.Setenv("CLEAN", "false") // related to javascript coverage calculation if err != nil { r.config.Test.SkipCoverage = true r.logger
------------------

--- Chunk 13---
Function Start (part 12): .Warn("failed to set CLEAN env variable, skipping coverage caluclation.", zap.Error(err)) } err = os.Setenv("APPEND", "--append") // related to python coverage calculation if err != nil { r.config.Test.SkipCoverage = true r.logger.Warn("failed to set APPEND env variable, skipping coverage caluclation.", zap.Error(err)) } } } if !r.config.Test.SkipCoverage && r.config.Test.Language == models.Java { err = java.MergeAndGenerateJacocoReport(ctx, r.logger) if err != nil { r.config.Test.SkipCoverage = true } } if len(flakyTestSets) > 0 { r.logger.Warn("flaky testsets detected, please rerun the specific testsets with --must-pass flag to remove flaky testcases", zap.Any("testSets", flakyTestSets)) } testRunStatus := "fail" if testRunResult { testRunStatus = "pass" } if testRunResult && r.config.Test.DisableMockUpload { r.logger.Warn("To enable storing mocks in cloud, please use --disableMockUpload=false flag or test:disableMockUpload:false
------------------

--- Chunk 14---
Function Start (part 13): in config file") } r.telemetry.TestRun(totalTestPassed, totalTestFailed, len(testSets), testRunStatus) if !abortTestRun { r.printSummary(ctx, testRunResult) coverageData := models.TestCoverage{} var err error if !r.config.Test.SkipCoverage { r.logger.Info("calculating coverage for the test run and inserting it into the report") coverageData, err = cov.GetCoverage() if err == nil { r.logger.Sugar().Infoln(models.HighlightPassingString("Total Coverage Percentage: ", coverageData.TotalCov)) err = cov.AppendCoverage(&coverageData, testRunID) if err != nil { utils.LogError(r.logger, err, "failed to update report with the coverage data") } } else { r.logger.Warn("failed to calculate coverage for the test run", zap.Any("error", err)) } } //executing afterTestRun hook, executed after running all the test-sets err = HookImpl.AfterTestRun(ctx, testRunID, testSets, coverageData) if err != nil { utils.LogError(r.logger, err, "failed
------------------

--- Chunk 15---
Function Start (end): to execute after test run hook") } } // return non-zero error code so that pipeline processes // know that there is a failure in tests if !testRunResult { utils.ErrCode = 1 } return nil }
------------------

--- Chunk 16---
Function Instrument (start): func (r *Replayer) Instrument(ctx context.Context) (*InstrumentState, error) { if !r.instrument { r.logger.Info("Keploy will not mock the outgoing calls when base path is provided", zap.Any("base path", r.config.Test.BasePath)) return &InstrumentState{}, nil } appID, err := r.instrumentation.Setup(ctx, r.config.Command, models.SetupOptions{Container: r.config.ContainerName, DockerNetwork: r.config.NetworkName, DockerDelay: r.config.BuildDelay}) if err != nil { if errors.Is(err, context.Canceled) { return &InstrumentState{}, err } return &InstrumentState{}, fmt.Errorf("failed to setup instrumentation: %w", err) } r.config.AppID = appID var cancel context.CancelFunc // starting the hooks and proxy select { case <-ctx.Done(): return &InstrumentState{}, context.Canceled default: hookCtx := context.WithoutCancel(ctx) hookCtx, cancel = context.WithCancel(hookCtx) err = r.instrumentation.Hook(hookCtx, appID, models.HookOptions{Mode: models.MODE_TEST, EnableTesting: r.config.EnableTesting,
------------------

--- Chunk 17---
Function Instrument (end): Rules: r.config.BypassRules}) if err != nil { cancel() if errors.Is(err, context.Canceled) { return &InstrumentState{}, err } return &InstrumentState{}, fmt.Errorf("failed to start the hooks and proxy: %w", err) } } return &InstrumentState{AppID: appID, HookCancel: cancel}, nil }
------------------

--- Chunk 18---
func (r *Replayer) GetNextTestRunID(ctx context.Context) (string, error) { testRunIDs, err := r.reportDB.GetAllTestRunIDs(ctx) if err != nil { if errors.Is(err, context.Canceled) { return "", err } return "", fmt.Errorf("failed to get all test run ids: %w", err) } return pkg.NextID(testRunIDs, models.TestRunTemplateName), nil }
------------------

--- Chunk 19---
func (r *Replayer) GetAllTestSetIDs(ctx context.Context) ([]string, error) { return r.testDB.GetAllTestSetIDs(ctx) }
------------------

--- Chunk 20---
func (r *Replayer) GetTestCases(ctx context.Context, testID string) ([]*models.TestCase, error) { return r.testDB.GetTestCases(ctx, testID) }
------------------

--- Chunk 21---
Function RunTestSet (start): func (r *Replayer) RunTestSet(ctx context.Context, testSetID string, testRunID string, appID uint64, serveTest bool) (models.TestSetStatus, error) { // creating error group to manage proper shutdown of all the go routines and to propagate the error to the caller runTestSetErrGrp, runTestSetCtx := errgroup.WithContext(ctx) runTestSetCtx = context.WithValue(runTestSetCtx, models.ErrGroupKey, runTestSetErrGrp) runTestSetCtx, runTestSetCtxCancel := context.WithCancel(runTestSetCtx) startTime := time.Now() exitLoopChan := make(chan bool, 2) defer func() { runTestSetCtxCancel() err := runTestSetErrGrp.Wait() if err != nil { utils.LogError(r.logger, err, "error in testLoopErrGrp") } close(exitLoopChan) }() testCases, err := r.testDB.GetTestCases(runTestSetCtx, testSetID) if err != nil { return models.TestSetStatusFailed, fmt.Errorf("failed to get test cases: %w", err) } if len(testCases) ==
------------------

--- Chunk 22---
Function RunTestSet (part 2): 0 { r.logger.Warn("no valid test cases found to run for test set", zap.String("test-set", testSetID)) testReport := &models.TestReport{ Version: models.GetVersion(), TestSet: testSetID, Status: string(models.TestSetStatusNoTestsToRun), Total: 0, Ignored: 0, } err = r.reportDB.InsertReport(runTestSetCtx, testRunID, testSetID, testReport) if err != nil { utils.LogError(r.logger, err, "failed to insert report") return models.TestSetStatusFailed, err } return models.TestSetStatusNoTestsToRun, nil } if _, ok := r.config.Test.IgnoredTests[testSetID]; ok && len(r.config.Test.IgnoredTests[testSetID]) == 0 { testReport := &models.TestReport{ Version: models.GetVersion(), TestSet: testSetID, Status: string(models.TestSetStatusIgnored), Total: len(testCases), Ignored: len(testCases), } err = r.reportDB.InsertReport(run
------------------

--- Chunk 23---
Function RunTestSet (part 3): TestSetCtx, testRunID, testSetID, testReport) if err != nil { utils.LogError(r.logger, err, "failed to insert report") return models.TestSetStatusFailed, err } verdict := TestReportVerdict{ total: testReport.Total, failed: 0, passed: 0, ignored: testReport.Ignored, status: true, duration: time.Duration(0), } completeTestReport[testSetID] = verdict totalTests += testReport.Total totalTestIgnored += testReport.Ignored return models.TestSetStatusIgnored, nil } var conf *models.TestSet conf, err = r.testSetConf.Read(runTestSetCtx, testSetID) if err != nil { if strings.Contains(err.Error(), "no such file or directory") || strings.Contains(err.Error(), "The system cannot find the file specified") { r.logger.Info("test-set config file not found, continuing execution...", zap.String("test-set", testSetID)) } else { return models.TestSetStatusFailed, fmt.Errorf("
------------------

--- Chunk 24---
Function RunTestSet (part 4): failed to read test set config: %w", err) } } if conf == nil { conf = &models.TestSet{} } if conf.PreScript != "" { r.logger.Info("Running Pre-script", zap.String("script", conf.PreScript), zap.String("test-set", testSetID)) err := r.executeScript(runTestSetCtx, conf.PreScript) if err != nil { return models.TestSetStatusFaultScript, fmt.Errorf("failed to execute pre-script: %w", err) } } var appErrChan = make(chan models.AppError, 1) var appErr models.AppError var success int var failure int var ignored int var totalConsumedMocks = map[string]models.MockState{} testSetStatus := models.TestSetStatusPassed testSetStatusByErrChan := models.TestSetStatusRunning cmdType := utils.CmdType(r.config.CommandType) var userIP string filteredMocks, unfilteredMocks, err := r.GetMocks(ctx, testSetID, models.BaseTime, time.Now()) if err != nil { return models.TestSetStatusFailed, err } pkg.InitSortCounter(int64(max(len(filteredMocks), len
------------------

--- Chunk 25---
Function RunTestSet (part 5): (unfilteredMocks)))) err = r.instrumentation.MockOutgoing(runTestSetCtx, appID, models.OutgoingOptions{ Rules: r.config.BypassRules, MongoPassword: r.config.Test.MongoPassword, SQLDelay: time.Duration(r.config.Test.Delay), FallBackOnMiss: r.config.Test.FallBackOnMiss, Mocking: r.config.Test.Mocking, Backdate: testCases[0].HTTPReq.Timestamp, }) if err != nil { utils.LogError(r.logger, err, "failed to mock outgoing") return models.TestSetStatusFailed, err } // filtering is redundant, but we need to set the mocks err = r.FilterAndSetMocks(ctx, appID, filteredMocks, unfilteredMocks, models.BaseTime, time.Now(), totalConsumedMocks) if err != nil { return models.TestSetStatusFailed, err } if r.instrument { if !serveTest { runTestSetErrGrp.Go(func() error { defer utils.Recover(r.logger) appErr = r.RunApplication(runTestSetCtx, appID, models.RunOptions{}) if appErr.AppErrorType == models
------------------

--- Chunk 26---
Function RunTestSet (part 6): .ErrCtxCanceled { return nil } appErrChan <- appErr return nil }) } // Checking for errors in the mocking and application runTestSetErrGrp.Go(func() error { defer utils.Recover(r.logger) select { case err := <-appErrChan: switch err.AppErrorType { case models.ErrCommandError: testSetStatusByErrChan = models.TestSetStatusFaultUserApp case models.ErrUnExpected: testSetStatusByErrChan = models.TestSetStatusAppHalted case models.ErrAppStopped: testSetStatusByErrChan = models.TestSetStatusAppHalted case models.ErrCtxCanceled: return nil case models.ErrInternal: testSetStatusByErrChan = models.TestSetStatusInternalErr default: testSetStatusByErrChan = models.TestSetStatusAppHalted } utils.LogError(r.logger, err, "application failed to run") case <-runTestSetCtx.Done(): testSetStatusByErrChan = models.TestSetStatusUserAbort } exitLoopChan <- true runTestSetCtx
------------------

--- Chunk 27---
Function RunTestSet (part 7): Cancel() return nil }) // Delay for user application to run select { case <-time.After(time.Duration(r.config.Test.Delay) * time.Second): case <-runTestSetCtx.Done(): return models.TestSetStatusUserAbort, context.Canceled } if utils.IsDockerCmd(cmdType) { userIP, err = r.instrumentation.GetContainerIP(ctx, appID) if err != nil { return models.TestSetStatusFailed, err } } } selectedTests := matcherUtils.ArrayToMap(r.config.Test.SelectedTests[testSetID]) ignoredTests := matcherUtils.ArrayToMap(r.config.Test.IgnoredTests[testSetID]) testCasesCount := len(testCases) if len(selectedTests) != 0 { testCasesCount = len(selectedTests) } // Inserting the initial report for the test set testReport := &models.TestReport{ Version: models.GetVersion(), Total: testCasesCount, Status: string(models.TestStatusRunning), } err = r.reportDB.InsertReport(runTestSetCtx, testRunID, testSetID, testReport) if err != nil {
------------------

--- Chunk 28---
Function RunTestSet (part 8): utils.LogError(r.logger, err, "failed to insert report") return models.TestSetStatusFailed, err } // var to exit the loop var exitLoop bool // var to store the error in the loop var loopErr error utils.TemplatizedValues = conf.Template utils.SecretValues = conf.Secret // Add secret files to .gitignore if they exist if len(utils.SecretValues) > 0 { err = utils.AddToGitIgnore(r.logger, r.config.Path, "/*/secret.yaml") if err != nil { r.logger.Warn("Failed to add secret files to .gitignore", zap.Error(err)) } } for idx, testCase := range testCases { // check if its the last test case running if idx == len(testCases)-1 && r.isLastTestSet { r.isLastTestCase = true testCase.IsLast = true } if _, ok := selectedTests[testCase.Name]; !ok && len(selectedTests) != 0 { continue } if _, ok := ignoredTests[testCase.Name]; ok { testCaseResult := &models.TestResult{ Kind:
------------------

--- Chunk 29---
Function RunTestSet (part 9): models.HTTP, Name: testSetID, Status: models.TestStatusIgnored, TestCaseID: testCase.Name, TestCasePath: filepath.Join(r.config.Path, testSetID), MockPath: filepath.Join(r.config.Path, testSetID, "mocks.yaml"), } loopErr = r.reportDB.InsertTestCaseResult(runTestSetCtx, testRunID, testSetID, testCaseResult) if loopErr != nil { utils.LogError(r.logger, err, "failed to insert test case result") break } ignored++ continue } // replace the request URL's BasePath/origin if provided if r.config.Test.BasePath != "" { newURL, err := ReplaceBaseURL(r.config.Test.BasePath, testCase.HTTPReq.URL) if err != nil { r.logger.Warn("failed to replace the request basePath", zap.String("testcase", testCase.Name), zap.String("basePath", r.config.Test.BasePath), zap.Error(err)) } else { testCase.HTTPReq.URL = newURL } r.logger.Debug("test case request origin", zap.String("testcase",
------------------

--- Chunk 30---
Function RunTestSet (part 10): testCase.Name), zap.String("TestCaseURL", testCase.HTTPReq.URL), zap.String("basePath", r.config.Test.BasePath)) } // Checking for errors in the mocking and application select { case <-exitLoopChan: testSetStatus = testSetStatusByErrChan exitLoop = true default: } if exitLoop { break } var testStatus models.TestStatus var testResult *models.Result var testPass bool var loopErr error err = r.FilterAndSetMocks(runTestSetCtx, appID, filteredMocks, unfilteredMocks, testCase.HTTPReq.Timestamp, testCase.HTTPResp.Timestamp, totalConsumedMocks) if err != nil { utils.LogError(r.logger, err, "failed to filter and set mocks") break } // Handle Docker environment IP replacement if utils.IsDockerCmd(cmdType) { err = r.replaceHostInTestCase(testCase, userIP, "docker container's IP") if err != nil { break } } // Handle user-provided host replacement if r.config.Test.Host != "" { err =
------------------

--- Chunk 31---
Function RunTestSet (part 11): r.replaceHostInTestCase(testCase, r.config.Test.Host, "host provided by the user") if err != nil { break } } // Handle user-provided port replacement if r.config.Test.Port != 0 { err = r.replacePortInTestCase(testCase, strconv.Itoa(int(r.config.Test.Port))) if err != nil { break } } started := time.Now().UTC() resp, loopErr := HookImpl.SimulateRequest(runTestSetCtx, appID, testCase, testSetID) if loopErr != nil { utils.LogError(r.logger, loopErr, "failed to simulate request") failure++ testSetStatus = models.TestSetStatusFailed testCaseResult := r.CreateFailedTestResult(testCase, testSetID, started, loopErr.Error()) loopErr = r.reportDB.InsertTestCaseResult(runTestSetCtx, testRunID, testSetID, testCaseResult) if loopErr != nil { utils.LogError(r.logger, loopErr, "failed to insert test case result for simulation error") break } continue } var consumedMocks []models.Mock
------------------

--- Chunk 32---
Function RunTestSet (part 12): State if r.instrument { consumedMocks, err = HookImpl.GetConsumedMocks(runTestSetCtx, appID) if err != nil { utils.LogError(r.logger, err, "failed to get consumed filtered mocks") } for _, m := range consumedMocks { totalConsumedMocks[m.Name] = m } } r.logger.Debug("test case kind", zap.Any("kind", testCase.Kind)) switch testCase.Kind { case models.HTTP: httpResp, ok := resp.(*models.HTTPResp) if !ok { r.logger.Error("invalid response type for HTTP test case") failure++ testSetStatus = models.TestSetStatusFailed testCaseResult := r.CreateFailedTestResult(testCase, testSetID, started, "invalid response type for HTTP test case") loopErr = r.reportDB.InsertTestCaseResult(runTestSetCtx, testRunID, testSetID, testCaseResult) if loopErr != nil { utils.LogError(r.logger, loopErr, fmt.Sprintf("failed to insert test case result for type assertion error in %s test case", testCase.Kind)) break } continue }
------------------

--- Chunk 33---
Function RunTestSet (part 13): testPass, testResult = r.compareHTTPResp(testCase, httpResp, testSetID) case models.GRPC_EXPORT: grpcResp, ok := resp.(*models.GrpcResp) if !ok { r.logger.Error("invalid response type for gRPC test case") failure++ testSetStatus = models.TestSetStatusFailed testCaseResult := r.CreateFailedTestResult(testCase, testSetID, started, "invalid response type for gRPC test case") loopErr = r.reportDB.InsertTestCaseResult(runTestSetCtx, testRunID, testSetID, testCaseResult) if loopErr != nil { utils.LogError(r.logger, loopErr, "failed to insert test case result for type assertion error") break } continue } testPass, testResult = r.compareGRPCResp(testCase, grpcResp, testSetID) } if !testPass { // log the consumed mocks during the test run of the test case for test set r.logger.Info("result", zap.Any("testcase id", models.HighlightFailingString(testCase.Name)), zap.Any("testset id", models.HighlightFailingString
------------------

--- Chunk 34---
Function RunTestSet (part 14): (testSetID)), zap.Any("passed", models.HighlightFailingString(testPass))) r.logger.Debug("Consumed Mocks", zap.Any("mocks", consumedMocks)) } else { r.logger.Info("result", zap.Any("testcase id", models.HighlightPassingString(testCase.Name)), zap.Any("testset id", models.HighlightPassingString(testSetID)), zap.Any("passed", models.HighlightPassingString(testPass))) } if testPass { testStatus = models.TestStatusPassed success++ } else { testStatus = models.TestStatusFailed failure++ testSetStatus = models.TestSetStatusFailed } if testResult != nil { var testCaseResult *models.TestResult switch testCase.Kind { case models.HTTP: httpResp := resp.(*models.HTTPResp) testCaseResult = &models.TestResult{ Kind: models.HTTP, Name: testSetID, Status: testStatus, Started: started.Unix(), Completed: time.Now().UTC().Unix(), TestCaseID: testCase.Name, Req: models.HTTPReq{ Method: testCase
------------------

--- Chunk 35---
Function RunTestSet (part 15): .HTTPReq.Method, ProtoMajor: testCase.HTTPReq.ProtoMajor, ProtoMinor: testCase.HTTPReq.ProtoMinor, URL: testCase.HTTPReq.URL, URLParams: testCase.HTTPReq.URLParams, Header: testCase.HTTPReq.Header, Body: testCase.HTTPReq.Body, Binary: testCase.HTTPReq.Binary, Form: testCase.HTTPReq.Form, Timestamp: testCase.HTTPReq.Timestamp, }, Res: *httpResp, TestCasePath: filepath.Join(r.config.Path, testSetID), MockPath: filepath.Join(r.config.Path, testSetID, "mocks.yaml"), Noise: testCase.Noise, Result: *testResult, } case models.GRPC_EXPORT: grpcResp := resp.(*models.GrpcResp) testCaseResult = &models.TestResult{ Kind: models.GRPC_EXPORT, Name: testSetID, Status: testStatus, Started: started.Unix(), Completed: time.Now().UTC().Unix(), TestCaseID: testCase.Name, GrpcReq:
------------------

--- Chunk 36---
Function RunTestSet (part 16): testCase.GrpcReq, GrpcRes: *grpcResp, TestCasePath: filepath.Join(r.config.Path, testSetID), MockPath: filepath.Join(r.config.Path, testSetID, "mocks.yaml"), Noise: testCase.Noise, Result: *testResult, } } if testCaseResult != nil { loopErr = r.reportDB.InsertTestCaseResult(runTestSetCtx, testRunID, testSetID, testCaseResult) if loopErr != nil { utils.LogError(r.logger, loopErr, "failed to insert test case result") break } } else { utils.LogError(r.logger, nil, "test case result is nil") break } } else { utils.LogError(r.logger, nil, "test result is nil") break } // We need to sleep for a second to avoid mismatching of mocks during keploy testing via test-bench if r.config.EnableTesting { r.logger.Debug("sleeping for a second to avoid mismatching of mocks during keploy testing via test-bench") time.Sleep(time.Second) }
------------------

--- Chunk 37---
Function RunTestSet (part 17): } if conf.PostScript != "" { //Execute the Post-script after each test-set if provided r.logger.Info("Running Post-script", zap.String("script", conf.PostScript), zap.String("test-set", testSetID)) err = r.executeScript(runTestSetCtx, conf.PostScript) if err != nil { return models.TestSetStatusFaultScript, fmt.Errorf("failed to execute post-script: %w", err) } } timeTaken := time.Since((startTime)) testCaseResults, err := r.reportDB.GetTestCaseResults(runTestSetCtx, testRunID, testSetID) if err != nil { if runTestSetCtx.Err() != context.Canceled { utils.LogError(r.logger, err, "failed to get test case results") testSetStatus = models.TestSetStatusInternalErr } } // Checking errors for final iteration // Checking for errors in the loop if loopErr != nil && !errors.Is(loopErr, context.Canceled) { testSetStatus = models.TestSetStatusInternalErr } else { // Checking for errors in the mocking and application select { case <-exitLoopChan:
------------------

--- Chunk 38---
Function RunTestSet (part 18): testSetStatus = testSetStatusByErrChan default: } } testReport = &models.TestReport{ Version: models.GetVersion(), TestSet: testSetID, Status: string(testSetStatus), Total: testCasesCount, Success: success, Failure: failure, Ignored: ignored, Tests: testCaseResults, } // final report should have reason for sudden stop of the test run so this should get canceled reportCtx := context.WithoutCancel(runTestSetCtx) err = r.reportDB.InsertReport(reportCtx, testRunID, testSetID, testReport) if err != nil { utils.LogError(r.logger, err, "failed to insert report") return models.TestSetStatusInternalErr, fmt.Errorf("failed to insert report") } err = utils.AddToGitIgnore(r.logger, r.config.Path, "/reports/") if err != nil { utils.LogError(r.logger, err, "failed to create .gitignore file") } // remove the unused mocks by the test cases of a testset (if the base path is not provided ) if r.config.Test.RemoveUnusedMocks && testSetStatus
------------------

--- Chunk 39---
Function RunTestSet (part 19): == models.TestSetStatusPassed && r.instrument { r.logger.Debug("consumed mocks from the completed testset", zap.Any("for test-set", testSetID), zap.Any("consumed mocks", totalConsumedMocks)) // delete the unused mocks from the data store r.logger.Info("deleting unused mocks from the data store", zap.Any("for test-set", testSetID)) err = r.mockDB.UpdateMocks(runTestSetCtx, testSetID, totalConsumedMocks) if err != nil { utils.LogError(r.logger, err, "failed to delete unused mocks") } } // TODO Need to decide on whether to use global variable or not verdict := TestReportVerdict{ total: testReport.Total, failed: testReport.Failure, passed: testReport.Success, ignored: testReport.Ignored, status: testSetStatus == models.TestSetStatusPassed, duration: timeTaken, } completeTestReport[testSetID] = verdict totalTests += testReport.Total totalTestPassed += testReport.Success totalTestFailed += testReport.Failure totalTestIgnored += testReport
------------------

--- Chunk 40---
Function RunTestSet (part 20): .Ignored totalTestTimeTaken += timeTaken timeTakenStr := timeWithUnits(timeTaken) if testSetStatus == models.TestSetStatusFailed || testSetStatus == models.TestSetStatusPassed { if testSetStatus == models.TestSetStatusFailed { pp.SetColorScheme(models.GetFailingColorScheme()) } else { pp.SetColorScheme(models.GetPassingColorScheme()) } if testReport.Ignored > 0 { if _, err := pp.Printf("\n <=========================================> \n TESTRUN SUMMARY. For test-set: %s\n"+"\tTotal tests: %s\n"+"\tTotal test passed: %s\n"+"\tTotal test failed: %s\n"+"\tTotal test ignored: %s\n"+"\tTime Taken: %s\n <=========================================> \n\n", testReport.TestSet, testReport.Total, testReport.Success, testReport.Failure, testReport.Ignored, timeTakenStr); err != nil { utils.LogError(r.logger, err, "failed to print testrun summary") } } else { if _, err := pp.Printf("\n <=========================================> \n TESTRUN SUMMARY.
------------------

--- Chunk 41---
Function RunTestSet (part 21): For test-set: %s\n"+"\tTotal tests: %s\n"+"\tTotal test passed: %s\n"+"\tTotal test failed: %s\n"+"\tTime Taken: %s\n <=========================================> \n\n", testReport.TestSet, testReport.Total, testReport.Success, testReport.Failure, timeTakenStr); err != nil { utils.LogError(r.logger, err, "failed to print testrun summary") } } } r.telemetry.TestSetRun(testReport.Success, testReport.Failure, testSetID, string(testSetStatus)) if r.config.Test.UpdateTemplate || r.config.Test.BasePath != "" { utils.RemoveDoubleQuotes(utils.TemplatizedValues) // Write the templatized values to the yaml. if len(utils.TemplatizedValues) > 0 { err = r.testSetConf.Write(ctx, testSetID, &models.TestSet{ PreScript: conf.PreScript, PostScript: conf.PostScript, Template: utils.TemplatizedValues, }) if err != nil { utils.LogError(r.logger, err, "failed to write the templatized values to the yaml
------------------

--- Chunk 42---
Function RunTestSet (end): ") } } } return testSetStatus, nil }
------------------

--- Chunk 43---
func (r *Replayer) GetMocks(ctx context.Context, testSetID string, afterTime time.Time, beforeTime time.Time) (filtered, unfiltered []*models.Mock, err error) { filtered, err = r.mockDB.GetFilteredMocks(ctx, testSetID, afterTime, beforeTime) if err != nil { utils.LogError(r.logger, err, "failed to get filtered mocks") return nil, nil, err } unfiltered, err = r.mockDB.GetUnFilteredMocks(ctx, testSetID, afterTime, beforeTime) if err != nil { utils.LogError(r.logger, err, "failed to get unfiltered mocks") return nil, nil, err } return filtered, unfiltered, err }
------------------

--- Chunk 44---
Function FilterAndSetMocks (start): func (r *Replayer) FilterAndSetMocks(ctx context.Context, appID uint64, filtered, unfiltered []*models.Mock, afterTime, beforeTime time.Time, totalConsumedMocks map[string]models.MockState) error { if !r.instrument { r.logger.Debug("Keploy will not filter and set mocks when base path is provided", zap.Any("base path", r.config.Test.BasePath)) return nil } filtered = pkg.FilterTcsMocks(ctx, r.logger, filtered, afterTime, beforeTime) unfiltered = pkg.FilterConfigMocks(ctx, r.logger, unfiltered, afterTime, beforeTime) filterOutDeleted := func(in []*models.Mock) []*models.Mock { out := make([]*models.Mock, 0, len(in)) for _, m := range in { // treat empty/missing names as never consumed if m == nil || m.Name == "" { out = append(out, m) continue } // we are picking mocks that are not consumed till now (not present in map), // and, mocks that are updated. if k, ok := totalConsumedMocks[m.Name]; !ok || k.Usage != models
------------------

--- Chunk 45---
Function FilterAndSetMocks (end): .Deleted { if ok { m.TestModeInfo.IsFiltered = k.IsFiltered m.TestModeInfo.SortOrder = k.SortOrder } out = append(out, m) } } return out } filtered = filterOutDeleted(filtered) unfiltered = filterOutDeleted(unfiltered) err := r.instrumentation.SetMocks(ctx, appID, filtered, unfiltered) if err != nil { utils.LogError(r.logger, err, "failed to set mocks") return err } return nil }
------------------

--- Chunk 46---
func (r *Replayer) GetTestSetStatus(ctx context.Context, testRunID string, testSetID string) (models.TestSetStatus, error) { testReport, err := r.reportDB.GetReport(ctx, testRunID, testSetID) if err != nil { return models.TestSetStatusFailed, fmt.Errorf("failed to get report: %w", err) } status, err := models.StringToTestSetStatus(testReport.Status) if err != nil { return models.TestSetStatusFailed, fmt.Errorf("failed to convert string to test set status: %w", err) } return status, nil }
------------------

--- Chunk 47---
func (r *Replayer) compareHTTPResp(tc *models.TestCase, actualResponse *models.HTTPResp, testSetID string) (bool, *models.Result) { noiseConfig := r.config.Test.GlobalNoise.Global if tsNoise, ok := r.config.Test.GlobalNoise.Testsets[testSetID]; ok { noiseConfig = LeftJoinNoise(r.config.Test.GlobalNoise.Global, tsNoise) } return httpMatcher.Match(tc, actualResponse, noiseConfig, r.config.Test.IgnoreOrdering, r.logger) }
------------------

--- Chunk 48---
func (r *Replayer) compareGRPCResp(tc *models.TestCase, actualResp *models.GrpcResp, testSetID string) (bool, *models.Result) { noiseConfig := r.config.Test.GlobalNoise.Global if tsNoise, ok := r.config.Test.GlobalNoise.Testsets[testSetID]; ok { noiseConfig = LeftJoinNoise(r.config.Test.GlobalNoise.Global, tsNoise) } return grpcMatcher.Match(tc, actualResp, noiseConfig, r.logger) }
------------------

--- Chunk 49---
Function printSummary (start): func (r *Replayer) printSummary(_ context.Context, _ bool) { if totalTests > 0 { testSuiteNames := make([]string, 0, len(completeTestReport)) for testSuiteName := range completeTestReport { testSuiteNames = append(testSuiteNames, testSuiteName) } sort.SliceStable(testSuiteNames, func(i, j int) bool { testSuitePartsI := strings.Split(testSuiteNames[i], "-") testSuitePartsJ := strings.Split(testSuiteNames[j], "-") if len(testSuitePartsI) < 3 || len(testSuitePartsJ) < 3 { return testSuiteNames[i] < testSuiteNames[j] } testSuiteIDNumberI, err1 := strconv.Atoi(testSuitePartsI[2]) testSuiteIDNumberJ, err2 := strconv.Atoi(testSuitePartsJ[2]) if err1 != nil || err2 != nil { return false } return testSuiteIDNumberI < testSuiteIDNumberJ }) totalTestTimeTakenStr := timeWithUnits(totalTestTimeTaken) if totalTestIgnored > 0 { if
------------------

--- Chunk 50---
Function printSummary (part 2): _, err := pp.Printf("\n <=========================================> \n COMPLETE TESTRUN SUMMARY. \n\tTotal tests: %s\n"+"\tTotal test passed: %s\n"+"\tTotal test failed: %s\n"+"\tTotal test ignored: %s\n"+"\tTotal time taken: %s\n", totalTests, totalTestPassed, totalTestFailed, totalTestIgnored, totalTestTimeTakenStr); err != nil { utils.LogError(r.logger, err, "failed to print test run summary") return } } else { if _, err := pp.Printf("\n <=========================================> \n COMPLETE TESTRUN SUMMARY. \n\tTotal tests: %s\n"+"\tTotal test passed: %s\n"+"\tTotal test failed: %s\n"+"\tTotal time taken: %s\n", totalTests, totalTestPassed, totalTestFailed, totalTestTimeTakenStr); err != nil { utils.LogError(r.logger, err, "failed to print test run summary") return } } header := "\n\tTest Suite Name\t\tTotal Test\tPassed\t\tFailed" if totalTestIgnored >
------------------

--- Chunk 51---
Function printSummary (part 3): 0 { header += "\t\tIgnored" } header += "\t\tTime Taken" if totalTestFailed > 0 { header += "\tFailed Testcases" } header += "\t\n" _, err := pp.Printf(header) if err != nil { utils.LogError(r.logger, err, "failed to print test suite summary header") return } for _, testSuiteName := range testSuiteNames { report := completeTestReport[testSuiteName] if report.status { pp.SetColorScheme(models.GetPassingColorScheme()) } else { pp.SetColorScheme(models.GetFailingColorScheme()) } testSetTimeTakenStr := timeWithUnits(report.duration) var format strings.Builder args := []interface{}{} // Using a more dynamic way to build format string and arguments // to ensure correct tabbing and conditional column format.WriteString("\n\t%s\t\t%s\t\t%s\t\t%s") args = append(args, testSuiteName, report.total, report.passed, report.failed) if totalTestIgnored > 0 && !r.config.Test.MustPass {
------------------

--- Chunk 52---
Function printSummary (end): format.WriteString("\t\t%s") args = append(args, report.ignored) } format.WriteString("\t\t%s") // Time Taken args = append(args, testSetTimeTakenStr) if totalTestFailed > 0 && !r.config.Test.MustPass { failedCasesStr := "-" if failedCases, ok := failedTCsBySetID[testSuiteName]; ok && len(failedCases) > 0 { failedCasesStr = strings.Join(failedCases, ", ") } format.WriteString("\t%s") args = append(args, failedCasesStr) } if _, err := pp.Printf(format.String(), args...); err != nil { utils.LogError(r.logger, err, "failed to print test suite details") return } } if _, err := pp.Printf("\n<=========================================> \n\n"); err != nil { utils.LogError(r.logger, err, "failed to print separator") return } } }
------------------

--- Chunk 53---
func (r *Replayer) RunApplication(ctx context.Context, appID uint64, opts models.RunOptions) models.AppError { return r.instrumentation.Run(ctx, appID, opts) }
------------------

--- Chunk 54---
func (r *Replayer) GetTestSetConf(ctx context.Context, testSet string) (*models.TestSet, error) { return r.testSetConf.Read(ctx, testSet) }
------------------

--- Chunk 55---
func (r *Replayer) DenoiseTestCases(ctx context.Context, testSetID string, noiseParams []*models.NoiseParams) ([]*models.NoiseParams, error) { testCases, err := r.testDB.GetTestCases(ctx, testSetID) if err != nil { return nil, fmt.Errorf("failed to get test cases: %w", err) } for _, v := range testCases { for _, noiseParam := range noiseParams { if v.Name == noiseParam.TestCaseID { // append the noise map if noiseParam.Ops == string(models.OpsAdd) { v.Noise = mergeMaps(v.Noise, noiseParam.Assertion) } else { // remove from the original noise map v.Noise = removeFromMap(v.Noise, noiseParam.Assertion) } err = r.testDB.UpdateTestCase(ctx, v, testSetID, true) if err != nil { return nil, fmt.Errorf("failed to update test case: %w", err) } noiseParam.AfterNoise = v.Noise } } } return noiseParams, nil }
------------------

--- Chunk 56---
Function Normalize (start): func (r *Replayer) Normalize(ctx context.Context) error { var testRun string if r.config.Normalize.TestRun == "" { testRunIDs, err := r.reportDB.GetAllTestRunIDs(ctx) if err != nil { if errors.Is(err, context.Canceled) { return err } return fmt.Errorf("failed to get all test run ids: %w", err) } testRun = pkg.LastID(testRunIDs, models.TestRunTemplateName) } if len(r.config.Normalize.SelectedTests) == 0 { testSetIDs, err := r.testDB.GetAllTestSetIDs(ctx) if err != nil { if errors.Is(err, context.Canceled) { return err } return fmt.Errorf("failed to get all test set ids: %w", err) } for _, testSetID := range testSetIDs { r.config.Normalize.SelectedTests = append(r.config.Normalize.SelectedTests, config.SelectedTests{TestSet: testSetID}) } } for _, testSet := range r.config.Normalize.SelectedTests { testSetID := testSet.TestSet testCases := testSet.Tests err := r
------------------

--- Chunk 57---
Function Normalize (end): .NormalizeTestCases(ctx, testRun, testSetID, testCases, nil) if err != nil { return err } } r.logger.Info("Normalized test cases successfully. Please run keploy tests to verify the changes.") return nil }
------------------

--- Chunk 58---
Function NormalizeTestCases (start): func (r *Replayer) NormalizeTestCases(ctx context.Context, testRun string, testSetID string, selectedTestCaseIDs []string, testCaseResults []models.TestResult) error { if len(testCaseResults) == 0 { testReport, err := r.reportDB.GetReport(ctx, testRun, testSetID) if err != nil { return fmt.Errorf("failed to get test report: %w", err) } testCaseResults = testReport.Tests } testCaseResultMap := make(map[string]models.TestResult) testCases, err := r.testDB.GetTestCases(ctx, testSetID) if err != nil { return fmt.Errorf("failed to get test cases: %w", err) } selectedTestCases := make([]*models.TestCase, 0, len(selectedTestCaseIDs)) if len(selectedTestCaseIDs) == 0 { selectedTestCases = testCases } else { for _, testCase := range testCases { if _, ok := matcherUtils.ArrayToMap(selectedTestCaseIDs)[testCase.Name]; ok { selectedTestCases = append(selectedTestCases, testCase) } } } for _, testCaseResult := range testCaseResults { testCase
------------------

--- Chunk 59---
Function NormalizeTestCases (end): ResultMap[testCaseResult.TestCaseID] = testCaseResult } for _, testCase := range selectedTestCases { if _, ok := testCaseResultMap[testCase.Name]; !ok { r.logger.Info("test case not found in the test report", zap.String("test-case-id", testCase.Name), zap.String("test-set-id", testSetID)) continue } if testCaseResultMap[testCase.Name].Status == models.TestStatusPassed { continue } testCase.HTTPResp = testCaseResultMap[testCase.Name].Res err = r.testDB.UpdateTestCase(ctx, testCase, testSetID, true) if err != nil { return fmt.Errorf("failed to update test case: %w", err) } } return nil }
------------------

--- Chunk 60---
func (r *Replayer) executeScript(ctx context.Context, script string) error { if script == "" { return nil } // Define the function to cancel the command cmdCancel := func(cmd *exec.Cmd) func() error { return func() error { return utils.InterruptProcessTree(r.logger, cmd.Process.Pid, syscall.SIGINT) } } cmdErr := utils.ExecuteCommand(ctx, r.logger, script, cmdCancel, 25*time.Second) if cmdErr.Err != nil { return fmt.Errorf("failed to execute script: %w", cmdErr.Err) } return nil }
------------------

--- Chunk 61---
func (r *Replayer) DeleteTestSet(ctx context.Context, testSetID string) error { return r.testDB.DeleteTestSet(ctx, testSetID) }
------------------

--- Chunk 62---
func (r *Replayer) DeleteTests(ctx context.Context, testSetID string, testCaseIDs []string) error { return r.testDB.DeleteTests(ctx, testSetID, testCaseIDs) }
------------------

--- Chunk 63---
func SetTestHooks(testHooks TestHooks) { HookImpl = testHooks }
------------------

--- Chunk 64---
Function CreateFailedTestResult (start): func (r *Replayer) CreateFailedTestResult(testCase *models.TestCase, testSetID string, started time.Time, errorMessage string) *models.TestResult { testCaseResult := &models.TestResult{ Kind: testCase.Kind, Name: testSetID, Status: models.TestStatusFailed, Started: started.Unix(), Completed: time.Now().UTC().Unix(), TestCaseID: testCase.Name, TestCasePath: filepath.Join(r.config.Path, testSetID), MockPath: filepath.Join(r.config.Path, testSetID, "mocks.yaml"), Noise: testCase.Noise, } var result *models.Result switch testCase.Kind { case models.HTTP: actualResponse := &models.HTTPResp{ StatusCode: 0, Header: make(map[string]string), Body: errorMessage, } _, result = r.compareHTTPResp(testCase, actualResponse, testSetID) testCaseResult.Req = models.HTTPReq{ Method: testCase.HTTPReq.Method, ProtoMajor: testCase.HTTPReq.ProtoMajor, ProtoMinor: testCase.HTTPReq.Proto
------------------

--- Chunk 65---
Function CreateFailedTestResult (part 2): Minor, URL: testCase.HTTPReq.URL, URLParams: testCase.HTTPReq.URLParams, Header: testCase.HTTPReq.Header, Body: testCase.HTTPReq.Body, Binary: testCase.HTTPReq.Binary, Form: testCase.HTTPReq.Form, Timestamp: testCase.HTTPReq.Timestamp, } testCaseResult.Res = *actualResponse case models.GRPC_EXPORT: actualResponse := &models.GrpcResp{ Headers: models.GrpcHeaders{ PseudoHeaders: make(map[string]string), OrdinaryHeaders: make(map[string]string), }, Body: models.GrpcLengthPrefixedMessage{ DecodedData: errorMessage, }, Trailers: models.GrpcHeaders{ PseudoHeaders: make(map[string]string), OrdinaryHeaders: make(map[string]string), }, } _, result = r.compareGRPCResp(testCase, actualResponse, testSetID) testCaseResult.GrpcReq = testCase.GrpcReq testCaseResult.GrpcRes = *actualResponse } if result != nil { testCaseResult.Result = *result
------------------

--- Chunk 66---
Function CreateFailedTestResult (end): } return testCaseResult }
------------------

--- Chunk 67---
func (r *Replayer) replaceHostInTestCase(testCase *models.TestCase, newHost, logContext string) error { var err error switch testCase.Kind { case models.HTTP: testCase.HTTPReq.URL, err = utils.ReplaceHost(testCase.HTTPReq.URL, newHost) if err != nil { utils.LogError(r.logger, err, fmt.Sprintf("failed to replace host to %s", logContext)) return err } r.logger.Debug("", zap.Any(fmt.Sprintf("replaced %s", logContext), testCase.HTTPReq.URL)) case models.GRPC_EXPORT: testCase.GrpcReq.Headers.PseudoHeaders[":authority"], err = utils.ReplaceGrpcHost(testCase.GrpcReq.Headers.PseudoHeaders[":authority"], newHost) if err != nil { utils.LogError(r.logger, err, fmt.Sprintf("failed to replace host to %s", logContext)) return err } r.logger.Debug("", zap.Any(fmt.Sprintf("replaced %s", logContext), testCase.GrpcReq.Headers.PseudoHeaders[":authority"])) } return nil }
------------------

--- Chunk 68---
func (r *Replayer) replacePortInTestCase(testCase *models.TestCase, newPort string) error { var err error switch testCase.Kind { case models.HTTP: testCase.HTTPReq.URL, err = utils.ReplacePort(testCase.HTTPReq.URL, newPort) case models.GRPC_EXPORT: testCase.GrpcReq.Headers.PseudoHeaders[":authority"], err = utils.ReplaceGrpcPort(testCase.GrpcReq.Headers.PseudoHeaders[":authority"], newPort) } if err != nil { utils.LogError(r.logger, err, "failed to replace port") return err } return nil }
------------------

--- Chunk 69---
func (r *Replayer) GetSelectedTestSets(ctx context.Context) ([]string, error) { // get all the testset ids testSetIDs, err := r.testDB.GetAllTestSetIDs(ctx) if err != nil { if errors.Is(err, context.Canceled) { return nil, err } utils.LogError(r.logger, err, "failed to get all test set ids") return nil, fmt.Errorf("mocks downloading failed to due to error in getting test set ids") } var testSets []string for _, testSetID := range testSetIDs { if _, ok := r.config.Test.SelectedTests[testSetID]; !ok && len(r.config.Test.SelectedTests) != 0 { continue } testSets = append(testSets, testSetID) } if len(testSets) == 0 { testSets = testSetIDs } // Sort the testsets. natsort.Sort(testSets) return testSets, nil }
------------------

--- Chunk 70---
func (r *Replayer) authenticateUser(ctx context.Context) error { //authenticate the user token, err := r.auth.GetToken(ctx) if err != nil { r.logger.Error("Failed to Authenticate user", zap.Error(err)) r.logger.Warn("Looks like you haven't logged in, skipping mock upload/download") r.logger.Warn("Please login using `keploy login` to perform mock upload/download action") return fmt.Errorf("mocks downloading failed to due to authentication error") } r.mock.setToken(token) return nil }
------------------

--- Chunk 71---
func (r *Replayer) DownloadMocks(ctx context.Context) error { // Authenticate the user for mock registry err := r.authenticateUser(ctx) if err != nil { return err } testSets, err := r.GetSelectedTestSets(ctx) if err != nil { utils.LogError(r.logger, err, "failed to get selected test sets") return fmt.Errorf("mocks downloading failed to due to error in getting selected test sets") } for _, testSetID := range testSets { r.logger.Info("Downloading mocks for the testset", zap.String("testset", testSetID)) err := r.mock.download(ctx, testSetID) if err != nil { if errors.Is(err, context.Canceled) { return err } utils.LogError(r.logger, err, "failed to download mocks", zap.Any("testset", testSetID)) continue } } return nil }
------------------

--- Chunk 72---
func (r *Replayer) UploadMocks(ctx context.Context) error { // Authenticate the user for mock registry err := r.authenticateUser(ctx) if err != nil { return err } testSets, err := r.GetSelectedTestSets(ctx) if err != nil { utils.LogError(r.logger, err, "failed to get selected test sets") return fmt.Errorf("mocks uploading failed to due to error in getting selected test sets") } for _, testSetID := range testSets { r.logger.Info("Uploading mocks for the testset", zap.String("testset", testSetID)) err := r.mock.upload(ctx, testSetID) if err != nil { if errors.Is(err, context.Canceled) { return err } utils.LogError(r.logger, err, "failed to upload mocks", zap.Any("testset", testSetID)) continue } } return nil }
------------------

--- File: pkg/service/replay/utils.go---

--- Chunk 1---
func LeftJoinNoise(globalNoise config.GlobalNoise, tsNoise config.GlobalNoise) config.GlobalNoise { noise := globalNoise if _, ok := noise["body"]; !ok { noise["body"] = make(map[string][]string) } if tsNoiseBody, ok := tsNoise["body"]; ok { for field, regexArr := range tsNoiseBody { noise["body"][field] = regexArr } } if _, ok := noise["header"]; !ok { noise["header"] = make(map[string][]string) } if tsNoiseHeader, ok := tsNoise["header"]; ok { for field, regexArr := range tsNoiseHeader { noise["header"][field] = regexArr } } return noise }
------------------

--- Chunk 2---
Function ReplaceBaseURL (start): func ReplaceBaseURL(newURL, oldURL string) (string, error) { parsedOldURL, err := url.Parse(oldURL) if err != nil { return "", fmt.Errorf("failed to parse the old URL: %v", err) } parsedNewURL, err := url.Parse(newURL) if err != nil { return "", fmt.Errorf("failed to parse the new URL: %v", err) } // if scheme is empty, then add the scheme from the old URL in order to parse it correctly if parsedNewURL.Scheme == "" { parsedNewURL.Scheme = parsedOldURL.Scheme parsedNewURL, err = url.Parse(parsedNewURL.String()) if err != nil { return "", fmt.Errorf("failed to parse the scheme added new URL: %v", err) } } parsedOldURL.Scheme = parsedNewURL.Scheme parsedOldURL.Host = parsedNewURL.Host apiPath := path.Join(parsedNewURL.Path, parsedOldURL.Path) parsedOldURL.Path = apiPath parsedOldURL.RawPath = apiPath replacedURL := parsedOldURL.String() decodedURL, err := url.PathUnescape(replaced
------------------

--- Chunk 3---
Function ReplaceBaseURL (end): URL) if err != nil { return "", fmt.Errorf("failed to decode the URL: %v", err) } return decodedURL, nil }
------------------

--- Chunk 4---
func mergeMaps(map1, map2 map[string][]string) map[string][]string { for key, values := range map2 { if _, exists := map1[key]; exists { map1[key] = append(map1[key], values...) } else { map1[key] = values } } return map1 }
------------------

--- Chunk 5---
func removeFromMap(map1, map2 map[string][]string) map[string][]string { for key := range map2 { delete(map1, key) } return map1 }
------------------

--- Chunk 6---
func timeWithUnits(duration time.Duration) string { if duration.Seconds() < 1 { return fmt.Sprintf("%v ms", duration.Milliseconds()) } else if duration.Minutes() < 1 { return fmt.Sprintf("%.2f s", duration.Seconds()) } else if duration.Hours() < 1 { return fmt.Sprintf("%.2f min", duration.Minutes()) } return fmt.Sprintf("%.2f hr", duration.Hours()) }
------------------

--- Chunk 7---
func getFailedTCs(results []models.TestResult) []string { ids := make([]string, 0, len(results)) for _, r := range results { if r.Status == models.TestStatusFailed { ids = append(ids, r.TestCaseID) } } return ids }
------------------

