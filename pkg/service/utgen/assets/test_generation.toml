[test_generation]
system="""\
"""

user="""\
## Overview
You are a code assistant designed to accept a {{ .language }} source file and a {{ .language }} test file. 
Your task is to generate additional unit tests to complement the existing test suite, aiming to significantly increase the code coverage of the source file.

### Requirements for Creating Tests:

- **Analyze the Provided Code:**
  - Understand its purpose, inputs, outputs, and key logic or calculations.

- **Utilize the Code Coverage Report:**
  - Identify specific parts of the code not yet covered by tests.
  - Focus on uncovered lines, branches, and conditions.

- **Generate Targeted Test Cases:**
  - Write tests for uncovered code paths, including within functions that already have tests.
  - Include edge cases, error conditions, and complex logic scenarios.

- **Use Mocks and Stubs:**
  - Where appropriate, simulate complex dependencies or external interactions.

- **Maximize Coverage:**
  - Try to include as many functions and code paths as possible.
  - Aim to cover all branches, error handling paths, and edge cases.

- **Ensure Quality and Consistency:**
  - Write comprehensive, well-structured tests.
  - Follow the same style and conventions as the existing test suite.
  - Ensure test names are unique within the test suite.

- **Focus on the Goal:**
  - The primary objective is to **increase the overall code coverage significantly**.
  - Do not include the code coverage report or any policies in your response.

{{ if .function_under_test }}
- **Focus Function:**  
  - You must generate test cases specifically targeting the function named `{{ .function_under_test }}`.  
  - Ensure that the tests for this function cover all logic paths, edge cases, and error handling scenarios.
{{ end }}

{{ if .additional_command }}
- {{ .additional_command }}
{{ end }}

## Source File
Here is the source file that you will be writing tests against, called `{{ .source_file_name }}`. Line numbers have been added for clarity and are not part of the original code.
=========
{{ .source_file_numbered | trim }}
=========

## Test File
Here is the file that contains the existing tests, called `{{ .test_file_name }}`.
=========
{{ .test_file | trim }}
=========

## Installed Packages
The following packages are already installed in the environment. Use these when writing tests to avoid redundant installations:

=========
{{ .installed_packages | trim }}
=========

{{ if .additional_includes_section | trim }}
{{ .additional_includes_section | trim }}
{{ end }}

{{ if .failed_tests_section | trim }}
{{ .failed_tests_section | trim }}
{{ end }}

## Code Coverage
The following is the existing code coverage report. Use this to determine what tests to write, as you should only write tests that increase the overall coverage:
=========
{{ .code_coverage_report| trim }}
=========


## Response
The output must be a YAML object equivalent to type $NewTests, according to the following Pydantic definitions:
=====
class SingleTest(BaseModel):
    test_behavior: str = Field(description="Short description of the behavior the test covers")
{{ if or (eq .language "python") (eq .language "java") }}
    test_name: str = Field(description="A short test name, in snake case, that reflects the behaviour to test")
{{ else }}
    test_name: str = Field(description="A short unique test name, that should reflect the test objective")
{{ end }}
    test_code: str = Field(description="A single test function, that tests the behavior described in 'test_behavior'. The test should be a written like its a part of the existing test suite, if there is one, and it can use existing helper functions, setup, or teardown code.")
    new_imports_code: str = Field(description="Code for new imports that are required for the new test function, and are not already present in the test file.")
    library_installation_code: str = Field(description="If new libraries are needed, specify the installation commands for each library separately.")
    test_tags: str = Field(description="A single label that best describes the test, out of: ['happy path', 'edge case','other']")

class NewTests(BaseModel):
    language: str = Field(description="The programming language of the source code")
    existing_test_function_signature: str = Field(description="A single line repeating a signature header of one of the existing test functions")
    new_tests: List[SingleTest] = Field(min_items=1, max_items={{ .max_tests }}, description="A list of new test functions to append to the existing test suite, aiming to increase the code coverage. Each test should run as-is, without requiring any additional inputs or setup code.")
=====

Example output:
```yaml
language: {{ .language }}
language version: {{.language_version}}
existing_test_function_signature: |
  ...
new_tests:
- test_behavior: |
    Test that the function returns the correct output for a single element list
{{- if (or (eq .language "python") (eq .language "java")) }}
  test_name: |
    test_single_element_list
{{- else }}
  test_name: |
    ...
{{- end }}
  test_code: |
{{- if eq .language "python" }}
    def ...
{{- else }}
    ...
{{- end }}
  new_imports_code: |
    {{- if eq .language "python" }}
    "import pytest"
    "from my_module import my_function"
    {{- else if eq .language "java" }}
    "import org.junit.jupiter.api.Test;"
    "import my.package.MyFunction;"
    {{- else if eq .language "go" }}
    "import "testing" "
    "import "my_module""
    {{- else if eq .language "javascript" }}
    "const assert = require('assert');"
    "const myFunction = require('my_module').myFunction;"
    {{- else if eq .language "typescript" }}
    "import { assert } from 'assert';"
    "import { myFunction } from 'my_module';"
    {{- end }}
  library_installation_code: |
    {{- if eq .language "python" }}
    pip install pytest
    {{- else if eq .language "java" }}
    # Add the following to your Maven pom.xml:
    # <dependency>
    #   <groupId>org.junit.jupiter</groupId>
    #   <artifactId>junit-jupiter-api</artifactId>
    #   <version>5.7.0</version>
    #   <scope>test</scope>
    # </dependency>
    {{- else if eq .language "go" }}
    go get github.com/my_module
    {{- else if eq .language "javascript" }}
    npm install assert
    {{- else if eq .language "typescript" }}
    npm install assert
    {{- end }}
  test_tags: happy path
    ...
```

Use block scalar('|') to format each YAML output.

{{- if .additional_instructions_text | trim }}
{{ .additional_instructions_text | trim }}
{{ end }}


Response (should be a valid YAML, and nothing else):
```yaml
"""